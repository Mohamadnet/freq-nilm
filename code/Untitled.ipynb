{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-08020822eb37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from dataloader import APPLIANCE_ORDER, get_train_test\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "cuda_av = False\n",
    "if torch.cuda.is_available():\n",
    "    cuda_av = True\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# num_hidden, num_iterations, num_layers, p, num_directions = sys.argv[1:6]\n",
    "\n",
    "\n",
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, num_layers, bidirectional):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        if bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "        if cell_type == \"RNN\":\n",
    "            self.rnn = nn.RNN(input_size=1, hidden_size=hidden_size,\n",
    "                              num_layers=num_layers, batch_first=True,\n",
    "                              bidirectional=bidirectional)\n",
    "        elif cell_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(input_size=1, hidden_size=hidden_size,\n",
    "                              num_layers=num_layers, batch_first=True,\n",
    "                              bidirectional=bidirectional)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(input_size=1, hidden_size=hidden_size,\n",
    "                               num_layers=num_layers, batch_first=True,\n",
    "                               bidirectional=bidirectional)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size * self.num_directions, 1)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred, hidden = self.rnn(x, None)\n",
    "        pred = self.linear(pred).view(pred.data.shape[0], -1, 1)\n",
    "        # pred = self.act(pred)\n",
    "        # pred = torch.clamp(pred, min=0.)\n",
    "        pred = self.act(pred)\n",
    "        pred = torch.min(pred, x)\n",
    "        return pred\n",
    "\n",
    "\n",
    "class AppliancesRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, num_layers, bidirectional, num_appliance):\n",
    "        super(AppliancesRNN, self).__init__()\n",
    "        self.num_appliance = num_appliance\n",
    "        self.preds = {}\n",
    "        self.order = ORDER\n",
    "        for appliance in range(self.num_appliance):\n",
    "            if cuda_av:\n",
    "                setattr(self, \"Appliance_\" + str(appliance), CustomRNN(cell_type,\n",
    "                                                                       hidden_size,\n",
    "                                                                       num_layers,\n",
    "                                                                       bidirectional).cuda())\n",
    "            else:\n",
    "                setattr(self, \"Appliance_\" + str(appliance), CustomRNN(cell_type,\n",
    "                                                                       hidden_size,\n",
    "                                                                       num_layers,\n",
    "                                                                       bidirectional))\n",
    "\n",
    "    def forward(self, *args):\n",
    "        agg_current = args[0]\n",
    "        flag = False\n",
    "        if np.random.random() > args[1]:\n",
    "            flag = True\n",
    "        # print(\"Subtracting prediction\")\n",
    "        else:\n",
    "            pass\n",
    "        # print(\"Subtracting true\")\n",
    "        for appliance in range(self.num_appliance):\n",
    "            # print(agg_current.mean().data[0])\n",
    "            # print appliance\n",
    "            # print self.order[appliance]\n",
    "            # print args[2+appliance]\n",
    "            #print(getattr(self, \"Appliance_\" + str(appliance)))\n",
    "            self.preds[appliance] = getattr(self, \"Appliance_\" + str(appliance))(agg_current)\n",
    "            if flag:\n",
    "                agg_current = agg_current - self.preds[appliance]\n",
    "            else:\n",
    "                agg_current = agg_current - args[2 + appliance]\n",
    "\n",
    "        return torch.cat([self.preds[a] for a in range(self.num_appliance)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataloader import APPLIANCE_ORDER, get_train_test\n",
    "train, test = get_train_test(num_folds=5, fold_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_aggregate = train[:, 0, :, :].reshape(-1, 24, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor = np.load('../2015-5appliances.numpy.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = tensor[:, 1:, :, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 870.54835262,   86.79575226,   66.9294258 ,   15.4395102 ,\n",
       "          9.09707779])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.mean(axis=3).mean(axis=2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 5, 112, 24)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83003428,  0.0827564 ,  0.06381463,  0.01472098,  0.00867371])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.sum(axis=3).sum(axis=2).sum(axis=0)/k.sum(axis=3).sum(axis=2).sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU 20 4 True 1.0 200\n",
      "GRU 20 4 True 1.0 400\n",
      "GRU 20 4 True 1.0 600\n",
      "GRU 20 4 True 1.0 800\n",
      "GRU 50 2 True 1.0 800\n",
      "GRU 50 4 True 1.0 200\n",
      "GRU 50 4 True 1.0 400\n",
      "GRU 50 4 True 1.0 600\n",
      "GRU 50 4 True 1.0 800\n",
      "GRU 100 2 True 1.0 200\n",
      "GRU 100 2 True 1.0 400\n",
      "GRU 100 2 True 1.0 600\n",
      "GRU 100 2 True 1.0 800\n",
      "GRU 100 4 True 1.0 200\n",
      "GRU 100 4 True 1.0 400\n",
      "GRU 100 4 True 1.0 600\n",
      "GRU 100 4 True 1.0 800\n",
      "LSTM 20 4 True 1.0 600\n",
      "LSTM 20 4 True 1.0 800\n",
      "LSTM 50 2 True 1.0 200\n",
      "LSTM 50 2 True 1.0 400\n",
      "LSTM 50 2 True 1.0 600\n",
      "LSTM 50 2 True 1.0 800\n",
      "LSTM 50 4 True 1.0 200\n",
      "LSTM 50 4 True 1.0 400\n",
      "LSTM 50 4 True 1.0 600\n",
      "LSTM 50 4 True 1.0 800\n",
      "LSTM 100 2 True 1.0 200\n",
      "LSTM 100 2 True 1.0 400\n",
      "LSTM 100 2 True 1.0 600\n",
      "LSTM 100 2 True 1.0 800\n",
      "LSTM 100 4 True 1.0 200\n",
      "LSTM 100 4 True 1.0 400\n",
      "LSTM 100 4 True 1.0 600\n",
      "LSTM 100 4 True 1.0 800\n",
      "RNN 20 4 True 1.0 800\n",
      "RNN 50 4 True 1.0 400\n",
      "RNN 50 4 True 1.0 600\n",
      "RNN 50 4 True 1.0 800\n",
      "RNN 100 2 True 1.0 800\n",
      "RNN 100 4 True 1.0 200\n",
      "RNN 100 4 True 1.0 400\n",
      "RNN 100 4 True 1.0 600\n",
      "RNN 100 4 True 1.0 800\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for cell_type in ['GRU', 'LSTM', 'RNN']:\n",
    "    result[cell_type] = {}\n",
    "    for hidden_size in [20, 50, 100]:\n",
    "        result[cell_type][hidden_size] = {}\n",
    "        for num_layers in [2,4]:\n",
    "            result[cell_type][hidden_size][num_layers] = {}\n",
    "            for bidirectional in [True]:\n",
    "                result[cell_type][hidden_size][num_layers][bidirectional] = {}\n",
    "                for lr in [1.0]:\n",
    "                    result[cell_type][hidden_size][num_layers][bidirectional][lr] = {}\n",
    "                    for iterations in [200, 400, 600, 800]:\n",
    "                        try:\n",
    "                            result[cell_type][hidden_size][num_layers][bidirectional][lr][iterations] = np.load(\"../../baseline/rnn-tree-greedy/{}-{}-{}-{}-{}-{}-0.0.npy\".format(cell_type, hidden_size, num_layers,bidirectional, lr, iterations))\n",
    "                        except:\n",
    "                            print (cell_type, hidden_size, num_layers,bidirectional, lr, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fridge hvac dw dr mw    {'mw': 9.09700017504, 'hvac': 157.325275074, '...\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(k.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fridge hvac dw dr mw\n"
     ]
    }
   ],
   "source": [
    "for key, v in k.item().items():\n",
    "    print (key)\n",
    "    df = (pd.Series(k.item()[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.218277583612178"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU 20 2 True 1.0 200 fridge hvac dr mw dw 87.8883687332\n",
      "GRU 20 2 True 1.0 400 fridge hvac dr mw dw 70.7448293607\n",
      "GRU 20 2 True 1.0 600 fridge hvac dr mw dw 63.8863365113\n",
      "GRU 20 2 True 1.0 800 fridge hvac dr mw dw 59.5332653231\n",
      "GRU 50 2 True 1.0 200 fridge hvac dw dr mw 85.5916375693\n",
      "GRU 50 2 True 1.0 400 fridge hvac dw dr mw 75.9527212211\n",
      "GRU 50 2 True 1.0 600 fridge hvac dw dr mw 73.8051532727\n",
      "LSTM 20 2 True 1.0 200 fridge hvac dr dw mw 50.9293867059\n",
      "LSTM 20 2 True 1.0 400 fridge hvac mw dw dr 45.9201925534\n",
      "LSTM 20 2 True 1.0 600 fridge hvac mw dw dr 45.2295050944\n",
      "LSTM 20 2 True 1.0 800 fridge hvac mw dw dr 45.0812698817\n",
      "LSTM 20 4 True 1.0 200 dr dw hvac fridge mw 209.762023734\n",
      "LSTM 20 4 True 1.0 400 dr dw hvac fridge mw 209.762023734\n",
      "RNN 20 2 True 1.0 200 fridge dr hvac dw mw 45.70670457\n",
      "RNN 20 2 True 1.0 400 fridge dw hvac mw dr 45.1265554654\n",
      "RNN 20 2 True 1.0 600 fridge hvac dw dr mw 45.2444659843\n",
      "RNN 20 2 True 1.0 800 fridge hvac dw dr mw 45.0487739834\n",
      "RNN 20 4 True 1.0 200 fridge hvac mw dw dr 48.5403501437\n",
      "RNN 20 4 True 1.0 400 fridge hvac mw dw dr 45.7065255652\n",
      "RNN 20 4 True 1.0 600 fridge hvac mw dw dr 45.3050634696\n",
      "RNN 50 2 True 1.0 200 fridge hvac mw dr dw 106.273353523\n",
      "RNN 50 2 True 1.0 400 fridge hvac dr mw dw 45.1702621886\n",
      "RNN 50 2 True 1.0 600 fridge hvac dr mw dw 45.1892651424\n",
      "RNN 50 2 True 1.0 800 fridge hvac dr mw dw 45.2462471434\n",
      "RNN 50 4 True 1.0 200 dw hvac dr fridge mw 139.81749773\n",
      "RNN 100 2 True 1.0 200 fridge hvac dr mw dw 90.4107714002\n",
      "RNN 100 2 True 1.0 400 fridge hvac dw dr mw 65.2625427718\n",
      "RNN 100 2 True 1.0 600 fridge hvac dw dr mw 65.2182775836\n"
     ]
    }
   ],
   "source": [
    "for cell_type in ['GRU', 'LSTM', 'RNN']:\n",
    "    for hidden_size in [20, 50, 100]:\n",
    "        for num_layers in [2,4]:\n",
    "            for bidirectional in [True]:\n",
    "                for lr in [1.0]:\n",
    "                    for iterations in [200, 400, 600, 800]:\n",
    "                        try:\n",
    "                            k = result[cell_type][hidden_size][num_layers][bidirectional][lr][iterations]\n",
    "#                             print (k)\n",
    "                            for key, v in k.item().items():\n",
    "                                df = (pd.Series(k.item()[key]))\n",
    "                            print (cell_type, hidden_size, num_layers,bidirectional, lr, iterations, key, df.mean())\n",
    "                        except:\n",
    "                            continue\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'fridge hvac dw dr mw': {'mw': 9.0970777913095713, 'hvac': 105.89336602885898, 'fridge': 28.494837124931699, 'dr': 66.31907802555186, 'dw': 15.439510946516529}}, dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['RNN'][20][2][True][1][800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def disagg_fold(fold_num, hidden_size, num_layers, bidirectional, lr, num_iterations, p):\n",
    "    # print (fold_num, hidden_size, num_layers, bidirectional, lr, num_iterations, p)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    train, test = get_train_test(num_folds=num_folds, fold_num=fold_num)\n",
    "    train_aggregate = train[:, 0, :, :].reshape(-1, 24, 1)\n",
    "    test_aggregate = test[:, 0, :, :].reshape(-1, 24, 1)\n",
    "\n",
    "    out_train = [None for temp in range(len(ORDER))]\n",
    "    for a_num, appliance in enumerate(ORDER):\n",
    "        out_train[a_num] = Variable(\n",
    "            torch.Tensor(train[:, APPLIANCE_ORDER.index(appliance), :, :].reshape((train_aggregate.shape[0], -1, 1))))\n",
    "        if cuda_av:\n",
    "            out_train[a_num] = out_train[a_num].cuda()\n",
    "\n",
    "    loss_func = nn.L1Loss()\n",
    "    a = AppliancesRNN(cell_type, hidden_size, num_layers, bidirectional, len(ORDER))\n",
    "    #print(a)\n",
    "    if cuda_av:\n",
    "        a = a.cuda()\n",
    "        loss_func = loss_func.cuda()\n",
    "    optimizer = torch.optim.Adam(a.parameters(), lr=lr)\n",
    "\n",
    "    inp = Variable(torch.Tensor(train_aggregate.reshape((train_aggregate.shape[0], -1, 1))).type(torch.FloatTensor),\n",
    "                   requires_grad=True)\n",
    "    for t in range(num_iterations):\n",
    "        inp = Variable(torch.Tensor(train_aggregate), requires_grad=True)\n",
    "        out = torch.cat([out_train[appliance_num] for appliance_num, appliance in enumerate(ORDER)])\n",
    "        if cuda_av:\n",
    "            inp = inp.cuda()\n",
    "            out = out.cuda()\n",
    "\n",
    "        params = [inp, p]\n",
    "        for a_num, appliance in enumerate(ORDER):\n",
    "            params.append(out_train[a_num])\n",
    "        # print(params)\n",
    "        pred = a(*params)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_func(pred, out)\n",
    "        if t % 1 == 0:\n",
    "            print(t, loss.data[0])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_inp = Variable(torch.Tensor(test_aggregate), requires_grad=False)\n",
    "    if cuda_av:\n",
    "        test_inp = test_inp.cuda()\n",
    "\n",
    "    params = [test_inp, -2]\n",
    "    for i in range(len(ORDER)):\n",
    "        params.append(None)\n",
    "    pr = a(*params)\n",
    "    pr = torch.clamp(pr, min=0.)\n",
    "    test_pred = torch.split(pr, test_aggregate.shape[0])\n",
    "    prediction_fold = [None for x in range(len(ORDER))]\n",
    "\n",
    "    if cuda_av:\n",
    "        for appliance_num, appliance in enumerate(ORDER):\n",
    "            prediction_fold[appliance_num] = test_pred[appliance_num].cpu().data.numpy().reshape(-1, 24)\n",
    "    else:\n",
    "        for appliance_num, appliance in enumerate(ORDER):\n",
    "            prediction_fold[appliance_num] = test_pred[appliance_num].data.numpy().reshape(-1, 24)\n",
    "    gt_fold = [None for x in range(len(ORDER))]\n",
    "    for appliance_num, appliance in enumerate(ORDER):\n",
    "        gt_fold[appliance_num] = test[:, APPLIANCE_ORDER.index(appliance), :, :].reshape(test_aggregate.shape[0], -1,\n",
    "                                                                                         1).reshape(-1, 24)\n",
    "\n",
    "    return prediction_fold, gt_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def disagg(hidden_size, num_layers, bidirectional, lr, num_iterations, p):\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    preds = {}\n",
    "    gts = {}\n",
    "\n",
    "    for appliance_num, appliance in enumerate(ORDER):\n",
    "        preds[appliance] = []\n",
    "        gts[appliance] = []\n",
    "\n",
    "    for cur_fold in range(num_folds):\n",
    "        print (cur_fold, hidden_size, num_layers, bidirectional, lr, num_iterations, p)\n",
    "        pred, gt = disagg_fold(cur_fold, hidden_size, num_layers, bidirectional, lr, num_iterations, p)\n",
    "        # pred[pred<0.] = 0.\n",
    "        for appliance_num, appliance in enumerate(ORDER):\n",
    "                preds[appliance].append(pred[appliance_num])\n",
    "                gts[appliance].append(gt[appliance_num])\n",
    "    for appliance in ORDER:\n",
    "        print (appliance, mean_absolute_error(np.concatenate(gts[appliance]).flatten(), np.concatenate(preds[appliance]).flatten()))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
