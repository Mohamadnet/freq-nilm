{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "from common import APPLIANCES_ORDER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor = np.load('../1H-input.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_subset_dataset(tensor):\n",
    "    t_subset = tensor[:, :, 180:194, :]\n",
    "    all_indices = np.array(list(range(320)))\n",
    "    for i in range(1, 7):\n",
    "        valid_homes = pd.DataFrame(t_subset[:, i, :].reshape(320, 14*24)).dropna().index\n",
    "        all_indices = np.intersect1d(all_indices, valid_homes)\n",
    "    t_subset = t_subset[all_indices, :, :, :].reshape(52, 7, 14, 24)\n",
    "    \n",
    "    # Create artificial aggregate\n",
    "    t_subset[:, 0, :,:] = 0.0\n",
    "    for i in range(1, 7):\n",
    "        t_subset[:, 0, :,:] = t_subset[:, 0, :,:] + t_subset[:, i, :,:]\n",
    "    # t_subset is of shape (#home, appliance, days*hours)\n",
    "    return t_subset, all_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 7, 14, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all, valid_homes = create_subset_dataset(tensor)\n",
    "t_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 7, 14, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_objective(y_pred, y_true):\n",
    "    with tf.name_scope(None):\n",
    "        return tf.losses.absolute_difference(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/nipun/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import Conv1D, Dense, Flatten, MaxPool1D, InputLayer, Activation, Dropout, MaxPooling1D\n",
    "\n",
    "\n",
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "n_movies = 3\n",
    "n_users=3\n",
    "n_latent_factors=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggregate', 'hvac', 'fridge', 'mw', 'dw', 'wm', 'oven']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPLIANCES_ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a2603c1d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAADeCAYAAACpOd4EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc871G/8L5IwZsDi4QXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d917f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(6,3))\n",
    "cbar_ax = fig.add_axes([.95, 0.15, .02, .7])\n",
    "home = 4\n",
    "appliance_num = 2\n",
    "sns.heatmap(t_all[home, 0, :, :],cmap='Greens',ax=ax[0],cbar_ax=None,cbar=False)\n",
    "sns.heatmap(t_all[home, appliance_num, :, :],cmap='Greens',ax=ax[1],cbar_ax=cbar_ax,vmax=t_all[home, 0, :, :].max())\n",
    "ax[0].set_title(\"Aggregate\")\n",
    "ax[1].set_title(APPLIANCES_ORDER[appliance_num])\n",
    "ax[0].set_ylabel(\"Day\")\n",
    "fig.text(0.5, 0, \"Hour of day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a262e2828>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAADeCAYAAACpOd4EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny0yS6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25ffa860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(6,3))\n",
    "cbar_ax = fig.add_axes([.95, 0.15, .02, .7])\n",
    "home = 4\n",
    "appliance_num = 2\n",
    "sns.heatmap(t_all[home, 0, :, :]-t_all[home, 1, :, :],cmap='Greens',ax=ax[0],cbar_ax=None,cbar=False)\n",
    "sns.heatmap(t_all[home, appliance_num, :, :],cmap='Greens',ax=ax[1],cbar_ax=cbar_ax,vmax=(t_all[home, 0, :, :]-t_all[home, 1, :, :]).max())\n",
    "ax[0].set_title(\"Aggregate\")\n",
    "ax[1].set_title(APPLIANCES_ORDER[appliance_num])\n",
    "ax[0].set_ylabel(\"Day\")\n",
    "fig.text(0.5, 0, \"Hour of day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_days = 14\n",
    "num_hours = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(num_days, num_hours, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(4, (14, 1), activation='relu', padding='same')(input_img)\n",
    "#x = Conv2D(10, (1, 2), activation='relu', padding='same')(input_img)\n",
    "\n",
    "\n",
    "#x = MaxPooling2D((1, 2), padding='same')(x)\n",
    "#x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "#x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "#encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "#x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "#x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "#x = Conv2D(16, (3, 3), activation='relu',padding='same')(x)\n",
    "#x = UpSampling2D((1, 2))(x)\n",
    "decoded = Conv2D(1, (1,24), activation='relu', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 14, 24, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 24, 4)         60        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 24, 1)         97        \n",
      "=================================================================\n",
      "Total params: 157\n",
      "Trainable params: 157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fridge\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "appliance_num=2\n",
    "print(APPLIANCES_ORDER[appliance_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxs = {appliance_num:t_all[:30, appliance_num, :, :].max() for appliance_num in range(7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5000.416633605957,\n",
       " 1: 3963.88330078125,\n",
       " 2: 288.85000610351562,\n",
       " 3: 960.7833251953125,\n",
       " 4: 1122.300048828125,\n",
       " 5: 498.43331909179688,\n",
       " 6: 2914.800048828125}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 3 samples\n",
      "Epoch 1/1500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.2908 - val_loss: 0.3183\n",
      "Epoch 2/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.2881 - val_loss: 0.3153\n",
      "Epoch 3/1500\n",
      "27/27 [==============================] - 0s 561us/step - loss: 0.2851 - val_loss: 0.3121\n",
      "Epoch 4/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.2820 - val_loss: 0.3088\n",
      "Epoch 5/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.2788 - val_loss: 0.3054\n",
      "Epoch 6/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.2755 - val_loss: 0.3018\n",
      "Epoch 7/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.2720 - val_loss: 0.2981\n",
      "Epoch 8/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.2684 - val_loss: 0.2943\n",
      "Epoch 9/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.2648 - val_loss: 0.2903\n",
      "Epoch 10/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.2609 - val_loss: 0.2862\n",
      "Epoch 11/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.2570 - val_loss: 0.2820\n",
      "Epoch 12/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.2529 - val_loss: 0.2776\n",
      "Epoch 13/1500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.2487 - val_loss: 0.2731\n",
      "Epoch 14/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.2444 - val_loss: 0.2684\n",
      "Epoch 15/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.2398 - val_loss: 0.2636\n",
      "Epoch 16/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.2351 - val_loss: 0.2586\n",
      "Epoch 17/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.2302 - val_loss: 0.2534\n",
      "Epoch 18/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.2252 - val_loss: 0.2482\n",
      "Epoch 19/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.2199 - val_loss: 0.2427\n",
      "Epoch 20/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.2145 - val_loss: 0.2371\n",
      "Epoch 21/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.2088 - val_loss: 0.2313\n",
      "Epoch 22/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.2030 - val_loss: 0.2254\n",
      "Epoch 23/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.1969 - val_loss: 0.2193\n",
      "Epoch 24/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.1907 - val_loss: 0.2132\n",
      "Epoch 25/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.1843 - val_loss: 0.2069\n",
      "Epoch 26/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.1777 - val_loss: 0.2004\n",
      "Epoch 27/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.1710 - val_loss: 0.1939\n",
      "Epoch 28/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.1642 - val_loss: 0.1873\n",
      "Epoch 29/1500\n",
      "27/27 [==============================] - 0s 493us/step - loss: 0.1573 - val_loss: 0.1808\n",
      "Epoch 30/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.1505 - val_loss: 0.1743\n",
      "Epoch 31/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.1437 - val_loss: 0.1680\n",
      "Epoch 32/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.1370 - val_loss: 0.1618\n",
      "Epoch 33/1500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.1306 - val_loss: 0.1560\n",
      "Epoch 34/1500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.1245 - val_loss: 0.1504\n",
      "Epoch 35/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.1190 - val_loss: 0.1453\n",
      "Epoch 36/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.1141 - val_loss: 0.1406\n",
      "Epoch 37/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.1099 - val_loss: 0.1364\n",
      "Epoch 38/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.1064 - val_loss: 0.1326\n",
      "Epoch 39/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.1037 - val_loss: 0.1291\n",
      "Epoch 40/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.1015 - val_loss: 0.1262\n",
      "Epoch 41/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0999 - val_loss: 0.1237\n",
      "Epoch 42/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0989 - val_loss: 0.1215\n",
      "Epoch 43/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0984 - val_loss: 0.1198\n",
      "Epoch 44/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0983 - val_loss: 0.1186\n",
      "Epoch 45/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0984 - val_loss: 0.1178\n",
      "Epoch 46/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0988 - val_loss: 0.1173\n",
      "Epoch 47/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0993 - val_loss: 0.1170\n",
      "Epoch 48/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0999 - val_loss: 0.1168\n",
      "Epoch 49/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.1005 - val_loss: 0.1166\n",
      "Epoch 50/1500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.1010 - val_loss: 0.1165\n",
      "Epoch 51/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.1014 - val_loss: 0.1165\n",
      "Epoch 52/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.1016 - val_loss: 0.1164\n",
      "Epoch 53/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.1018 - val_loss: 0.1164\n",
      "Epoch 54/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.1018 - val_loss: 0.1164\n",
      "Epoch 55/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.1017 - val_loss: 0.1164\n",
      "Epoch 56/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.1014 - val_loss: 0.1163\n",
      "Epoch 57/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.1011 - val_loss: 0.1164\n",
      "Epoch 58/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.1007 - val_loss: 0.1164\n",
      "Epoch 59/1500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 0.1003 - val_loss: 0.1165\n",
      "Epoch 60/1500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0998 - val_loss: 0.1166\n",
      "Epoch 61/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0994 - val_loss: 0.1167\n",
      "Epoch 62/1500\n",
      "27/27 [==============================] - 0s 330us/step - loss: 0.0990 - val_loss: 0.1169\n",
      "Epoch 63/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0987 - val_loss: 0.1171\n",
      "Epoch 64/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0983 - val_loss: 0.1174\n",
      "Epoch 65/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0981 - val_loss: 0.1177\n",
      "Epoch 66/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0979 - val_loss: 0.1180\n",
      "Epoch 67/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0977 - val_loss: 0.1184\n",
      "Epoch 68/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0976 - val_loss: 0.1188\n",
      "Epoch 69/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0975 - val_loss: 0.1191\n",
      "Epoch 70/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0974 - val_loss: 0.1195\n",
      "Epoch 71/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0974 - val_loss: 0.1198\n",
      "Epoch 72/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0974 - val_loss: 0.1202\n",
      "Epoch 73/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0974 - val_loss: 0.1204\n",
      "Epoch 74/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0974 - val_loss: 0.1206\n",
      "Epoch 75/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0974 - val_loss: 0.1208\n",
      "Epoch 76/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0974 - val_loss: 0.1209\n",
      "Epoch 77/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0974 - val_loss: 0.1210\n",
      "Epoch 78/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0974 - val_loss: 0.1210\n",
      "Epoch 79/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0974 - val_loss: 0.1210\n",
      "Epoch 80/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0974 - val_loss: 0.1209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0973 - val_loss: 0.1208\n",
      "Epoch 82/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0973 - val_loss: 0.1206\n",
      "Epoch 83/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0972 - val_loss: 0.1205\n",
      "Epoch 84/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0972 - val_loss: 0.1203\n",
      "Epoch 85/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0971 - val_loss: 0.1201\n",
      "Epoch 86/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0971 - val_loss: 0.1199\n",
      "Epoch 87/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0970 - val_loss: 0.1197\n",
      "Epoch 88/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0969 - val_loss: 0.1194\n",
      "Epoch 89/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0969 - val_loss: 0.1192\n",
      "Epoch 90/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0968 - val_loss: 0.1190\n",
      "Epoch 91/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0968 - val_loss: 0.1189\n",
      "Epoch 92/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0968 - val_loss: 0.1187\n",
      "Epoch 93/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0967 - val_loss: 0.1185\n",
      "Epoch 94/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0967 - val_loss: 0.1184\n",
      "Epoch 95/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0967 - val_loss: 0.1182\n",
      "Epoch 96/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0966 - val_loss: 0.1181\n",
      "Epoch 97/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0966 - val_loss: 0.1180\n",
      "Epoch 98/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0966 - val_loss: 0.1179\n",
      "Epoch 99/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0966 - val_loss: 0.1179\n",
      "Epoch 100/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0965 - val_loss: 0.1178\n",
      "Epoch 101/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0965 - val_loss: 0.1178\n",
      "Epoch 102/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0965 - val_loss: 0.1177\n",
      "Epoch 103/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0965 - val_loss: 0.1177\n",
      "Epoch 104/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0964 - val_loss: 0.1177\n",
      "Epoch 105/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0964 - val_loss: 0.1177\n",
      "Epoch 106/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0964 - val_loss: 0.1177\n",
      "Epoch 107/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0963 - val_loss: 0.1177\n",
      "Epoch 108/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0963 - val_loss: 0.1177\n",
      "Epoch 109/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0963 - val_loss: 0.1177\n",
      "Epoch 110/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0962 - val_loss: 0.1177\n",
      "Epoch 111/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0962 - val_loss: 0.1177\n",
      "Epoch 112/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0962 - val_loss: 0.1177\n",
      "Epoch 113/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0962 - val_loss: 0.1177\n",
      "Epoch 114/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0961 - val_loss: 0.1178\n",
      "Epoch 115/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0961 - val_loss: 0.1178\n",
      "Epoch 116/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0961 - val_loss: 0.1178\n",
      "Epoch 117/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0960 - val_loss: 0.1178\n",
      "Epoch 118/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0960 - val_loss: 0.1178\n",
      "Epoch 119/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0960 - val_loss: 0.1178\n",
      "Epoch 120/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0960 - val_loss: 0.1177\n",
      "Epoch 121/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0959 - val_loss: 0.1177\n",
      "Epoch 122/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0959 - val_loss: 0.1177\n",
      "Epoch 123/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0959 - val_loss: 0.1177\n",
      "Epoch 124/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0958 - val_loss: 0.1176\n",
      "Epoch 125/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0958 - val_loss: 0.1176\n",
      "Epoch 126/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0958 - val_loss: 0.1175\n",
      "Epoch 127/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0958 - val_loss: 0.1175\n",
      "Epoch 128/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0957 - val_loss: 0.1174\n",
      "Epoch 129/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0957 - val_loss: 0.1174\n",
      "Epoch 130/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0957 - val_loss: 0.1173\n",
      "Epoch 131/1500\n",
      "27/27 [==============================] - 0s 312us/step - loss: 0.0956 - val_loss: 0.1173\n",
      "Epoch 132/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0956 - val_loss: 0.1172\n",
      "Epoch 133/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0956 - val_loss: 0.1172\n",
      "Epoch 134/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0956 - val_loss: 0.1171\n",
      "Epoch 135/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0955 - val_loss: 0.1170\n",
      "Epoch 136/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0955 - val_loss: 0.1170\n",
      "Epoch 137/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0955 - val_loss: 0.1169\n",
      "Epoch 138/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0954 - val_loss: 0.1169\n",
      "Epoch 139/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0954 - val_loss: 0.1168\n",
      "Epoch 140/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0954 - val_loss: 0.1168\n",
      "Epoch 141/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0954 - val_loss: 0.1168\n",
      "Epoch 142/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0953 - val_loss: 0.1167\n",
      "Epoch 143/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0953 - val_loss: 0.1167\n",
      "Epoch 144/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0953 - val_loss: 0.1166\n",
      "Epoch 145/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0953 - val_loss: 0.1166\n",
      "Epoch 146/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0952 - val_loss: 0.1166\n",
      "Epoch 147/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0952 - val_loss: 0.1166\n",
      "Epoch 148/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0952 - val_loss: 0.1165\n",
      "Epoch 149/1500\n",
      "27/27 [==============================] - 0s 449us/step - loss: 0.0951 - val_loss: 0.1165\n",
      "Epoch 150/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0951 - val_loss: 0.1165\n",
      "Epoch 151/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0951 - val_loss: 0.1164\n",
      "Epoch 152/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0951 - val_loss: 0.1164\n",
      "Epoch 153/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0950 - val_loss: 0.1164\n",
      "Epoch 154/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0950 - val_loss: 0.1163\n",
      "Epoch 155/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0950 - val_loss: 0.1163\n",
      "Epoch 156/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0949 - val_loss: 0.1163\n",
      "Epoch 157/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0949 - val_loss: 0.1163\n",
      "Epoch 158/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0949 - val_loss: 0.1162\n",
      "Epoch 159/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0949 - val_loss: 0.1162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0948 - val_loss: 0.1162\n",
      "Epoch 161/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0948 - val_loss: 0.1161\n",
      "Epoch 162/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0948 - val_loss: 0.1161\n",
      "Epoch 163/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0947 - val_loss: 0.1160\n",
      "Epoch 164/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0947 - val_loss: 0.1160\n",
      "Epoch 165/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0947 - val_loss: 0.1160\n",
      "Epoch 166/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0947 - val_loss: 0.1159\n",
      "Epoch 167/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0946 - val_loss: 0.1159\n",
      "Epoch 168/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0946 - val_loss: 0.1159\n",
      "Epoch 169/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0946 - val_loss: 0.1158\n",
      "Epoch 170/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0946 - val_loss: 0.1158\n",
      "Epoch 171/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0945 - val_loss: 0.1157\n",
      "Epoch 172/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0945 - val_loss: 0.1157\n",
      "Epoch 173/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0945 - val_loss: 0.1156\n",
      "Epoch 174/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0944 - val_loss: 0.1156\n",
      "Epoch 175/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0944 - val_loss: 0.1155\n",
      "Epoch 176/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0944 - val_loss: 0.1155\n",
      "Epoch 177/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0944 - val_loss: 0.1154\n",
      "Epoch 178/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0943 - val_loss: 0.1154\n",
      "Epoch 179/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0943 - val_loss: 0.1153\n",
      "Epoch 180/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0943 - val_loss: 0.1153\n",
      "Epoch 181/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0942 - val_loss: 0.1153\n",
      "Epoch 182/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0942 - val_loss: 0.1152\n",
      "Epoch 183/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0942 - val_loss: 0.1152\n",
      "Epoch 184/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0941 - val_loss: 0.1151\n",
      "Epoch 185/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0941 - val_loss: 0.1151\n",
      "Epoch 186/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0941 - val_loss: 0.1150\n",
      "Epoch 187/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0941 - val_loss: 0.1150\n",
      "Epoch 188/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0940 - val_loss: 0.1149\n",
      "Epoch 189/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0940 - val_loss: 0.1149\n",
      "Epoch 190/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0940 - val_loss: 0.1148\n",
      "Epoch 191/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0939 - val_loss: 0.1147\n",
      "Epoch 192/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0939 - val_loss: 0.1147\n",
      "Epoch 193/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0939 - val_loss: 0.1146\n",
      "Epoch 194/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0938 - val_loss: 0.1146\n",
      "Epoch 195/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0938 - val_loss: 0.1145\n",
      "Epoch 196/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0938 - val_loss: 0.1145\n",
      "Epoch 197/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0937 - val_loss: 0.1144\n",
      "Epoch 198/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0937 - val_loss: 0.1144\n",
      "Epoch 199/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0937 - val_loss: 0.1143\n",
      "Epoch 200/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0936 - val_loss: 0.1143\n",
      "Epoch 201/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0936 - val_loss: 0.1142\n",
      "Epoch 202/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0936 - val_loss: 0.1142\n",
      "Epoch 203/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0935 - val_loss: 0.1142\n",
      "Epoch 204/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0935 - val_loss: 0.1141\n",
      "Epoch 205/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0935 - val_loss: 0.1141\n",
      "Epoch 206/1500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0934 - val_loss: 0.1140\n",
      "Epoch 207/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0934 - val_loss: 0.1140\n",
      "Epoch 208/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0933 - val_loss: 0.1139\n",
      "Epoch 209/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0933 - val_loss: 0.1138\n",
      "Epoch 210/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0933 - val_loss: 0.1138\n",
      "Epoch 211/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0932 - val_loss: 0.1137\n",
      "Epoch 212/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0932 - val_loss: 0.1136\n",
      "Epoch 213/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0932 - val_loss: 0.1135\n",
      "Epoch 214/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0931 - val_loss: 0.1135\n",
      "Epoch 215/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0931 - val_loss: 0.1134\n",
      "Epoch 216/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0930 - val_loss: 0.1133\n",
      "Epoch 217/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0930 - val_loss: 0.1132\n",
      "Epoch 218/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0929 - val_loss: 0.1131\n",
      "Epoch 219/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0929 - val_loss: 0.1130\n",
      "Epoch 220/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0929 - val_loss: 0.1130\n",
      "Epoch 221/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0928 - val_loss: 0.1129\n",
      "Epoch 222/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0928 - val_loss: 0.1128\n",
      "Epoch 223/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0927 - val_loss: 0.1128\n",
      "Epoch 224/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0927 - val_loss: 0.1127\n",
      "Epoch 225/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0926 - val_loss: 0.1126\n",
      "Epoch 226/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0926 - val_loss: 0.1125\n",
      "Epoch 227/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0925 - val_loss: 0.1124\n",
      "Epoch 228/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0925 - val_loss: 0.1123\n",
      "Epoch 229/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0924 - val_loss: 0.1122\n",
      "Epoch 230/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0924 - val_loss: 0.1121\n",
      "Epoch 231/1500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0923 - val_loss: 0.1119\n",
      "Epoch 232/1500\n",
      "27/27 [==============================] - 0s 556us/step - loss: 0.0923 - val_loss: 0.1118\n",
      "Epoch 233/1500\n",
      "27/27 [==============================] - 0s 649us/step - loss: 0.0922 - val_loss: 0.1117\n",
      "Epoch 234/1500\n",
      "27/27 [==============================] - 0s 642us/step - loss: 0.0922 - val_loss: 0.1116\n",
      "Epoch 235/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0921 - val_loss: 0.1115\n",
      "Epoch 236/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0921 - val_loss: 0.1114\n",
      "Epoch 237/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0920 - val_loss: 0.1113\n",
      "Epoch 238/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0920 - val_loss: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0919 - val_loss: 0.1110\n",
      "Epoch 240/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0919 - val_loss: 0.1109\n",
      "Epoch 241/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0918 - val_loss: 0.1108\n",
      "Epoch 242/1500\n",
      "27/27 [==============================] - 0s 330us/step - loss: 0.0918 - val_loss: 0.1107\n",
      "Epoch 243/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0917 - val_loss: 0.1105\n",
      "Epoch 244/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0917 - val_loss: 0.1104\n",
      "Epoch 245/1500\n",
      "27/27 [==============================] - 0s 295us/step - loss: 0.0916 - val_loss: 0.1103\n",
      "Epoch 246/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0916 - val_loss: 0.1102\n",
      "Epoch 247/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0916 - val_loss: 0.1101\n",
      "Epoch 248/1500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0915 - val_loss: 0.1099\n",
      "Epoch 249/1500\n",
      "27/27 [==============================] - 0s 292us/step - loss: 0.0915 - val_loss: 0.1098\n",
      "Epoch 250/1500\n",
      "27/27 [==============================] - 0s 309us/step - loss: 0.0914 - val_loss: 0.1097\n",
      "Epoch 251/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0914 - val_loss: 0.1095\n",
      "Epoch 252/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0913 - val_loss: 0.1094\n",
      "Epoch 253/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0913 - val_loss: 0.1093\n",
      "Epoch 254/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0912 - val_loss: 0.1092\n",
      "Epoch 255/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0912 - val_loss: 0.1090\n",
      "Epoch 256/1500\n",
      "27/27 [==============================] - 0s 330us/step - loss: 0.0911 - val_loss: 0.1089\n",
      "Epoch 257/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0911 - val_loss: 0.1087\n",
      "Epoch 258/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0910 - val_loss: 0.1086\n",
      "Epoch 259/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0910 - val_loss: 0.1085\n",
      "Epoch 260/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0909 - val_loss: 0.1084\n",
      "Epoch 261/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0909 - val_loss: 0.1082\n",
      "Epoch 262/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0908 - val_loss: 0.1081\n",
      "Epoch 263/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0908 - val_loss: 0.1080\n",
      "Epoch 264/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0907 - val_loss: 0.1079\n",
      "Epoch 265/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0907 - val_loss: 0.1077\n",
      "Epoch 266/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0906 - val_loss: 0.1076\n",
      "Epoch 267/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0906 - val_loss: 0.1075\n",
      "Epoch 268/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0905 - val_loss: 0.1074\n",
      "Epoch 269/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0905 - val_loss: 0.1073\n",
      "Epoch 270/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0904 - val_loss: 0.1072\n",
      "Epoch 271/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0904 - val_loss: 0.1071\n",
      "Epoch 272/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0903 - val_loss: 0.1070\n",
      "Epoch 273/1500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0903 - val_loss: 0.1069\n",
      "Epoch 274/1500\n",
      "27/27 [==============================] - 0s 624us/step - loss: 0.0903 - val_loss: 0.1068\n",
      "Epoch 275/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0902 - val_loss: 0.1066\n",
      "Epoch 276/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0902 - val_loss: 0.1065\n",
      "Epoch 277/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0901 - val_loss: 0.1064\n",
      "Epoch 278/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0901 - val_loss: 0.1063\n",
      "Epoch 279/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0900 - val_loss: 0.1062\n",
      "Epoch 280/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0900 - val_loss: 0.1061\n",
      "Epoch 281/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0899 - val_loss: 0.1060\n",
      "Epoch 282/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0899 - val_loss: 0.1059\n",
      "Epoch 283/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0898 - val_loss: 0.1058\n",
      "Epoch 284/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0898 - val_loss: 0.1057\n",
      "Epoch 285/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0897 - val_loss: 0.1056\n",
      "Epoch 286/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0897 - val_loss: 0.1055\n",
      "Epoch 287/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0897 - val_loss: 0.1055\n",
      "Epoch 288/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0896 - val_loss: 0.1054\n",
      "Epoch 289/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0896 - val_loss: 0.1053\n",
      "Epoch 290/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0895 - val_loss: 0.1052\n",
      "Epoch 291/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0895 - val_loss: 0.1051\n",
      "Epoch 292/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0894 - val_loss: 0.1050\n",
      "Epoch 293/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0894 - val_loss: 0.1049\n",
      "Epoch 294/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0894 - val_loss: 0.1048\n",
      "Epoch 295/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0893 - val_loss: 0.1047\n",
      "Epoch 296/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0893 - val_loss: 0.1046\n",
      "Epoch 297/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0892 - val_loss: 0.1045\n",
      "Epoch 298/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0892 - val_loss: 0.1044\n",
      "Epoch 299/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0891 - val_loss: 0.1044\n",
      "Epoch 300/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0891 - val_loss: 0.1043\n",
      "Epoch 301/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0891 - val_loss: 0.1042\n",
      "Epoch 302/1500\n",
      "27/27 [==============================] - 0s 531us/step - loss: 0.0890 - val_loss: 0.1041\n",
      "Epoch 303/1500\n",
      "27/27 [==============================] - 0s 550us/step - loss: 0.0890 - val_loss: 0.1041\n",
      "Epoch 304/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0889 - val_loss: 0.1040\n",
      "Epoch 305/1500\n",
      "27/27 [==============================] - 0s 510us/step - loss: 0.0889 - val_loss: 0.1039\n",
      "Epoch 306/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0889 - val_loss: 0.1038\n",
      "Epoch 307/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0888 - val_loss: 0.1038\n",
      "Epoch 308/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0888 - val_loss: 0.1037\n",
      "Epoch 309/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0887 - val_loss: 0.1036\n",
      "Epoch 310/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0887 - val_loss: 0.1035\n",
      "Epoch 311/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0887 - val_loss: 0.1035\n",
      "Epoch 312/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0886 - val_loss: 0.1034\n",
      "Epoch 313/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0886 - val_loss: 0.1034\n",
      "Epoch 314/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0885 - val_loss: 0.1033\n",
      "Epoch 315/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0885 - val_loss: 0.1033\n",
      "Epoch 316/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0885 - val_loss: 0.1032\n",
      "Epoch 317/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0884 - val_loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0884 - val_loss: 0.1030\n",
      "Epoch 319/1500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0883 - val_loss: 0.1029\n",
      "Epoch 320/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0883 - val_loss: 0.1029\n",
      "Epoch 321/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0883 - val_loss: 0.1028\n",
      "Epoch 322/1500\n",
      "27/27 [==============================] - 0s 559us/step - loss: 0.0882 - val_loss: 0.1028\n",
      "Epoch 323/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0882 - val_loss: 0.1027\n",
      "Epoch 324/1500\n",
      "27/27 [==============================] - 0s 560us/step - loss: 0.0881 - val_loss: 0.1026\n",
      "Epoch 325/1500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.1026\n",
      "Epoch 326/1500\n",
      "27/27 [==============================] - 0s 757us/step - loss: 0.0881 - val_loss: 0.1025\n",
      "Epoch 327/1500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0880 - val_loss: 0.1025\n",
      "Epoch 328/1500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 0.0880 - val_loss: 0.1024\n",
      "Epoch 329/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0879 - val_loss: 0.1023\n",
      "Epoch 330/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0879 - val_loss: 0.1022\n",
      "Epoch 331/1500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 0.0878 - val_loss: 0.1021\n",
      "Epoch 332/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0878 - val_loss: 0.1021\n",
      "Epoch 333/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0878 - val_loss: 0.1020\n",
      "Epoch 334/1500\n",
      "27/27 [==============================] - 0s 535us/step - loss: 0.0877 - val_loss: 0.1019\n",
      "Epoch 335/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0877 - val_loss: 0.1018\n",
      "Epoch 336/1500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0876 - val_loss: 0.1017\n",
      "Epoch 337/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0876 - val_loss: 0.1017\n",
      "Epoch 338/1500\n",
      "27/27 [==============================] - 0s 581us/step - loss: 0.0875 - val_loss: 0.1016\n",
      "Epoch 339/1500\n",
      "27/27 [==============================] - 0s 691us/step - loss: 0.0875 - val_loss: 0.1015\n",
      "Epoch 340/1500\n",
      "27/27 [==============================] - 0s 575us/step - loss: 0.0875 - val_loss: 0.1014\n",
      "Epoch 341/1500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0874 - val_loss: 0.1013\n",
      "Epoch 342/1500\n",
      "27/27 [==============================] - 0s 561us/step - loss: 0.0874 - val_loss: 0.1012\n",
      "Epoch 343/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0873 - val_loss: 0.1012\n",
      "Epoch 344/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0873 - val_loss: 0.1011\n",
      "Epoch 345/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0872 - val_loss: 0.1009\n",
      "Epoch 346/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0872 - val_loss: 0.1009\n",
      "Epoch 347/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0872 - val_loss: 0.1008\n",
      "Epoch 348/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0871 - val_loss: 0.1007\n",
      "Epoch 349/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0871 - val_loss: 0.1006\n",
      "Epoch 350/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0870 - val_loss: 0.1005\n",
      "Epoch 351/1500\n",
      "27/27 [==============================] - 0s 753us/step - loss: 0.0870 - val_loss: 0.1005\n",
      "Epoch 352/1500\n",
      "27/27 [==============================] - 0s 790us/step - loss: 0.0869 - val_loss: 0.1004\n",
      "Epoch 353/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0869 - val_loss: 0.1003\n",
      "Epoch 354/1500\n",
      "27/27 [==============================] - 0s 611us/step - loss: 0.0869 - val_loss: 0.1002\n",
      "Epoch 355/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0868 - val_loss: 0.1001\n",
      "Epoch 356/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0868 - val_loss: 0.1000\n",
      "Epoch 357/1500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0867 - val_loss: 0.0999\n",
      "Epoch 358/1500\n",
      "27/27 [==============================] - 0s 944us/step - loss: 0.0867 - val_loss: 0.0997\n",
      "Epoch 359/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0867 - val_loss: 0.0997\n",
      "Epoch 360/1500\n",
      "27/27 [==============================] - 0s 566us/step - loss: 0.0866 - val_loss: 0.0996\n",
      "Epoch 361/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0866 - val_loss: 0.0995\n",
      "Epoch 362/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0865 - val_loss: 0.0994\n",
      "Epoch 363/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0865 - val_loss: 0.0993\n",
      "Epoch 364/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0865 - val_loss: 0.0992\n",
      "Epoch 365/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0864 - val_loss: 0.0991\n",
      "Epoch 366/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0864 - val_loss: 0.0989\n",
      "Epoch 367/1500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0988\n",
      "Epoch 368/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0863 - val_loss: 0.0988\n",
      "Epoch 369/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0863 - val_loss: 0.0987\n",
      "Epoch 370/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0862 - val_loss: 0.0986\n",
      "Epoch 371/1500\n",
      "27/27 [==============================] - 0s 622us/step - loss: 0.0862 - val_loss: 0.0985\n",
      "Epoch 372/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0861 - val_loss: 0.0984\n",
      "Epoch 373/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0861 - val_loss: 0.0984\n",
      "Epoch 374/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0861 - val_loss: 0.0982\n",
      "Epoch 375/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0860 - val_loss: 0.0981\n",
      "Epoch 376/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0860 - val_loss: 0.0981\n",
      "Epoch 377/1500\n",
      "27/27 [==============================] - 0s 564us/step - loss: 0.0860 - val_loss: 0.0981\n",
      "Epoch 378/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0859 - val_loss: 0.0979\n",
      "Epoch 379/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0859 - val_loss: 0.0978\n",
      "Epoch 380/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0859 - val_loss: 0.0978\n",
      "Epoch 381/1500\n",
      "27/27 [==============================] - 0s 504us/step - loss: 0.0858 - val_loss: 0.0978\n",
      "Epoch 382/1500\n",
      "27/27 [==============================] - 0s 481us/step - loss: 0.0858 - val_loss: 0.0977\n",
      "Epoch 383/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0858 - val_loss: 0.0976\n",
      "Epoch 384/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0857 - val_loss: 0.0975\n",
      "Epoch 385/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0857 - val_loss: 0.0974\n",
      "Epoch 386/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0857 - val_loss: 0.0974\n",
      "Epoch 387/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0856 - val_loss: 0.0973\n",
      "Epoch 388/1500\n",
      "27/27 [==============================] - 0s 304us/step - loss: 0.0856 - val_loss: 0.0972\n",
      "Epoch 389/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0856 - val_loss: 0.0971\n",
      "Epoch 390/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0855 - val_loss: 0.0971\n",
      "Epoch 391/1500\n",
      "27/27 [==============================] - 0s 317us/step - loss: 0.0855 - val_loss: 0.0970\n",
      "Epoch 392/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0855 - val_loss: 0.0970\n",
      "Epoch 393/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0854 - val_loss: 0.0969\n",
      "Epoch 394/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0854 - val_loss: 0.0969\n",
      "Epoch 395/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0854 - val_loss: 0.0968\n",
      "Epoch 396/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0853 - val_loss: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0853 - val_loss: 0.0967\n",
      "Epoch 398/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0853 - val_loss: 0.0967\n",
      "Epoch 399/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0853 - val_loss: 0.0967\n",
      "Epoch 400/1500\n",
      "27/27 [==============================] - 0s 319us/step - loss: 0.0852 - val_loss: 0.0966\n",
      "Epoch 401/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0852 - val_loss: 0.0966\n",
      "Epoch 402/1500\n",
      "27/27 [==============================] - 0s 320us/step - loss: 0.0852 - val_loss: 0.0966\n",
      "Epoch 403/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0851 - val_loss: 0.0965\n",
      "Epoch 404/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0851 - val_loss: 0.0965\n",
      "Epoch 405/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0851 - val_loss: 0.0965\n",
      "Epoch 406/1500\n",
      "27/27 [==============================] - 0s 296us/step - loss: 0.0850 - val_loss: 0.0964\n",
      "Epoch 407/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0850 - val_loss: 0.0964\n",
      "Epoch 408/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0850 - val_loss: 0.0964\n",
      "Epoch 409/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0850 - val_loss: 0.0963\n",
      "Epoch 410/1500\n",
      "27/27 [==============================] - 0s 304us/step - loss: 0.0849 - val_loss: 0.0963\n",
      "Epoch 411/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0849 - val_loss: 0.0962\n",
      "Epoch 412/1500\n",
      "27/27 [==============================] - 0s 288us/step - loss: 0.0849 - val_loss: 0.0962\n",
      "Epoch 413/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0848 - val_loss: 0.0961\n",
      "Epoch 414/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0848 - val_loss: 0.0960\n",
      "Epoch 415/1500\n",
      "27/27 [==============================] - 0s 292us/step - loss: 0.0848 - val_loss: 0.0960\n",
      "Epoch 416/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0848 - val_loss: 0.0960\n",
      "Epoch 417/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0847 - val_loss: 0.0959\n",
      "Epoch 418/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0847 - val_loss: 0.0958\n",
      "Epoch 419/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0847 - val_loss: 0.0958\n",
      "Epoch 420/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0846 - val_loss: 0.0958\n",
      "Epoch 421/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0846 - val_loss: 0.0957\n",
      "Epoch 422/1500\n",
      "27/27 [==============================] - 0s 300us/step - loss: 0.0846 - val_loss: 0.0957\n",
      "Epoch 423/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0846 - val_loss: 0.0956\n",
      "Epoch 424/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0845 - val_loss: 0.0956\n",
      "Epoch 425/1500\n",
      "27/27 [==============================] - 0s 313us/step - loss: 0.0845 - val_loss: 0.0955\n",
      "Epoch 426/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0845 - val_loss: 0.0956\n",
      "Epoch 427/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0844 - val_loss: 0.0954\n",
      "Epoch 428/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0844 - val_loss: 0.0954\n",
      "Epoch 429/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.0844 - val_loss: 0.0955\n",
      "Epoch 430/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0844 - val_loss: 0.0954\n",
      "Epoch 431/1500\n",
      "27/27 [==============================] - 0s 308us/step - loss: 0.0843 - val_loss: 0.0953\n",
      "Epoch 432/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0843 - val_loss: 0.0953\n",
      "Epoch 433/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0843 - val_loss: 0.0953\n",
      "Epoch 434/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0842 - val_loss: 0.0952\n",
      "Epoch 435/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0842 - val_loss: 0.0952\n",
      "Epoch 436/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0842 - val_loss: 0.0952\n",
      "Epoch 437/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0842 - val_loss: 0.0951\n",
      "Epoch 438/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0841 - val_loss: 0.0951\n",
      "Epoch 439/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0841 - val_loss: 0.0951\n",
      "Epoch 440/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0841 - val_loss: 0.0950\n",
      "Epoch 441/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0840 - val_loss: 0.0950\n",
      "Epoch 442/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0840 - val_loss: 0.0951\n",
      "Epoch 443/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0840 - val_loss: 0.0950\n",
      "Epoch 444/1500\n",
      "27/27 [==============================] - 0s 296us/step - loss: 0.0840 - val_loss: 0.0950\n",
      "Epoch 445/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0839 - val_loss: 0.0950\n",
      "Epoch 446/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0839 - val_loss: 0.0949\n",
      "Epoch 447/1500\n",
      "27/27 [==============================] - 0s 517us/step - loss: 0.0839 - val_loss: 0.0950\n",
      "Epoch 448/1500\n",
      "27/27 [==============================] - 0s 545us/step - loss: 0.0838 - val_loss: 0.0949\n",
      "Epoch 449/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0838 - val_loss: 0.0949\n",
      "Epoch 450/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0838 - val_loss: 0.0949\n",
      "Epoch 451/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0838 - val_loss: 0.0949\n",
      "Epoch 452/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0837 - val_loss: 0.0948\n",
      "Epoch 453/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0837 - val_loss: 0.0949\n",
      "Epoch 454/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0837 - val_loss: 0.0949\n",
      "Epoch 455/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0837 - val_loss: 0.0948\n",
      "Epoch 456/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0836 - val_loss: 0.0948\n",
      "Epoch 457/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0836 - val_loss: 0.0948\n",
      "Epoch 458/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0836 - val_loss: 0.0947\n",
      "Epoch 459/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0836 - val_loss: 0.0948\n",
      "Epoch 460/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0835 - val_loss: 0.0948\n",
      "Epoch 461/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0835 - val_loss: 0.0947\n",
      "Epoch 462/1500\n",
      "27/27 [==============================] - 0s 575us/step - loss: 0.0835 - val_loss: 0.0947\n",
      "Epoch 463/1500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0835 - val_loss: 0.0947\n",
      "Epoch 464/1500\n",
      "27/27 [==============================] - 0s 521us/step - loss: 0.0834 - val_loss: 0.0947\n",
      "Epoch 465/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0834 - val_loss: 0.0946\n",
      "Epoch 466/1500\n",
      "27/27 [==============================] - 0s 523us/step - loss: 0.0834 - val_loss: 0.0947\n",
      "Epoch 467/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0834 - val_loss: 0.0947\n",
      "Epoch 468/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0833 - val_loss: 0.0946\n",
      "Epoch 469/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0833 - val_loss: 0.0946\n",
      "Epoch 470/1500\n",
      "27/27 [==============================] - 0s 538us/step - loss: 0.0833 - val_loss: 0.0946\n",
      "Epoch 471/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0833 - val_loss: 0.0945\n",
      "Epoch 472/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0833 - val_loss: 0.0945\n",
      "Epoch 473/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0832 - val_loss: 0.0946\n",
      "Epoch 474/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0832 - val_loss: 0.0945\n",
      "Epoch 475/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0832 - val_loss: 0.0945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0832 - val_loss: 0.0945\n",
      "Epoch 477/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0831 - val_loss: 0.0944\n",
      "Epoch 478/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0831 - val_loss: 0.0944\n",
      "Epoch 479/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0831 - val_loss: 0.0945\n",
      "Epoch 480/1500\n",
      "27/27 [==============================] - 0s 297us/step - loss: 0.0831 - val_loss: 0.0943\n",
      "Epoch 481/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0831 - val_loss: 0.0944\n",
      "Epoch 482/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0830 - val_loss: 0.0945\n",
      "Epoch 483/1500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0830 - val_loss: 0.0942\n",
      "Epoch 484/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0830 - val_loss: 0.0943\n",
      "Epoch 485/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0830 - val_loss: 0.0944\n",
      "Epoch 486/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0830 - val_loss: 0.0942\n",
      "Epoch 487/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0830 - val_loss: 0.0943\n",
      "Epoch 488/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0829 - val_loss: 0.0943\n",
      "Epoch 489/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0829 - val_loss: 0.0941\n",
      "Epoch 490/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0829 - val_loss: 0.0942\n",
      "Epoch 491/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0829 - val_loss: 0.0942\n",
      "Epoch 492/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0829 - val_loss: 0.0941\n",
      "Epoch 493/1500\n",
      "27/27 [==============================] - 0s 306us/step - loss: 0.0828 - val_loss: 0.0941\n",
      "Epoch 494/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0828 - val_loss: 0.0942\n",
      "Epoch 495/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0828 - val_loss: 0.0941\n",
      "Epoch 496/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0828 - val_loss: 0.0941\n",
      "Epoch 497/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0828 - val_loss: 0.0942\n",
      "Epoch 498/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0828 - val_loss: 0.0941\n",
      "Epoch 499/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0827 - val_loss: 0.0940\n",
      "Epoch 500/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0827 - val_loss: 0.0941\n",
      "Epoch 501/1500\n",
      "27/27 [==============================] - 0s 319us/step - loss: 0.0827 - val_loss: 0.0941\n",
      "Epoch 502/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0827 - val_loss: 0.0940\n",
      "Epoch 503/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0827 - val_loss: 0.0940\n",
      "Epoch 504/1500\n",
      "27/27 [==============================] - 0s 316us/step - loss: 0.0827 - val_loss: 0.0941\n",
      "Epoch 505/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0827 - val_loss: 0.0939\n",
      "Epoch 506/1500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.0826 - val_loss: 0.0940\n",
      "Epoch 507/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0826 - val_loss: 0.0940\n",
      "Epoch 508/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0826 - val_loss: 0.0939\n",
      "Epoch 509/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0826 - val_loss: 0.0939\n",
      "Epoch 510/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0826 - val_loss: 0.0939\n",
      "Epoch 511/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0826 - val_loss: 0.0938\n",
      "Epoch 512/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0825 - val_loss: 0.0938\n",
      "Epoch 513/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0825 - val_loss: 0.0939\n",
      "Epoch 514/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0825 - val_loss: 0.0938\n",
      "Epoch 515/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0825 - val_loss: 0.0938\n",
      "Epoch 516/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0825 - val_loss: 0.0938\n",
      "Epoch 517/1500\n",
      "27/27 [==============================] - 0s 312us/step - loss: 0.0825 - val_loss: 0.0938\n",
      "Epoch 518/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0825 - val_loss: 0.0937\n",
      "Epoch 519/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0825 - val_loss: 0.0937\n",
      "Epoch 520/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0824 - val_loss: 0.0938\n",
      "Epoch 521/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0824 - val_loss: 0.0936\n",
      "Epoch 522/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0824 - val_loss: 0.0937\n",
      "Epoch 523/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0824 - val_loss: 0.0938\n",
      "Epoch 524/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0824 - val_loss: 0.0936\n",
      "Epoch 525/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0824 - val_loss: 0.0937\n",
      "Epoch 526/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0824 - val_loss: 0.0937\n",
      "Epoch 527/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0823 - val_loss: 0.0936\n",
      "Epoch 528/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0823 - val_loss: 0.0936\n",
      "Epoch 529/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0823 - val_loss: 0.0936\n",
      "Epoch 530/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0823 - val_loss: 0.0936\n",
      "Epoch 531/1500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.0823 - val_loss: 0.0937\n",
      "Epoch 532/1500\n",
      "27/27 [==============================] - 0s 608us/step - loss: 0.0823 - val_loss: 0.0935\n",
      "Epoch 533/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0823 - val_loss: 0.0935\n",
      "Epoch 534/1500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0823 - val_loss: 0.0936\n",
      "Epoch 535/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0823 - val_loss: 0.0935\n",
      "Epoch 536/1500\n",
      "27/27 [==============================] - 0s 294us/step - loss: 0.0822 - val_loss: 0.0935\n",
      "Epoch 537/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0822 - val_loss: 0.0935\n",
      "Epoch 538/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0822 - val_loss: 0.0934\n",
      "Epoch 539/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0822 - val_loss: 0.0934\n",
      "Epoch 540/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0822 - val_loss: 0.0934\n",
      "Epoch 541/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0822 - val_loss: 0.0934\n",
      "Epoch 542/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0822 - val_loss: 0.0934\n",
      "Epoch 543/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0822 - val_loss: 0.0934\n",
      "Epoch 544/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0822 - val_loss: 0.0933\n",
      "Epoch 545/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0821 - val_loss: 0.0933\n",
      "Epoch 546/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0821 - val_loss: 0.0933\n",
      "Epoch 547/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0821 - val_loss: 0.0933\n",
      "Epoch 548/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0821 - val_loss: 0.0933\n",
      "Epoch 549/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0821 - val_loss: 0.0933\n",
      "Epoch 550/1500\n",
      "27/27 [==============================] - 0s 282us/step - loss: 0.0821 - val_loss: 0.0932\n",
      "Epoch 551/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0821 - val_loss: 0.0932\n",
      "Epoch 552/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0821 - val_loss: 0.0933\n",
      "Epoch 553/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0821 - val_loss: 0.0932\n",
      "Epoch 554/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0821 - val_loss: 0.0932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0820 - val_loss: 0.0933\n",
      "Epoch 556/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0820 - val_loss: 0.0931\n",
      "Epoch 557/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0820 - val_loss: 0.0932\n",
      "Epoch 558/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0820 - val_loss: 0.0933\n",
      "Epoch 559/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0820 - val_loss: 0.0931\n",
      "Epoch 560/1500\n",
      "27/27 [==============================] - 0s 296us/step - loss: 0.0820 - val_loss: 0.0932\n",
      "Epoch 561/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0820 - val_loss: 0.0932\n",
      "Epoch 562/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0820 - val_loss: 0.0931\n",
      "Epoch 563/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0820 - val_loss: 0.0931\n",
      "Epoch 564/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0820 - val_loss: 0.0932\n",
      "Epoch 565/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0820 - val_loss: 0.0930\n",
      "Epoch 566/1500\n",
      "27/27 [==============================] - 0s 316us/step - loss: 0.0820 - val_loss: 0.0931\n",
      "Epoch 567/1500\n",
      "27/27 [==============================] - 0s 308us/step - loss: 0.0819 - val_loss: 0.0931\n",
      "Epoch 568/1500\n",
      "27/27 [==============================] - 0s 300us/step - loss: 0.0819 - val_loss: 0.0930\n",
      "Epoch 569/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0819 - val_loss: 0.0930\n",
      "Epoch 570/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0819 - val_loss: 0.0930\n",
      "Epoch 571/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0819 - val_loss: 0.0929\n",
      "Epoch 572/1500\n",
      "27/27 [==============================] - 0s 498us/step - loss: 0.0819 - val_loss: 0.0929\n",
      "Epoch 573/1500\n",
      "27/27 [==============================] - 0s 512us/step - loss: 0.0819 - val_loss: 0.0930\n",
      "Epoch 574/1500\n",
      "27/27 [==============================] - 0s 330us/step - loss: 0.0819 - val_loss: 0.0929\n",
      "Epoch 575/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0819 - val_loss: 0.0929\n",
      "Epoch 576/1500\n",
      "27/27 [==============================] - 0s 310us/step - loss: 0.0819 - val_loss: 0.0930\n",
      "Epoch 577/1500\n",
      "27/27 [==============================] - 0s 304us/step - loss: 0.0819 - val_loss: 0.0929\n",
      "Epoch 578/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0819 - val_loss: 0.0928\n",
      "Epoch 579/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0819 - val_loss: 0.0929\n",
      "Epoch 580/1500\n",
      "27/27 [==============================] - 0s 308us/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 581/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 582/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0818 - val_loss: 0.0929\n",
      "Epoch 583/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 584/1500\n",
      "27/27 [==============================] - 0s 320us/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 585/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 586/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 587/1500\n",
      "27/27 [==============================] - 0s 319us/step - loss: 0.0818 - val_loss: 0.0927\n",
      "Epoch 588/1500\n",
      "27/27 [==============================] - 0s 313us/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 589/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 590/1500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0818 - val_loss: 0.0927\n",
      "Epoch 591/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0818 - val_loss: 0.0927\n",
      "Epoch 592/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0818 - val_loss: 0.0928\n",
      "Epoch 593/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0818 - val_loss: 0.0927\n",
      "Epoch 594/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 595/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0817 - val_loss: 0.0928\n",
      "Epoch 596/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 597/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 598/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 599/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 600/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 601/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 602/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 603/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 604/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0817 - val_loss: 0.0927\n",
      "Epoch 605/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0817 - val_loss: 0.0926\n",
      "Epoch 606/1500\n",
      "27/27 [==============================] - 0s 330us/step - loss: 0.0817 - val_loss: 0.0926\n",
      "Epoch 607/1500\n",
      "27/27 [==============================] - 0s 282us/step - loss: 0.0817 - val_loss: 0.0926\n",
      "Epoch 608/1500\n",
      "27/27 [==============================] - 0s 309us/step - loss: 0.0817 - val_loss: 0.0926\n",
      "Epoch 609/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 610/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 611/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 612/1500\n",
      "27/27 [==============================] - 0s 296us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 613/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 614/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 615/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 616/1500\n",
      "27/27 [==============================] - 0s 317us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 617/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 618/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 619/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 620/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 621/1500\n",
      "27/27 [==============================] - 0s 307us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 622/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 623/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 624/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 625/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0816 - val_loss: 0.0926\n",
      "Epoch 626/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 627/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 628/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 629/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 630/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 631/1500\n",
      "27/27 [==============================] - 0s 284us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 632/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 633/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0815 - val_loss: 0.0926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 634/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 635/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0815 - val_loss: 0.0925\n",
      "Epoch 636/1500\n",
      "27/27 [==============================] - 0s 292us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 637/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 638/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0815 - val_loss: 0.0925\n",
      "Epoch 639/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0815 - val_loss: 0.0925\n",
      "Epoch 640/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 641/1500\n",
      "27/27 [==============================] - 0s 320us/step - loss: 0.0815 - val_loss: 0.0925\n",
      "Epoch 642/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0815 - val_loss: 0.0925\n",
      "Epoch 643/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0815 - val_loss: 0.0926\n",
      "Epoch 644/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0815 - val_loss: 0.0925\n",
      "Epoch 645/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 646/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0814 - val_loss: 0.0926\n",
      "Epoch 647/1500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 648/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 649/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0814 - val_loss: 0.0926\n",
      "Epoch 650/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 651/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 652/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 653/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 654/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0814 - val_loss: 0.0924\n",
      "Epoch 655/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 656/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 657/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 658/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0814 - val_loss: 0.0924\n",
      "Epoch 659/1500\n",
      "27/27 [==============================] - 0s 307us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 660/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 661/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0814 - val_loss: 0.0924\n",
      "Epoch 662/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0814 - val_loss: 0.0925\n",
      "Epoch 663/1500\n",
      "27/27 [==============================] - 0s 691us/step - loss: 0.0813 - val_loss: 0.0925\n",
      "Epoch 664/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 665/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0813 - val_loss: 0.0925\n",
      "Epoch 666/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0813 - val_loss: 0.0925\n",
      "Epoch 667/1500\n",
      "27/27 [==============================] - 0s 542us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 668/1500\n",
      "27/27 [==============================] - 0s 620us/step - loss: 0.0813 - val_loss: 0.0925\n",
      "Epoch 669/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0813 - val_loss: 0.0925\n",
      "Epoch 670/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 671/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0813 - val_loss: 0.0925\n",
      "Epoch 672/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 673/1500\n",
      "27/27 [==============================] - 0s 330us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 674/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0813 - val_loss: 0.0925\n",
      "Epoch 675/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 676/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 677/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0813 - val_loss: 0.0925\n",
      "Epoch 678/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 679/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 680/1500\n",
      "27/27 [==============================] - 0s 563us/step - loss: 0.0813 - val_loss: 0.0925\n",
      "Epoch 681/1500\n",
      "27/27 [==============================] - 0s 717us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 682/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0813 - val_loss: 0.0924\n",
      "Epoch 683/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 684/1500\n",
      "27/27 [==============================] - 0s 675us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 685/1500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 686/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 687/1500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 688/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 689/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 690/1500\n",
      "27/27 [==============================] - 0s 487us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 691/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 692/1500\n",
      "27/27 [==============================] - 0s 449us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 693/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 694/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 695/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0812 - val_loss: 0.0923\n",
      "Epoch 696/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 697/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 698/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0812 - val_loss: 0.0923\n",
      "Epoch 699/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 700/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 701/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0812 - val_loss: 0.0923\n",
      "Epoch 702/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0812 - val_loss: 0.0924\n",
      "Epoch 703/1500\n",
      "27/27 [==============================] - 0s 509us/step - loss: 0.0811 - val_loss: 0.0924\n",
      "Epoch 704/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 705/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 706/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0811 - val_loss: 0.0924\n",
      "Epoch 707/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0811 - val_loss: 0.0924\n",
      "Epoch 708/1500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 709/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 710/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0811 - val_loss: 0.0924\n",
      "Epoch 711/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 712/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0811 - val_loss: 0.0923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 714/1500\n",
      "27/27 [==============================] - 0s 299us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 715/1500\n",
      "27/27 [==============================] - 0s 304us/step - loss: 0.0811 - val_loss: 0.0922\n",
      "Epoch 716/1500\n",
      "27/27 [==============================] - 0s 303us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 717/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 718/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0811 - val_loss: 0.0922\n",
      "Epoch 719/1500\n",
      "27/27 [==============================] - 0s 305us/step - loss: 0.0811 - val_loss: 0.0922\n",
      "Epoch 720/1500\n",
      "27/27 [==============================] - 0s 301us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 721/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 722/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0811 - val_loss: 0.0922\n",
      "Epoch 723/1500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 0.0811 - val_loss: 0.0922\n",
      "Epoch 724/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0811 - val_loss: 0.0923\n",
      "Epoch 725/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0810 - val_loss: 0.0923\n",
      "Epoch 726/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 727/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 728/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 729/1500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.0810 - val_loss: 0.0923\n",
      "Epoch 730/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 731/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 732/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 733/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 734/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 735/1500\n",
      "27/27 [==============================] - 0s 320us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 736/1500\n",
      "27/27 [==============================] - 0s 292us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 737/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 738/1500\n",
      "27/27 [==============================] - 0s 319us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 739/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0810 - val_loss: 0.0921\n",
      "Epoch 740/1500\n",
      "27/27 [==============================] - 0s 308us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 741/1500\n",
      "27/27 [==============================] - 0s 309us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 742/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0810 - val_loss: 0.0921\n",
      "Epoch 743/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0810 - val_loss: 0.0921\n",
      "Epoch 744/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0810 - val_loss: 0.0922\n",
      "Epoch 745/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0810 - val_loss: 0.0921\n",
      "Epoch 746/1500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0810 - val_loss: 0.0921\n",
      "Epoch 747/1500\n",
      "27/27 [==============================] - 0s 788us/step - loss: 0.0810 - val_loss: 0.0921\n",
      "Epoch 748/1500\n",
      "27/27 [==============================] - 0s 664us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 749/1500\n",
      "27/27 [==============================] - 0s 532us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 750/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 751/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 752/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 753/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 754/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 755/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 756/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 757/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 758/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 759/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 760/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0809 - val_loss: 0.0921\n",
      "Epoch 761/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 762/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 763/1500\n",
      "27/27 [==============================] - 0s 302us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 764/1500\n",
      "27/27 [==============================] - 0s 511us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 765/1500\n",
      "27/27 [==============================] - 0s 582us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 766/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 767/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 768/1500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 769/1500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 770/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 771/1500\n",
      "27/27 [==============================] - 0s 507us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 772/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0809 - val_loss: 0.0920\n",
      "Epoch 773/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 774/1500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0808 - val_loss: 0.0920\n",
      "Epoch 775/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0808 - val_loss: 0.0920\n",
      "Epoch 776/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 777/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0808 - val_loss: 0.0920\n",
      "Epoch 778/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0808 - val_loss: 0.0920\n",
      "Epoch 779/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 780/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 781/1500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 782/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 783/1500\n",
      "27/27 [==============================] - 0s 499us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 784/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 785/1500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 786/1500\n",
      "27/27 [==============================] - 0s 500us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 787/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 788/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 789/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 790/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0808 - val_loss: 0.0918\n",
      "Epoch 791/1500\n",
      "27/27 [==============================] - 0s 494us/step - loss: 0.0808 - val_loss: 0.0919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 793/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 794/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0808 - val_loss: 0.0918\n",
      "Epoch 795/1500\n",
      "27/27 [==============================] - 0s 319us/step - loss: 0.0808 - val_loss: 0.0919\n",
      "Epoch 796/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0808 - val_loss: 0.0918\n",
      "Epoch 797/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0808 - val_loss: 0.0918\n",
      "Epoch 798/1500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0808 - val_loss: 0.0918\n",
      "Epoch 799/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 800/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 801/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 802/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0807 - val_loss: 0.0919\n",
      "Epoch 803/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 804/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 805/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 806/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 807/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 808/1500\n",
      "27/27 [==============================] - 0s 320us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 809/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 810/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 811/1500\n",
      "27/27 [==============================] - 0s 533us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 812/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 813/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 814/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 815/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 816/1500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 817/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0807 - val_loss: 0.0917\n",
      "Epoch 818/1500\n",
      "27/27 [==============================] - 0s 613us/step - loss: 0.0807 - val_loss: 0.0918\n",
      "Epoch 819/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0807 - val_loss: 0.0917\n",
      "Epoch 820/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0807 - val_loss: 0.0917\n",
      "Epoch 821/1500\n",
      "27/27 [==============================] - 0s 523us/step - loss: 0.0807 - val_loss: 0.0917\n",
      "Epoch 822/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0807 - val_loss: 0.0917\n",
      "Epoch 823/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0807 - val_loss: 0.0917\n",
      "Epoch 824/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0807 - val_loss: 0.0917\n",
      "Epoch 825/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0807 - val_loss: 0.0917\n",
      "Epoch 826/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0807 - val_loss: 0.0917\n",
      "Epoch 827/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 828/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 829/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 830/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 831/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 832/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 833/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 834/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 835/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 836/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 837/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 838/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 839/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 840/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 841/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 842/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0806 - val_loss: 0.0917\n",
      "Epoch 843/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 844/1500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 845/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 846/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 847/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 848/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 849/1500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 850/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 851/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 852/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 853/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 854/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 855/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 856/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 857/1500\n",
      "27/27 [==============================] - 0s 320us/step - loss: 0.0806 - val_loss: 0.0916\n",
      "Epoch 858/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0805 - val_loss: 0.0916\n",
      "Epoch 859/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0805 - val_loss: 0.0916\n",
      "Epoch 860/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0805 - val_loss: 0.0916\n",
      "Epoch 861/1500\n",
      "27/27 [==============================] - 0s 330us/step - loss: 0.0805 - val_loss: 0.0916\n",
      "Epoch 862/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 863/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0805 - val_loss: 0.0916\n",
      "Epoch 864/1500\n",
      "27/27 [==============================] - 0s 305us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 865/1500\n",
      "27/27 [==============================] - 0s 538us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 866/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 867/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 868/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 869/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 870/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0805 - val_loss: 0.0915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 872/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 873/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 874/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 875/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 876/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 877/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 878/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 879/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 880/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0805 - val_loss: 0.0914\n",
      "Epoch 881/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 882/1500\n",
      "27/27 [==============================] - 0s 306us/step - loss: 0.0805 - val_loss: 0.0914\n",
      "Epoch 883/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 884/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0805 - val_loss: 0.0914\n",
      "Epoch 885/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0805 - val_loss: 0.0915\n",
      "Epoch 886/1500\n",
      "27/27 [==============================] - 0s 305us/step - loss: 0.0805 - val_loss: 0.0914\n",
      "Epoch 887/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0805 - val_loss: 0.0914\n",
      "Epoch 888/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0805 - val_loss: 0.0914\n",
      "Epoch 889/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 890/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 891/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 892/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 893/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 894/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 895/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 896/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 897/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 898/1500\n",
      "27/27 [==============================] - 0s 320us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 899/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 900/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 901/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 902/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 903/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 904/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 905/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 906/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 907/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 908/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 909/1500\n",
      "27/27 [==============================] - 0s 309us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 910/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 911/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 912/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0804 - val_loss: 0.0913\n",
      "Epoch 913/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 914/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 915/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0804 - val_loss: 0.0913\n",
      "Epoch 916/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 917/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0804 - val_loss: 0.0913\n",
      "Epoch 918/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0804 - val_loss: 0.0913\n",
      "Epoch 919/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0804 - val_loss: 0.0914\n",
      "Epoch 920/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 921/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 922/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0803 - val_loss: 0.0914\n",
      "Epoch 923/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 924/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 925/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0803 - val_loss: 0.0914\n",
      "Epoch 926/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 927/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 928/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 929/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 930/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 931/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 932/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 933/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 934/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 935/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 936/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 937/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 938/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 939/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 940/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0803 - val_loss: 0.0912\n",
      "Epoch 941/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 942/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 943/1500\n",
      "27/27 [==============================] - 0s 330us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 944/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0803 - val_loss: 0.0912\n",
      "Epoch 945/1500\n",
      "27/27 [==============================] - 0s 517us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 946/1500\n",
      "27/27 [==============================] - 0s 549us/step - loss: 0.0803 - val_loss: 0.0912\n",
      "Epoch 947/1500\n",
      "27/27 [==============================] - 0s 506us/step - loss: 0.0803 - val_loss: 0.0912\n",
      "Epoch 948/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 949/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0803 - val_loss: 0.0912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950/1500\n",
      "27/27 [==============================] - 0s 486us/step - loss: 0.0803 - val_loss: 0.0912\n",
      "Epoch 951/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0803 - val_loss: 0.0912\n",
      "Epoch 952/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 953/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 954/1500\n",
      "27/27 [==============================] - 0s 298us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 955/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 956/1500\n",
      "27/27 [==============================] - 0s 298us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 957/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 958/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 959/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 960/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 961/1500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 962/1500\n",
      "27/27 [==============================] - 0s 542us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 963/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 964/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 965/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 966/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 967/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 968/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 969/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 970/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 971/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 972/1500\n",
      "27/27 [==============================] - 0s 768us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 973/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 974/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 975/1500\n",
      "27/27 [==============================] - 0s 791us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 976/1500\n",
      "27/27 [==============================] - 0s 584us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 977/1500\n",
      "27/27 [==============================] - 0s 644us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 978/1500\n",
      "27/27 [==============================] - 0s 991us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 979/1500\n",
      "27/27 [==============================] - 0s 518us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 980/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 981/1500\n",
      "27/27 [==============================] - 0s 519us/step - loss: 0.0802 - val_loss: 0.0912\n",
      "Epoch 982/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 983/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 984/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 985/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 986/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0802 - val_loss: 0.0911\n",
      "Epoch 987/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 988/1500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 989/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 990/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 991/1500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 992/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 993/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 994/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 995/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 996/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 997/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 998/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 999/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 1000/1500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 1001/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 1002/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 1003/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1004/1500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 1005/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0801 - val_loss: 0.0911\n",
      "Epoch 1006/1500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1007/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1008/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1009/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1010/1500\n",
      "27/27 [==============================] - 0s 488us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1011/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1012/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1013/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1014/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1015/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1016/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1017/1500\n",
      "27/27 [==============================] - 0s 477us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1018/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1019/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1020/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1021/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1022/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1023/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1024/1500\n",
      "27/27 [==============================] - 0s 502us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 1025/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1026/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1027/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1028/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0800 - val_loss: 0.0910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1029/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1030/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1031/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1032/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1033/1500\n",
      "27/27 [==============================] - 0s 575us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1034/1500\n",
      "27/27 [==============================] - 0s 523us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1035/1500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1036/1500\n",
      "27/27 [==============================] - 0s 536us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1037/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1038/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1039/1500\n",
      "27/27 [==============================] - 0s 305us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1040/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1041/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1042/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1043/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1044/1500\n",
      "27/27 [==============================] - 0s 300us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1045/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1046/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0800 - val_loss: 0.0910\n",
      "Epoch 1047/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1048/1500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1049/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1050/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1051/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1052/1500\n",
      "27/27 [==============================] - 0s 310us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1053/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1054/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1055/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1056/1500\n",
      "27/27 [==============================] - 0s 297us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1057/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1058/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1059/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1060/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1061/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1062/1500\n",
      "27/27 [==============================] - 0s 313us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1063/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1064/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1065/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0800 - val_loss: 0.0909\n",
      "Epoch 1066/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0799 - val_loss: 0.0909\n",
      "Epoch 1067/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0799 - val_loss: 0.0909\n",
      "Epoch 1068/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0799 - val_loss: 0.0909\n",
      "Epoch 1069/1500\n",
      "27/27 [==============================] - 0s 316us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1070/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0799 - val_loss: 0.0909\n",
      "Epoch 1071/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0799 - val_loss: 0.0909\n",
      "Epoch 1072/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1073/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0799 - val_loss: 0.0909\n",
      "Epoch 1074/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1075/1500\n",
      "27/27 [==============================] - 0s 295us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1076/1500\n",
      "27/27 [==============================] - 0s 523us/step - loss: 0.0799 - val_loss: 0.0909\n",
      "Epoch 1077/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1078/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1079/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0799 - val_loss: 0.0909\n",
      "Epoch 1080/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1081/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0799 - val_loss: 0.0909\n",
      "Epoch 1082/1500\n",
      "27/27 [==============================] - 0s 306us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1083/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1084/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1085/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1086/1500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1087/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1088/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1089/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1090/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1091/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1092/1500\n",
      "27/27 [==============================] - 0s 295us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1093/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1094/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1095/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1096/1500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1097/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1098/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1099/1500\n",
      "27/27 [==============================] - 0s 296us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1100/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1101/1500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1102/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0799 - val_loss: 0.0907\n",
      "Epoch 1103/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1104/1500\n",
      "27/27 [==============================] - 0s 280us/step - loss: 0.0799 - val_loss: 0.0907\n",
      "Epoch 1105/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0799 - val_loss: 0.0908\n",
      "Epoch 1106/1500\n",
      "27/27 [==============================] - 0s 312us/step - loss: 0.0799 - val_loss: 0.0907\n",
      "Epoch 1107/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 336us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1108/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0798 - val_loss: 0.0908\n",
      "Epoch 1109/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1110/1500\n",
      "27/27 [==============================] - 0s 479us/step - loss: 0.0798 - val_loss: 0.0908\n",
      "Epoch 1111/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1112/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1113/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1114/1500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1115/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1116/1500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1117/1500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1118/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1119/1500\n",
      "27/27 [==============================] - 0s 538us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1120/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1121/1500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1122/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1123/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1124/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1125/1500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1126/1500\n",
      "27/27 [==============================] - 0s 292us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1127/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1128/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1129/1500\n",
      "27/27 [==============================] - 0s 305us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1130/1500\n",
      "27/27 [==============================] - 0s 296us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1131/1500\n",
      "27/27 [==============================] - 0s 295us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1132/1500\n",
      "27/27 [==============================] - 0s 297us/step - loss: 0.0798 - val_loss: 0.0907\n",
      "Epoch 1133/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1134/1500\n",
      "27/27 [==============================] - 0s 308us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1135/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1136/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1137/1500\n",
      "27/27 [==============================] - 0s 316us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1138/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1139/1500\n",
      "27/27 [==============================] - 0s 305us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1140/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1141/1500\n",
      "27/27 [==============================] - 0s 286us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1142/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0798 - val_loss: 0.0905\n",
      "Epoch 1143/1500\n",
      "27/27 [==============================] - 0s 312us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1144/1500\n",
      "27/27 [==============================] - 0s 274us/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 1145/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0798 - val_loss: 0.0905\n",
      "Epoch 1146/1500\n",
      "27/27 [==============================] - 0s 319us/step - loss: 0.0798 - val_loss: 0.0905\n",
      "Epoch 1147/1500\n",
      "27/27 [==============================] - 0s 265us/step - loss: 0.0798 - val_loss: 0.0905\n",
      "Epoch 1148/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1149/1500\n",
      "27/27 [==============================] - 0s 319us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1150/1500\n",
      "27/27 [==============================] - 0s 330us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1151/1500\n",
      "27/27 [==============================] - 0s 312us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1152/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1153/1500\n",
      "27/27 [==============================] - 0s 293us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1154/1500\n",
      "27/27 [==============================] - 0s 303us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1155/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1156/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1157/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1158/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1159/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1160/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1161/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1162/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1163/1500\n",
      "27/27 [==============================] - 0s 321us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1164/1500\n",
      "27/27 [==============================] - 0s 304us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1165/1500\n",
      "27/27 [==============================] - 0s 294us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1166/1500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1167/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1168/1500\n",
      "27/27 [==============================] - 0s 316us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1169/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1170/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1171/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1172/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0797 - val_loss: 0.0905\n",
      "Epoch 1173/1500\n",
      "27/27 [==============================] - 0s 493us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1174/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1175/1500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1176/1500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1177/1500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1178/1500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1179/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1180/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1181/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1182/1500\n",
      "27/27 [==============================] - 0s 503us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1183/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1184/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1185/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0797 - val_loss: 0.0904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1186/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1187/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1188/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1189/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1190/1500\n",
      "27/27 [==============================] - 0s 320us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1191/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1192/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1193/1500\n",
      "27/27 [==============================] - 0s 282us/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 1194/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1195/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1196/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1197/1500\n",
      "27/27 [==============================] - 0s 309us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1198/1500\n",
      "27/27 [==============================] - 0s 299us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1199/1500\n",
      "27/27 [==============================] - 0s 309us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1200/1500\n",
      "27/27 [==============================] - 0s 293us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1201/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1202/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1203/1500\n",
      "27/27 [==============================] - 0s 265us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1204/1500\n",
      "27/27 [==============================] - 0s 286us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1205/1500\n",
      "27/27 [==============================] - 0s 269us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1206/1500\n",
      "27/27 [==============================] - 0s 282us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1207/1500\n",
      "27/27 [==============================] - 0s 281us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1208/1500\n",
      "27/27 [==============================] - 0s 269us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1209/1500\n",
      "27/27 [==============================] - 0s 287us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1210/1500\n",
      "27/27 [==============================] - 0s 266us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1211/1500\n",
      "27/27 [==============================] - 0s 321us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1212/1500\n",
      "27/27 [==============================] - 0s 291us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1213/1500\n",
      "27/27 [==============================] - 0s 304us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1214/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1215/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1216/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1217/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1218/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1219/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1220/1500\n",
      "27/27 [==============================] - 0s 487us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1221/1500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1222/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1223/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1224/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1225/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1226/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1227/1500\n",
      "27/27 [==============================] - 0s 486us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1228/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1229/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0796 - val_loss: 0.0904\n",
      "Epoch 1230/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1231/1500\n",
      "27/27 [==============================] - 0s 310us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1232/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1233/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1234/1500\n",
      "27/27 [==============================] - 0s 304us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1235/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1236/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1237/1500\n",
      "27/27 [==============================] - 0s 312us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1238/1500\n",
      "27/27 [==============================] - 0s 312us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1239/1500\n",
      "27/27 [==============================] - 0s 313us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1240/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0796 - val_loss: 0.0903\n",
      "Epoch 1241/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1242/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1243/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1244/1500\n",
      "27/27 [==============================] - 0s 306us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1245/1500\n",
      "27/27 [==============================] - 0s 309us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1246/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1247/1500\n",
      "27/27 [==============================] - 0s 302us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1248/1500\n",
      "27/27 [==============================] - 0s 296us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1249/1500\n",
      "27/27 [==============================] - 0s 306us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1250/1500\n",
      "27/27 [==============================] - 0s 288us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1251/1500\n",
      "27/27 [==============================] - 0s 313us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1252/1500\n",
      "27/27 [==============================] - 0s 280us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1253/1500\n",
      "27/27 [==============================] - 0s 295us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1254/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1255/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1256/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1257/1500\n",
      "27/27 [==============================] - 0s 320us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1258/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1259/1500\n",
      "27/27 [==============================] - 0s 293us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1260/1500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1261/1500\n",
      "27/27 [==============================] - 0s 310us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1262/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1263/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0795 - val_loss: 0.0903\n",
      "Epoch 1264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 330us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1265/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1266/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1267/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1268/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1269/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1270/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1271/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1272/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1273/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1274/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1275/1500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1276/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1277/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1278/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1279/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1280/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1281/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1282/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0795 - val_loss: 0.0901\n",
      "Epoch 1283/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1284/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.0795 - val_loss: 0.0902\n",
      "Epoch 1285/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0795 - val_loss: 0.0901\n",
      "Epoch 1286/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1287/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1288/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1289/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1290/1500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1291/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1292/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1293/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1294/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1295/1500\n",
      "27/27 [==============================] - 0s 305us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1296/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1297/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1298/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1299/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1300/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1301/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1302/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1303/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1304/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1305/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1306/1500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1307/1500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1308/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1309/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1310/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1311/1500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1312/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1313/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1314/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1315/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1316/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1317/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1318/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1319/1500\n",
      "27/27 [==============================] - 0s 302us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1320/1500\n",
      "27/27 [==============================] - 0s 291us/step - loss: 0.0794 - val_loss: 0.0901\n",
      "Epoch 1321/1500\n",
      "27/27 [==============================] - 0s 315us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1322/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0794 - val_loss: 0.0902\n",
      "Epoch 1323/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1324/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1325/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0793 - val_loss: 0.0902\n",
      "Epoch 1326/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1327/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1328/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0793 - val_loss: 0.0902\n",
      "Epoch 1329/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1330/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1331/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1332/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1333/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1334/1500\n",
      "27/27 [==============================] - 0s 301us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1335/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1336/1500\n",
      "27/27 [==============================] - 0s 305us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1337/1500\n",
      "27/27 [==============================] - 0s 290us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1338/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1339/1500\n",
      "27/27 [==============================] - 0s 271us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1340/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1341/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1342/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0793 - val_loss: 0.0902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1343/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1344/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1345/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0793 - val_loss: 0.0902\n",
      "Epoch 1346/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1347/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1348/1500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.0793 - val_loss: 0.0902\n",
      "Epoch 1349/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1350/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1351/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0793 - val_loss: 0.0902\n",
      "Epoch 1352/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0793 - val_loss: 0.0902\n",
      "Epoch 1353/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1354/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1355/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0793 - val_loss: 0.0902\n",
      "Epoch 1356/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0793 - val_loss: 0.0902\n",
      "Epoch 1357/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0793 - val_loss: 0.0901\n",
      "Epoch 1358/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0793 - val_loss: 0.0902\n",
      "Epoch 1359/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1360/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1361/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1362/1500\n",
      "27/27 [==============================] - 0s 292us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1363/1500\n",
      "27/27 [==============================] - 0s 306us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1364/1500\n",
      "27/27 [==============================] - 0s 312us/step - loss: 0.0792 - val_loss: 0.0901\n",
      "Epoch 1365/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1366/1500\n",
      "27/27 [==============================] - 0s 321us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1367/1500\n",
      "27/27 [==============================] - 0s 314us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1368/1500\n",
      "27/27 [==============================] - 0s 302us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1369/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1370/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1371/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1372/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1373/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1374/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1375/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1376/1500\n",
      "27/27 [==============================] - 0s 311us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1377/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1378/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1379/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1380/1500\n",
      "27/27 [==============================] - 0s 303us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1381/1500\n",
      "27/27 [==============================] - 0s 309us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1382/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1383/1500\n",
      "27/27 [==============================] - 0s 321us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1384/1500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1385/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1386/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1387/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1388/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1389/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1390/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1391/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1392/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1393/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1394/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0792 - val_loss: 0.0902\n",
      "Epoch 1395/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1396/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1397/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1398/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1399/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1400/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1401/1500\n",
      "27/27 [==============================] - 0s 310us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1402/1500\n",
      "27/27 [==============================] - 0s 343us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1403/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1404/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1405/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1406/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1407/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1408/1500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1409/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1410/1500\n",
      "27/27 [==============================] - 0s 332us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1411/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1412/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1413/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1414/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1415/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1416/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1417/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1418/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1419/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1420/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0791 - val_loss: 0.0903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1421/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1422/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1423/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1424/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1425/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0791 - val_loss: 0.0903\n",
      "Epoch 1426/1500\n",
      "27/27 [==============================] - 0s 326us/step - loss: 0.0791 - val_loss: 0.0902\n",
      "Epoch 1427/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1428/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1429/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1430/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1431/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1432/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1433/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1434/1500\n",
      "27/27 [==============================] - 0s 271us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1435/1500\n",
      "27/27 [==============================] - 0s 301us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1436/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1437/1500\n",
      "27/27 [==============================] - 0s 294us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1438/1500\n",
      "27/27 [==============================] - 0s 290us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1439/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1440/1500\n",
      "27/27 [==============================] - 0s 286us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1441/1500\n",
      "27/27 [==============================] - 0s 301us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1442/1500\n",
      "27/27 [==============================] - 0s 292us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1443/1500\n",
      "27/27 [==============================] - 0s 291us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1444/1500\n",
      "27/27 [==============================] - 0s 277us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1445/1500\n",
      "27/27 [==============================] - 0s 285us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1446/1500\n",
      "27/27 [==============================] - 0s 275us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1447/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1448/1500\n",
      "27/27 [==============================] - 0s 277us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1449/1500\n",
      "27/27 [==============================] - 0s 296us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1450/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1451/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0790 - val_loss: 0.0904\n",
      "Epoch 1452/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0790 - val_loss: 0.0904\n",
      "Epoch 1453/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1454/1500\n",
      "27/27 [==============================] - 0s 499us/step - loss: 0.0790 - val_loss: 0.0903\n",
      "Epoch 1455/1500\n",
      "27/27 [==============================] - 0s 491us/step - loss: 0.0790 - val_loss: 0.0904\n",
      "Epoch 1456/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0790 - val_loss: 0.0904\n",
      "Epoch 1457/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0789 - val_loss: 0.0903\n",
      "Epoch 1458/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1459/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1460/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1461/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1462/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1463/1500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1464/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1465/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1466/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1467/1500\n",
      "27/27 [==============================] - 0s 307us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1468/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1469/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1470/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1471/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1472/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1473/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1474/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1475/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0789 - val_loss: 0.0905\n",
      "Epoch 1476/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1477/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0789 - val_loss: 0.0905\n",
      "Epoch 1478/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1479/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0789 - val_loss: 0.0905\n",
      "Epoch 1480/1500\n",
      "27/27 [==============================] - 0s 303us/step - loss: 0.0789 - val_loss: 0.0905\n",
      "Epoch 1481/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0789 - val_loss: 0.0904\n",
      "Epoch 1482/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0789 - val_loss: 0.0905\n",
      "Epoch 1483/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0789 - val_loss: 0.0905\n",
      "Epoch 1484/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0789 - val_loss: 0.0905\n",
      "Epoch 1485/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1486/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1487/1500\n",
      "27/27 [==============================] - 0s 307us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1488/1500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1489/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1490/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1491/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1492/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1493/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1494/1500\n",
      "27/27 [==============================] - 0s 319us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1495/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1496/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1497/1500\n",
      "27/27 [==============================] - 0s 312us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1498/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0788 - val_loss: 0.0905\n",
      "Epoch 1499/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0788 - val_loss: 0.0905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0788 - val_loss: 0.0905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2641d128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "autoencoder.fit(((t_all[:30, 0, :, :]-t_all[:30, 1, :, :]).reshape(-1, num_days, num_hours,1)/maxs[0]),(t_all[:30, appliance_num, :, :].reshape(-1, num_days, num_hours,1) /maxs[appliance_num])\n",
    "                ,validation_split=0.1,epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = maxs[appliance_num]*autoencoder.predict((t_all[30:, 0, :, :]-t_all[30:, 1, :, :]).reshape(-1, num_days, num_hours,1)/maxs[0]).reshape(-1, num_days, num_hours)\n",
    "gt =t_all[30:, appliance_num, :, :]\n",
    "\n",
    "\n",
    "pred_fl = pred.flatten()\n",
    "gt_fl = gt.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22, 14, 24), (30, 14, 24, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape, (t_all[:30, 0, :, :].reshape(-1, num_days, num_hours,1)/maxs[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.172464696846166"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(gt_fl, pred_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 3 samples\n",
      "Epoch 1/1500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0533 - val_loss: 0.0446\n",
      "Epoch 2/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0415 - val_loss: 0.0355\n",
      "Epoch 3/1500\n",
      "27/27 [==============================] - 0s 502us/step - loss: 0.0326 - val_loss: 0.0282\n",
      "Epoch 4/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0259 - val_loss: 0.0228\n",
      "Epoch 5/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0211 - val_loss: 0.0190\n",
      "Epoch 6/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0179 - val_loss: 0.0165\n",
      "Epoch 7/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0156 - val_loss: 0.0146\n",
      "Epoch 8/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0139 - val_loss: 0.0133\n",
      "Epoch 9/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0127 - val_loss: 0.0124\n",
      "Epoch 10/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 11/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 12/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 13/1500\n",
      "27/27 [==============================] - 0s 512us/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 14/1500\n",
      "27/27 [==============================] - 0s 500us/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 15/1500\n",
      "27/27 [==============================] - 0s 497us/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 16/1500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 17/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 18/1500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 19/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 20/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 21/1500\n",
      "27/27 [==============================] - 0s 517us/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 22/1500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 23/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 24/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 25/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 26/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 27/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 28/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 29/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 30/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 31/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 32/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 33/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 34/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 35/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 36/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 37/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 38/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 39/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 40/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 41/1500\n",
      "27/27 [==============================] - 0s 325us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 42/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 43/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 44/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 45/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 46/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 47/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 48/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 49/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 50/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 51/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 52/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 53/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 54/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 55/1500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 56/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 57/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 58/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 59/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 60/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 61/1500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 62/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 63/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 64/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 65/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 66/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 67/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 68/1500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 69/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 70/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 71/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 72/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 73/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 74/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 75/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 76/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 77/1500\n",
      "27/27 [==============================] - 0s 481us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 78/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 79/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 80/1500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0101 - val_loss: 0.0109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 82/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 83/1500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 84/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 85/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 86/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 87/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 88/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 89/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 90/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 91/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 92/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 93/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 94/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 95/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 96/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 97/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 98/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 99/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 100/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 101/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 102/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 103/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 104/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 105/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 106/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 107/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 108/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 109/1500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 110/1500\n",
      "27/27 [==============================] - 0s 520us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 111/1500\n",
      "27/27 [==============================] - 0s 476us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 112/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 113/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 114/1500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 115/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 116/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 117/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 118/1500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 119/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 120/1500\n",
      "27/27 [==============================] - 0s 299us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 121/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 122/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 123/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 124/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 125/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 126/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 127/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 128/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 129/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 130/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 131/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 132/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 133/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 134/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 135/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 136/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 137/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 138/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 139/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 140/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 141/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 142/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 143/1500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 144/1500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 145/1500\n",
      "27/27 [==============================] - 0s 554us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 146/1500\n",
      "27/27 [==============================] - 0s 517us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 147/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 148/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 149/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 150/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 151/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 152/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 153/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 154/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 155/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 156/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 157/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 158/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 159/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0099 - val_loss: 0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 161/1500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 162/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 163/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 164/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 165/1500\n",
      "27/27 [==============================] - 0s 486us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 166/1500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 167/1500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 168/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 169/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 170/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 171/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 172/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 173/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 174/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 175/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 176/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 177/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 178/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 179/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 180/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 181/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 182/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 183/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 184/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 185/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 186/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 187/1500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 188/1500\n",
      "27/27 [==============================] - 0s 493us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 189/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 190/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 191/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 192/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 193/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 194/1500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 195/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 196/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 197/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 198/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 199/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 200/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 201/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 202/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 203/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 204/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 205/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 206/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 207/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 208/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 209/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 210/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 211/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 212/1500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 213/1500\n",
      "27/27 [==============================] - 0s 508us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 214/1500\n",
      "27/27 [==============================] - 0s 521us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 215/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 216/1500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 217/1500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 218/1500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 219/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 220/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 221/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 222/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 223/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 224/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 225/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 226/1500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 227/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 228/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 229/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 230/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 231/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 232/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 233/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 234/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 235/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 236/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 237/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 238/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0097 - val_loss: 0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 240/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 241/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 242/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 243/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 244/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 245/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 246/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 247/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 248/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 249/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 250/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 251/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 252/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 253/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 254/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 255/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 256/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 257/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 258/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 259/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 260/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 261/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 262/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 263/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 264/1500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 265/1500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 266/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 267/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 268/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 269/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 270/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 271/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 272/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 273/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 274/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 275/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 276/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 277/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 278/1500\n",
      "27/27 [==============================] - 0s 494us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 279/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 280/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 281/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 282/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 283/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 284/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 285/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 286/1500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 287/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 288/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 289/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 290/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 291/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 292/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 293/1500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 294/1500\n",
      "27/27 [==============================] - 0s 577us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 295/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 296/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 297/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 298/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 299/1500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 300/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 301/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 302/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 303/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 304/1500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 305/1500\n",
      "27/27 [==============================] - 0s 487us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 306/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 307/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 308/1500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 309/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 310/1500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 311/1500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 312/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 313/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 314/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 315/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 316/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 317/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0096 - val_loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 319/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 320/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 321/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 322/1500\n",
      "27/27 [==============================] - 0s 539us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 323/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 324/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 325/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 326/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 327/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 328/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 329/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 330/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 331/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 332/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 333/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 334/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 335/1500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 336/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 337/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 338/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 339/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 340/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 341/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 342/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 343/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 344/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 345/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 346/1500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 347/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 348/1500\n",
      "27/27 [==============================] - 0s 479us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 349/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 350/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 351/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 352/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 353/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 354/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 355/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 356/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 357/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 358/1500\n",
      "27/27 [==============================] - 0s 483us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 359/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 360/1500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 361/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 362/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 363/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 364/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 365/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 366/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 367/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 368/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 369/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 370/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 371/1500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 372/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 373/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 374/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 375/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 376/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 377/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 378/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 379/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 380/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 381/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 382/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 383/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 384/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 385/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 386/1500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 387/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 388/1500\n",
      "27/27 [==============================] - 0s 497us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 389/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 390/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 391/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 392/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 393/1500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 394/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 395/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 396/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0094 - val_loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 398/1500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 399/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 400/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 401/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 402/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 403/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 404/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 405/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 406/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 407/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 408/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 409/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 410/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 411/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 412/1500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 413/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 414/1500\n",
      "27/27 [==============================] - 0s 493us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 415/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 416/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 417/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 418/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 419/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 420/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 421/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 422/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 423/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 424/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 425/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 426/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 427/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 428/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 429/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 430/1500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 431/1500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 432/1500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 433/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 434/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 435/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 436/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 437/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 438/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 439/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 440/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 441/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 442/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 443/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 444/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 445/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 446/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 447/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 448/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 449/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 450/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 451/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 452/1500\n",
      "27/27 [==============================] - 0s 514us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 453/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 454/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 455/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 456/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 457/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 458/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 459/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 460/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 461/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 462/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 463/1500\n",
      "27/27 [==============================] - 0s 328us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 464/1500\n",
      "27/27 [==============================] - 0s 313us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 465/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 466/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 467/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 468/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 469/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 470/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 471/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 472/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 473/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 474/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 475/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0092 - val_loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 477/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 478/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 479/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 480/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 481/1500\n",
      "27/27 [==============================] - 0s 499us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 482/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 483/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 484/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 485/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 486/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 487/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 488/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 489/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 490/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 491/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 492/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 493/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0091 - val_loss: 0.0101\n",
      "Epoch 494/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 495/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 496/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 497/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 498/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 499/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 500/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 501/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 502/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 503/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 504/1500\n",
      "27/27 [==============================] - 0s 494us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 505/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 506/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 507/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 508/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 509/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 510/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 511/1500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 512/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 513/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 514/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 515/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 516/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 517/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 518/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 519/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 520/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 521/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 522/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 523/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 524/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 525/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 526/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 527/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 528/1500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 529/1500\n",
      "27/27 [==============================] - 0s 500us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 530/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 531/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 532/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 533/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 534/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 535/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 536/1500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 537/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 538/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 539/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 540/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 541/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 542/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 543/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 544/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 545/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 546/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 547/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 548/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 549/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 550/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 551/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 552/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 553/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 554/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0090 - val_loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/1500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 556/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 557/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 558/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 559/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 560/1500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 561/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 562/1500\n",
      "27/27 [==============================] - 0s 277us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 563/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 564/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 565/1500\n",
      "27/27 [==============================] - 0s 494us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 566/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 567/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 568/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 569/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 570/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 571/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 572/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 573/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 574/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 575/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 576/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 577/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 578/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 579/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 580/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 581/1500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 582/1500\n",
      "27/27 [==============================] - 0s 517us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 583/1500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 584/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 585/1500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 586/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 587/1500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 588/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 589/1500\n",
      "27/27 [==============================] - 0s 477us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 590/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 591/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 592/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 593/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 594/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 595/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 596/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 597/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 598/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 599/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 600/1500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 601/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 602/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 603/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 604/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 605/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 606/1500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 607/1500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 608/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 609/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 610/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 611/1500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 612/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 613/1500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 614/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 615/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 616/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 617/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 618/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 619/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 620/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 621/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 622/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 623/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 624/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 625/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 626/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 627/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 628/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 629/1500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 630/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 631/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 632/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 633/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0088 - val_loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 634/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 635/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 636/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 637/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 638/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 639/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 640/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 641/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 642/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 643/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 644/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 645/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 646/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 647/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 648/1500\n",
      "27/27 [==============================] - 0s 497us/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 649/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 650/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 651/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 652/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 653/1500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 654/1500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 655/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 656/1500\n",
      "27/27 [==============================] - 0s 491us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 657/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 658/1500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 659/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 660/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 661/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 662/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 663/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 664/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 665/1500\n",
      "27/27 [==============================] - 0s 494us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 666/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 667/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 668/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 669/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 670/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 671/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 672/1500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 673/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 674/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 675/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 676/1500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 677/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 678/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 679/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 680/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 681/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 682/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 683/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 684/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 685/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 686/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 687/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 688/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 689/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 690/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 691/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 692/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 693/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 694/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 695/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 696/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 697/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 698/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 699/1500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 700/1500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 701/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 702/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 703/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 704/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 705/1500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 706/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 707/1500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 708/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 709/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 710/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 711/1500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 712/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0086 - val_loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 714/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 715/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 716/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 717/1500\n",
      "27/27 [==============================] - 0s 449us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 718/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 719/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 720/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 721/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 722/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 723/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 724/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 725/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 726/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 727/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 728/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 729/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 730/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 731/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 732/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 733/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 734/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 735/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 736/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 737/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 738/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 739/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 740/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 741/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 742/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 743/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 744/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 745/1500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 746/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 747/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 748/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 749/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 750/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 751/1500\n",
      "27/27 [==============================] - 0s 486us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 752/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 753/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 754/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 755/1500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 756/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 757/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 758/1500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 759/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 760/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 761/1500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 762/1500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 763/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 764/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 765/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 766/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 767/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 768/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 769/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 770/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 771/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 772/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 773/1500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 774/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 775/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 776/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 777/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 778/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 779/1500\n",
      "27/27 [==============================] - 0s 488us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 780/1500\n",
      "27/27 [==============================] - 0s 525us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 781/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 782/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 783/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 784/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 785/1500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 786/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 787/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 788/1500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 789/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 790/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 791/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0084 - val_loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 793/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 794/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 795/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 796/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 797/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 798/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 799/1500\n",
      "27/27 [==============================] - 0s 518us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 800/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 801/1500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 802/1500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 803/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 804/1500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 805/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 806/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 807/1500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 808/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 809/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 810/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 811/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 812/1500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 813/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 814/1500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 815/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 816/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 817/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 818/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 819/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 820/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 821/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 822/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 823/1500\n",
      "27/27 [==============================] - 0s 479us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 824/1500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 825/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 826/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 827/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 828/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 829/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 830/1500\n",
      "27/27 [==============================] - 0s 488us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 831/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 832/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 833/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 834/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 835/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 836/1500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 837/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 838/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 839/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 840/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 841/1500\n",
      "27/27 [==============================] - 0s 491us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 842/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 843/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 844/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 845/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 846/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 847/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 848/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 849/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 850/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 851/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 852/1500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 853/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 854/1500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 855/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 856/1500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 857/1500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 858/1500\n",
      "27/27 [==============================] - 0s 506us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 859/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 860/1500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 861/1500\n",
      "27/27 [==============================] - 0s 481us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 862/1500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 863/1500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 864/1500\n",
      "27/27 [==============================] - 0s 553us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 865/1500\n",
      "27/27 [==============================] - 0s 504us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 866/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 867/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 868/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 869/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 870/1500\n",
      "27/27 [==============================] - 0s 502us/step - loss: 0.0082 - val_loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 872/1500\n",
      "27/27 [==============================] - 0s 487us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 873/1500\n",
      "27/27 [==============================] - 0s 476us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 874/1500\n",
      "27/27 [==============================] - 0s 520us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 875/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 876/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 877/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 878/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 879/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 880/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 881/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 882/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 883/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 884/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 885/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 886/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 887/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 888/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 889/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 890/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 891/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 892/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 893/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 894/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 895/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 896/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 897/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 898/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 899/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 900/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 901/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 902/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 903/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 904/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 905/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 906/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 907/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 908/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 909/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 910/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 911/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 912/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 913/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 914/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 915/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 916/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 917/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 918/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 919/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 920/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 921/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 922/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 923/1500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 924/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 925/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 926/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 927/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 928/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 929/1500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 930/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 931/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 932/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 933/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 934/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 935/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 936/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 937/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 938/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 939/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 940/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 941/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 942/1500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 943/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 944/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 945/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 946/1500\n",
      "27/27 [==============================] - 0s 449us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 947/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 948/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 949/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0081 - val_loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950/1500\n",
      "27/27 [==============================] - 0s 323us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 951/1500\n",
      "27/27 [==============================] - 0s 338us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 952/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 953/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 954/1500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 955/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 956/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 957/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 958/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 959/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 960/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 961/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 962/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 963/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 964/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 965/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 966/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 967/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 968/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 969/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 970/1500\n",
      "27/27 [==============================] - 0s 333us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 971/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 972/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 973/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 974/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 975/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 976/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 977/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 978/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 979/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 980/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 981/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 982/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 983/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 984/1500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 985/1500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 986/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 987/1500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 988/1500\n",
      "27/27 [==============================] - 0s 477us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 989/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 990/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 991/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 992/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 993/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 994/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 995/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 996/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 997/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 998/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 999/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1000/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1001/1500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1002/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1003/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1004/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1005/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1006/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1007/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1008/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1009/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1010/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1011/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1012/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1013/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1014/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1015/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1016/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1017/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1018/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1019/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1020/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1021/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1022/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1023/1500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1024/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1025/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1026/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1027/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1028/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0079 - val_loss: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1029/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1030/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1031/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1032/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1033/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1034/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 1035/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1036/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1037/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1038/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1039/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1040/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1041/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1042/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1043/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1044/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1045/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1046/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1047/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1048/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1049/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1050/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1051/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1052/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1053/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1054/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1055/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1056/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1057/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1058/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 1059/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1060/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1061/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1062/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1063/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1064/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1065/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1066/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1067/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1068/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1069/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1070/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1071/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1072/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1073/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1074/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1075/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1076/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1077/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 1078/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1079/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1080/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1081/1500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1082/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1083/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1084/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1085/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1086/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1087/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1088/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1089/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1090/1500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1091/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1092/1500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1093/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1094/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1095/1500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1096/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1097/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1098/1500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1099/1500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1100/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1101/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1102/1500\n",
      "27/27 [==============================] - 0s 479us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1103/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1104/1500\n",
      "27/27 [==============================] - 0s 509us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1105/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1106/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1107/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 405us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1108/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1109/1500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1110/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1111/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1112/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1113/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1114/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1115/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1116/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1117/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1118/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1119/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1120/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1121/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1122/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1123/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1124/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1125/1500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1126/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1127/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1128/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1129/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1130/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1131/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1132/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1133/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1134/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1135/1500\n",
      "27/27 [==============================] - 0s 488us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1136/1500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1137/1500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1138/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1139/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1140/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1141/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1142/1500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1143/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1144/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1145/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1146/1500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1147/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1148/1500\n",
      "27/27 [==============================] - 0s 555us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1149/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1150/1500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1151/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1152/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1153/1500\n",
      "27/27 [==============================] - 0s 530us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1154/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1155/1500\n",
      "27/27 [==============================] - 0s 494us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1156/1500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1157/1500\n",
      "27/27 [==============================] - 0s 535us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1158/1500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1159/1500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1160/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1161/1500\n",
      "27/27 [==============================] - 0s 513us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1162/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1163/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1164/1500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1165/1500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1166/1500\n",
      "27/27 [==============================] - 0s 494us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1167/1500\n",
      "27/27 [==============================] - 0s 502us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1168/1500\n",
      "27/27 [==============================] - 0s 544us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1169/1500\n",
      "27/27 [==============================] - 0s 514us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1170/1500\n",
      "27/27 [==============================] - 0s 534us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1171/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1172/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1173/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1174/1500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1175/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1176/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1177/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1178/1500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1179/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1180/1500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1181/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1182/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1183/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1184/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1185/1500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0075 - val_loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1186/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1187/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1188/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1189/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1190/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1191/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1192/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1193/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1194/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1195/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1196/1500\n",
      "27/27 [==============================] - 0s 349us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1197/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1198/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1199/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1200/1500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1201/1500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1202/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1203/1500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1204/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1205/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1206/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1207/1500\n",
      "27/27 [==============================] - 0s 334us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1208/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1209/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1210/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1211/1500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1212/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1213/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1214/1500\n",
      "27/27 [==============================] - 0s 350us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1215/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1216/1500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1217/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1218/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1219/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1220/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1221/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1222/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1223/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1224/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1225/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1226/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1227/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1228/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1229/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1230/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1231/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1232/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1233/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1234/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1235/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1236/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1237/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1238/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1239/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1240/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1241/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1242/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1243/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1244/1500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1245/1500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1246/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1247/1500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1248/1500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1249/1500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1250/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1251/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1252/1500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1253/1500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1254/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1255/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1256/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1257/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1258/1500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1259/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1260/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1261/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1262/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1263/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 391us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1265/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1266/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1267/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1268/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1269/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1270/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1271/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1272/1500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1273/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1274/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1275/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1276/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1277/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1278/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1279/1500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1280/1500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1281/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1282/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1283/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1284/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1285/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1286/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1287/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1288/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1289/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1290/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1291/1500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1292/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1293/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1294/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1295/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1296/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1297/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1298/1500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1299/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1300/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1301/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1302/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1303/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1304/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1305/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1306/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1307/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1308/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1309/1500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1310/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1311/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1312/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1313/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1314/1500\n",
      "27/27 [==============================] - 0s 327us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1315/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1316/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1317/1500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1318/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1319/1500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1320/1500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1321/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1322/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1323/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1324/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1325/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1326/1500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1327/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1328/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1329/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1330/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1331/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1332/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1333/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1334/1500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1335/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1336/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1337/1500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1338/1500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1339/1500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1340/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1341/1500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1342/1500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0073 - val_loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1343/1500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1344/1500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1345/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1346/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1347/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1348/1500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1349/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1350/1500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1351/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1352/1500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1353/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1354/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1355/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1356/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1357/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1358/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 1359/1500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1360/1500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1361/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1362/1500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1363/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1364/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1365/1500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1366/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1367/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1368/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1369/1500\n",
      "27/27 [==============================] - 0s 329us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1370/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1371/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1372/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1373/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1374/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1375/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1376/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1377/1500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1378/1500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1379/1500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1380/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1381/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1382/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1383/1500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1384/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1385/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1386/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1387/1500\n",
      "27/27 [==============================] - 0s 322us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1388/1500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1389/1500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1390/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1391/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1392/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1393/1500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1394/1500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1395/1500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1396/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1397/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1398/1500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1399/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1400/1500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1401/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1402/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1403/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1404/1500\n",
      "27/27 [==============================] - 0s 356us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1405/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1406/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1407/1500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1408/1500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1409/1500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1410/1500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1411/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1412/1500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 1413/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1414/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1415/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1416/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1417/1500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1418/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1419/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1420/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1421/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 389us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1422/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1423/1500\n",
      "27/27 [==============================] - 0s 337us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1424/1500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1425/1500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 1426/1500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1427/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1428/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1429/1500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1430/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1431/1500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1432/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1433/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1434/1500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1435/1500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1436/1500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1437/1500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1438/1500\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1439/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1440/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1441/1500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1442/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1443/1500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1444/1500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1445/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1446/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1447/1500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1448/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1449/1500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1450/1500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1451/1500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1452/1500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1453/1500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1454/1500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1455/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1456/1500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1457/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1458/1500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1459/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1460/1500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1461/1500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1462/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1463/1500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1464/1500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1465/1500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1466/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1467/1500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1468/1500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1469/1500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1470/1500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1471/1500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1472/1500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1473/1500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1474/1500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1475/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1476/1500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1477/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1478/1500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1479/1500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1480/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1481/1500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1482/1500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1483/1500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1484/1500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1485/1500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1486/1500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1487/1500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1488/1500\n",
      "27/27 [==============================] - 0s 541us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1489/1500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1490/1500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1491/1500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1492/1500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1493/1500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1494/1500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1495/1500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1496/1500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1497/1500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1498/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 1499/1500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0071 - val_loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500/1500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0071 - val_loss: 0.0103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a27953c18>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 3 samples\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1503 - val_loss: 0.1490\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.1392 - val_loss: 0.1378\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 503us/step - loss: 0.1281 - val_loss: 0.1268\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 479us/step - loss: 0.1171 - val_loss: 0.1158\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.1063 - val_loss: 0.1051\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0956 - val_loss: 0.0948\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 500us/step - loss: 0.0855 - val_loss: 0.0850\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0758 - val_loss: 0.0758\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0668 - val_loss: 0.0671\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0584 - val_loss: 0.0592\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0507 - val_loss: 0.0520\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0437 - val_loss: 0.0455\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0374 - val_loss: 0.0396\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0320 - val_loss: 0.0344\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0273 - val_loss: 0.0298\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0235 - val_loss: 0.0260\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0203 - val_loss: 0.0229\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0178 - val_loss: 0.0202\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0156 - val_loss: 0.0180\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0139 - val_loss: 0.0161\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0086 - val_loss: 0.0100\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0080 - val_loss: 0.0094\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0075 - val_loss: 0.0088\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0071 - val_loss: 0.0083\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 508us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 504us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0049 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 346us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 352us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 488us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 477us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 491us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0046 - val_loss: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 520us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 487us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 545us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 510us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 341us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 406us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 511us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 481us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 477us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 516us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 511us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0045 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 492us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 0s 449us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 274/500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 275/500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 276/500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 277/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 278/500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 279/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 280/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 281/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 282/500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 283/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 284/500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 285/500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 286/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 287/500\n",
      "27/27 [==============================] - 0s 370us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 288/500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 289/500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 290/500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 291/500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 292/500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 293/500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 294/500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 295/500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 296/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 297/500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 298/500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 299/500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 300/500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 301/500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 302/500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 303/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 304/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 305/500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 306/500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 307/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 308/500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 309/500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 310/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 311/500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 312/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 313/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 314/500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 315/500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 316/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 317/500\n",
      "27/27 [==============================] - 0s 477us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 318/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 319/500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 320/500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0044 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 322/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 323/500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 324/500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 325/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 326/500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 327/500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 328/500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 329/500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 330/500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 331/500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 332/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 333/500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 334/500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 335/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 336/500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 337/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 338/500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 339/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 340/500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 341/500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 342/500\n",
      "27/27 [==============================] - 0s 324us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 343/500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 344/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 345/500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 346/500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 347/500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 348/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 349/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 350/500\n",
      "27/27 [==============================] - 0s 387us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 351/500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 352/500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 353/500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 354/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 355/500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 356/500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 357/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 358/500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 359/500\n",
      "27/27 [==============================] - 0s 479us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 360/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 361/500\n",
      "27/27 [==============================] - 0s 466us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 362/500\n",
      "27/27 [==============================] - 0s 492us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 363/500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 364/500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 365/500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 366/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 367/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 368/500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 369/500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 370/500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 371/500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 372/500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 373/500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 374/500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 375/500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 376/500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 377/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 378/500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 379/500\n",
      "27/27 [==============================] - 0s 501us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 380/500\n",
      "27/27 [==============================] - 0s 486us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 381/500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 382/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 383/500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 384/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 385/500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 386/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 387/500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 388/500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 389/500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 390/500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 391/500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 392/500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 393/500\n",
      "27/27 [==============================] - 0s 351us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 394/500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 395/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 396/500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 397/500\n",
      "27/27 [==============================] - 0s 476us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 398/500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 399/500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 400/500\n",
      "27/27 [==============================] - 0s 342us/step - loss: 0.0044 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 402/500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 403/500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 404/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 405/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 406/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 407/500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 408/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 409/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 410/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 411/500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 412/500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 413/500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 414/500\n",
      "27/27 [==============================] - 0s 344us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 415/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 416/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 417/500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 418/500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 419/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 420/500\n",
      "27/27 [==============================] - 0s 339us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 421/500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 422/500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 423/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 424/500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 425/500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 426/500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 427/500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 428/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 429/500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 430/500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 431/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 432/500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 433/500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 434/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 435/500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 436/500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 437/500\n",
      "27/27 [==============================] - 0s 476us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 438/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 439/500\n",
      "27/27 [==============================] - 0s 377us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 440/500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 441/500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 442/500\n",
      "27/27 [==============================] - 0s 336us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 443/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 444/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 445/500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 446/500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 447/500\n",
      "27/27 [==============================] - 0s 509us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 448/500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 449/500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 450/500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 451/500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 452/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 453/500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 454/500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 455/500\n",
      "27/27 [==============================] - 0s 506us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 456/500\n",
      "27/27 [==============================] - 0s 487us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 457/500\n",
      "27/27 [==============================] - 0s 535us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 458/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 459/500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 460/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 461/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 462/500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 463/500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 464/500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 465/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 466/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 467/500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 468/500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 469/500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 470/500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 471/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 472/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 473/500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 474/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 475/500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 476/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 477/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 478/500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 479/500\n",
      "27/27 [==============================] - 0s 507us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 480/500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 0.0044 - val_loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 482/500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 483/500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 484/500\n",
      "27/27 [==============================] - 0s 476us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 485/500\n",
      "27/27 [==============================] - 0s 508us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 486/500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 487/500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 488/500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 489/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 490/500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 491/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 492/500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 493/500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 494/500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 495/500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 496/500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 497/500\n",
      "27/27 [==============================] - 0s 491us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 498/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 499/500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 500/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0044 - val_loss: 0.0044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.412188654306377"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appliance_num=6 # Oven\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "autoencoder.fit(((t_all[:30, 0, :, :]-t_all[:30, 1, :, :]-t_all[:30, 2, :, :]).reshape(-1, num_days, num_hours,1)/maxs[0]),(t_all[:30, appliance_num, :, :].reshape(-1, num_days, num_hours,1) /maxs[appliance_num])\n",
    "                ,validation_split=0.1,epochs=500)\n",
    "pred = maxs[appliance_num]*autoencoder.predict((t_all[30:, 0, :, :]-t_all[30:, 1, :, :]-t_all[30:, 2, :, :]).reshape(-1, num_days, num_hours,1)/maxs[0]).reshape(-1, num_days, num_hours)\n",
    "gt =t_all[30:, appliance_num, :, :]\n",
    "\n",
    "\n",
    "pred_fl = pred.flatten()\n",
    "gt_fl = gt.flatten()\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(gt_fl, pred_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggregate', 'hvac', 'fridge', 'mw', 'dw', 'wm', 'oven']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPLIANCES_ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0222361523182295"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appliance_num=4 # Oven\n",
    "autoencoder.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "autoencoder.fit(((t_all[:30, 0, :, :]-t_all[:30, 1, :, :]-t_all[:30, 2, :, :]-t_all[:30, 6, :, :]).reshape(-1, num_days, num_hours,1)/maxs[0]),(t_all[:30, appliance_num, :, :].reshape(-1, num_days, num_hours,1) /maxs[appliance_num])\n",
    "                ,validation_split=0.1,epochs=500)\n",
    "pred = maxs[appliance_num]*autoencoder.predict((t_all[30:, 0, :, :]-t_all[30:, 1, :, :]-t_all[30:, 2, :, :]-t_all[30:, 6, :, :]).reshape(-1, num_days, num_hours,1)/maxs[0]).reshape(-1, num_days, num_hours)\n",
    "gt =t_all[30:, appliance_num, :, :]\n",
    "\n",
    "\n",
    "pred_fl = pred.flatten()\n",
    "gt_fl = gt.flatten()\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(gt_fl, pred_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggregate', 'hvac', 'fridge', 'mw', 'dw', 'wm', 'oven']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPLIANCES_ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 3 samples\n",
      "Epoch 1/500\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0065 - val_loss: 0.0086\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 526us/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 503us/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 527us/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 476us/step - loss: 0.0065 - val_loss: 0.0084\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 479us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 449us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 493us/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 493us/step - loss: 0.0064 - val_loss: 0.0083\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 449us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 515us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 443us/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0062 - val_loss: 0.0081\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 388us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 475us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0062 - val_loss: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 498us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 518us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 530us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 486us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 523us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 526us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 392us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 366us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 509us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 476us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 469us/step - loss: 0.0060 - val_loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 487us/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 500us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0061 - val_loss: 0.0078\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 442us/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 505us/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 451us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 518us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 430us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 348us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 386us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 0s 453us/step - loss: 0.0060 - val_loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 488us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 0s 465us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 0s 479us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 560us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 0s 532us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 0s 518us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 0s 497us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 0s 486us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 0s 501us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 0s 462us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 0s 383us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 274/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 275/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 276/500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 277/500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 278/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 279/500\n",
      "27/27 [==============================] - 0s 375us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 280/500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 281/500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 282/500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 283/500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 284/500\n",
      "27/27 [==============================] - 0s 481us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 285/500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 286/500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 287/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 288/500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 289/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 290/500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 291/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 292/500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 293/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 294/500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 295/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 296/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 297/500\n",
      "27/27 [==============================] - 0s 389us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 298/500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 299/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 300/500\n",
      "27/27 [==============================] - 0s 368us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 301/500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 302/500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 303/500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 304/500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 305/500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 306/500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 307/500\n",
      "27/27 [==============================] - 0s 353us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 308/500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 309/500\n",
      "27/27 [==============================] - 0s 456us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 310/500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 311/500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 312/500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 313/500\n",
      "27/27 [==============================] - 0s 331us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 314/500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 315/500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 316/500\n",
      "27/27 [==============================] - 0s 347us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 317/500\n",
      "27/27 [==============================] - 0s 358us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 318/500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 319/500\n",
      "27/27 [==============================] - 0s 335us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 320/500\n",
      "27/27 [==============================] - 0s 365us/step - loss: 0.0059 - val_loss: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/500\n",
      "27/27 [==============================] - 0s 379us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 322/500\n",
      "27/27 [==============================] - 0s 359us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 323/500\n",
      "27/27 [==============================] - 0s 376us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 324/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 325/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 326/500\n",
      "27/27 [==============================] - 0s 483us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 327/500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 328/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 329/500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 330/500\n",
      "27/27 [==============================] - 0s 395us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 331/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 332/500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 333/500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 334/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 335/500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 336/500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 337/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 338/500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 339/500\n",
      "27/27 [==============================] - 0s 394us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 340/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 341/500\n",
      "27/27 [==============================] - 0s 405us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 342/500\n",
      "27/27 [==============================] - 0s 432us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 343/500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 344/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 345/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 346/500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 347/500\n",
      "27/27 [==============================] - 0s 502us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 348/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 349/500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 350/500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 351/500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 352/500\n",
      "27/27 [==============================] - 0s 488us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 353/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 354/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 355/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 356/500\n",
      "27/27 [==============================] - 0s 416us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 357/500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 358/500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 359/500\n",
      "27/27 [==============================] - 0s 340us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 360/500\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 361/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 362/500\n",
      "27/27 [==============================] - 0s 367us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 363/500\n",
      "27/27 [==============================] - 0s 361us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 364/500\n",
      "27/27 [==============================] - 0s 374us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 365/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 366/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 367/500\n",
      "27/27 [==============================] - 0s 369us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 368/500\n",
      "27/27 [==============================] - 0s 357us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 369/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 370/500\n",
      "27/27 [==============================] - 0s 434us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 371/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 372/500\n",
      "27/27 [==============================] - 0s 497us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 373/500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 374/500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 375/500\n",
      "27/27 [==============================] - 0s 425us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 376/500\n",
      "27/27 [==============================] - 0s 528us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 377/500\n",
      "27/27 [==============================] - 0s 422us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 378/500\n",
      "27/27 [==============================] - 0s 412us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 379/500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 380/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 381/500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 382/500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 383/500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 384/500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 385/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 386/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 387/500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 388/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 389/500\n",
      "27/27 [==============================] - 0s 391us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 390/500\n",
      "27/27 [==============================] - 0s 402us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 391/500\n",
      "27/27 [==============================] - 0s 404us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 392/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 393/500\n",
      "27/27 [==============================] - 0s 415us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 394/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 395/500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 396/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 397/500\n",
      "27/27 [==============================] - 0s 378us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 398/500\n",
      "27/27 [==============================] - 0s 397us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 399/500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 400/500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 0.0058 - val_loss: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 402/500\n",
      "27/27 [==============================] - 0s 417us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 403/500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 404/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 405/500\n",
      "27/27 [==============================] - 0s 476us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 406/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 407/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 408/500\n",
      "27/27 [==============================] - 0s 516us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 409/500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 410/500\n",
      "27/27 [==============================] - 0s 408us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 411/500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 412/500\n",
      "27/27 [==============================] - 0s 461us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 413/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 414/500\n",
      "27/27 [==============================] - 0s 418us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 415/500\n",
      "27/27 [==============================] - 0s 429us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 416/500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 417/500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 418/500\n",
      "27/27 [==============================] - 0s 390us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 419/500\n",
      "27/27 [==============================] - 0s 414us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 420/500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 421/500\n",
      "27/27 [==============================] - 0s 480us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 422/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 423/500\n",
      "27/27 [==============================] - 0s 431us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 424/500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 425/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 426/500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 427/500\n",
      "27/27 [==============================] - 0s 513us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 428/500\n",
      "27/27 [==============================] - 0s 401us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 429/500\n",
      "27/27 [==============================] - 0s 382us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 430/500\n",
      "27/27 [==============================] - 0s 381us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 431/500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 432/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 433/500\n",
      "27/27 [==============================] - 0s 399us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 434/500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 435/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 436/500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 437/500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 438/500\n",
      "27/27 [==============================] - 0s 441us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 439/500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 440/500\n",
      "27/27 [==============================] - 0s 409us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 441/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 442/500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 443/500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 444/500\n",
      "27/27 [==============================] - 0s 385us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 445/500\n",
      "27/27 [==============================] - 0s 410us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 446/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 447/500\n",
      "27/27 [==============================] - 0s 452us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 448/500\n",
      "27/27 [==============================] - 0s 398us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 449/500\n",
      "27/27 [==============================] - 0s 345us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 450/500\n",
      "27/27 [==============================] - 0s 433us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 451/500\n",
      "27/27 [==============================] - 0s 400us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 452/500\n",
      "27/27 [==============================] - 0s 424us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 453/500\n",
      "27/27 [==============================] - 0s 476us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 454/500\n",
      "27/27 [==============================] - 0s 363us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 455/500\n",
      "27/27 [==============================] - 0s 355us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 456/500\n",
      "27/27 [==============================] - 0s 423us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 457/500\n",
      "27/27 [==============================] - 0s 384us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 458/500\n",
      "27/27 [==============================] - 0s 492us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 459/500\n",
      "27/27 [==============================] - 0s 360us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 460/500\n",
      "27/27 [==============================] - 0s 362us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 461/500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 462/500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 463/500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 464/500\n",
      "27/27 [==============================] - 0s 494us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 465/500\n",
      "27/27 [==============================] - 0s 380us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 466/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 467/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 468/500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 469/500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 470/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 471/500\n",
      "27/27 [==============================] - 0s 471us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 472/500\n",
      "27/27 [==============================] - 0s 437us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 473/500\n",
      "27/27 [==============================] - 0s 449us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 474/500\n",
      "27/27 [==============================] - 0s 455us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 475/500\n",
      "27/27 [==============================] - 0s 438us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 476/500\n",
      "27/27 [==============================] - 0s 446us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 477/500\n",
      "27/27 [==============================] - 0s 403us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 478/500\n",
      "27/27 [==============================] - 0s 407us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 479/500\n",
      "27/27 [==============================] - 0s 373us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 480/500\n",
      "27/27 [==============================] - 0s 420us/step - loss: 0.0058 - val_loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "27/27 [==============================] - 0s 393us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 482/500\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 483/500\n",
      "27/27 [==============================] - 0s 436us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 484/500\n",
      "27/27 [==============================] - 0s 354us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 485/500\n",
      "27/27 [==============================] - 0s 364us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 486/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 487/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 488/500\n",
      "27/27 [==============================] - 0s 486us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 489/500\n",
      "27/27 [==============================] - 0s 449us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 490/500\n",
      "27/27 [==============================] - 0s 450us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 491/500\n",
      "27/27 [==============================] - 0s 477us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 492/500\n",
      "27/27 [==============================] - 0s 517us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 493/500\n",
      "27/27 [==============================] - 0s 421us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 494/500\n",
      "27/27 [==============================] - 0s 458us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 495/500\n",
      "27/27 [==============================] - 0s 411us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 496/500\n",
      "27/27 [==============================] - 0s 558us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 497/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 498/500\n",
      "27/27 [==============================] - 0s 396us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 499/500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 500/500\n",
      "27/27 [==============================] - 0s 515us/step - loss: 0.0058 - val_loss: 0.0078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.2571131812695322"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appliance_num=3 # Oven\n",
    "autoencoder.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "autoencoder.fit(((t_all[:30, 0, :, :]-t_all[:30, 1, :, :]-t_all[:30, 2, :, :]-t_all[:30, 6, :, :]-t_all[:30, 4, :, :]).reshape(-1, num_days, num_hours,1)/maxs[0]),(t_all[:30, appliance_num, :, :].reshape(-1, num_days, num_hours,1) /maxs[appliance_num])\n",
    "                ,validation_split=0.1,epochs=500)\n",
    "pred = maxs[appliance_num]*autoencoder.predict((t_all[30:, 0, :, :]-t_all[30:, 1, :, :]-t_all[30:, 2, :, :]-t_all[30:, 6, :, :]-t_all[30:, 4, :, :]).reshape(-1, num_days, num_hours,1)/maxs[0]).reshape(-1, num_days, num_hours)\n",
    "gt =t_all[30:, appliance_num, :, :]\n",
    "\n",
    "\n",
    "pred_fl = pred.flatten()\n",
    "gt_fl = gt.flatten()\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(gt_fl, pred_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a463ea630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_overall_appliance = (maxs[appliance_num]*autoencoder.predict(t_all[30:, 0, :, :].reshape(-1, num_days, num_hours,1)/maxs[0])).reshape(-1,14,24)\n",
    "ax = pd.DataFrame(pred_overall_appliance[1, 3, :]).squeeze().plot(label='Predicted HVAC')\n",
    "pd.DataFrame(gt[1, 3, :]).squeeze().plot(ax=ax,label=\"GT HVAC\")\n",
    "pd.DataFrame(t_all[31,4, 3, :]).squeeze().plot(ax=ax,label=\"GT DW\")\n",
    "plt.legend()\n",
    "plt.savefig(\"/Users/nipun/Desktop/hvac-dw-cnn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a42001ef0>]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKaVs6v8DpJPza5aLVqIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a41cbcc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(autoencoder.layers[2].get_weights()[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_agg = t_all[:30, 0, :].reshape(30*14, 24)\n",
    "train_appliance = {}\n",
    "test_appliance = {}\n",
    "for appliance_num, appliance in enumerate(APPLIANCES_ORDER[1:]):\n",
    "    train_appliance[appliance] = t_all[:30, appliance_num+1, :].reshape(30*14, 24)\n",
    "    test_appliance[appliance] = t_all[30:, appliance_num+1, :].reshape(22*14, 24)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_hvac = t_all[30:, 1, :].reshape(22*14, 24)\n",
    "test_fridge = t_all[30:, 2, :].reshape(22*14, 24)\n",
    "\n",
    "test_mw = t_all[30:, 3, :].reshape(22*14, 24)\n",
    "\n",
    "\n",
    "\n",
    "test_agg = t_all[30:, 0, :].reshape(22*14, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_hvac' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-122380d9c71b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_hvac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_hvac' is not defined"
     ]
    }
   ],
   "source": [
    "train_hvac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_hvac' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-26ef9ccd3f53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_hvac_fridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_hvac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_fridge\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_hvac_fridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_hvac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_fridge\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_hvac' is not defined"
     ]
    }
   ],
   "source": [
    "train_hvac_fridge = np.hstack([train_hvac, train_fridge])\n",
    "test_hvac_fridge = np.hstack([test_hvac, test_fridge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fridge\n",
      "********************\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/500\n",
      "378/378 [==============================] - 1s 3ms/step - loss: 104.0335 - val_loss: 80.1024\n",
      "Epoch 2/500\n",
      "378/378 [==============================] - 0s 128us/step - loss: 73.5439 - val_loss: 82.9650\n",
      "Epoch 3/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 69.5276 - val_loss: 71.1884\n",
      "Epoch 4/500\n",
      "378/378 [==============================] - 0s 124us/step - loss: 65.7872 - val_loss: 66.9487\n",
      "Epoch 5/500\n",
      "378/378 [==============================] - 0s 123us/step - loss: 61.5952 - val_loss: 60.5597\n",
      "Epoch 6/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 57.9371 - val_loss: 58.2805\n",
      "Epoch 7/500\n",
      "378/378 [==============================] - 0s 123us/step - loss: 54.5536 - val_loss: 53.5956\n",
      "Epoch 8/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 52.0083 - val_loss: 48.1487\n",
      "Epoch 9/500\n",
      "378/378 [==============================] - 0s 110us/step - loss: 49.8050 - val_loss: 47.3854\n",
      "Epoch 10/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 48.4076 - val_loss: 50.2753\n",
      "Epoch 11/500\n",
      "378/378 [==============================] - 0s 126us/step - loss: 48.1385 - val_loss: 44.8737\n",
      "Epoch 12/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 47.0126 - val_loss: 49.4019\n",
      "Epoch 13/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 46.6314 - val_loss: 44.6897\n",
      "Epoch 14/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 45.7859 - val_loss: 47.2255\n",
      "Epoch 15/500\n",
      "378/378 [==============================] - 0s 124us/step - loss: 45.4930 - val_loss: 45.9505\n",
      "Epoch 16/500\n",
      "378/378 [==============================] - 0s 123us/step - loss: 44.4689 - val_loss: 46.0596\n",
      "Epoch 17/500\n",
      "378/378 [==============================] - 0s 148us/step - loss: 43.9302 - val_loss: 43.3321\n",
      "Epoch 18/500\n",
      "378/378 [==============================] - 0s 140us/step - loss: 44.4852 - val_loss: 46.0947\n",
      "Epoch 19/500\n",
      "378/378 [==============================] - 0s 149us/step - loss: 44.3549 - val_loss: 44.9310\n",
      "Epoch 20/500\n",
      "378/378 [==============================] - 0s 174us/step - loss: 44.6102 - val_loss: 43.7336\n",
      "Epoch 21/500\n",
      "378/378 [==============================] - 0s 160us/step - loss: 44.0030 - val_loss: 48.1959\n",
      "Epoch 22/500\n",
      "378/378 [==============================] - 0s 158us/step - loss: 43.8427 - val_loss: 46.0852\n",
      "Epoch 23/500\n",
      "378/378 [==============================] - 0s 164us/step - loss: 43.7722 - val_loss: 45.0606\n",
      "Epoch 24/500\n",
      "378/378 [==============================] - 0s 156us/step - loss: 43.6814 - val_loss: 45.7697\n",
      "Epoch 25/500\n",
      "378/378 [==============================] - 0s 126us/step - loss: 43.6771 - val_loss: 46.1566\n",
      "Epoch 26/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 43.5886 - val_loss: 47.4341\n",
      "Epoch 27/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 42.9120 - val_loss: 43.5555\n",
      "Epoch 28/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 42.4706 - val_loss: 47.4463\n",
      "Epoch 29/500\n",
      "378/378 [==============================] - 0s 127us/step - loss: 42.8407 - val_loss: 44.2160\n",
      "Epoch 30/500\n",
      "378/378 [==============================] - 0s 149us/step - loss: 42.2783 - val_loss: 42.4520\n",
      "Epoch 31/500\n",
      "378/378 [==============================] - 0s 160us/step - loss: 43.3057 - val_loss: 46.7205\n",
      "Epoch 32/500\n",
      "378/378 [==============================] - 0s 184us/step - loss: 42.4322 - val_loss: 45.1091\n",
      "Epoch 33/500\n",
      "378/378 [==============================] - 0s 142us/step - loss: 42.2389 - val_loss: 40.7218\n",
      "Epoch 34/500\n",
      "378/378 [==============================] - 0s 123us/step - loss: 42.0600 - val_loss: 49.7435\n",
      "Epoch 35/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 42.2471 - val_loss: 44.0191\n",
      "Epoch 36/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 42.5494 - val_loss: 45.9218\n",
      "Epoch 37/500\n",
      "378/378 [==============================] - 0s 129us/step - loss: 41.5170 - val_loss: 41.8289\n",
      "Epoch 38/500\n",
      "378/378 [==============================] - 0s 145us/step - loss: 42.4506 - val_loss: 47.9723\n",
      "Epoch 39/500\n",
      "378/378 [==============================] - 0s 165us/step - loss: 42.6541 - val_loss: 45.8354\n",
      "Epoch 40/500\n",
      "378/378 [==============================] - 0s 177us/step - loss: 42.0716 - val_loss: 41.1500\n",
      "Epoch 41/500\n",
      "378/378 [==============================] - 0s 136us/step - loss: 41.4746 - val_loss: 48.8116\n",
      "Epoch 42/500\n",
      "378/378 [==============================] - 0s 136us/step - loss: 41.2513 - val_loss: 42.3331\n",
      "Epoch 43/500\n",
      "378/378 [==============================] - 0s 140us/step - loss: 41.2785 - val_loss: 45.9130\n",
      "Epoch 44/500\n",
      "378/378 [==============================] - 0s 141us/step - loss: 41.6845 - val_loss: 44.5290\n",
      "Epoch 45/500\n",
      "378/378 [==============================] - 0s 145us/step - loss: 41.2962 - val_loss: 42.9995\n",
      "Epoch 46/500\n",
      "378/378 [==============================] - 0s 137us/step - loss: 40.9711 - val_loss: 45.8175\n",
      "Epoch 47/500\n",
      "378/378 [==============================] - 0s 135us/step - loss: 40.8149 - val_loss: 41.8467\n",
      "Epoch 48/500\n",
      "378/378 [==============================] - 0s 135us/step - loss: 41.4019 - val_loss: 45.1568\n",
      "Epoch 49/500\n",
      "378/378 [==============================] - 0s 126us/step - loss: 40.9754 - val_loss: 43.5708\n",
      "Epoch 50/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 40.2788 - val_loss: 47.1195\n",
      "Epoch 51/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 41.0625 - val_loss: 44.8752\n",
      "Epoch 52/500\n",
      "378/378 [==============================] - 0s 127us/step - loss: 40.3319 - val_loss: 44.8103\n",
      "Epoch 53/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 41.1924 - val_loss: 44.8948\n",
      "Epoch 54/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 41.0538 - val_loss: 42.7822\n",
      "Epoch 55/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 40.2997 - val_loss: 44.7457\n",
      "Epoch 56/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 40.9821 - val_loss: 44.7372\n",
      "Epoch 57/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 40.7127 - val_loss: 41.2518\n",
      "Epoch 58/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 39.8744 - val_loss: 45.4890\n",
      "Epoch 59/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 39.5597 - val_loss: 43.3057\n",
      "Epoch 60/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 40.1709 - val_loss: 43.7829\n",
      "Epoch 61/500\n",
      "378/378 [==============================] - 0s 129us/step - loss: 41.0494 - val_loss: 43.0961\n",
      "Epoch 62/500\n",
      "378/378 [==============================] - 0s 130us/step - loss: 39.2322 - val_loss: 44.9770\n",
      "Epoch 63/500\n",
      "378/378 [==============================] - 0s 130us/step - loss: 39.1229 - val_loss: 41.1290\n",
      "Epoch 64/500\n",
      "378/378 [==============================] - 0s 137us/step - loss: 40.3158 - val_loss: 44.3470\n",
      "Epoch 65/500\n",
      "378/378 [==============================] - 0s 127us/step - loss: 39.8204 - val_loss: 45.1032\n",
      "Epoch 66/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 39.9711 - val_loss: 41.7657\n",
      "Epoch 67/500\n",
      "378/378 [==============================] - 0s 123us/step - loss: 40.3331 - val_loss: 43.3147\n",
      "Epoch 68/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 39.7473 - val_loss: 42.9658\n",
      "Epoch 69/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 38.9953 - val_loss: 41.1763\n",
      "Epoch 70/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 39.6315 - val_loss: 45.8329\n",
      "Epoch 71/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 39.7593 - val_loss: 42.4869\n",
      "Epoch 72/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 39.4382 - val_loss: 41.9857\n",
      "Epoch 73/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 39.6509 - val_loss: 46.6549\n",
      "Epoch 74/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 40.6982 - val_loss: 41.7623\n",
      "Epoch 75/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 39.1051 - val_loss: 40.3273\n",
      "Epoch 76/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 39.8424 - val_loss: 42.8496\n",
      "Epoch 77/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 38.8710 - val_loss: 42.2651\n",
      "Epoch 78/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 38.0188 - val_loss: 40.2959\n",
      "Epoch 79/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 38.6100 - val_loss: 43.2281\n",
      "Epoch 80/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 38.8302 - val_loss: 42.8166\n",
      "Epoch 81/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 39.6735 - val_loss: 42.1837\n",
      "Epoch 82/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 39.6392 - val_loss: 42.4519\n",
      "Epoch 83/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 39.2762 - val_loss: 41.7199\n",
      "Epoch 84/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 38.3054 - val_loss: 42.9781\n",
      "Epoch 85/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 38.9147 - val_loss: 41.6997\n",
      "Epoch 86/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 38.7012 - val_loss: 42.5982\n",
      "Epoch 87/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 39.7174 - val_loss: 44.3348\n",
      "Epoch 88/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 38.1136 - val_loss: 41.5925\n",
      "Epoch 89/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 39.2501 - val_loss: 41.0288\n",
      "Epoch 90/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 38.9085 - val_loss: 42.4723\n",
      "Epoch 91/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 39.5742 - val_loss: 44.1792\n",
      "Epoch 92/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 38.1642 - val_loss: 42.0135\n",
      "Epoch 93/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 37.9017 - val_loss: 39.7521\n",
      "Epoch 94/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 38.5336 - val_loss: 43.5638\n",
      "Epoch 95/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 38.6539 - val_loss: 39.9789\n",
      "Epoch 96/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 38.2280 - val_loss: 43.8354\n",
      "Epoch 97/500\n",
      "378/378 [==============================] - 0s 131us/step - loss: 37.6934 - val_loss: 41.9996\n",
      "Epoch 98/500\n",
      "378/378 [==============================] - 0s 136us/step - loss: 38.3388 - val_loss: 40.3986\n",
      "Epoch 99/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 38.4684 - val_loss: 43.0004\n",
      "Epoch 100/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 37.7812 - val_loss: 40.8004\n",
      "Epoch 101/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 38.3084 - val_loss: 42.5884\n",
      "Epoch 102/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 38.0219 - val_loss: 40.1661\n",
      "Epoch 103/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 37.8136 - val_loss: 42.0351\n",
      "Epoch 104/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 38.4676 - val_loss: 41.8278\n",
      "Epoch 105/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 38.0989 - val_loss: 39.3695\n",
      "Epoch 106/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 38.5142 - val_loss: 40.6178\n",
      "Epoch 107/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 37.7047 - val_loss: 42.8883\n",
      "Epoch 108/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 37.3515 - val_loss: 41.1268\n",
      "Epoch 109/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 37.6724 - val_loss: 42.5482\n",
      "Epoch 110/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 37.7970 - val_loss: 44.6775\n",
      "Epoch 111/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 37.0464 - val_loss: 41.4212\n",
      "Epoch 112/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 37.3740 - val_loss: 40.7406\n",
      "Epoch 113/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 38.1242 - val_loss: 42.7961\n",
      "Epoch 114/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 37.1698 - val_loss: 42.5217\n",
      "Epoch 115/500\n",
      "378/378 [==============================] - 0s 108us/step - loss: 36.6577 - val_loss: 38.7924\n",
      "Epoch 116/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 38.2747 - val_loss: 42.1709\n",
      "Epoch 117/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 37.2091 - val_loss: 42.9062\n",
      "Epoch 118/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 37.9202 - val_loss: 40.6951\n",
      "Epoch 119/500\n",
      "378/378 [==============================] - 0s 138us/step - loss: 37.7985 - val_loss: 40.9422\n",
      "Epoch 120/500\n",
      "378/378 [==============================] - 0s 144us/step - loss: 37.1773 - val_loss: 41.2419\n",
      "Epoch 121/500\n",
      "378/378 [==============================] - 0s 139us/step - loss: 37.9636 - val_loss: 41.1232\n",
      "Epoch 122/500\n",
      "378/378 [==============================] - 0s 135us/step - loss: 37.3918 - val_loss: 41.6713\n",
      "Epoch 123/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 36.3932 - val_loss: 41.4056\n",
      "Epoch 124/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 36.7046 - val_loss: 42.2162\n",
      "Epoch 125/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 37.0647 - val_loss: 42.7995\n",
      "Epoch 126/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 36.5751 - val_loss: 39.7770\n",
      "Epoch 127/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 37.5386 - val_loss: 43.7344\n",
      "Epoch 128/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 37.2338 - val_loss: 40.3577\n",
      "Epoch 129/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 36.8634 - val_loss: 42.2646\n",
      "Epoch 130/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 37.5268 - val_loss: 41.8290\n",
      "Epoch 131/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 37.6206 - val_loss: 40.4287\n",
      "Epoch 132/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 36.8056 - val_loss: 43.1433\n",
      "Epoch 133/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 37.6017 - val_loss: 41.4761\n",
      "Epoch 134/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 37.0967 - val_loss: 40.5701\n",
      "Epoch 135/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 37.5803 - val_loss: 43.6633\n",
      "Epoch 136/500\n",
      "378/378 [==============================] - 0s 129us/step - loss: 36.5535 - val_loss: 40.9257\n",
      "Epoch 137/500\n",
      "378/378 [==============================] - 0s 145us/step - loss: 36.9403 - val_loss: 41.8853\n",
      "Epoch 138/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 37.1445 - val_loss: 42.3455\n",
      "Epoch 139/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 36.7953 - val_loss: 42.5648\n",
      "Epoch 140/500\n",
      "378/378 [==============================] - 0s 124us/step - loss: 37.2671 - val_loss: 41.5168\n",
      "Epoch 141/500\n",
      "378/378 [==============================] - 0s 123us/step - loss: 36.3948 - val_loss: 41.5488\n",
      "Epoch 142/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 36.7204 - val_loss: 43.5029\n",
      "Epoch 143/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 36.8382 - val_loss: 42.0986\n",
      "Epoch 144/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 36.7946 - val_loss: 42.4184\n",
      "Epoch 145/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 36.5353 - val_loss: 40.5995\n",
      "Epoch 146/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 36.3156 - val_loss: 41.9622\n",
      "Epoch 147/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 36.2562 - val_loss: 41.3804\n",
      "Epoch 148/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 36.0928 - val_loss: 43.0357\n",
      "Epoch 149/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 36.3101 - val_loss: 44.4459\n",
      "Epoch 150/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 36.7756 - val_loss: 40.4137\n",
      "Epoch 151/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 36.3767 - val_loss: 44.1017\n",
      "Epoch 152/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 36.4884 - val_loss: 40.0036\n",
      "Epoch 153/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 36.3941 - val_loss: 43.1410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 36.6051 - val_loss: 40.9227\n",
      "Epoch 155/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 36.8613 - val_loss: 37.9792\n",
      "Epoch 156/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 36.0987 - val_loss: 39.7679\n",
      "Epoch 157/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 35.8294 - val_loss: 40.1168\n",
      "Epoch 158/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 35.9135 - val_loss: 40.3052\n",
      "Epoch 159/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 35.9357 - val_loss: 41.5186\n",
      "Epoch 160/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 36.4006 - val_loss: 42.6061\n",
      "Epoch 161/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 36.0867 - val_loss: 39.4884\n",
      "Epoch 162/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 36.2109 - val_loss: 40.9371\n",
      "Epoch 163/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 35.8086 - val_loss: 40.4950\n",
      "Epoch 164/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 36.3686 - val_loss: 41.0350\n",
      "Epoch 165/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 36.5588 - val_loss: 40.5976\n",
      "Epoch 166/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 35.3359 - val_loss: 41.4256\n",
      "Epoch 167/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 35.9847 - val_loss: 42.4337\n",
      "Epoch 168/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 35.3983 - val_loss: 41.2303\n",
      "Epoch 169/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 35.9816 - val_loss: 41.5328\n",
      "Epoch 170/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 36.5666 - val_loss: 43.9853\n",
      "Epoch 171/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 35.7636 - val_loss: 39.1470\n",
      "Epoch 172/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 36.1742 - val_loss: 42.7128\n",
      "Epoch 173/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 35.5819 - val_loss: 39.3321\n",
      "Epoch 174/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 35.7133 - val_loss: 39.9044\n",
      "Epoch 175/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 35.7240 - val_loss: 40.8036\n",
      "Epoch 176/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 35.6581 - val_loss: 38.8584\n",
      "Epoch 177/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 36.0380 - val_loss: 39.5968\n",
      "Epoch 178/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 35.1719 - val_loss: 39.5981\n",
      "Epoch 179/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 35.2089 - val_loss: 40.9771\n",
      "Epoch 180/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 36.0237 - val_loss: 39.9841\n",
      "Epoch 181/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 35.6023 - val_loss: 40.0825\n",
      "Epoch 182/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 36.5747 - val_loss: 40.2889\n",
      "Epoch 183/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 35.0117 - val_loss: 40.0691\n",
      "Epoch 184/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 34.9315 - val_loss: 40.7599\n",
      "Epoch 185/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 35.4915 - val_loss: 39.3586\n",
      "Epoch 186/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 35.4378 - val_loss: 37.8337\n",
      "Epoch 187/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 34.6471 - val_loss: 40.5622\n",
      "Epoch 188/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 34.3123 - val_loss: 41.8082\n",
      "Epoch 189/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 35.4651 - val_loss: 38.2440\n",
      "Epoch 190/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 35.1621 - val_loss: 38.5763\n",
      "Epoch 191/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 34.6551 - val_loss: 38.7860\n",
      "Epoch 192/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 35.0629 - val_loss: 41.1443\n",
      "Epoch 193/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 35.5129 - val_loss: 39.1493\n",
      "Epoch 194/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 35.2658 - val_loss: 41.4198\n",
      "Epoch 195/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 34.7779 - val_loss: 40.7980\n",
      "Epoch 196/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 34.8862 - val_loss: 40.9140\n",
      "Epoch 197/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 34.8743 - val_loss: 41.8909\n",
      "Epoch 198/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 34.9811 - val_loss: 40.3892\n",
      "Epoch 199/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 34.7969 - val_loss: 39.4014\n",
      "Epoch 200/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 35.0890 - val_loss: 43.0319\n",
      "Epoch 201/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 34.5145 - val_loss: 40.5962\n",
      "Epoch 202/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 33.5780 - val_loss: 38.8348\n",
      "Epoch 203/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 35.1359 - val_loss: 41.8587\n",
      "Epoch 204/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 34.4528 - val_loss: 42.7902\n",
      "Epoch 205/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 34.6293 - val_loss: 40.3214\n",
      "Epoch 206/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 34.3915 - val_loss: 41.8413\n",
      "Epoch 207/500\n",
      "378/378 [==============================] - 0s 135us/step - loss: 33.8281 - val_loss: 39.3678\n",
      "Epoch 208/500\n",
      "378/378 [==============================] - 0s 131us/step - loss: 34.6807 - val_loss: 39.3762\n",
      "Epoch 209/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 34.6764 - val_loss: 40.1510\n",
      "Epoch 210/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 34.6784 - val_loss: 39.5043\n",
      "Epoch 211/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 34.5211 - val_loss: 39.0586\n",
      "Epoch 212/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 33.9104 - val_loss: 40.3789\n",
      "Epoch 213/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 34.3465 - val_loss: 40.7001\n",
      "Epoch 214/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 34.0345 - val_loss: 37.1951\n",
      "Epoch 215/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 33.1767 - val_loss: 36.8480\n",
      "Epoch 216/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 33.4834 - val_loss: 39.8700\n",
      "Epoch 217/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 33.5928 - val_loss: 37.8554\n",
      "Epoch 218/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 33.8481 - val_loss: 39.6575\n",
      "Epoch 219/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 33.7444 - val_loss: 39.6737\n",
      "Epoch 220/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 33.6347 - val_loss: 39.5478\n",
      "Epoch 221/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 33.2341 - val_loss: 37.9035\n",
      "Epoch 222/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 33.6352 - val_loss: 40.9090\n",
      "Epoch 223/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 33.3126 - val_loss: 39.1993\n",
      "Epoch 224/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 33.8085 - val_loss: 40.9065\n",
      "Epoch 225/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 34.0013 - val_loss: 39.4138\n",
      "Epoch 226/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 33.1372 - val_loss: 38.9036\n",
      "Epoch 227/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 33.5136 - val_loss: 39.4523\n",
      "Epoch 228/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 33.1981 - val_loss: 39.3788\n",
      "Epoch 229/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 34.0994 - val_loss: 40.0920\n",
      "Epoch 230/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 33.7761 - val_loss: 38.8550\n",
      "Epoch 231/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 33.1654 - val_loss: 40.7713\n",
      "Epoch 232/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 33.2325 - val_loss: 39.1207\n",
      "Epoch 233/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 33.4129 - val_loss: 41.0991\n",
      "Epoch 234/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 33.4390 - val_loss: 40.5542\n",
      "Epoch 235/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 32.3369 - val_loss: 40.3075\n",
      "Epoch 236/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 33.1326 - val_loss: 41.1542\n",
      "Epoch 237/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 33.1350 - val_loss: 40.2384\n",
      "Epoch 238/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 32.3292 - val_loss: 38.4436\n",
      "Epoch 239/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 33.5944 - val_loss: 41.0797\n",
      "Epoch 240/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 32.7899 - val_loss: 39.7161\n",
      "Epoch 241/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 32.7902 - val_loss: 40.3507\n",
      "Epoch 242/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 32.6278 - val_loss: 40.6046\n",
      "Epoch 243/500\n",
      "378/378 [==============================] - 0s 109us/step - loss: 32.6562 - val_loss: 38.6116\n",
      "Epoch 244/500\n",
      "378/378 [==============================] - 0s 104us/step - loss: 32.3921 - val_loss: 38.9213\n",
      "Epoch 245/500\n",
      "378/378 [==============================] - 0s 109us/step - loss: 31.9833 - val_loss: 37.8780\n",
      "Epoch 246/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 32.6613 - val_loss: 38.0931\n",
      "Epoch 247/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 32.2458 - val_loss: 38.0734\n",
      "Epoch 248/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 32.2783 - val_loss: 38.4257\n",
      "Epoch 249/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 32.8058 - val_loss: 37.4787\n",
      "Epoch 250/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 32.3892 - val_loss: 38.5760\n",
      "Epoch 251/500\n",
      "378/378 [==============================] - 0s 129us/step - loss: 31.8504 - val_loss: 38.8264\n",
      "Epoch 252/500\n",
      "378/378 [==============================] - 0s 147us/step - loss: 32.6496 - val_loss: 39.7328\n",
      "Epoch 253/500\n",
      "378/378 [==============================] - 0s 158us/step - loss: 32.8848 - val_loss: 38.6988\n",
      "Epoch 254/500\n",
      "378/378 [==============================] - 0s 143us/step - loss: 32.1924 - val_loss: 37.5768\n",
      "Epoch 255/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 32.1575 - val_loss: 38.1733\n",
      "Epoch 256/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 32.2895 - val_loss: 38.2265\n",
      "Epoch 257/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 32.4456 - val_loss: 39.3512\n",
      "Epoch 258/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 31.7110 - val_loss: 40.1061\n",
      "Epoch 259/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 32.6290 - val_loss: 39.3175\n",
      "Epoch 260/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 31.6322 - val_loss: 39.9267\n",
      "Epoch 261/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 32.0425 - val_loss: 39.3842\n",
      "Epoch 262/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 31.8770 - val_loss: 37.8634\n",
      "Epoch 263/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 32.2401 - val_loss: 38.3843\n",
      "Epoch 264/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 31.9199 - val_loss: 40.1153\n",
      "Epoch 265/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 32.0201 - val_loss: 39.0634\n",
      "Epoch 266/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 32.1032 - val_loss: 38.9554\n",
      "Epoch 267/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.9224 - val_loss: 38.0711\n",
      "Epoch 268/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 31.9938 - val_loss: 38.6844\n",
      "Epoch 269/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 32.0690 - val_loss: 40.0462\n",
      "Epoch 270/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.6396 - val_loss: 39.5965\n",
      "Epoch 271/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 32.0912 - val_loss: 40.2744\n",
      "Epoch 272/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 31.9187 - val_loss: 39.5437\n",
      "Epoch 273/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 32.0368 - val_loss: 40.3475\n",
      "Epoch 274/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.6007 - val_loss: 40.0427\n",
      "Epoch 275/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 32.3510 - val_loss: 40.2399\n",
      "Epoch 276/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 31.9359 - val_loss: 39.6656\n",
      "Epoch 277/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.5143 - val_loss: 40.0709\n",
      "Epoch 278/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 31.5180 - val_loss: 38.3469\n",
      "Epoch 279/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 31.4433 - val_loss: 40.1589\n",
      "Epoch 280/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 32.8190 - val_loss: 39.7440\n",
      "Epoch 281/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 32.2347 - val_loss: 40.3970\n",
      "Epoch 282/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.8447 - val_loss: 40.1331\n",
      "Epoch 283/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.4352 - val_loss: 38.7765\n",
      "Epoch 284/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 31.5202 - val_loss: 38.9538\n",
      "Epoch 285/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 31.7205 - val_loss: 40.0717\n",
      "Epoch 286/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 31.8096 - val_loss: 39.4729\n",
      "Epoch 287/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.4904 - val_loss: 40.7404\n",
      "Epoch 288/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 32.0193 - val_loss: 40.5975\n",
      "Epoch 289/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.8245 - val_loss: 41.0510\n",
      "Epoch 290/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 32.0844 - val_loss: 38.8660\n",
      "Epoch 291/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 31.2984 - val_loss: 39.3991\n",
      "Epoch 292/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.8212 - val_loss: 40.5605\n",
      "Epoch 293/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 32.0310 - val_loss: 40.6840\n",
      "Epoch 294/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 31.5821 - val_loss: 38.9809\n",
      "Epoch 295/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.7669 - val_loss: 38.2291\n",
      "Epoch 296/500\n",
      "378/378 [==============================] - 0s 110us/step - loss: 31.6155 - val_loss: 38.1854\n",
      "Epoch 297/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 31.4318 - val_loss: 39.0626\n",
      "Epoch 298/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 31.7502 - val_loss: 40.4638\n",
      "Epoch 299/500\n",
      "378/378 [==============================] - 0s 108us/step - loss: 31.5481 - val_loss: 40.0488\n",
      "Epoch 300/500\n",
      "378/378 [==============================] - 0s 110us/step - loss: 30.6654 - val_loss: 39.5720\n",
      "Epoch 301/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 30.8151 - val_loss: 38.1565\n",
      "Epoch 302/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 32.0689 - val_loss: 39.8381\n",
      "Epoch 303/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 31.6052 - val_loss: 39.1679\n",
      "Epoch 304/500\n",
      "378/378 [==============================] - 0s 123us/step - loss: 31.3682 - val_loss: 39.7888\n",
      "Epoch 305/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 31.7615 - val_loss: 38.7943\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 112us/step - loss: 31.1762 - val_loss: 39.1932\n",
      "Epoch 307/500\n",
      "378/378 [==============================] - 0s 124us/step - loss: 31.3601 - val_loss: 40.4758\n",
      "Epoch 308/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.9723 - val_loss: 39.7988\n",
      "Epoch 309/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 31.2240 - val_loss: 39.2697\n",
      "Epoch 310/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 31.3497 - val_loss: 39.5279\n",
      "Epoch 311/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 31.1582 - val_loss: 39.6884\n",
      "Epoch 312/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 31.5861 - val_loss: 40.0486\n",
      "Epoch 313/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 31.2570 - val_loss: 38.6425\n",
      "Epoch 314/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 31.3038 - val_loss: 40.4669\n",
      "Epoch 315/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 31.9954 - val_loss: 41.9334\n",
      "Epoch 316/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.3679 - val_loss: 41.2329\n",
      "Epoch 317/500\n",
      "378/378 [==============================] - 0s 137us/step - loss: 31.5218 - val_loss: 40.7655\n",
      "Epoch 318/500\n",
      "378/378 [==============================] - 0s 139us/step - loss: 31.6142 - val_loss: 39.9809\n",
      "Epoch 319/500\n",
      "378/378 [==============================] - 0s 143us/step - loss: 31.4562 - val_loss: 40.3262\n",
      "Epoch 320/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 31.4370 - val_loss: 41.6874\n",
      "Epoch 321/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 31.4294 - val_loss: 38.9304\n",
      "Epoch 322/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 31.0041 - val_loss: 39.5018\n",
      "Epoch 323/500\n",
      "378/378 [==============================] - 0s 124us/step - loss: 31.4846 - val_loss: 39.0897\n",
      "Epoch 324/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 30.9111 - val_loss: 39.8756\n",
      "Epoch 325/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 31.1426 - val_loss: 39.9551\n",
      "Epoch 326/500\n",
      "378/378 [==============================] - 0s 140us/step - loss: 31.4511 - val_loss: 42.4207\n",
      "Epoch 327/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 31.7267 - val_loss: 40.2815\n",
      "Epoch 328/500\n",
      "378/378 [==============================] - 0s 127us/step - loss: 31.3319 - val_loss: 40.4035\n",
      "Epoch 329/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.9088 - val_loss: 40.7895\n",
      "Epoch 330/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 30.8061 - val_loss: 40.8743\n",
      "Epoch 331/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.0416 - val_loss: 42.1785\n",
      "Epoch 332/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 31.0934 - val_loss: 41.2613\n",
      "Epoch 333/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 31.4310 - val_loss: 40.6687\n",
      "Epoch 334/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.8968 - val_loss: 40.0269\n",
      "Epoch 335/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 31.2072 - val_loss: 39.6861\n",
      "Epoch 336/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 31.3627 - val_loss: 39.9449\n",
      "Epoch 337/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 31.5941 - val_loss: 40.3691\n",
      "Epoch 338/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 30.8323 - val_loss: 40.6163\n",
      "Epoch 339/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 31.0530 - val_loss: 40.5178\n",
      "Epoch 340/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 31.3706 - val_loss: 41.5034\n",
      "Epoch 341/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 30.9251 - val_loss: 41.8167\n",
      "Epoch 342/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 31.3378 - val_loss: 41.0410\n",
      "Epoch 343/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 31.0038 - val_loss: 42.0460\n",
      "Epoch 344/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 31.5542 - val_loss: 38.7011\n",
      "Epoch 345/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.9995 - val_loss: 40.5179\n",
      "Epoch 346/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.8664 - val_loss: 39.7197\n",
      "Epoch 347/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 30.7968 - val_loss: 39.8042\n",
      "Epoch 348/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 31.3351 - val_loss: 40.9780\n",
      "Epoch 349/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 31.0728 - val_loss: 39.5267\n",
      "Epoch 350/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.6935 - val_loss: 41.0507\n",
      "Epoch 351/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 31.2417 - val_loss: 39.2725\n",
      "Epoch 352/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.7594 - val_loss: 42.9680\n",
      "Epoch 353/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 31.1339 - val_loss: 40.1520\n",
      "Epoch 354/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 31.2462 - val_loss: 39.7720\n",
      "Epoch 355/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 31.0445 - val_loss: 40.7611\n",
      "Epoch 356/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.6748 - val_loss: 39.9286\n",
      "Epoch 357/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.8844 - val_loss: 41.1739\n",
      "Epoch 358/500\n",
      "378/378 [==============================] - 0s 110us/step - loss: 30.8852 - val_loss: 39.9802\n",
      "Epoch 359/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.3380 - val_loss: 40.3607\n",
      "Epoch 360/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 30.6271 - val_loss: 39.8885\n",
      "Epoch 361/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.7246 - val_loss: 39.4884\n",
      "Epoch 362/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.5408 - val_loss: 39.2351\n",
      "Epoch 363/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 30.4051 - val_loss: 40.5264\n",
      "Epoch 364/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.6440 - val_loss: 39.8891\n",
      "Epoch 365/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 31.2815 - val_loss: 40.2606\n",
      "Epoch 366/500\n",
      "378/378 [==============================] - 0s 131us/step - loss: 31.0982 - val_loss: 41.5259\n",
      "Epoch 367/500\n",
      "378/378 [==============================] - 0s 145us/step - loss: 31.3395 - val_loss: 40.8794\n",
      "Epoch 368/500\n",
      "378/378 [==============================] - 0s 153us/step - loss: 30.7414 - val_loss: 38.3555\n",
      "Epoch 369/500\n",
      "378/378 [==============================] - 0s 132us/step - loss: 30.4409 - val_loss: 39.9452\n",
      "Epoch 370/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.7530 - val_loss: 40.7835\n",
      "Epoch 371/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 30.7052 - val_loss: 41.7158\n",
      "Epoch 372/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 31.4735 - val_loss: 40.1631\n",
      "Epoch 373/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.3573 - val_loss: 39.7269\n",
      "Epoch 374/500\n",
      "378/378 [==============================] - 0s 126us/step - loss: 30.9443 - val_loss: 39.9814\n",
      "Epoch 375/500\n",
      "378/378 [==============================] - 0s 110us/step - loss: 30.4814 - val_loss: 40.2537\n",
      "Epoch 376/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 31.3785 - val_loss: 40.2174\n",
      "Epoch 377/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.7557 - val_loss: 39.7024\n",
      "Epoch 378/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 31.3892 - val_loss: 39.6333\n",
      "Epoch 379/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.9077 - val_loss: 40.5202\n",
      "Epoch 380/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 30.9289 - val_loss: 40.3811\n",
      "Epoch 381/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 31.1997 - val_loss: 42.2661\n",
      "Epoch 382/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 30.6856 - val_loss: 40.5898\n",
      "Epoch 383/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.2197 - val_loss: 40.3579\n",
      "Epoch 384/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.1481 - val_loss: 38.9558\n",
      "Epoch 385/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.6162 - val_loss: 39.1890\n",
      "Epoch 386/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 30.5506 - val_loss: 38.9824\n",
      "Epoch 387/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 31.0495 - val_loss: 38.4847\n",
      "Epoch 388/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.6081 - val_loss: 39.1477\n",
      "Epoch 389/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.6526 - val_loss: 39.9162\n",
      "Epoch 390/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.9777 - val_loss: 39.2943\n",
      "Epoch 391/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.2468 - val_loss: 41.0840\n",
      "Epoch 392/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 31.0274 - val_loss: 39.0025\n",
      "Epoch 393/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 31.2719 - val_loss: 38.3878\n",
      "Epoch 394/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.9318 - val_loss: 40.7006\n",
      "Epoch 395/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 31.2238 - val_loss: 39.7894\n",
      "Epoch 396/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.2653 - val_loss: 39.3546\n",
      "Epoch 397/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.3448 - val_loss: 40.1611\n",
      "Epoch 398/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 30.5298 - val_loss: 40.2074\n",
      "Epoch 399/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 30.8110 - val_loss: 39.4222\n",
      "Epoch 400/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.2634 - val_loss: 38.2084\n",
      "Epoch 401/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.8555 - val_loss: 40.3814\n",
      "Epoch 402/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.7609 - val_loss: 39.2130\n",
      "Epoch 403/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.1720 - val_loss: 39.8305\n",
      "Epoch 404/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 31.1160 - val_loss: 39.7367\n",
      "Epoch 405/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.9318 - val_loss: 40.1310\n",
      "Epoch 406/500\n",
      "378/378 [==============================] - 0s 110us/step - loss: 30.6782 - val_loss: 41.4852\n",
      "Epoch 407/500\n",
      "378/378 [==============================] - 0s 106us/step - loss: 30.6017 - val_loss: 41.2509\n",
      "Epoch 408/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 31.4026 - val_loss: 42.1216\n",
      "Epoch 409/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.4075 - val_loss: 40.1767\n",
      "Epoch 410/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 30.2170 - val_loss: 41.5693\n",
      "Epoch 411/500\n",
      "378/378 [==============================] - 0s 110us/step - loss: 31.1166 - val_loss: 39.1333\n",
      "Epoch 412/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 31.0525 - val_loss: 39.4924\n",
      "Epoch 413/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 30.6204 - val_loss: 42.4384\n",
      "Epoch 414/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.6252 - val_loss: 39.4593\n",
      "Epoch 415/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.2652 - val_loss: 38.2620\n",
      "Epoch 416/500\n",
      "378/378 [==============================] - 0s 127us/step - loss: 30.5431 - val_loss: 39.5074\n",
      "Epoch 417/500\n",
      "378/378 [==============================] - 0s 124us/step - loss: 30.4167 - val_loss: 41.1863\n",
      "Epoch 418/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.3338 - val_loss: 40.9955\n",
      "Epoch 419/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.5837 - val_loss: 40.8305\n",
      "Epoch 420/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.2243 - val_loss: 39.9133\n",
      "Epoch 421/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.3353 - val_loss: 39.7060\n",
      "Epoch 422/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.8174 - val_loss: 38.4152\n",
      "Epoch 423/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.3533 - val_loss: 40.2639\n",
      "Epoch 424/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 30.2485 - val_loss: 39.0004\n",
      "Epoch 425/500\n",
      "378/378 [==============================] - 0s 123us/step - loss: 30.5796 - val_loss: 39.4051\n",
      "Epoch 426/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.5380 - val_loss: 40.9850\n",
      "Epoch 427/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 31.1968 - val_loss: 39.8298\n",
      "Epoch 428/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 30.4565 - val_loss: 39.1908\n",
      "Epoch 429/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 30.7562 - val_loss: 39.7028\n",
      "Epoch 430/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 29.8779 - val_loss: 40.3042\n",
      "Epoch 431/500\n",
      "378/378 [==============================] - 0s 124us/step - loss: 30.6204 - val_loss: 39.3020\n",
      "Epoch 432/500\n",
      "378/378 [==============================] - 0s 141us/step - loss: 30.6257 - val_loss: 37.8392\n",
      "Epoch 433/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 30.4159 - val_loss: 37.8130\n",
      "Epoch 434/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 31.1642 - val_loss: 38.9769\n",
      "Epoch 435/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 30.6226 - val_loss: 38.8080\n",
      "Epoch 436/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 30.0750 - val_loss: 41.5153\n",
      "Epoch 437/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 30.3290 - val_loss: 39.2093\n",
      "Epoch 438/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 31.0403 - val_loss: 39.2562\n",
      "Epoch 439/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.6607 - val_loss: 40.1348\n",
      "Epoch 440/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 29.8219 - val_loss: 39.7103\n",
      "Epoch 441/500\n",
      "378/378 [==============================] - 0s 110us/step - loss: 30.4798 - val_loss: 40.2748\n",
      "Epoch 442/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.3315 - val_loss: 40.6481\n",
      "Epoch 443/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 29.9586 - val_loss: 41.7228\n",
      "Epoch 444/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 30.5015 - val_loss: 39.1771\n",
      "Epoch 445/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 30.3006 - val_loss: 42.6020\n",
      "Epoch 446/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.5700 - val_loss: 40.0667\n",
      "Epoch 447/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.3689 - val_loss: 41.5413\n",
      "Epoch 448/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 30.5158 - val_loss: 39.0737\n",
      "Epoch 449/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.5732 - val_loss: 40.6396\n",
      "Epoch 450/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 30.5456 - val_loss: 40.4941\n",
      "Epoch 451/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 30.6499 - val_loss: 40.1168\n",
      "Epoch 452/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.6815 - val_loss: 38.7778\n",
      "Epoch 453/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 29.9414 - val_loss: 39.3367\n",
      "Epoch 454/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 30.2941 - val_loss: 38.7558\n",
      "Epoch 455/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 30.4684 - val_loss: 39.9339\n",
      "Epoch 456/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.8758 - val_loss: 41.2318\n",
      "Epoch 457/500\n",
      "378/378 [==============================] - 0s 123us/step - loss: 30.0184 - val_loss: 40.6614\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 117us/step - loss: 30.3796 - val_loss: 40.3136\n",
      "Epoch 459/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.4188 - val_loss: 39.4738\n",
      "Epoch 460/500\n",
      "378/378 [==============================] - 0s 134us/step - loss: 30.3670 - val_loss: 41.0653\n",
      "Epoch 461/500\n",
      "378/378 [==============================] - 0s 139us/step - loss: 31.0115 - val_loss: 40.8251\n",
      "Epoch 462/500\n",
      "378/378 [==============================] - 0s 148us/step - loss: 29.9184 - val_loss: 39.8697\n",
      "Epoch 463/500\n",
      "378/378 [==============================] - 0s 142us/step - loss: 30.1677 - val_loss: 40.4435\n",
      "Epoch 464/500\n",
      "378/378 [==============================] - 0s 109us/step - loss: 30.2846 - val_loss: 39.8982\n",
      "Epoch 465/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 30.1463 - val_loss: 40.1937\n",
      "Epoch 466/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 30.7215 - val_loss: 39.5725\n",
      "Epoch 467/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 30.6679 - val_loss: 40.0594\n",
      "Epoch 468/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.2605 - val_loss: 40.2787\n",
      "Epoch 469/500\n",
      "378/378 [==============================] - 0s 122us/step - loss: 30.7998 - val_loss: 40.6502\n",
      "Epoch 470/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 30.2017 - val_loss: 40.5727\n",
      "Epoch 471/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.5701 - val_loss: 40.0939\n",
      "Epoch 472/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.2308 - val_loss: 41.4846\n",
      "Epoch 473/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 30.5639 - val_loss: 40.9715\n",
      "Epoch 474/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 29.9164 - val_loss: 40.4180\n",
      "Epoch 475/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 30.1598 - val_loss: 39.9764\n",
      "Epoch 476/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 30.3017 - val_loss: 40.2078\n",
      "Epoch 477/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.2758 - val_loss: 40.3070\n",
      "Epoch 478/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.0853 - val_loss: 40.0043\n",
      "Epoch 479/500\n",
      "378/378 [==============================] - 0s 109us/step - loss: 29.8395 - val_loss: 39.9165\n",
      "Epoch 480/500\n",
      "378/378 [==============================] - 0s 107us/step - loss: 30.2189 - val_loss: 41.9646\n",
      "Epoch 481/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 31.1160 - val_loss: 42.3742\n",
      "Epoch 482/500\n",
      "378/378 [==============================] - 0s 120us/step - loss: 30.0229 - val_loss: 41.2193\n",
      "Epoch 483/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 29.6877 - val_loss: 39.6180\n",
      "Epoch 484/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.5883 - val_loss: 40.9395\n",
      "Epoch 485/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 29.8305 - val_loss: 41.0310\n",
      "Epoch 486/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 29.7814 - val_loss: 40.0478\n",
      "Epoch 487/500\n",
      "378/378 [==============================] - 0s 115us/step - loss: 30.7570 - val_loss: 40.6354\n",
      "Epoch 488/500\n",
      "378/378 [==============================] - 0s 118us/step - loss: 30.1819 - val_loss: 42.2014\n",
      "Epoch 489/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.2726 - val_loss: 41.4132\n",
      "Epoch 490/500\n",
      "378/378 [==============================] - 0s 119us/step - loss: 30.4976 - val_loss: 40.4997\n",
      "Epoch 491/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 30.5545 - val_loss: 40.1144\n",
      "Epoch 492/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.3070 - val_loss: 41.5619\n",
      "Epoch 493/500\n",
      "378/378 [==============================] - 0s 117us/step - loss: 30.2813 - val_loss: 40.8578\n",
      "Epoch 494/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 29.7680 - val_loss: 40.8972\n",
      "Epoch 495/500\n",
      "378/378 [==============================] - 0s 121us/step - loss: 30.4461 - val_loss: 41.0887\n",
      "Epoch 496/500\n",
      "378/378 [==============================] - 0s 114us/step - loss: 30.7840 - val_loss: 41.8095\n",
      "Epoch 497/500\n",
      "378/378 [==============================] - 0s 113us/step - loss: 30.0379 - val_loss: 41.4529\n",
      "Epoch 498/500\n",
      "378/378 [==============================] - 0s 111us/step - loss: 29.6094 - val_loss: 41.3542\n",
      "Epoch 499/500\n",
      "378/378 [==============================] - 0s 116us/step - loss: 29.9991 - val_loss: 41.5048\n",
      "Epoch 500/500\n",
      "378/378 [==============================] - 0s 112us/step - loss: 30.2172 - val_loss: 40.0301\n",
      "mw\n",
      "********************\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/250\n",
      "378/378 [==============================] - 1s 3ms/step - loss: 83.8219 - val_loss: 17.9068\n",
      "Epoch 2/250\n",
      "378/378 [==============================] - 0s 158us/step - loss: 15.9060 - val_loss: 9.1364\n",
      "Epoch 3/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 8.6676 - val_loss: 8.4402\n",
      "Epoch 4/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 7.5378 - val_loss: 8.3536\n",
      "Epoch 5/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.9806 - val_loss: 8.3394\n",
      "Epoch 6/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.8319 - val_loss: 8.3364\n",
      "Epoch 7/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.6353 - val_loss: 8.3336\n",
      "Epoch 8/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.5548 - val_loss: 8.3308\n",
      "Epoch 9/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.5012 - val_loss: 8.3275\n",
      "Epoch 10/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3987 - val_loss: 8.3269\n",
      "Epoch 11/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.4453 - val_loss: 8.3271\n",
      "Epoch 12/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.4317 - val_loss: 8.3288\n",
      "Epoch 13/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.4610 - val_loss: 8.3305\n",
      "Epoch 14/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.4278 - val_loss: 8.3305\n",
      "Epoch 15/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.4111 - val_loss: 8.3299\n",
      "Epoch 16/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3986 - val_loss: 8.3305\n",
      "Epoch 17/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3594 - val_loss: 8.3305\n",
      "Epoch 18/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3660 - val_loss: 8.3305\n",
      "Epoch 19/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3618 - val_loss: 8.3305\n",
      "Epoch 20/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.4251 - val_loss: 8.3305\n",
      "Epoch 21/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3732 - val_loss: 8.3305\n",
      "Epoch 22/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3477 - val_loss: 8.3305\n",
      "Epoch 23/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3357 - val_loss: 8.3305\n",
      "Epoch 24/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3571 - val_loss: 8.3305\n",
      "Epoch 25/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3493 - val_loss: 8.3305\n",
      "Epoch 26/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3137 - val_loss: 8.3305\n",
      "Epoch 27/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3493 - val_loss: 8.3305\n",
      "Epoch 28/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3213 - val_loss: 8.3305\n",
      "Epoch 29/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3604 - val_loss: 8.3305\n",
      "Epoch 30/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 6.3377 - val_loss: 8.3305\n",
      "Epoch 31/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3254 - val_loss: 8.3305\n",
      "Epoch 32/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 6.3174 - val_loss: 8.3305\n",
      "Epoch 33/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3316 - val_loss: 8.3305\n",
      "Epoch 34/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3302 - val_loss: 8.3305\n",
      "Epoch 35/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 121us/step - loss: 6.3622 - val_loss: 8.3305\n",
      "Epoch 36/250\n",
      "378/378 [==============================] - 0s 114us/step - loss: 6.3444 - val_loss: 8.3305\n",
      "Epoch 37/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3139 - val_loss: 8.3305\n",
      "Epoch 38/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3362 - val_loss: 8.3305\n",
      "Epoch 39/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3247 - val_loss: 8.3305\n",
      "Epoch 40/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3242 - val_loss: 8.3305\n",
      "Epoch 41/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3202 - val_loss: 8.3305\n",
      "Epoch 42/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3161 - val_loss: 8.3305\n",
      "Epoch 43/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3093 - val_loss: 8.3305\n",
      "Epoch 44/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 6.3236 - val_loss: 8.3305\n",
      "Epoch 45/250\n",
      "378/378 [==============================] - 0s 180us/step - loss: 6.3189 - val_loss: 8.3305\n",
      "Epoch 46/250\n",
      "378/378 [==============================] - 0s 149us/step - loss: 6.3081 - val_loss: 8.3305\n",
      "Epoch 47/250\n",
      "378/378 [==============================] - 0s 141us/step - loss: 6.3318 - val_loss: 8.3305\n",
      "Epoch 48/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3134 - val_loss: 8.3305\n",
      "Epoch 49/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3074 - val_loss: 8.3305\n",
      "Epoch 50/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3299 - val_loss: 8.3305\n",
      "Epoch 51/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3110 - val_loss: 8.3305\n",
      "Epoch 52/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3149 - val_loss: 8.3305\n",
      "Epoch 53/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3224 - val_loss: 8.3305\n",
      "Epoch 54/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3119 - val_loss: 8.3305\n",
      "Epoch 55/250\n",
      "378/378 [==============================] - 0s 140us/step - loss: 6.3101 - val_loss: 8.3305\n",
      "Epoch 56/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 6.3043 - val_loss: 8.3305\n",
      "Epoch 57/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3084 - val_loss: 8.3305\n",
      "Epoch 58/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3243 - val_loss: 8.3305\n",
      "Epoch 59/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 6.3036 - val_loss: 8.3305\n",
      "Epoch 60/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3057 - val_loss: 8.3305\n",
      "Epoch 61/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3265 - val_loss: 8.3305\n",
      "Epoch 62/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 6.3062 - val_loss: 8.3305\n",
      "Epoch 63/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 64/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3051 - val_loss: 8.3305\n",
      "Epoch 65/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3094 - val_loss: 8.3305\n",
      "Epoch 66/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3042 - val_loss: 8.3305\n",
      "Epoch 67/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3096 - val_loss: 8.3305\n",
      "Epoch 68/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3021 - val_loss: 8.3305\n",
      "Epoch 69/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3027 - val_loss: 8.3305\n",
      "Epoch 70/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3144 - val_loss: 8.3305\n",
      "Epoch 71/250\n",
      "378/378 [==============================] - 0s 114us/step - loss: 6.3022 - val_loss: 8.3305\n",
      "Epoch 72/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3013 - val_loss: 8.3305\n",
      "Epoch 73/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3075 - val_loss: 8.3305\n",
      "Epoch 74/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3030 - val_loss: 8.3305\n",
      "Epoch 75/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3057 - val_loss: 8.3305\n",
      "Epoch 76/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3083 - val_loss: 8.3305\n",
      "Epoch 77/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 78/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.3121 - val_loss: 8.3305\n",
      "Epoch 79/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3025 - val_loss: 8.3305\n",
      "Epoch 80/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3060 - val_loss: 8.3305\n",
      "Epoch 81/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 6.3025 - val_loss: 8.3305\n",
      "Epoch 82/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.2999 - val_loss: 8.3305\n",
      "Epoch 83/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3070 - val_loss: 8.3305\n",
      "Epoch 84/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.2971 - val_loss: 8.3305\n",
      "Epoch 85/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3019 - val_loss: 8.3305\n",
      "Epoch 86/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3153 - val_loss: 8.3305\n",
      "Epoch 87/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.3059 - val_loss: 8.3305\n",
      "Epoch 88/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3069 - val_loss: 8.3305\n",
      "Epoch 89/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3007 - val_loss: 8.3305\n",
      "Epoch 90/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3034 - val_loss: 8.3305\n",
      "Epoch 91/250\n",
      "378/378 [==============================] - 0s 113us/step - loss: 6.3056 - val_loss: 8.3305\n",
      "Epoch 92/250\n",
      "378/378 [==============================] - 0s 114us/step - loss: 6.3047 - val_loss: 8.3305\n",
      "Epoch 93/250\n",
      "378/378 [==============================] - 0s 113us/step - loss: 6.3082 - val_loss: 8.3305\n",
      "Epoch 94/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 6.2995 - val_loss: 8.3305\n",
      "Epoch 95/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.3089 - val_loss: 8.3305\n",
      "Epoch 96/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3063 - val_loss: 8.3305\n",
      "Epoch 97/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3115 - val_loss: 8.3305\n",
      "Epoch 98/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 6.3056 - val_loss: 8.3305\n",
      "Epoch 99/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3052 - val_loss: 8.3305\n",
      "Epoch 100/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.3015 - val_loss: 8.3305\n",
      "Epoch 101/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3017 - val_loss: 8.3305\n",
      "Epoch 102/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3070 - val_loss: 8.3305\n",
      "Epoch 103/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.2973 - val_loss: 8.3305\n",
      "Epoch 104/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 6.3028 - val_loss: 8.3305\n",
      "Epoch 105/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3007 - val_loss: 8.3305\n",
      "Epoch 106/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3028 - val_loss: 8.3305\n",
      "Epoch 107/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3049 - val_loss: 8.3305\n",
      "Epoch 108/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3045 - val_loss: 8.3305\n",
      "Epoch 109/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3040 - val_loss: 8.3305\n",
      "Epoch 110/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3008 - val_loss: 8.3305\n",
      "Epoch 111/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3032 - val_loss: 8.3305\n",
      "Epoch 112/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 6.3018 - val_loss: 8.3305\n",
      "Epoch 113/250\n",
      "378/378 [==============================] - 0s 113us/step - loss: 6.3068 - val_loss: 8.3305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3000 - val_loss: 8.3305\n",
      "Epoch 115/250\n",
      "378/378 [==============================] - 0s 111us/step - loss: 6.3026 - val_loss: 8.3305\n",
      "Epoch 116/250\n",
      "378/378 [==============================] - 0s 113us/step - loss: 6.3038 - val_loss: 8.3305\n",
      "Epoch 117/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 118/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3026 - val_loss: 8.3305\n",
      "Epoch 119/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 6.3047 - val_loss: 8.3305\n",
      "Epoch 120/250\n",
      "378/378 [==============================] - 0s 114us/step - loss: 6.3041 - val_loss: 8.3305\n",
      "Epoch 121/250\n",
      "378/378 [==============================] - 0s 114us/step - loss: 6.3017 - val_loss: 8.3305\n",
      "Epoch 122/250\n",
      "378/378 [==============================] - 0s 113us/step - loss: 6.3045 - val_loss: 8.3305\n",
      "Epoch 123/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3047 - val_loss: 8.3305\n",
      "Epoch 124/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3028 - val_loss: 8.3305\n",
      "Epoch 125/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 6.3055 - val_loss: 8.3305\n",
      "Epoch 126/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3039 - val_loss: 8.3305\n",
      "Epoch 127/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3027 - val_loss: 8.3305\n",
      "Epoch 128/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3031 - val_loss: 8.3305\n",
      "Epoch 129/250\n",
      "378/378 [==============================] - 0s 146us/step - loss: 6.3028 - val_loss: 8.3305\n",
      "Epoch 130/250\n",
      "378/378 [==============================] - 0s 138us/step - loss: 6.3013 - val_loss: 8.3305\n",
      "Epoch 131/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 6.3009 - val_loss: 8.3305\n",
      "Epoch 132/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3086 - val_loss: 8.3305\n",
      "Epoch 133/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3023 - val_loss: 8.3305\n",
      "Epoch 134/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3018 - val_loss: 8.3305\n",
      "Epoch 135/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3041 - val_loss: 8.3305\n",
      "Epoch 136/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3063 - val_loss: 8.3305\n",
      "Epoch 137/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.3061 - val_loss: 8.3305\n",
      "Epoch 138/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3008 - val_loss: 8.3305\n",
      "Epoch 139/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3028 - val_loss: 8.3305\n",
      "Epoch 140/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3019 - val_loss: 8.3305\n",
      "Epoch 141/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3014 - val_loss: 8.3305\n",
      "Epoch 142/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3025 - val_loss: 8.3305\n",
      "Epoch 143/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 6.3036 - val_loss: 8.3305\n",
      "Epoch 144/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3017 - val_loss: 8.3305\n",
      "Epoch 145/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3004 - val_loss: 8.3305\n",
      "Epoch 146/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3049 - val_loss: 8.3305\n",
      "Epoch 147/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.3036 - val_loss: 8.3305\n",
      "Epoch 148/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 149/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.2990 - val_loss: 8.3305\n",
      "Epoch 150/250\n",
      "378/378 [==============================] - 0s 159us/step - loss: 6.3033 - val_loss: 8.3305\n",
      "Epoch 151/250\n",
      "378/378 [==============================] - 0s 159us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 152/250\n",
      "378/378 [==============================] - 0s 141us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 153/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 154/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3090 - val_loss: 8.3305\n",
      "Epoch 155/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 156/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.2981 - val_loss: 8.3305\n",
      "Epoch 157/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.3005 - val_loss: 8.3305\n",
      "Epoch 158/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3094 - val_loss: 8.3305\n",
      "Epoch 159/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3025 - val_loss: 8.3305\n",
      "Epoch 160/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3125 - val_loss: 8.3305\n",
      "Epoch 161/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.3011 - val_loss: 8.3305\n",
      "Epoch 162/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 6.3069 - val_loss: 8.3305\n",
      "Epoch 163/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 164/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.3057 - val_loss: 8.3305\n",
      "Epoch 165/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3009 - val_loss: 8.3305\n",
      "Epoch 166/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3042 - val_loss: 8.3305\n",
      "Epoch 167/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3017 - val_loss: 8.3305\n",
      "Epoch 168/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3026 - val_loss: 8.3305\n",
      "Epoch 169/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 170/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 171/250\n",
      "378/378 [==============================] - 0s 140us/step - loss: 6.3014 - val_loss: 8.3305\n",
      "Epoch 172/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.2989 - val_loss: 8.3305\n",
      "Epoch 173/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 174/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.3043 - val_loss: 8.3305\n",
      "Epoch 175/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 6.3013 - val_loss: 8.3305\n",
      "Epoch 176/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 177/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3025 - val_loss: 8.3305\n",
      "Epoch 178/250\n",
      "378/378 [==============================] - 0s 113us/step - loss: 6.3019 - val_loss: 8.3305\n",
      "Epoch 179/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 180/250\n",
      "378/378 [==============================] - 0s 114us/step - loss: 6.3018 - val_loss: 8.3305\n",
      "Epoch 181/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3025 - val_loss: 8.3305\n",
      "Epoch 182/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3013 - val_loss: 8.3305\n",
      "Epoch 183/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3015 - val_loss: 8.3305\n",
      "Epoch 184/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3028 - val_loss: 8.3305\n",
      "Epoch 185/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 186/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3020 - val_loss: 8.3305\n",
      "Epoch 187/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3013 - val_loss: 8.3305\n",
      "Epoch 188/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 6.3009 - val_loss: 8.3305\n",
      "Epoch 189/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3015 - val_loss: 8.3305\n",
      "Epoch 190/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3006 - val_loss: 8.3305\n",
      "Epoch 191/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3030 - val_loss: 8.3305\n",
      "Epoch 192/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 129us/step - loss: 6.3026 - val_loss: 8.3305\n",
      "Epoch 193/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 194/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.3023 - val_loss: 8.3305\n",
      "Epoch 195/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 196/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.2995 - val_loss: 8.3305\n",
      "Epoch 197/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3016 - val_loss: 8.3305\n",
      "Epoch 198/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 199/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 200/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3010 - val_loss: 8.3305\n",
      "Epoch 201/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 202/250\n",
      "378/378 [==============================] - 0s 114us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 203/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3031 - val_loss: 8.3305\n",
      "Epoch 204/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 205/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3073 - val_loss: 8.3305\n",
      "Epoch 206/250\n",
      "378/378 [==============================] - 0s 106us/step - loss: 6.3018 - val_loss: 8.3305\n",
      "Epoch 207/250\n",
      "378/378 [==============================] - 0s 113us/step - loss: 6.3020 - val_loss: 8.3305\n",
      "Epoch 208/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3009 - val_loss: 8.3305\n",
      "Epoch 209/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3010 - val_loss: 8.3305\n",
      "Epoch 210/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 211/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3011 - val_loss: 8.3305\n",
      "Epoch 212/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3017 - val_loss: 8.3305\n",
      "Epoch 213/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 214/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 215/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 216/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 217/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 6.3013 - val_loss: 8.3305\n",
      "Epoch 218/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 219/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 6.3023 - val_loss: 8.3305\n",
      "Epoch 220/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 221/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3009 - val_loss: 8.3305\n",
      "Epoch 222/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 223/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3010 - val_loss: 8.3305\n",
      "Epoch 224/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 225/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 226/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 227/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3021 - val_loss: 8.3305\n",
      "Epoch 228/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 229/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 6.3021 - val_loss: 8.3305\n",
      "Epoch 230/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 6.3008 - val_loss: 8.3305\n",
      "Epoch 231/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 232/250\n",
      "378/378 [==============================] - 0s 112us/step - loss: 6.3050 - val_loss: 8.3305\n",
      "Epoch 233/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.3009 - val_loss: 8.3305\n",
      "Epoch 234/250\n",
      "378/378 [==============================] - 0s 114us/step - loss: 6.3016 - val_loss: 8.3305\n",
      "Epoch 235/250\n",
      "378/378 [==============================] - 0s 180us/step - loss: 6.3084 - val_loss: 8.3305\n",
      "Epoch 236/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 237/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 238/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 6.3014 - val_loss: 8.3305\n",
      "Epoch 239/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 240/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 6.3025 - val_loss: 8.3305\n",
      "Epoch 241/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 6.3015 - val_loss: 8.3305\n",
      "Epoch 242/250\n",
      "378/378 [==============================] - 0s 139us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 243/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 6.3007 - val_loss: 8.3305\n",
      "Epoch 244/250\n",
      "378/378 [==============================] - 0s 145us/step - loss: 6.3014 - val_loss: 8.3305\n",
      "Epoch 245/250\n",
      "378/378 [==============================] - 0s 141us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 246/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 6.3029 - val_loss: 8.3305\n",
      "Epoch 247/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 248/250\n",
      "378/378 [==============================] - 0s 138us/step - loss: 6.3025 - val_loss: 8.3305\n",
      "Epoch 249/250\n",
      "378/378 [==============================] - 0s 178us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "Epoch 250/250\n",
      "378/378 [==============================] - 0s 140us/step - loss: 6.3012 - val_loss: 8.3305\n",
      "dw\n",
      "********************\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/250\n",
      "378/378 [==============================] - 1s 3ms/step - loss: 88.8070 - val_loss: 27.0537\n",
      "Epoch 2/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 23.8474 - val_loss: 16.5754\n",
      "Epoch 3/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 16.2885 - val_loss: 15.3362\n",
      "Epoch 4/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 14.8806 - val_loss: 15.1313\n",
      "Epoch 5/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 14.3470 - val_loss: 15.0873\n",
      "Epoch 6/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 14.0234 - val_loss: 15.0768\n",
      "Epoch 7/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.8086 - val_loss: 15.0720\n",
      "Epoch 8/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.7636 - val_loss: 15.0704\n",
      "Epoch 9/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.6758 - val_loss: 15.0676\n",
      "Epoch 10/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.6207 - val_loss: 15.0651\n",
      "Epoch 11/250\n",
      "378/378 [==============================] - 0s 112us/step - loss: 13.6369 - val_loss: 15.0648\n",
      "Epoch 12/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.5958 - val_loss: 15.0648\n",
      "Epoch 13/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.6300 - val_loss: 15.0648\n",
      "Epoch 14/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.5852 - val_loss: 15.0648\n",
      "Epoch 15/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.5750 - val_loss: 15.0648\n",
      "Epoch 16/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.5561 - val_loss: 15.0648\n",
      "Epoch 17/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4897 - val_loss: 15.0648\n",
      "Epoch 18/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.5354 - val_loss: 15.0648\n",
      "Epoch 19/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4976 - val_loss: 15.0648\n",
      "Epoch 20/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.5699 - val_loss: 15.0648\n",
      "Epoch 21/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.5366 - val_loss: 15.0648\n",
      "Epoch 22/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.5273 - val_loss: 15.0648\n",
      "Epoch 23/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4944 - val_loss: 15.0648\n",
      "Epoch 24/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.5043 - val_loss: 15.0648\n",
      "Epoch 25/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.5022 - val_loss: 15.0648\n",
      "Epoch 26/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.4721 - val_loss: 15.0648\n",
      "Epoch 27/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4894 - val_loss: 15.0648\n",
      "Epoch 28/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4748 - val_loss: 15.0648\n",
      "Epoch 29/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4939 - val_loss: 15.0648\n",
      "Epoch 30/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4882 - val_loss: 15.0648\n",
      "Epoch 31/250\n",
      "378/378 [==============================] - 0s 147us/step - loss: 13.4665 - val_loss: 15.0648\n",
      "Epoch 32/250\n",
      "378/378 [==============================] - 0s 136us/step - loss: 13.4645 - val_loss: 15.0648\n",
      "Epoch 33/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4709 - val_loss: 15.0648\n",
      "Epoch 34/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4623 - val_loss: 15.0648\n",
      "Epoch 35/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4907 - val_loss: 15.0648\n",
      "Epoch 36/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4793 - val_loss: 15.0648\n",
      "Epoch 37/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4697 - val_loss: 15.0648\n",
      "Epoch 38/250\n",
      "378/378 [==============================] - 0s 110us/step - loss: 13.4852 - val_loss: 15.0648\n",
      "Epoch 39/250\n",
      "378/378 [==============================] - 0s 110us/step - loss: 13.5081 - val_loss: 15.0648\n",
      "Epoch 40/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 13.4590 - val_loss: 15.0648\n",
      "Epoch 41/250\n",
      "378/378 [==============================] - 0s 113us/step - loss: 13.4690 - val_loss: 15.0648\n",
      "Epoch 42/250\n",
      "378/378 [==============================] - 0s 112us/step - loss: 13.4574 - val_loss: 15.0648\n",
      "Epoch 43/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4556 - val_loss: 15.0648\n",
      "Epoch 44/250\n",
      "378/378 [==============================] - 0s 111us/step - loss: 13.4849 - val_loss: 15.0648\n",
      "Epoch 45/250\n",
      "378/378 [==============================] - 0s 110us/step - loss: 13.4650 - val_loss: 15.0648\n",
      "Epoch 46/250\n",
      "378/378 [==============================] - 0s 114us/step - loss: 13.4597 - val_loss: 15.0648\n",
      "Epoch 47/250\n",
      "378/378 [==============================] - 0s 112us/step - loss: 13.4779 - val_loss: 15.0648\n",
      "Epoch 48/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4569 - val_loss: 15.0648\n",
      "Epoch 49/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4761 - val_loss: 15.0648\n",
      "Epoch 50/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.4626 - val_loss: 15.0648\n",
      "Epoch 51/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4567 - val_loss: 15.0648\n",
      "Epoch 52/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 13.4476 - val_loss: 15.0648\n",
      "Epoch 53/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4640 - val_loss: 15.0648\n",
      "Epoch 54/250\n",
      "378/378 [==============================] - 0s 155us/step - loss: 13.4589 - val_loss: 15.0648\n",
      "Epoch 55/250\n",
      "378/378 [==============================] - 0s 147us/step - loss: 13.4535 - val_loss: 15.0648\n",
      "Epoch 56/250\n",
      "378/378 [==============================] - 0s 146us/step - loss: 13.4530 - val_loss: 15.0648\n",
      "Epoch 57/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4541 - val_loss: 15.0648\n",
      "Epoch 58/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 13.4690 - val_loss: 15.0648\n",
      "Epoch 59/250\n",
      "378/378 [==============================] - 0s 110us/step - loss: 13.4498 - val_loss: 15.0648\n",
      "Epoch 60/250\n",
      "378/378 [==============================] - 0s 112us/step - loss: 13.4471 - val_loss: 15.0648\n",
      "Epoch 61/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4676 - val_loss: 15.0648\n",
      "Epoch 62/250\n",
      "378/378 [==============================] - 0s 112us/step - loss: 13.4530 - val_loss: 15.0648\n",
      "Epoch 63/250\n",
      "378/378 [==============================] - 0s 109us/step - loss: 13.4593 - val_loss: 15.0648\n",
      "Epoch 64/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 13.4471 - val_loss: 15.0648\n",
      "Epoch 65/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4552 - val_loss: 15.0648\n",
      "Epoch 66/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4494 - val_loss: 15.0648\n",
      "Epoch 67/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4624 - val_loss: 15.0648\n",
      "Epoch 68/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4461 - val_loss: 15.0648\n",
      "Epoch 69/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4506 - val_loss: 15.0648\n",
      "Epoch 70/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4569 - val_loss: 15.0648\n",
      "Epoch 71/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4473 - val_loss: 15.0648\n",
      "Epoch 72/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4472 - val_loss: 15.0648\n",
      "Epoch 73/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4620 - val_loss: 15.0648\n",
      "Epoch 74/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4461 - val_loss: 15.0648\n",
      "Epoch 75/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4514 - val_loss: 15.0648\n",
      "Epoch 76/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4516 - val_loss: 15.0648\n",
      "Epoch 77/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4563 - val_loss: 15.0648\n",
      "Epoch 78/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4503 - val_loss: 15.0648\n",
      "Epoch 79/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4501 - val_loss: 15.0648\n",
      "Epoch 80/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4505 - val_loss: 15.0648\n",
      "Epoch 81/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.4466 - val_loss: 15.0648\n",
      "Epoch 82/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4454 - val_loss: 15.0648\n",
      "Epoch 83/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4519 - val_loss: 15.0648\n",
      "Epoch 84/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4495 - val_loss: 15.0648\n",
      "Epoch 85/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4462 - val_loss: 15.0648\n",
      "Epoch 86/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4659 - val_loss: 15.0648\n",
      "Epoch 87/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 13.4515 - val_loss: 15.0648\n",
      "Epoch 88/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4526 - val_loss: 15.0648\n",
      "Epoch 89/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.4473 - val_loss: 15.0648\n",
      "Epoch 90/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4509 - val_loss: 15.0648\n",
      "Epoch 91/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4507 - val_loss: 15.0648\n",
      "Epoch 92/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4473 - val_loss: 15.0648\n",
      "Epoch 93/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4469 - val_loss: 15.0648\n",
      "Epoch 94/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 13.4443 - val_loss: 15.0648\n",
      "Epoch 95/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.4499 - val_loss: 15.0648\n",
      "Epoch 96/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 126us/step - loss: 13.4612 - val_loss: 15.0648\n",
      "Epoch 97/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4559 - val_loss: 15.0648\n",
      "Epoch 98/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4462 - val_loss: 15.0648\n",
      "Epoch 99/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4459 - val_loss: 15.0648\n",
      "Epoch 100/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4473 - val_loss: 15.0648\n",
      "Epoch 101/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4471 - val_loss: 15.0648\n",
      "Epoch 102/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4526 - val_loss: 15.0648\n",
      "Epoch 103/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4521 - val_loss: 15.0648\n",
      "Epoch 104/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4508 - val_loss: 15.0648\n",
      "Epoch 105/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4481 - val_loss: 15.0648\n",
      "Epoch 106/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4490 - val_loss: 15.0648\n",
      "Epoch 107/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.4481 - val_loss: 15.0648\n",
      "Epoch 108/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 109/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4506 - val_loss: 15.0648\n",
      "Epoch 110/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.4454 - val_loss: 15.0648\n",
      "Epoch 111/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4491 - val_loss: 15.0648\n",
      "Epoch 112/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4482 - val_loss: 15.0648\n",
      "Epoch 113/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4517 - val_loss: 15.0648\n",
      "Epoch 114/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.4460 - val_loss: 15.0648\n",
      "Epoch 115/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4479 - val_loss: 15.0648\n",
      "Epoch 116/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4459 - val_loss: 15.0648\n",
      "Epoch 117/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4471 - val_loss: 15.0648\n",
      "Epoch 118/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4490 - val_loss: 15.0648\n",
      "Epoch 119/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 13.4469 - val_loss: 15.0648\n",
      "Epoch 120/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4505 - val_loss: 15.0648\n",
      "Epoch 121/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.4457 - val_loss: 15.0648\n",
      "Epoch 122/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4469 - val_loss: 15.0648\n",
      "Epoch 123/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4533 - val_loss: 15.0648\n",
      "Epoch 124/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.4464 - val_loss: 15.0648\n",
      "Epoch 125/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4518 - val_loss: 15.0648\n",
      "Epoch 126/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4489 - val_loss: 15.0648\n",
      "Epoch 127/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4477 - val_loss: 15.0648\n",
      "Epoch 128/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4468 - val_loss: 15.0648\n",
      "Epoch 129/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4469 - val_loss: 15.0648\n",
      "Epoch 130/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 131/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4483 - val_loss: 15.0648\n",
      "Epoch 132/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4512 - val_loss: 15.0648\n",
      "Epoch 133/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4502 - val_loss: 15.0648\n",
      "Epoch 134/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4456 - val_loss: 15.0648\n",
      "Epoch 135/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.4516 - val_loss: 15.0648\n",
      "Epoch 136/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4519 - val_loss: 15.0648\n",
      "Epoch 137/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 13.4465 - val_loss: 15.0648\n",
      "Epoch 138/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 139/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4463 - val_loss: 15.0648\n",
      "Epoch 140/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.4457 - val_loss: 15.0648\n",
      "Epoch 141/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4453 - val_loss: 15.0648\n",
      "Epoch 142/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4475 - val_loss: 15.0648\n",
      "Epoch 143/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4475 - val_loss: 15.0648\n",
      "Epoch 144/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 145/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4470 - val_loss: 15.0648\n",
      "Epoch 146/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4492 - val_loss: 15.0648\n",
      "Epoch 147/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4468 - val_loss: 15.0648\n",
      "Epoch 148/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 13.4462 - val_loss: 15.0648\n",
      "Epoch 149/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4467 - val_loss: 15.0648\n",
      "Epoch 150/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.4486 - val_loss: 15.0648\n",
      "Epoch 151/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 152/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 153/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.4459 - val_loss: 15.0648\n",
      "Epoch 154/250\n",
      "378/378 [==============================] - 0s 116us/step - loss: 13.4396 - val_loss: 15.0648\n",
      "Epoch 155/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.4474 - val_loss: 15.0648\n",
      "Epoch 156/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4502 - val_loss: 15.0648\n",
      "Epoch 157/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 158/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4489 - val_loss: 15.0648\n",
      "Epoch 159/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4457 - val_loss: 15.0648\n",
      "Epoch 160/250\n",
      "378/378 [==============================] - 0s 115us/step - loss: 13.4554 - val_loss: 15.0648\n",
      "Epoch 161/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4528 - val_loss: 15.0648\n",
      "Epoch 162/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4498 - val_loss: 15.0648\n",
      "Epoch 163/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4469 - val_loss: 15.0648\n",
      "Epoch 164/250\n",
      "378/378 [==============================] - 0s 117us/step - loss: 13.4457 - val_loss: 15.0648\n",
      "Epoch 165/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 166/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4453 - val_loss: 15.0648\n",
      "Epoch 167/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4455 - val_loss: 15.0648\n",
      "Epoch 168/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4497 - val_loss: 15.0648\n",
      "Epoch 169/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 170/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 171/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4453 - val_loss: 15.0648\n",
      "Epoch 172/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4457 - val_loss: 15.0648\n",
      "Epoch 173/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 174/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.4501 - val_loss: 15.0648\n",
      "Epoch 175/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 176/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4471 - val_loss: 15.0648\n",
      "Epoch 177/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 178/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.4483 - val_loss: 15.0648\n",
      "Epoch 179/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 180/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 13.4468 - val_loss: 15.0648\n",
      "Epoch 181/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4453 - val_loss: 15.0648\n",
      "Epoch 182/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 183/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 13.4445 - val_loss: 15.0648\n",
      "Epoch 184/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 13.4459 - val_loss: 15.0648\n",
      "Epoch 185/250\n",
      "378/378 [==============================] - 0s 151us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 186/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 187/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 188/250\n",
      "378/378 [==============================] - 0s 143us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 189/250\n",
      "378/378 [==============================] - 0s 150us/step - loss: 13.4469 - val_loss: 15.0648\n",
      "Epoch 190/250\n",
      "378/378 [==============================] - 0s 145us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 191/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 192/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4463 - val_loss: 15.0648\n",
      "Epoch 193/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 194/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4451 - val_loss: 15.0648\n",
      "Epoch 195/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 196/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4454 - val_loss: 15.0648\n",
      "Epoch 197/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4470 - val_loss: 15.0648\n",
      "Epoch 198/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 199/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 200/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4469 - val_loss: 15.0648\n",
      "Epoch 201/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 13.4457 - val_loss: 15.0648\n",
      "Epoch 202/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 203/250\n",
      "378/378 [==============================] - 0s 137us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 204/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 205/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.4475 - val_loss: 15.0648\n",
      "Epoch 206/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4457 - val_loss: 15.0648\n",
      "Epoch 207/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4493 - val_loss: 15.0648\n",
      "Epoch 208/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 209/250\n",
      "378/378 [==============================] - 0s 160us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 210/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 211/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 212/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4462 - val_loss: 15.0648\n",
      "Epoch 213/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 214/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 215/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 216/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 13.4455 - val_loss: 15.0648\n",
      "Epoch 217/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 218/250\n",
      "378/378 [==============================] - 0s 136us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 219/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 220/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.4454 - val_loss: 15.0648\n",
      "Epoch 221/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 222/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.4453 - val_loss: 15.0648\n",
      "Epoch 223/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4529 - val_loss: 15.0648\n",
      "Epoch 224/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 225/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 226/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 227/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 228/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 229/250\n",
      "378/378 [==============================] - 0s 149us/step - loss: 13.4478 - val_loss: 15.0648\n",
      "Epoch 230/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 231/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.4454 - val_loss: 15.0648\n",
      "Epoch 232/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.4475 - val_loss: 15.0648\n",
      "Epoch 233/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4459 - val_loss: 15.0648\n",
      "Epoch 234/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 235/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.4512 - val_loss: 15.0648\n",
      "Epoch 236/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 237/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 238/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.4455 - val_loss: 15.0648\n",
      "Epoch 239/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4448 - val_loss: 15.0648\n",
      "Epoch 240/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4443 - val_loss: 15.0648\n",
      "Epoch 241/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 13.4458 - val_loss: 15.0648\n",
      "Epoch 242/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 243/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.4499 - val_loss: 15.0648\n",
      "Epoch 244/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4463 - val_loss: 15.0648\n",
      "Epoch 245/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 246/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 247/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 248/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 128us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 249/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "Epoch 250/250\n",
      "378/378 [==============================] - 0s 113us/step - loss: 13.4452 - val_loss: 15.0648\n",
      "wm\n",
      "********************\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 3ms/step - loss: 83.1399 - val_loss: 17.0875\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 15.5730 - val_loss: 5.7701\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 7.4662 - val_loss: 4.5463\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 6.1663 - val_loss: 4.3702\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 5.5833 - val_loss: 4.3453\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 5.3496 - val_loss: 4.3410\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 5.1049 - val_loss: 4.3410\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 5.0757 - val_loss: 4.3410\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.9750 - val_loss: 4.3410\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.8889 - val_loss: 4.3410\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 116us/step - loss: 4.9104 - val_loss: 4.3410\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 110us/step - loss: 4.8698 - val_loss: 4.3410\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.8947 - val_loss: 4.3410\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 111us/step - loss: 4.8756 - val_loss: 4.3410\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 112us/step - loss: 4.8541 - val_loss: 4.3410\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.8294 - val_loss: 4.3410\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 112us/step - loss: 4.7914 - val_loss: 4.3410\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.8266 - val_loss: 4.3410\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7914 - val_loss: 4.3410\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.8456 - val_loss: 4.3410\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.8388 - val_loss: 4.3410\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.8020 - val_loss: 4.3410\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7891 - val_loss: 4.3410\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7675 - val_loss: 4.3410\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 4.7936 - val_loss: 4.3410\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7624 - val_loss: 4.3410\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.8092 - val_loss: 4.3410\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7803 - val_loss: 4.3410\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7942 - val_loss: 4.3410\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 134us/step - loss: 4.7814 - val_loss: 4.3410\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7552 - val_loss: 4.3410\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7570 - val_loss: 4.3410\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7664 - val_loss: 4.3410\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7657 - val_loss: 4.3410\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7832 - val_loss: 4.3410\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 133us/step - loss: 4.7741 - val_loss: 4.3410\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7536 - val_loss: 4.3410\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7773 - val_loss: 4.3410\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7866 - val_loss: 4.3410\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7525 - val_loss: 4.3410\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7605 - val_loss: 4.3410\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7473 - val_loss: 4.3410\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7483 - val_loss: 4.3410\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7674 - val_loss: 4.3410\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 112us/step - loss: 4.7554 - val_loss: 4.3410\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7519 - val_loss: 4.3410\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7615 - val_loss: 4.3410\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7456 - val_loss: 4.3410\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7627 - val_loss: 4.3410\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7313 - val_loss: 4.3410\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 116us/step - loss: 4.7510 - val_loss: 4.3410\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7439 - val_loss: 4.3410\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 121us/step - loss: 4.7563 - val_loss: 4.3410\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7474 - val_loss: 4.3410\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7449 - val_loss: 4.3410\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7330 - val_loss: 4.3410\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7409 - val_loss: 4.3410\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7396 - val_loss: 4.3410\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7391 - val_loss: 4.3410\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7326 - val_loss: 4.3410\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7497 - val_loss: 4.3410\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7366 - val_loss: 4.3410\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7472 - val_loss: 4.3410\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7406 - val_loss: 4.3410\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7340 - val_loss: 4.3410\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7343 - val_loss: 4.3410\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7482 - val_loss: 4.3410\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7369 - val_loss: 4.3410\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7344 - val_loss: 4.3410\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7479 - val_loss: 4.3410\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 172us/step - loss: 4.7350 - val_loss: 4.3410\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7327 - val_loss: 4.3410\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 116us/step - loss: 4.7509 - val_loss: 4.3410\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 116us/step - loss: 4.7330 - val_loss: 4.3410\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 137us/step - loss: 4.7389 - val_loss: 4.3410\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 150us/step - loss: 4.7433 - val_loss: 4.3410\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7436 - val_loss: 4.3410\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7427 - val_loss: 4.3410\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7372 - val_loss: 4.3410\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 122us/step - loss: 4.7403 - val_loss: 4.3410\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7328 - val_loss: 4.3410\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7329 - val_loss: 4.3410\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7414 - val_loss: 4.3410\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7337 - val_loss: 4.3410\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7585 - val_loss: 4.3410\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7378 - val_loss: 4.3410\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7478 - val_loss: 4.3410\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 133us/step - loss: 4.7342 - val_loss: 4.3410\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 135us/step - loss: 4.7374 - val_loss: 4.3410\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 152us/step - loss: 4.7334 - val_loss: 4.3410\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 144us/step - loss: 4.7333 - val_loss: 4.3410\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 150us/step - loss: 4.7343 - val_loss: 4.3410\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7344 - val_loss: 4.3410\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7366 - val_loss: 4.3410\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7488 - val_loss: 4.3410\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 116us/step - loss: 4.7440 - val_loss: 4.3410\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7370 - val_loss: 4.3410\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7309 - val_loss: 4.3410\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 116us/step - loss: 4.7319 - val_loss: 4.3410\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7432 - val_loss: 4.3410\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7407 - val_loss: 4.3410\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7382 - val_loss: 4.3410\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7352 - val_loss: 4.3410\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7358 - val_loss: 4.3410\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7355 - val_loss: 4.3410\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7319 - val_loss: 4.3410\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 133us/step - loss: 4.7343 - val_loss: 4.3410\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7345 - val_loss: 4.3410\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 133us/step - loss: 4.7404 - val_loss: 4.3410\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7414 - val_loss: 4.3410\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7340 - val_loss: 4.3410\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7326 - val_loss: 4.3410\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7320 - val_loss: 4.3410\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7311 - val_loss: 4.3410\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7399 - val_loss: 4.3410\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7329 - val_loss: 4.3410\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7376 - val_loss: 4.3410\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7389 - val_loss: 4.3410\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7396 - val_loss: 4.3410\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7347 - val_loss: 4.3410\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7354 - val_loss: 4.3410\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7355 - val_loss: 4.3410\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7345 - val_loss: 4.3410\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 133us/step - loss: 4.7309 - val_loss: 4.3410\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7368 - val_loss: 4.3410\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 4.7370 - val_loss: 4.3410\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7357 - val_loss: 4.3410\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7378 - val_loss: 4.3410\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7373 - val_loss: 4.3410\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7344 - val_loss: 4.3410\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7320 - val_loss: 4.3410\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7361 - val_loss: 4.3410\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7326 - val_loss: 4.3410\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7351 - val_loss: 4.3410\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 121us/step - loss: 4.7349 - val_loss: 4.3410\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7370 - val_loss: 4.3410\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7321 - val_loss: 4.3410\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7326 - val_loss: 4.3410\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7323 - val_loss: 4.3410\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 116us/step - loss: 4.7361 - val_loss: 4.3410\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7338 - val_loss: 4.3410\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 119us/step - loss: 4.7265 - val_loss: 4.3410\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7330 - val_loss: 4.3410\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7379 - val_loss: 4.3410\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7319 - val_loss: 4.3410\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7332 - val_loss: 4.3410\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 136us/step - loss: 4.7318 - val_loss: 4.3410\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7411 - val_loss: 4.3410\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 122us/step - loss: 4.7391 - val_loss: 4.3410\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7347 - val_loss: 4.3410\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7332 - val_loss: 4.3410\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7354 - val_loss: 4.3410\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7351 - val_loss: 4.3410\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7318 - val_loss: 4.3410\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 122us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 156us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7360 - val_loss: 4.3410\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7310 - val_loss: 4.3410\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 4.7335 - val_loss: 4.3410\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7312 - val_loss: 4.3410\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 121us/step - loss: 4.7309 - val_loss: 4.3410\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7325 - val_loss: 4.3410\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 4.7320 - val_loss: 4.3410\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 4.7330 - val_loss: 4.3410\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7319 - val_loss: 4.3410\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 116us/step - loss: 4.7332 - val_loss: 4.3410\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7328 - val_loss: 4.3410\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7308 - val_loss: 4.3410\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7337 - val_loss: 4.3410\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7328 - val_loss: 4.3410\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7333 - val_loss: 4.3410\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7326 - val_loss: 4.3410\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 139us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7325 - val_loss: 4.3410\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 170us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 147us/step - loss: 4.7319 - val_loss: 4.3410\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 179us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7318 - val_loss: 4.3410\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7399 - val_loss: 4.3410\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7334 - val_loss: 4.3410\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7323 - val_loss: 4.3410\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7362 - val_loss: 4.3410\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7318 - val_loss: 4.3410\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7362 - val_loss: 4.3410\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 4.554 - 0s 129us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 135us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7364 - val_loss: 4.3410\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7325 - val_loss: 4.3410\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7320 - val_loss: 4.3410\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 121us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 136us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 141us/step - loss: 4.7333 - val_loss: 4.3410\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 6.104 - 0s 123us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 133us/step - loss: 4.7338 - val_loss: 4.3410\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 120us/step - loss: 4.7337 - val_loss: 4.3410\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 131us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 4.7322 - val_loss: 4.3410\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7326 - val_loss: 4.3410\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7461 - val_loss: 4.3410\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 124us/step - loss: 4.7322 - val_loss: 4.3410\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7318 - val_loss: 4.3410\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 132us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 130us/step - loss: 4.7319 - val_loss: 4.3410\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7331 - val_loss: 4.3410\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 129us/step - loss: 4.7338 - val_loss: 4.3410\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 126us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 4.7328 - val_loss: 4.3410\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 111us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 113us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 112us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 142us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 121us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 111us/step - loss: 4.7379 - val_loss: 4.3410\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 111us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 111us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 111us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 117us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 118us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 122us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 122us/step - loss: 4.7327 - val_loss: 4.3410\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7340 - val_loss: 4.3410\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 125us/step - loss: 4.7322 - val_loss: 4.3410\n",
      "oven\n",
      "********************\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/250\n",
      "378/378 [==============================] - 1s 3ms/step - loss: 85.4946 - val_loss: 24.5830\n",
      "Epoch 2/250\n",
      "378/378 [==============================] - 0s 139us/step - loss: 23.2607 - val_loss: 14.3820\n",
      "Epoch 3/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 16.4812 - val_loss: 13.7477\n",
      "Epoch 4/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 15.5363 - val_loss: 13.6055\n",
      "Epoch 5/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 15.1210 - val_loss: 13.5485\n",
      "Epoch 6/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.8384 - val_loss: 13.5376\n",
      "Epoch 7/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 14.7746 - val_loss: 13.5344\n",
      "Epoch 8/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 14.6760 - val_loss: 13.5317\n",
      "Epoch 9/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 134us/step - loss: 14.6388 - val_loss: 13.5292\n",
      "Epoch 10/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 14.5970 - val_loss: 13.5281\n",
      "Epoch 11/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 14.5895 - val_loss: 13.5295\n",
      "Epoch 12/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 14.5554 - val_loss: 13.5289\n",
      "Epoch 13/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 14.5966 - val_loss: 13.5239\n",
      "Epoch 14/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 14.5681 - val_loss: 13.5176\n",
      "Epoch 15/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 14.5617 - val_loss: 13.5187\n",
      "Epoch 16/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 14.5268 - val_loss: 13.5165\n",
      "Epoch 17/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 14.5224 - val_loss: 13.5165\n",
      "Epoch 18/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.5293 - val_loss: 13.5165\n",
      "Epoch 19/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 14.4986 - val_loss: 13.5171\n",
      "Epoch 20/250\n",
      "378/378 [==============================] - 0s 137us/step - loss: 14.5334 - val_loss: 13.5167\n",
      "Epoch 21/250\n",
      "378/378 [==============================] - 0s 139us/step - loss: 14.5318 - val_loss: 13.5176\n",
      "Epoch 22/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 14.4993 - val_loss: 13.5195\n",
      "Epoch 23/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 14.4883 - val_loss: 13.5187\n",
      "Epoch 24/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 14.5015 - val_loss: 13.5181\n",
      "Epoch 25/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 14.5031 - val_loss: 13.5165\n",
      "Epoch 26/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 14.4649 - val_loss: 13.5165\n",
      "Epoch 27/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 14.5126 - val_loss: 13.5165\n",
      "Epoch 28/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 14.4765 - val_loss: 13.5165\n",
      "Epoch 29/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.5286 - val_loss: 13.5165\n",
      "Epoch 30/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 14.4686 - val_loss: 13.5165\n",
      "Epoch 31/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4754 - val_loss: 13.5165\n",
      "Epoch 32/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4791 - val_loss: 13.5165\n",
      "Epoch 33/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4849 - val_loss: 13.5165\n",
      "Epoch 34/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 14.4909 - val_loss: 13.5165\n",
      "Epoch 35/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 14.4872 - val_loss: 13.5165\n",
      "Epoch 36/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.4868 - val_loss: 13.5165\n",
      "Epoch 37/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 14.4879 - val_loss: 13.5165\n",
      "Epoch 38/250\n",
      "378/378 [==============================] - 0s 136us/step - loss: 14.5085 - val_loss: 13.5165\n",
      "Epoch 39/250\n",
      "378/378 [==============================] - 0s 147us/step - loss: 14.4830 - val_loss: 13.5165\n",
      "Epoch 40/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.4634 - val_loss: 13.5165\n",
      "Epoch 41/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.4808 - val_loss: 13.5165\n",
      "Epoch 42/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 14.4824 - val_loss: 13.5165\n",
      "Epoch 43/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 14.4680 - val_loss: 13.5165\n",
      "Epoch 44/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 14.5001 - val_loss: 13.5165\n",
      "Epoch 45/250\n",
      "378/378 [==============================] - ETA: 0s - loss: 8.339 - 0s 129us/step - loss: 14.4864 - val_loss: 13.5165\n",
      "Epoch 46/250\n",
      "378/378 [==============================] - ETA: 0s - loss: 8.701 - 0s 133us/step - loss: 14.4744 - val_loss: 13.5165\n",
      "Epoch 47/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 14.4934 - val_loss: 13.5165\n",
      "Epoch 48/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4646 - val_loss: 13.5165\n",
      "Epoch 49/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 14.4704 - val_loss: 13.5165\n",
      "Epoch 50/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 14.4709 - val_loss: 13.5165\n",
      "Epoch 51/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 14.4679 - val_loss: 13.5165\n",
      "Epoch 52/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 14.4801 - val_loss: 13.5165\n",
      "Epoch 53/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 14.4552 - val_loss: 13.5165\n",
      "Epoch 54/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 14.4637 - val_loss: 13.5165\n",
      "Epoch 55/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 14.4611 - val_loss: 13.5165\n",
      "Epoch 56/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.4682 - val_loss: 13.5165\n",
      "Epoch 57/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.4561 - val_loss: 13.5165\n",
      "Epoch 58/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 14.4487 - val_loss: 13.5165\n",
      "Epoch 59/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 14.4685 - val_loss: 13.5165\n",
      "Epoch 60/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 14.4620 - val_loss: 13.5165\n",
      "Epoch 61/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4613 - val_loss: 13.5165\n",
      "Epoch 62/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4651 - val_loss: 13.5171\n",
      "Epoch 63/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 14.4619 - val_loss: 13.5205\n",
      "Epoch 64/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 14.4586 - val_loss: 13.5199\n",
      "Epoch 65/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 14.4815 - val_loss: 13.5173\n",
      "Epoch 66/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 14.4579 - val_loss: 13.5165\n",
      "Epoch 67/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 14.4718 - val_loss: 13.5165\n",
      "Epoch 68/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4608 - val_loss: 13.5165\n",
      "Epoch 69/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.4773 - val_loss: 13.5165\n",
      "Epoch 70/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 14.4585 - val_loss: 13.5165\n",
      "Epoch 71/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 14.4619 - val_loss: 13.5165\n",
      "Epoch 72/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 14.4703 - val_loss: 13.5165\n",
      "Epoch 73/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 14.4532 - val_loss: 13.5165\n",
      "Epoch 74/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.4636 - val_loss: 13.5165\n",
      "Epoch 75/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 14.4611 - val_loss: 13.5165\n",
      "Epoch 76/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 14.4746 - val_loss: 13.5165\n",
      "Epoch 77/250\n",
      "378/378 [==============================] - 0s 137us/step - loss: 14.4516 - val_loss: 13.5165\n",
      "Epoch 78/250\n",
      "378/378 [==============================] - 0s 165us/step - loss: 14.4638 - val_loss: 13.5165\n",
      "Epoch 79/250\n",
      "378/378 [==============================] - 0s 146us/step - loss: 14.4767 - val_loss: 13.5165\n",
      "Epoch 80/250\n",
      "378/378 [==============================] - 0s 154us/step - loss: 14.4590 - val_loss: 13.5165\n",
      "Epoch 81/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4584 - val_loss: 13.5165\n",
      "Epoch 82/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 14.4599 - val_loss: 13.5165\n",
      "Epoch 83/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 14.4577 - val_loss: 13.5165\n",
      "Epoch 84/250\n",
      "378/378 [==============================] - 0s 149us/step - loss: 14.4513 - val_loss: 13.5165\n",
      "Epoch 85/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 14.4619 - val_loss: 13.5165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 14.4617 - val_loss: 13.5180\n",
      "Epoch 87/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 14.4544 - val_loss: 13.5179\n",
      "Epoch 88/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 14.4448 - val_loss: 13.5183\n",
      "Epoch 89/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 14.4630 - val_loss: 13.5165\n",
      "Epoch 90/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4542 - val_loss: 13.5165\n",
      "Epoch 91/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 14.4567 - val_loss: 13.5181\n",
      "Epoch 92/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 14.4473 - val_loss: 13.5075\n",
      "Epoch 93/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 14.4660 - val_loss: 13.5007\n",
      "Epoch 94/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4361 - val_loss: 13.5165\n",
      "Epoch 95/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 14.4503 - val_loss: 13.5090\n",
      "Epoch 96/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 14.4592 - val_loss: 13.4720\n",
      "Epoch 97/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 14.4329 - val_loss: 13.4639\n",
      "Epoch 98/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 14.4308 - val_loss: 13.4675\n",
      "Epoch 99/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 14.3995 - val_loss: 13.4251\n",
      "Epoch 100/250\n",
      "378/378 [==============================] - 0s 141us/step - loss: 14.4174 - val_loss: 13.3731\n",
      "Epoch 101/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 14.3545 - val_loss: 13.3941\n",
      "Epoch 102/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 14.3508 - val_loss: 13.3359\n",
      "Epoch 103/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 14.3103 - val_loss: 13.3279\n",
      "Epoch 104/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.2802 - val_loss: 13.3228\n",
      "Epoch 105/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 14.2609 - val_loss: 13.2721\n",
      "Epoch 106/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.2139 - val_loss: 13.2903\n",
      "Epoch 107/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.1983 - val_loss: 13.2771\n",
      "Epoch 108/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 14.0828 - val_loss: 13.1795\n",
      "Epoch 109/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 14.0993 - val_loss: 13.0846\n",
      "Epoch 110/250\n",
      "378/378 [==============================] - 0s 138us/step - loss: 14.0076 - val_loss: 13.1016\n",
      "Epoch 111/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 14.0304 - val_loss: 13.1182\n",
      "Epoch 112/250\n",
      "378/378 [==============================] - 0s 139us/step - loss: 13.9632 - val_loss: 13.0712\n",
      "Epoch 113/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.9006 - val_loss: 13.0824\n",
      "Epoch 114/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.9263 - val_loss: 13.0582\n",
      "Epoch 115/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.7625 - val_loss: 13.1548\n",
      "Epoch 116/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.8256 - val_loss: 13.0120\n",
      "Epoch 117/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 13.7829 - val_loss: 13.0370\n",
      "Epoch 118/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 13.8275 - val_loss: 12.9281\n",
      "Epoch 119/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 13.8204 - val_loss: 12.9648\n",
      "Epoch 120/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.7946 - val_loss: 12.9704\n",
      "Epoch 121/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.7651 - val_loss: 12.9854\n",
      "Epoch 122/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.7233 - val_loss: 12.9734\n",
      "Epoch 123/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.6040 - val_loss: 12.9451\n",
      "Epoch 124/250\n",
      "378/378 [==============================] - 0s 139us/step - loss: 13.6852 - val_loss: 12.8959\n",
      "Epoch 125/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.6510 - val_loss: 12.8554\n",
      "Epoch 126/250\n",
      "378/378 [==============================] - 0s 211us/step - loss: 13.5999 - val_loss: 12.8074\n",
      "Epoch 127/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 13.5885 - val_loss: 12.8861\n",
      "Epoch 128/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 13.4836 - val_loss: 12.8323\n",
      "Epoch 129/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 13.4353 - val_loss: 12.7927\n",
      "Epoch 130/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.6071 - val_loss: 12.7419\n",
      "Epoch 131/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 13.5183 - val_loss: 12.6590\n",
      "Epoch 132/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.4677 - val_loss: 12.6050\n",
      "Epoch 133/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.4859 - val_loss: 12.6885\n",
      "Epoch 134/250\n",
      "378/378 [==============================] - 0s 124us/step - loss: 13.5135 - val_loss: 12.6759\n",
      "Epoch 135/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 13.3991 - val_loss: 12.7643\n",
      "Epoch 136/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.4379 - val_loss: 12.7539\n",
      "Epoch 137/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.4065 - val_loss: 12.7252\n",
      "Epoch 138/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.3669 - val_loss: 12.7693\n",
      "Epoch 139/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.3049 - val_loss: 12.7138\n",
      "Epoch 140/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 13.3928 - val_loss: 12.7738\n",
      "Epoch 141/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.4343 - val_loss: 12.6631\n",
      "Epoch 142/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.2826 - val_loss: 12.6483\n",
      "Epoch 143/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.3228 - val_loss: 12.5174\n",
      "Epoch 144/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.2871 - val_loss: 12.3914\n",
      "Epoch 145/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.2982 - val_loss: 12.5352\n",
      "Epoch 146/250\n",
      "378/378 [==============================] - 0s 138us/step - loss: 13.2078 - val_loss: 12.2640\n",
      "Epoch 147/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.1396 - val_loss: 12.2060\n",
      "Epoch 148/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.2084 - val_loss: 12.2880\n",
      "Epoch 149/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.1740 - val_loss: 12.5510\n",
      "Epoch 150/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 13.1966 - val_loss: 12.2309\n",
      "Epoch 151/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.1939 - val_loss: 12.3188\n",
      "Epoch 152/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 13.1223 - val_loss: 12.3875\n",
      "Epoch 153/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.3229 - val_loss: 12.6054\n",
      "Epoch 154/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.1322 - val_loss: 12.4197\n",
      "Epoch 155/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 13.0788 - val_loss: 12.3705\n",
      "Epoch 156/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.1723 - val_loss: 12.4310\n",
      "Epoch 157/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.0013 - val_loss: 12.2281\n",
      "Epoch 158/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 13.0248 - val_loss: 12.4465\n",
      "Epoch 159/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 13.2175 - val_loss: 12.5020\n",
      "Epoch 160/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.0156 - val_loss: 12.6371\n",
      "Epoch 161/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.1961 - val_loss: 12.2693\n",
      "Epoch 162/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 13.1523 - val_loss: 12.6401\n",
      "Epoch 163/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.1433 - val_loss: 12.6641\n",
      "Epoch 164/250\n",
      "378/378 [==============================] - 0s 137us/step - loss: 13.0366 - val_loss: 12.6070\n",
      "Epoch 165/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.1367 - val_loss: 12.6366\n",
      "Epoch 166/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.1739 - val_loss: 12.5923\n",
      "Epoch 167/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 13.0676 - val_loss: 12.5381\n",
      "Epoch 168/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.0624 - val_loss: 12.5364\n",
      "Epoch 169/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 13.0203 - val_loss: 12.5293\n",
      "Epoch 170/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 12.9440 - val_loss: 12.6299\n",
      "Epoch 171/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 13.1113 - val_loss: 12.6174\n",
      "Epoch 172/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 13.0804 - val_loss: 12.5971\n",
      "Epoch 173/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 12.9573 - val_loss: 12.5656\n",
      "Epoch 174/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 13.1154 - val_loss: 12.5035\n",
      "Epoch 175/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 13.1325 - val_loss: 12.6030\n",
      "Epoch 176/250\n",
      "378/378 [==============================] - 0s 145us/step - loss: 13.1203 - val_loss: 12.5818\n",
      "Epoch 177/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 13.0066 - val_loss: 12.3141\n",
      "Epoch 178/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 12.9833 - val_loss: 12.4126\n",
      "Epoch 179/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 13.0624 - val_loss: 12.4718\n",
      "Epoch 180/250\n",
      "378/378 [==============================] - 0s 140us/step - loss: 13.0250 - val_loss: 12.5041\n",
      "Epoch 181/250\n",
      "378/378 [==============================] - 0s 144us/step - loss: 12.9819 - val_loss: 12.3958\n",
      "Epoch 182/250\n",
      "378/378 [==============================] - 0s 151us/step - loss: 12.9655 - val_loss: 12.6193\n",
      "Epoch 183/250\n",
      "378/378 [==============================] - 0s 146us/step - loss: 12.9404 - val_loss: 12.5503\n",
      "Epoch 184/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 12.9704 - val_loss: 12.6115\n",
      "Epoch 185/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 13.0110 - val_loss: 12.5220\n",
      "Epoch 186/250\n",
      "378/378 [==============================] - ETA: 0s - loss: 20.68 - 0s 129us/step - loss: 12.9959 - val_loss: 12.2808\n",
      "Epoch 187/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 12.9206 - val_loss: 12.1808\n",
      "Epoch 188/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 13.0088 - val_loss: 12.2347\n",
      "Epoch 189/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 13.0576 - val_loss: 12.1633\n",
      "Epoch 190/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 12.9613 - val_loss: 12.1796\n",
      "Epoch 191/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 12.9055 - val_loss: 12.2568\n",
      "Epoch 192/250\n",
      "378/378 [==============================] - 0s 137us/step - loss: 12.9760 - val_loss: 12.3352\n",
      "Epoch 193/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 12.9435 - val_loss: 12.2705\n",
      "Epoch 194/250\n",
      "378/378 [==============================] - 0s 105us/step - loss: 12.9510 - val_loss: 12.1830\n",
      "Epoch 195/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 12.9667 - val_loss: 12.2900\n",
      "Epoch 196/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 12.9616 - val_loss: 12.3646\n",
      "Epoch 197/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 12.9087 - val_loss: 12.4651\n",
      "Epoch 198/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 12.9797 - val_loss: 12.4514\n",
      "Epoch 199/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 13.0087 - val_loss: 12.4321\n",
      "Epoch 200/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 12.9954 - val_loss: 12.2824\n",
      "Epoch 201/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 12.8830 - val_loss: 12.4137\n",
      "Epoch 202/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 12.9623 - val_loss: 12.5426\n",
      "Epoch 203/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 12.8850 - val_loss: 12.6690\n",
      "Epoch 204/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 12.8357 - val_loss: 12.6236\n",
      "Epoch 205/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 12.9581 - val_loss: 12.4853\n",
      "Epoch 206/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 12.9478 - val_loss: 12.2952\n",
      "Epoch 207/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 12.9523 - val_loss: 12.4060\n",
      "Epoch 208/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 12.8466 - val_loss: 12.3185\n",
      "Epoch 209/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 12.9324 - val_loss: 12.3965\n",
      "Epoch 210/250\n",
      "378/378 [==============================] - 0s 138us/step - loss: 12.8792 - val_loss: 12.6624\n",
      "Epoch 211/250\n",
      "378/378 [==============================] - 0s 127us/step - loss: 12.9159 - val_loss: 12.4546\n",
      "Epoch 212/250\n",
      "378/378 [==============================] - 0s 118us/step - loss: 12.9178 - val_loss: 12.4683\n",
      "Epoch 213/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 12.8867 - val_loss: 12.4595\n",
      "Epoch 214/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 12.8817 - val_loss: 12.3445\n",
      "Epoch 215/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 12.8515 - val_loss: 12.4234\n",
      "Epoch 216/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 12.9086 - val_loss: 12.3110\n",
      "Epoch 217/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 12.8702 - val_loss: 12.3821\n",
      "Epoch 218/250\n",
      "378/378 [==============================] - 0s 121us/step - loss: 12.9218 - val_loss: 12.2241\n",
      "Epoch 219/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 12.7628 - val_loss: 12.2175\n",
      "Epoch 220/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 12.9640 - val_loss: 12.3532\n",
      "Epoch 221/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 12.8357 - val_loss: 12.4899\n",
      "Epoch 222/250\n",
      "378/378 [==============================] - 0s 126us/step - loss: 12.8780 - val_loss: 12.3274\n",
      "Epoch 223/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 12.7763 - val_loss: 12.2431\n",
      "Epoch 224/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 12.8570 - val_loss: 12.4958\n",
      "Epoch 225/250\n",
      "378/378 [==============================] - 0s 125us/step - loss: 12.7729 - val_loss: 12.3801\n",
      "Epoch 226/250\n",
      "378/378 [==============================] - 0s 134us/step - loss: 12.7953 - val_loss: 12.5323\n",
      "Epoch 227/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 12.7385 - val_loss: 12.4820\n",
      "Epoch 228/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 12.8622 - val_loss: 12.6100\n",
      "Epoch 229/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 12.7570 - val_loss: 12.4748\n",
      "Epoch 230/250\n",
      "378/378 [==============================] - 0s 131us/step - loss: 12.8744 - val_loss: 12.4058\n",
      "Epoch 231/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 12.7637 - val_loss: 12.5549\n",
      "Epoch 232/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 12.7855 - val_loss: 12.4922\n",
      "Epoch 233/250\n",
      "378/378 [==============================] - 0s 135us/step - loss: 12.7410 - val_loss: 12.4675\n",
      "Epoch 234/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 12.8480 - val_loss: 12.3852\n",
      "Epoch 235/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 12.7787 - val_loss: 12.2245\n",
      "Epoch 236/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 12.7565 - val_loss: 12.2052\n",
      "Epoch 237/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 12.7496 - val_loss: 12.2602\n",
      "Epoch 238/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 131us/step - loss: 12.7644 - val_loss: 12.3515\n",
      "Epoch 239/250\n",
      "378/378 [==============================] - 0s 133us/step - loss: 12.8034 - val_loss: 12.4435\n",
      "Epoch 240/250\n",
      "378/378 [==============================] - 0s 119us/step - loss: 12.6870 - val_loss: 12.4177\n",
      "Epoch 241/250\n",
      "378/378 [==============================] - 0s 128us/step - loss: 12.7014 - val_loss: 12.5220\n",
      "Epoch 242/250\n",
      "378/378 [==============================] - 0s 132us/step - loss: 12.6575 - val_loss: 12.5753\n",
      "Epoch 243/250\n",
      "378/378 [==============================] - 0s 122us/step - loss: 12.7996 - val_loss: 12.5444\n",
      "Epoch 244/250\n",
      "378/378 [==============================] - ETA: 0s - loss: 10.83 - 0s 128us/step - loss: 12.7116 - val_loss: 12.3564\n",
      "Epoch 245/250\n",
      "378/378 [==============================] - 0s 137us/step - loss: 12.6985 - val_loss: 12.5121\n",
      "Epoch 246/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 12.6630 - val_loss: 12.5820\n",
      "Epoch 247/250\n",
      "378/378 [==============================] - 0s 129us/step - loss: 12.6963 - val_loss: 12.7727\n",
      "Epoch 248/250\n",
      "378/378 [==============================] - 0s 120us/step - loss: 12.7422 - val_loss: 12.8242\n",
      "Epoch 249/250\n",
      "378/378 [==============================] - 0s 123us/step - loss: 12.7765 - val_loss: 12.7122\n",
      "Epoch 250/250\n",
      "378/378 [==============================] - 0s 130us/step - loss: 12.7599 - val_loss: 12.5652\n"
     ]
    }
   ],
   "source": [
    "#pred_appliance = {}\n",
    "sequence_length=24\n",
    "num_iterations_dictionary = {'hvac':400,'fridge':500,'mw':250,'dw':250,'oven':250, 'wm':300}\n",
    "for appliance in APPLIANCES_ORDER[2:]:\n",
    "\n",
    "\n",
    "    print(appliance)\n",
    "    print(\"*\"*20)\n",
    "    np.random.seed(0)\n",
    "    from keras.layers.merge import Subtract, Minimum\n",
    "    model = Sequential()\n",
    "    filters=20\n",
    "    kernel_size=2\n",
    "    model.add(InputLayer(input_shape=(sequence_length,1)))\n",
    "    model.add(Conv1D(filters,\n",
    "                     kernel_size,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1 ,name='C1'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "\n",
    "    model.add(Dropout(rate=0.1))\n",
    "    model.add(Conv1D(filters=20,\n",
    "                     kernel_size=5,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1 ))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Dropout(rate=0.1))\n",
    "\n",
    "    model.add(Conv1D(filters=25,\n",
    "                     kernel_size=3,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1 ))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "\n",
    "    model.add(Dropout(rate=0.1))\n",
    "\n",
    "    model.add(Conv1D(filters=30,\n",
    "                     kernel_size=2,\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     strides=1 ))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Dropout(rate=0.1))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    model.add(Dense(sequence_length, activation='relu'))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "\n",
    "\n",
    "    model.compile('adam','mean_absolute_error')\n",
    "    model.fit(train_agg.reshape(-1, 24, 1), train_appliance[appliance], epochs=num_iterations_dictionary[appliance], validation_split=0.1)\n",
    "    pred_appliance[appliance] = model.predict(test_agg.reshape(-1,24,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('per-appliance.pdf','wb') as f:\n",
    "    f.write(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='pdf'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 24, 1)             0         \n",
      "_________________________________________________________________\n",
      "C1 (Conv1D)                  (None, 24, 20)            220       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 12, 20)            0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 12, 20)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 12, 20)            2020      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 6, 20)             0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 6, 20)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 6, 25)             1525      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 3, 25)             0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 3, 25)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 3, 30)             1530      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 1, 30)             0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 24)                744       \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 6,039\n",
      "Trainable params: 6,039\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = {}\n",
    "for appliance in APPLIANCES_ORDER[1:]:\n",
    "    try:\n",
    "        mae[appliance] = mean_absolute_error(test_appliance[appliance], pred_appliance[appliance])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dw         14.499116\n",
       "fridge     34.620154\n",
       "hvac      331.035001\n",
       "mw          6.300214\n",
       "oven       18.633957\n",
       "wm          5.617521\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dw         14.499116\n",
       "fridge     34.620154\n",
       "hvac      331.035001\n",
       "mw          6.300214\n",
       "oven       18.633957\n",
       "wm          5.617521\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a32620588>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAA8CAYAAAB2H0HmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCFDhi2CLKBnyJAhwxbB/wG6pPMOssjkuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a259777f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_agg.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a32611080>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEFCAYAAADdWD2lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN4hR0mAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25bf0e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(test_appliance['dw'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a3699e668>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a368b6320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(test_appliance['hvac'][14]).plot(label='GT')\n",
    "\n",
    "pd.Series(pred_appliance['hvac'][14]).plot(label='Pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0c3c11c20fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_hvac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_agg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_hvac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_fridge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pred_hvac = model.predict(test_agg)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(pred_hvac, test_fridge))\n",
    "print(mean_absolute_error(pred_hvac, test_agg))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.907349e-06\n",
       "1    -3.877686e+00\n",
       "2    -9.150000e+00\n",
       "3     0.000000e+00\n",
       "4     0.000000e+00\n",
       "5    -9.633333e+00\n",
       "6     0.000000e+00\n",
       "7     2.861023e-06\n",
       "8    -8.683333e+00\n",
       "9     9.536743e-07\n",
       "10    0.000000e+00\n",
       "11    9.536743e-07\n",
       "12   -9.583333e+00\n",
       "13   -9.516666e+00\n",
       "14   -4.711666e+01\n",
       "15    3.099442e-06\n",
       "16   -4.685000e+01\n",
       "17    9.536743e-07\n",
       "18   -7.310000e+01\n",
       "19   -7.350000e+01\n",
       "20   -4.180000e+01\n",
       "21    0.000000e+00\n",
       "22   -9.616667e+00\n",
       "23   -9.533334e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(pred_hvac) - pd.DataFrame(test_agg)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f56c5e38e529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#pd.Series(test_agg[1, :]).plot(label='GT')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_agg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.Series(test_mw[1, :]).plot(label='GT')\n",
    "#pd.Series(test_agg[1, :]).plot(label='GT')\n",
    "\n",
    "\n",
    "pd.Series(model.predict(test_agg[1:2])[0, :24]).plot(label='Pred')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
