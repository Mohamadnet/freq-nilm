{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "from common import APPLIANCES_ORDER\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor = np.load('../1H-input.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_subset_dataset(tensor):\n",
    "    t_subset = tensor[:, :, 180:194, :]\n",
    "    all_indices = np.array(list(range(320)))\n",
    "    for i in range(1, 7):\n",
    "        valid_homes = pd.DataFrame(t_subset[:, i, :].reshape(320, 14*24)).dropna().index\n",
    "        all_indices = np.intersect1d(all_indices, valid_homes)\n",
    "    t_subset = t_subset[all_indices, :, :, :].reshape(52, 7, 14*24)\n",
    "    \n",
    "    # Create artificial aggregate\n",
    "    t_subset[:, 0, :] = 0.0\n",
    "    for i in range(1, 7):\n",
    "        t_subset[:, 0, :] = t_subset[:, 0, :] + t_subset[:, i, :]\n",
    "    # t_subset is of shape (#home, appliance, days*hours)\n",
    "    return t_subset, all_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 7, 336)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all, valid_homes = create_subset_dataset(tensor)\n",
    "t_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 7, 336)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_objective(y_pred, y_true):\n",
    "    with tf.name_scope(None):\n",
    "        return tf.losses.absolute_difference(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/nipun/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "n_movies = 3\n",
    "n_users=3\n",
    "n_latent_factors=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fake = 1000\n",
    "t_all_new = np.zeros((max_fake, 7, 336))\n",
    "t_all_new[:52,:,:] = t_all.copy()\n",
    "\n",
    "np.random.seed(0)\n",
    "for i in range(52, max_fake):\n",
    "    home_agg = np.zeros((1, 336))\n",
    "    for appliance in range(1, 7):\n",
    "        t_home_chosen = np.random.choice(list(range(30)))\n",
    "        t_all_new[i, appliance, :] = t_all.copy()[t_home_chosen, appliance, :]\n",
    "        home_agg += t_all.copy()[t_home_chosen, appliance, :]\n",
    "    t_all_new[i, 0, :] = home_agg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg = t_all_new[52:, 0, :].reshape((max_fake-52)*14, 24)\n",
    "train_appliance = t_all[:30, 1:, :].reshape(30*14, 6*24)\n",
    "\n",
    "train_hvac = t_all_new[52:, 1, :].reshape((max_fake-52)*14, 24)\n",
    "train_fridge = t_all_new[52:, 2, :].reshape((max_fake-52)*14, 24)\n",
    "train_mw = t_all_new[52:, 3, :].reshape((max_fake-52)*14, 24)\n",
    "train_dw = t_all_new[52:, 4, :].reshape((max_fake-52)*14, 24)\n",
    "train_wm = t_all_new[52:, 5, :].reshape((max_fake-52)*14, 24)\n",
    "train_oven = t_all_new[52:, 6, :].reshape((max_fake-52)*14, 24)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_agg_new = train_hvac + train_fridge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_hvac = t_all_new[30:52, 1, :].reshape(22*14, 24)\n",
    "test_fridge = t_all[30:52, 2, :].reshape(22*14, 24)\n",
    "test_mw = t_all[30:52, 3, :].reshape(22*14, 24)\n",
    "test_dw = t_all[30:52, 4, :].reshape(22*14, 24)\n",
    "test_wm = t_all[30:52, 5, :].reshape(22*14, 24)\n",
    "test_oven = t_all[30:52, 6, :].reshape(22*14, 24)\n",
    "test_appliance = t_all[30:52, 1:, :].reshape(22*14, 6*24)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_agg = t_all[30:, 0, :].reshape(22*14, 24)\n",
    "test_agg_new = test_hvac + test_fridge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_appliance = {}\n",
    "test_appliance = {}\n",
    "for appliance_num, appliance in enumerate(APPLIANCES_ORDER[1:]):\n",
    "    train_appliance[appliance] = t_all_new[52:, appliance_num+1, :].reshape((max_fake-52)*14, 24)\n",
    "    test_appliance[appliance] = t_all[30:52, appliance_num+1, :].reshape(22*14, 24)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_hvac = t_all[30:52, 1, :].reshape(22*14, 24)\n",
    "test_fridge = t_all[30:52, 2, :].reshape(22*14, 24)\n",
    "\n",
    "test_mw = t_all[30:, 3, :].reshape(22*14, 24)\n",
    "\n",
    "\n",
    "\n",
    "test_agg = t_all[30:, 0, :].reshape(22*14, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13272, 24)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hvac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hvac_fridge = np.hstack([train_hvac, train_fridge])\n",
    "test_hvac_fridge = np.hstack([test_hvac, test_fridge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvac\n",
      "********************\n",
      "Train on 11944 samples, validate on 1328 samples\n",
      "Epoch 1/900\n",
      "11944/11944 [==============================] - 1s 98us/step - loss: 241.3034 - val_loss: 131.7954\n",
      "Epoch 2/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 129.5200 - val_loss: 131.6489\n",
      "Epoch 3/900\n",
      "11944/11944 [==============================] - 1s 49us/step - loss: 129.0373 - val_loss: 131.6791\n",
      "Epoch 4/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 128.8662 - val_loss: 131.6417\n",
      "Epoch 5/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 128.8787 - val_loss: 131.6755\n",
      "Epoch 6/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 128.8457 - val_loss: 131.6756\n",
      "Epoch 7/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 128.8496 - val_loss: 131.6500\n",
      "Epoch 8/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 128.7699 - val_loss: 131.5964\n",
      "Epoch 9/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 128.7150 - val_loss: 131.4092\n",
      "Epoch 10/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 128.5762 - val_loss: 131.0042\n",
      "Epoch 11/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 128.2423 - val_loss: 130.7174\n",
      "Epoch 12/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 127.3067 - val_loss: 129.0527\n",
      "Epoch 13/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 126.7131 - val_loss: 128.3278\n",
      "Epoch 14/900\n",
      "11944/11944 [==============================] - 1s 65us/step - loss: 125.7195 - val_loss: 127.6492\n",
      "Epoch 15/900\n",
      "11944/11944 [==============================] - 1s 63us/step - loss: 125.4165 - val_loss: 127.4503\n",
      "Epoch 16/900\n",
      "11944/11944 [==============================] - 1s 66us/step - loss: 124.9956 - val_loss: 127.7012\n",
      "Epoch 17/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 124.6213 - val_loss: 126.9276\n",
      "Epoch 18/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 123.8915 - val_loss: 125.8789\n",
      "Epoch 19/900\n",
      "11944/11944 [==============================] - 1s 53us/step - loss: 123.2240 - val_loss: 125.0762\n",
      "Epoch 20/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 122.8721 - val_loss: 124.7199\n",
      "Epoch 21/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 122.4243 - val_loss: 124.4246\n",
      "Epoch 22/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 122.1287 - val_loss: 123.8430\n",
      "Epoch 23/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 121.8745 - val_loss: 123.0229\n",
      "Epoch 24/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 121.2906 - val_loss: 123.0561\n",
      "Epoch 25/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 121.0835 - val_loss: 121.9457\n",
      "Epoch 26/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 120.7335 - val_loss: 122.1522\n",
      "Epoch 27/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 120.5668 - val_loss: 120.8375\n",
      "Epoch 28/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 120.3567 - val_loss: 121.6323\n",
      "Epoch 29/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 120.2497 - val_loss: 120.7476\n",
      "Epoch 30/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 120.1711 - val_loss: 120.8771\n",
      "Epoch 31/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 119.6160 - val_loss: 120.2824\n",
      "Epoch 32/900\n",
      "11944/11944 [==============================] - 1s 54us/step - loss: 119.6328 - val_loss: 120.2723\n",
      "Epoch 33/900\n",
      "11944/11944 [==============================] - 1s 52us/step - loss: 119.3408 - val_loss: 120.0828\n",
      "Epoch 34/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 119.3291 - val_loss: 119.6458\n",
      "Epoch 35/900\n",
      "11944/11944 [==============================] - 1s 54us/step - loss: 119.0085 - val_loss: 119.1905\n",
      "Epoch 36/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 119.0720 - val_loss: 119.4701\n",
      "Epoch 37/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 118.8981 - val_loss: 118.4988\n",
      "Epoch 38/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 118.5455 - val_loss: 118.9104\n",
      "Epoch 39/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 118.8621 - val_loss: 118.4526\n",
      "Epoch 40/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 118.5256 - val_loss: 118.9068\n",
      "Epoch 41/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 118.3453 - val_loss: 118.9568\n",
      "Epoch 42/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 118.2966 - val_loss: 118.8797\n",
      "Epoch 43/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 118.1006 - val_loss: 119.0778\n",
      "Epoch 44/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 118.0026 - val_loss: 117.9662\n",
      "Epoch 45/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 117.8673 - val_loss: 117.7860\n",
      "Epoch 46/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 117.6451 - val_loss: 117.3566\n",
      "Epoch 47/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 117.6278 - val_loss: 117.4802\n",
      "Epoch 48/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 117.5471 - val_loss: 117.2105\n",
      "Epoch 49/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 117.7323 - val_loss: 116.8479\n",
      "Epoch 50/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 117.3889 - val_loss: 116.8657\n",
      "Epoch 51/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 117.2915 - val_loss: 117.7864\n",
      "Epoch 52/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 117.4928 - val_loss: 117.0795\n",
      "Epoch 53/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 117.4274 - val_loss: 117.2012\n",
      "Epoch 54/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 117.0941 - val_loss: 117.1202\n",
      "Epoch 55/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 117.2538 - val_loss: 117.4649\n",
      "Epoch 56/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 117.0921 - val_loss: 116.6693\n",
      "Epoch 57/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 116.9352 - val_loss: 115.3774\n",
      "Epoch 58/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 116.8206 - val_loss: 115.6601\n",
      "Epoch 59/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 116.8636 - val_loss: 115.7974\n",
      "Epoch 60/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 116.8564 - val_loss: 116.3374\n",
      "Epoch 61/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 116.6707 - val_loss: 116.5232\n",
      "Epoch 62/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 116.5781 - val_loss: 115.6264\n",
      "Epoch 63/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 116.7048 - val_loss: 116.5557\n",
      "Epoch 64/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 116.7771 - val_loss: 117.5348\n",
      "Epoch 65/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 116.5784 - val_loss: 115.9248\n",
      "Epoch 66/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 116.5519 - val_loss: 115.4206\n",
      "Epoch 67/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 116.5330 - val_loss: 116.2085\n",
      "Epoch 68/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 116.5173 - val_loss: 115.7980\n",
      "Epoch 69/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 116.6082 - val_loss: 115.4100\n",
      "Epoch 70/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 116.4032 - val_loss: 116.0479\n",
      "Epoch 71/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 116.2815 - val_loss: 115.0832\n",
      "Epoch 72/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 116.1154 - val_loss: 116.0862\n",
      "Epoch 73/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 116.2336 - val_loss: 114.4783\n",
      "Epoch 74/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 39us/step - loss: 116.2077 - val_loss: 115.5994\n",
      "Epoch 75/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 116.1997 - val_loss: 115.5648\n",
      "Epoch 76/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 115.9720 - val_loss: 114.7041\n",
      "Epoch 77/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 116.1805 - val_loss: 114.9477\n",
      "Epoch 78/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 116.0154 - val_loss: 114.9790\n",
      "Epoch 79/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 115.8932 - val_loss: 114.7419\n",
      "Epoch 80/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 115.6681 - val_loss: 114.5064\n",
      "Epoch 81/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 115.8580 - val_loss: 114.3362\n",
      "Epoch 82/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 115.5988 - val_loss: 114.5099\n",
      "Epoch 83/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 115.4282 - val_loss: 113.9165\n",
      "Epoch 84/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 115.5381 - val_loss: 114.7689\n",
      "Epoch 85/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 115.7495 - val_loss: 114.1052\n",
      "Epoch 86/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 115.5108 - val_loss: 114.5304\n",
      "Epoch 87/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 115.3159 - val_loss: 114.9320\n",
      "Epoch 88/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 115.3717 - val_loss: 115.9757\n",
      "Epoch 89/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 115.3590 - val_loss: 115.2724\n",
      "Epoch 90/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 115.2852 - val_loss: 114.6845\n",
      "Epoch 91/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 115.2207 - val_loss: 114.1019\n",
      "Epoch 92/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 115.3189 - val_loss: 114.9935\n",
      "Epoch 93/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 115.1825 - val_loss: 113.2601\n",
      "Epoch 94/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 115.2491 - val_loss: 114.3952\n",
      "Epoch 95/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 115.2932 - val_loss: 115.1936\n",
      "Epoch 96/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 115.0764 - val_loss: 113.2204\n",
      "Epoch 97/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 115.1995 - val_loss: 114.3214\n",
      "Epoch 98/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 115.2610 - val_loss: 114.2559\n",
      "Epoch 99/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 115.0244 - val_loss: 114.1683\n",
      "Epoch 100/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 115.0152 - val_loss: 114.6063\n",
      "Epoch 101/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 115.2772 - val_loss: 113.9157\n",
      "Epoch 102/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.9064 - val_loss: 114.2517\n",
      "Epoch 103/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 115.0817 - val_loss: 114.7777\n",
      "Epoch 104/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 114.8865 - val_loss: 114.6549\n",
      "Epoch 105/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.9318 - val_loss: 113.7156\n",
      "Epoch 106/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.7571 - val_loss: 113.3541\n",
      "Epoch 107/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 115.0542 - val_loss: 113.1864\n",
      "Epoch 108/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 114.8748 - val_loss: 113.6571\n",
      "Epoch 109/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 114.9944 - val_loss: 115.5458\n",
      "Epoch 110/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.8989 - val_loss: 112.8165\n",
      "Epoch 111/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.8191 - val_loss: 114.5606\n",
      "Epoch 112/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.6946 - val_loss: 112.8827\n",
      "Epoch 113/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.9952 - val_loss: 113.7257\n",
      "Epoch 114/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.8335 - val_loss: 113.1644\n",
      "Epoch 115/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.8011 - val_loss: 112.8219\n",
      "Epoch 116/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.7994 - val_loss: 114.0519\n",
      "Epoch 117/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 114.8637 - val_loss: 112.2320\n",
      "Epoch 118/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 114.6259 - val_loss: 112.6034\n",
      "Epoch 119/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 114.7440 - val_loss: 113.3535\n",
      "Epoch 120/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 114.7943 - val_loss: 113.5143\n",
      "Epoch 121/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 114.7408 - val_loss: 113.8336\n",
      "Epoch 122/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 114.6494 - val_loss: 113.6500\n",
      "Epoch 123/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.6459 - val_loss: 112.2985\n",
      "Epoch 124/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 114.5782 - val_loss: 113.0352\n",
      "Epoch 125/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 114.5849 - val_loss: 113.1795\n",
      "Epoch 126/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 114.8152 - val_loss: 114.7572\n",
      "Epoch 127/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 114.5531 - val_loss: 113.2344\n",
      "Epoch 128/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 114.7477 - val_loss: 113.5742\n",
      "Epoch 129/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 114.5198 - val_loss: 112.4839\n",
      "Epoch 130/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.2956 - val_loss: 113.8144\n",
      "Epoch 131/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 114.4028 - val_loss: 112.5575\n",
      "Epoch 132/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 114.3963 - val_loss: 112.0459\n",
      "Epoch 133/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 114.5616 - val_loss: 111.9565\n",
      "Epoch 134/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 114.4218 - val_loss: 112.5420\n",
      "Epoch 135/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 114.3997 - val_loss: 112.8249\n",
      "Epoch 136/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 114.4334 - val_loss: 111.8804\n",
      "Epoch 137/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 114.6280 - val_loss: 113.0935\n",
      "Epoch 138/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.4237 - val_loss: 113.5076\n",
      "Epoch 139/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 114.4418 - val_loss: 112.7061\n",
      "Epoch 140/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 114.4650 - val_loss: 112.6654\n",
      "Epoch 141/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 114.3511 - val_loss: 112.7817\n",
      "Epoch 142/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 114.2937 - val_loss: 112.1836\n",
      "Epoch 143/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.3195 - val_loss: 112.3153\n",
      "Epoch 144/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.3052 - val_loss: 112.6534\n",
      "Epoch 145/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.1045 - val_loss: 114.4038\n",
      "Epoch 146/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.3073 - val_loss: 113.0365\n",
      "Epoch 147/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.1356 - val_loss: 114.1503\n",
      "Epoch 148/900\n",
      "11944/11944 [==============================] - 1s 51us/step - loss: 114.2476 - val_loss: 112.1323\n",
      "Epoch 149/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 114.3413 - val_loss: 112.5976\n",
      "Epoch 150/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.1454 - val_loss: 111.2872\n",
      "Epoch 151/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 114.1726 - val_loss: 111.5700\n",
      "Epoch 152/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 114.2986 - val_loss: 111.3714\n",
      "Epoch 153/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 114.0246 - val_loss: 112.5040\n",
      "Epoch 154/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.1278 - val_loss: 112.0757\n",
      "Epoch 155/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.1387 - val_loss: 111.3835\n",
      "Epoch 156/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.0283 - val_loss: 111.6003\n",
      "Epoch 157/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 114.2476 - val_loss: 113.2260\n",
      "Epoch 158/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 114.0406 - val_loss: 111.6050\n",
      "Epoch 159/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 114.0149 - val_loss: 113.0805\n",
      "Epoch 160/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.8241 - val_loss: 112.5370\n",
      "Epoch 161/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.8145 - val_loss: 110.6007\n",
      "Epoch 162/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 114.0176 - val_loss: 112.1043\n",
      "Epoch 163/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.8268 - val_loss: 110.8976\n",
      "Epoch 164/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.8197 - val_loss: 111.3437\n",
      "Epoch 165/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.6944 - val_loss: 111.0467\n",
      "Epoch 166/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.7515 - val_loss: 110.8325\n",
      "Epoch 167/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.9098 - val_loss: 110.4370\n",
      "Epoch 168/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.7259 - val_loss: 112.1537\n",
      "Epoch 169/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 114.0397 - val_loss: 111.1377\n",
      "Epoch 170/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.7717 - val_loss: 111.3430\n",
      "Epoch 171/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.7431 - val_loss: 111.9308\n",
      "Epoch 172/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.7361 - val_loss: 111.6958\n",
      "Epoch 173/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.6202 - val_loss: 111.3216\n",
      "Epoch 174/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.5535 - val_loss: 111.6161\n",
      "Epoch 175/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.8764 - val_loss: 111.4305\n",
      "Epoch 176/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 113.7564 - val_loss: 111.6386\n",
      "Epoch 177/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.6303 - val_loss: 113.2815\n",
      "Epoch 178/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.8670 - val_loss: 111.0883\n",
      "Epoch 179/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.5418 - val_loss: 111.7929\n",
      "Epoch 180/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.6153 - val_loss: 112.7018\n",
      "Epoch 181/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.6977 - val_loss: 111.5523\n",
      "Epoch 182/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.3442 - val_loss: 110.3775\n",
      "Epoch 183/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.7119 - val_loss: 110.7908\n",
      "Epoch 184/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.5082 - val_loss: 111.4506\n",
      "Epoch 185/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.4315 - val_loss: 111.1064\n",
      "Epoch 186/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.5418 - val_loss: 112.1264\n",
      "Epoch 187/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.4761 - val_loss: 110.8660\n",
      "Epoch 188/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.3051 - val_loss: 110.8544\n",
      "Epoch 189/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.3990 - val_loss: 112.2092\n",
      "Epoch 190/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.6138 - val_loss: 111.9071\n",
      "Epoch 191/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.3224 - val_loss: 110.5780\n",
      "Epoch 192/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.3593 - val_loss: 110.7517\n",
      "Epoch 193/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.4084 - val_loss: 113.2622\n",
      "Epoch 194/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.4906 - val_loss: 110.3442\n",
      "Epoch 195/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.6252 - val_loss: 110.9019\n",
      "Epoch 196/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.2347 - val_loss: 110.2924\n",
      "Epoch 197/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.5194 - val_loss: 110.3363\n",
      "Epoch 198/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.3401 - val_loss: 110.6948\n",
      "Epoch 199/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.6037 - val_loss: 112.1439\n",
      "Epoch 200/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.6219 - val_loss: 111.0861\n",
      "Epoch 201/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.3325 - val_loss: 110.9255\n",
      "Epoch 202/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.2744 - val_loss: 109.9826\n",
      "Epoch 203/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 113.2642 - val_loss: 110.3891\n",
      "Epoch 204/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 113.4616 - val_loss: 110.1292\n",
      "Epoch 205/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 113.2317 - val_loss: 109.5456\n",
      "Epoch 206/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.3054 - val_loss: 109.7294\n",
      "Epoch 207/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.1626 - val_loss: 110.9916\n",
      "Epoch 208/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.4522 - val_loss: 112.2415\n",
      "Epoch 209/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.2885 - val_loss: 113.1654\n",
      "Epoch 210/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.2000 - val_loss: 110.9277\n",
      "Epoch 211/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.3373 - val_loss: 110.2584\n",
      "Epoch 212/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.3732 - val_loss: 110.7342\n",
      "Epoch 213/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.5921 - val_loss: 110.9626\n",
      "Epoch 214/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.0785 - val_loss: 109.7494\n",
      "Epoch 215/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.1813 - val_loss: 109.9429\n",
      "Epoch 216/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.1578 - val_loss: 110.7215\n",
      "Epoch 217/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 113.2151 - val_loss: 109.6560\n",
      "Epoch 218/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.4192 - val_loss: 111.0412\n",
      "Epoch 219/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.1848 - val_loss: 111.8261\n",
      "Epoch 220/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.1097 - val_loss: 111.4526\n",
      "Epoch 221/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.1969 - val_loss: 109.7197\n",
      "Epoch 222/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.1749 - val_loss: 112.9476\n",
      "Epoch 223/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 113.0012 - val_loss: 111.7181\n",
      "Epoch 224/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.1216 - val_loss: 110.4388\n",
      "Epoch 225/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 113.2199 - val_loss: 109.6194\n",
      "Epoch 226/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 113.1282 - val_loss: 110.3122\n",
      "Epoch 227/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.7364 - val_loss: 109.0235\n",
      "Epoch 228/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 113.0064 - val_loss: 111.7457\n",
      "Epoch 229/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.7047 - val_loss: 109.4711\n",
      "Epoch 230/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 112.7268 - val_loss: 109.1057\n",
      "Epoch 231/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.6736 - val_loss: 111.0886\n",
      "Epoch 232/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.8773 - val_loss: 109.1081\n",
      "Epoch 233/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.4857 - val_loss: 110.0947\n",
      "Epoch 234/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.5333 - val_loss: 108.9911\n",
      "Epoch 235/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.8605 - val_loss: 109.6875\n",
      "Epoch 236/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.6485 - val_loss: 110.7412\n",
      "Epoch 237/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.6381 - val_loss: 109.4644\n",
      "Epoch 238/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.5608 - val_loss: 110.5384\n",
      "Epoch 239/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 112.4184 - val_loss: 110.4719\n",
      "Epoch 240/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.6191 - val_loss: 109.6755\n",
      "Epoch 241/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.7276 - val_loss: 109.1235\n",
      "Epoch 242/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.1279 - val_loss: 110.8880\n",
      "Epoch 243/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.4095 - val_loss: 109.9220\n",
      "Epoch 244/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.6226 - val_loss: 110.0131\n",
      "Epoch 245/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.5515 - val_loss: 109.3679\n",
      "Epoch 246/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.6854 - val_loss: 108.9200\n",
      "Epoch 247/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 112.6864 - val_loss: 109.3246\n",
      "Epoch 248/900\n",
      "11944/11944 [==============================] - 1s 52us/step - loss: 112.2872 - val_loss: 110.6132\n",
      "Epoch 249/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 112.5452 - val_loss: 109.0044\n",
      "Epoch 250/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 112.4925 - val_loss: 110.2248\n",
      "Epoch 251/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 112.4299 - val_loss: 111.3605\n",
      "Epoch 252/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 112.4585 - val_loss: 109.1993\n",
      "Epoch 253/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 112.5493 - val_loss: 109.4574\n",
      "Epoch 254/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 112.5720 - val_loss: 109.3818\n",
      "Epoch 255/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 112.5740 - val_loss: 108.9231\n",
      "Epoch 256/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 112.5527 - val_loss: 110.9272\n",
      "Epoch 257/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 112.2508 - val_loss: 109.1362\n",
      "Epoch 258/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 112.4205 - val_loss: 108.7093\n",
      "Epoch 259/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 112.2205 - val_loss: 110.4497\n",
      "Epoch 260/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 112.3234 - val_loss: 110.6017\n",
      "Epoch 261/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 112.1081 - val_loss: 110.4193\n",
      "Epoch 262/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 112.7051 - val_loss: 110.4805\n",
      "Epoch 263/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 112.1407 - val_loss: 109.3556\n",
      "Epoch 264/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 112.3108 - val_loss: 110.0751\n",
      "Epoch 265/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 112.1839 - val_loss: 109.2105\n",
      "Epoch 266/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 112.0487 - val_loss: 108.7890\n",
      "Epoch 267/900\n",
      "11944/11944 [==============================] - 1s 61us/step - loss: 112.5905 - val_loss: 109.3523\n",
      "Epoch 268/900\n",
      "11944/11944 [==============================] - 1s 64us/step - loss: 112.2719 - val_loss: 110.0452\n",
      "Epoch 269/900\n",
      "11944/11944 [==============================] - 1s 64us/step - loss: 112.3594 - val_loss: 109.1508\n",
      "Epoch 270/900\n",
      "11944/11944 [==============================] - 1s 50us/step - loss: 112.1331 - val_loss: 108.7710\n",
      "Epoch 271/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 112.2790 - val_loss: 111.0220\n",
      "Epoch 272/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 112.2000 - val_loss: 108.5810\n",
      "Epoch 273/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 112.1087 - val_loss: 109.6514\n",
      "Epoch 274/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.1733 - val_loss: 109.0687\n",
      "Epoch 275/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.1049 - val_loss: 108.9639\n",
      "Epoch 276/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.2460 - val_loss: 108.9987\n",
      "Epoch 277/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.2067 - val_loss: 109.3803\n",
      "Epoch 278/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 112.4260 - val_loss: 108.9820\n",
      "Epoch 279/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 112.2183 - val_loss: 108.5117\n",
      "Epoch 280/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.2389 - val_loss: 110.4959\n",
      "Epoch 281/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 112.1395 - val_loss: 109.2755\n",
      "Epoch 282/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.4103 - val_loss: 110.8185\n",
      "Epoch 283/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 112.3275 - val_loss: 109.0761\n",
      "Epoch 284/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 112.2397 - val_loss: 109.2074\n",
      "Epoch 285/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.1570 - val_loss: 108.5210\n",
      "Epoch 286/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 112.2317 - val_loss: 108.8672\n",
      "Epoch 287/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.8631 - val_loss: 109.0600\n",
      "Epoch 288/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.7926 - val_loss: 107.7327\n",
      "Epoch 289/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.2418 - val_loss: 108.6710\n",
      "Epoch 290/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.0555 - val_loss: 109.5990\n",
      "Epoch 291/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.1077 - val_loss: 109.4138\n",
      "Epoch 292/900\n",
      "11944/11944 [==============================] - 1s 49us/step - loss: 112.1335 - val_loss: 109.8781\n",
      "Epoch 293/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 41us/step - loss: 111.8087 - val_loss: 109.3279\n",
      "Epoch 294/900\n",
      "11944/11944 [==============================] - 1s 49us/step - loss: 111.8707 - val_loss: 108.4166\n",
      "Epoch 295/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 112.0677 - val_loss: 108.0083\n",
      "Epoch 296/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 111.9568 - val_loss: 108.0721\n",
      "Epoch 297/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 111.8092 - val_loss: 108.3763\n",
      "Epoch 298/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 111.8983 - val_loss: 108.7830\n",
      "Epoch 299/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 111.9294 - val_loss: 108.4833\n",
      "Epoch 300/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.9105 - val_loss: 109.1099\n",
      "Epoch 301/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.1296 - val_loss: 110.2822\n",
      "Epoch 302/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.7091 - val_loss: 107.8520\n",
      "Epoch 303/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 111.6758 - val_loss: 107.6586\n",
      "Epoch 304/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.9605 - val_loss: 110.5168\n",
      "Epoch 305/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.5720 - val_loss: 108.3408\n",
      "Epoch 306/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.7953 - val_loss: 108.2636\n",
      "Epoch 307/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.9829 - val_loss: 108.5055\n",
      "Epoch 308/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.9203 - val_loss: 107.8575\n",
      "Epoch 309/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.9196 - val_loss: 108.1504\n",
      "Epoch 310/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.0418 - val_loss: 108.8264\n",
      "Epoch 311/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 111.7001 - val_loss: 107.6037\n",
      "Epoch 312/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 111.5674 - val_loss: 107.8267\n",
      "Epoch 313/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 111.7427 - val_loss: 109.5916\n",
      "Epoch 314/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 112.0924 - val_loss: 108.0552\n",
      "Epoch 315/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.5509 - val_loss: 108.2623\n",
      "Epoch 316/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.7093 - val_loss: 108.1315\n",
      "Epoch 317/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.9894 - val_loss: 108.8160\n",
      "Epoch 318/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.5681 - val_loss: 110.6864\n",
      "Epoch 319/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.5184 - val_loss: 110.2793\n",
      "Epoch 320/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 111.6728 - val_loss: 107.3226\n",
      "Epoch 321/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 111.6810 - val_loss: 109.6867\n",
      "Epoch 322/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 111.7653 - val_loss: 107.4990\n",
      "Epoch 323/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 111.4011 - val_loss: 109.2684\n",
      "Epoch 324/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 111.8075 - val_loss: 108.4175\n",
      "Epoch 325/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 111.4854 - val_loss: 108.8944\n",
      "Epoch 326/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.6983 - val_loss: 108.5672\n",
      "Epoch 327/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 112.0008 - val_loss: 108.4834\n",
      "Epoch 328/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.7691 - val_loss: 108.1279\n",
      "Epoch 329/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 111.5836 - val_loss: 108.0866\n",
      "Epoch 330/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.6698 - val_loss: 110.6908\n",
      "Epoch 331/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.5597 - val_loss: 107.6773\n",
      "Epoch 332/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.6285 - val_loss: 107.8983\n",
      "Epoch 333/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.7099 - val_loss: 107.8029\n",
      "Epoch 334/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.6750 - val_loss: 107.6140\n",
      "Epoch 335/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.8150 - val_loss: 108.9727\n",
      "Epoch 336/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.6793 - val_loss: 108.4186\n",
      "Epoch 337/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.4591 - val_loss: 107.3331\n",
      "Epoch 338/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.7491 - val_loss: 109.7089\n",
      "Epoch 339/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.4757 - val_loss: 108.5849\n",
      "Epoch 340/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.4010 - val_loss: 109.4931\n",
      "Epoch 341/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.5798 - val_loss: 107.7982\n",
      "Epoch 342/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.6667 - val_loss: 107.8604\n",
      "Epoch 343/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.4337 - val_loss: 107.7044\n",
      "Epoch 344/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 111.6111 - val_loss: 107.3729\n",
      "Epoch 345/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.7387 - val_loss: 107.2995\n",
      "Epoch 346/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.4862 - val_loss: 108.8364\n",
      "Epoch 347/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.7197 - val_loss: 109.4443\n",
      "Epoch 348/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 111.5901 - val_loss: 108.5213\n",
      "Epoch 349/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 111.8311 - val_loss: 109.3779\n",
      "Epoch 350/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.3265 - val_loss: 109.4242\n",
      "Epoch 351/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.3954 - val_loss: 108.6518\n",
      "Epoch 352/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.3613 - val_loss: 107.2652\n",
      "Epoch 353/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.5302 - val_loss: 110.7424\n",
      "Epoch 354/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.5293 - val_loss: 108.0334\n",
      "Epoch 355/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.4367 - val_loss: 109.4862\n",
      "Epoch 356/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.5665 - val_loss: 109.1497\n",
      "Epoch 357/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.5556 - val_loss: 109.7682\n",
      "Epoch 358/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.1579 - val_loss: 107.5289\n",
      "Epoch 359/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.3692 - val_loss: 106.8140\n",
      "Epoch 360/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.5902 - val_loss: 107.3519\n",
      "Epoch 361/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.5060 - val_loss: 106.9898\n",
      "Epoch 362/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.6502 - val_loss: 111.2340\n",
      "Epoch 363/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.3915 - val_loss: 108.7552\n",
      "Epoch 364/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.5755 - val_loss: 107.0592\n",
      "Epoch 365/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.4659 - val_loss: 110.3152\n",
      "Epoch 366/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.5571 - val_loss: 108.7180\n",
      "Epoch 367/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.5046 - val_loss: 107.5131\n",
      "Epoch 368/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.2294 - val_loss: 107.4175\n",
      "Epoch 369/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 111.3170 - val_loss: 107.2849\n",
      "Epoch 370/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 111.1441 - val_loss: 108.0073\n",
      "Epoch 371/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 111.0449 - val_loss: 106.8836\n",
      "Epoch 372/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 110.8756 - val_loss: 106.6726\n",
      "Epoch 373/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 110.6426 - val_loss: 109.8735\n",
      "Epoch 374/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 110.9568 - val_loss: 106.0474\n",
      "Epoch 375/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 110.9469 - val_loss: 106.3928\n",
      "Epoch 376/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 111.1468 - val_loss: 108.2077\n",
      "Epoch 377/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.9327 - val_loss: 106.7500\n",
      "Epoch 378/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 110.7318 - val_loss: 106.9248\n",
      "Epoch 379/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 110.9872 - val_loss: 107.4735\n",
      "Epoch 380/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 110.9236 - val_loss: 106.9967\n",
      "Epoch 381/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 110.9319 - val_loss: 105.8647\n",
      "Epoch 382/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 110.5134 - val_loss: 106.7884\n",
      "Epoch 383/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 111.0810 - val_loss: 106.8525\n",
      "Epoch 384/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 110.9885 - val_loss: 108.0694\n",
      "Epoch 385/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 111.0004 - val_loss: 106.3740\n",
      "Epoch 386/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 111.0012 - val_loss: 108.0704\n",
      "Epoch 387/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 110.9704 - val_loss: 106.4596\n",
      "Epoch 388/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.6582 - val_loss: 105.6158\n",
      "Epoch 389/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.8935 - val_loss: 110.7347\n",
      "Epoch 390/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.7045 - val_loss: 106.6753\n",
      "Epoch 391/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 111.0066 - val_loss: 107.2442\n",
      "Epoch 392/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 110.9084 - val_loss: 107.4474\n",
      "Epoch 393/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 110.9390 - val_loss: 109.2995\n",
      "Epoch 394/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 111.2638 - val_loss: 107.1365\n",
      "Epoch 395/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 110.7047 - val_loss: 105.8829\n",
      "Epoch 396/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 110.8453 - val_loss: 106.1294\n",
      "Epoch 397/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.7278 - val_loss: 106.3415\n",
      "Epoch 398/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 110.9844 - val_loss: 109.5440\n",
      "Epoch 399/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 110.8917 - val_loss: 106.0704\n",
      "Epoch 400/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 110.7913 - val_loss: 107.7184\n",
      "Epoch 401/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 110.7904 - val_loss: 105.4900\n",
      "Epoch 402/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.6701 - val_loss: 106.8993\n",
      "Epoch 403/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 110.5637 - val_loss: 105.5107\n",
      "Epoch 404/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 110.8627 - val_loss: 106.8773\n",
      "Epoch 405/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.7866 - val_loss: 106.7438\n",
      "Epoch 406/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.4860 - val_loss: 106.1300\n",
      "Epoch 407/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.7033 - val_loss: 105.2174\n",
      "Epoch 408/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.7065 - val_loss: 107.7931\n",
      "Epoch 409/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.5196 - val_loss: 106.9966\n",
      "Epoch 410/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.5983 - val_loss: 107.0561\n",
      "Epoch 411/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 110.4637 - val_loss: 107.1773\n",
      "Epoch 412/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.5258 - val_loss: 106.3482\n",
      "Epoch 413/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 110.5859 - val_loss: 108.3062\n",
      "Epoch 414/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.8127 - val_loss: 106.3902\n",
      "Epoch 415/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 110.9360 - val_loss: 110.3728\n",
      "Epoch 416/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 110.3060 - val_loss: 107.1246\n",
      "Epoch 417/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.7564 - val_loss: 107.2441\n",
      "Epoch 418/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 110.5734 - val_loss: 104.9024\n",
      "Epoch 419/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.7408 - val_loss: 107.9928\n",
      "Epoch 420/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 110.6015 - val_loss: 107.4880\n",
      "Epoch 421/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.6158 - val_loss: 106.5424\n",
      "Epoch 422/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 110.3051 - val_loss: 108.4054\n",
      "Epoch 423/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.5408 - val_loss: 105.7145\n",
      "Epoch 424/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.5514 - val_loss: 105.7194\n",
      "Epoch 425/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.4093 - val_loss: 105.8918\n",
      "Epoch 426/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.7956 - val_loss: 108.5532\n",
      "Epoch 427/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.5252 - val_loss: 105.3638\n",
      "Epoch 428/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.5075 - val_loss: 105.8928\n",
      "Epoch 429/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.5275 - val_loss: 105.9696\n",
      "Epoch 430/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 110.6189 - val_loss: 105.2027\n",
      "Epoch 431/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 110.5261 - val_loss: 104.9887\n",
      "Epoch 432/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 110.5347 - val_loss: 105.9559\n",
      "Epoch 433/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.5710 - val_loss: 108.4396\n",
      "Epoch 434/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.5331 - val_loss: 105.0275\n",
      "Epoch 435/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.3121 - val_loss: 105.7126\n",
      "Epoch 436/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.4601 - val_loss: 105.4771\n",
      "Epoch 437/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.3871 - val_loss: 109.3959\n",
      "Epoch 438/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.5169 - val_loss: 105.7114\n",
      "Epoch 439/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.4861 - val_loss: 108.3614\n",
      "Epoch 440/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 110.0759 - val_loss: 109.1151\n",
      "Epoch 441/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.3682 - val_loss: 108.1917\n",
      "Epoch 442/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.3969 - val_loss: 106.5702\n",
      "Epoch 443/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.5376 - val_loss: 111.3606\n",
      "Epoch 444/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.3425 - val_loss: 105.3670\n",
      "Epoch 445/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.2858 - val_loss: 105.0676\n",
      "Epoch 446/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.2674 - val_loss: 107.2883\n",
      "Epoch 447/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.6089 - val_loss: 106.3150\n",
      "Epoch 448/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.2944 - val_loss: 105.6460 ETA: 0s - loss: 110\n",
      "Epoch 449/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.3775 - val_loss: 104.8972\n",
      "Epoch 450/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 110.5575 - val_loss: 105.7408\n",
      "Epoch 451/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 110.1649 - val_loss: 106.9669\n",
      "Epoch 452/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.2962 - val_loss: 109.6507\n",
      "Epoch 453/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.2889 - val_loss: 105.6908\n",
      "Epoch 454/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 110.2424 - val_loss: 107.6594\n",
      "Epoch 455/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 110.3393 - val_loss: 104.8990\n",
      "Epoch 456/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 110.2317 - val_loss: 105.5566\n",
      "Epoch 457/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.1651 - val_loss: 110.0100\n",
      "Epoch 458/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.2995 - val_loss: 104.5992\n",
      "Epoch 459/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.0313 - val_loss: 104.8388\n",
      "Epoch 460/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.1508 - val_loss: 107.7965\n",
      "Epoch 461/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.0195 - val_loss: 108.0925\n",
      "Epoch 462/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.0682 - val_loss: 106.4475\n",
      "Epoch 463/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.0791 - val_loss: 105.5361\n",
      "Epoch 464/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.0649 - val_loss: 106.8880\n",
      "Epoch 465/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.0261 - val_loss: 106.2835\n",
      "Epoch 466/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.8204 - val_loss: 104.5535\n",
      "Epoch 467/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.3519 - val_loss: 106.9847\n",
      "Epoch 468/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.7238 - val_loss: 106.2829\n",
      "Epoch 469/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.1250 - val_loss: 111.8351\n",
      "Epoch 470/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.3750 - val_loss: 107.5906\n",
      "Epoch 471/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.2325 - val_loss: 105.0641\n",
      "Epoch 472/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.1780 - val_loss: 107.5259\n",
      "Epoch 473/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.0884 - val_loss: 105.8312\n",
      "Epoch 474/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.0975 - val_loss: 105.2710\n",
      "Epoch 475/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 110.2052 - val_loss: 109.2157\n",
      "Epoch 476/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 110.1123 - val_loss: 105.7598\n",
      "Epoch 477/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.4730 - val_loss: 105.3116\n",
      "Epoch 478/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.2729 - val_loss: 107.0413\n",
      "Epoch 479/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 110.1215 - val_loss: 105.2341\n",
      "Epoch 480/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.1148 - val_loss: 107.6604\n",
      "Epoch 481/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 110.1437 - val_loss: 107.5597\n",
      "Epoch 482/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.7996 - val_loss: 104.8108\n",
      "Epoch 483/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 109.9180 - val_loss: 104.2097\n",
      "Epoch 484/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.1878 - val_loss: 106.5395\n",
      "Epoch 485/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 110.0899 - val_loss: 106.5709\n",
      "Epoch 486/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.0226 - val_loss: 103.9228\n",
      "Epoch 487/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.3273 - val_loss: 107.4620\n",
      "Epoch 488/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.0056 - val_loss: 109.7059\n",
      "Epoch 489/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.2706 - val_loss: 105.8674\n",
      "Epoch 490/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.0516 - val_loss: 104.0809\n",
      "Epoch 491/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.1259 - val_loss: 105.3640\n",
      "Epoch 492/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.9762 - val_loss: 104.1870\n",
      "Epoch 493/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.0458 - val_loss: 104.9208\n",
      "Epoch 494/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.8876 - val_loss: 107.2390\n",
      "Epoch 495/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.9888 - val_loss: 104.6754\n",
      "Epoch 496/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.0846 - val_loss: 105.1470\n",
      "Epoch 497/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.1099 - val_loss: 104.8895\n",
      "Epoch 498/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.6034 - val_loss: 104.5296\n",
      "Epoch 499/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.1237 - val_loss: 104.1043\n",
      "Epoch 500/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.9295 - val_loss: 106.2390\n",
      "Epoch 501/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.9420 - val_loss: 106.8875\n",
      "Epoch 502/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.9795 - val_loss: 107.6091\n",
      "Epoch 503/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.8998 - val_loss: 104.6405\n",
      "Epoch 504/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 110.0187 - val_loss: 105.6127\n",
      "Epoch 505/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 109.9016 - val_loss: 105.2776\n",
      "Epoch 506/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.9579 - val_loss: 104.2487\n",
      "Epoch 507/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 109.9536 - val_loss: 107.6843\n",
      "Epoch 508/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 110.0855 - val_loss: 104.1344\n",
      "Epoch 509/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 109.6415 - val_loss: 104.1473\n",
      "Epoch 510/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.1230 - val_loss: 105.7572\n",
      "Epoch 511/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.8377 - val_loss: 104.5877\n",
      "Epoch 512/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.5605 - val_loss: 104.8689\n",
      "Epoch 513/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 110.0048 - val_loss: 107.6240\n",
      "Epoch 514/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.8354 - val_loss: 104.4346\n",
      "Epoch 515/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.8050 - val_loss: 104.0461\n",
      "Epoch 516/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 109.6639 - val_loss: 104.2316\n",
      "Epoch 517/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 110.0767 - val_loss: 107.0638\n",
      "Epoch 518/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.8573 - val_loss: 107.0364\n",
      "Epoch 519/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.7867 - val_loss: 105.5549\n",
      "Epoch 520/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 110.1031 - val_loss: 105.1897\n",
      "Epoch 521/900\n",
      "11944/11944 [==============================] - 0s 32us/step - loss: 109.7694 - val_loss: 105.2979\n",
      "Epoch 522/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 110.1483 - val_loss: 105.3784\n",
      "Epoch 523/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.9584 - val_loss: 108.6914\n",
      "Epoch 524/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.9485 - val_loss: 103.9549\n",
      "Epoch 525/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 109.6183 - val_loss: 107.5868\n",
      "Epoch 526/900\n",
      "11944/11944 [==============================] - 1s 58us/step - loss: 109.7207 - val_loss: 109.2545\n",
      "Epoch 527/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.6214 - val_loss: 104.6179\n",
      "Epoch 528/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 109.8705 - val_loss: 105.5577\n",
      "Epoch 529/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.5705 - val_loss: 103.8552\n",
      "Epoch 530/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.8717 - val_loss: 105.7533\n",
      "Epoch 531/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.8880 - val_loss: 103.8399\n",
      "Epoch 532/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5802 - val_loss: 106.5940\n",
      "Epoch 533/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.9706 - val_loss: 105.2719\n",
      "Epoch 534/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.8841 - val_loss: 104.5331\n",
      "Epoch 535/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.7583 - val_loss: 104.4017\n",
      "Epoch 536/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.7187 - val_loss: 106.1049\n",
      "Epoch 537/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.9607 - val_loss: 109.4804\n",
      "Epoch 538/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.5686 - val_loss: 106.2951\n",
      "Epoch 539/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.6889 - val_loss: 104.0148\n",
      "Epoch 540/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.8565 - val_loss: 103.7188\n",
      "Epoch 541/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 109.6141 - val_loss: 104.8106\n",
      "Epoch 542/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.3828 - val_loss: 107.5530\n",
      "Epoch 543/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.7961 - val_loss: 104.8685\n",
      "Epoch 544/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.7538 - val_loss: 103.9029\n",
      "Epoch 545/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.5768 - val_loss: 107.3110\n",
      "Epoch 546/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.6185 - val_loss: 104.4981\n",
      "Epoch 547/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.7260 - val_loss: 103.5497\n",
      "Epoch 548/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5607 - val_loss: 105.3993\n",
      "Epoch 549/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.7669 - val_loss: 106.1082\n",
      "Epoch 550/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.8742 - val_loss: 105.2768\n",
      "Epoch 551/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 109.6053 - val_loss: 105.7883\n",
      "Epoch 552/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.7712 - val_loss: 105.0541\n",
      "Epoch 553/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.8072 - val_loss: 107.0991\n",
      "Epoch 554/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.7614 - val_loss: 103.6913\n",
      "Epoch 555/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.6269 - val_loss: 108.1549\n",
      "Epoch 556/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.6260 - val_loss: 104.2422\n",
      "Epoch 557/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.4451 - val_loss: 103.6263\n",
      "Epoch 558/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.6221 - val_loss: 105.1058\n",
      "Epoch 559/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.4142 - val_loss: 104.6936\n",
      "Epoch 560/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.5571 - val_loss: 104.0683\n",
      "Epoch 561/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.8167 - val_loss: 104.3743\n",
      "Epoch 562/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.6949 - val_loss: 106.4372\n",
      "Epoch 563/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.6148 - val_loss: 105.5300\n",
      "Epoch 564/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5314 - val_loss: 104.1590\n",
      "Epoch 565/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.7625 - val_loss: 104.2242\n",
      "Epoch 566/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3416 - val_loss: 105.4397\n",
      "Epoch 567/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.9176 - val_loss: 106.7270\n",
      "Epoch 568/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.1877 - val_loss: 107.9862\n",
      "Epoch 569/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 110.0133 - val_loss: 105.5570\n",
      "Epoch 570/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.6324 - val_loss: 109.1091\n",
      "Epoch 571/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.6021 - val_loss: 106.7248\n",
      "Epoch 572/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.2906 - val_loss: 103.8995\n",
      "Epoch 573/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.4746 - val_loss: 103.7420\n",
      "Epoch 574/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.9545 - val_loss: 105.9755\n",
      "Epoch 575/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3648 - val_loss: 105.9695\n",
      "Epoch 576/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.5321 - val_loss: 110.4125\n",
      "Epoch 577/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.7916 - val_loss: 106.6493\n",
      "Epoch 578/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.6372 - val_loss: 104.4849\n",
      "Epoch 579/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.3961 - val_loss: 104.0390\n",
      "Epoch 580/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 109.5419 - val_loss: 105.7959\n",
      "Epoch 581/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.8790 - val_loss: 105.3925\n",
      "Epoch 582/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 109.5155 - val_loss: 105.1226\n",
      "Epoch 583/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.7226 - val_loss: 107.5120\n",
      "Epoch 584/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.5117 - val_loss: 104.4268\n",
      "Epoch 585/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.7703 - val_loss: 107.1259\n",
      "Epoch 586/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.5761 - val_loss: 104.8015\n",
      "Epoch 587/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5624 - val_loss: 105.0260\n",
      "Epoch 588/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.9537 - val_loss: 105.6972\n",
      "Epoch 589/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.6793 - val_loss: 105.2489\n",
      "Epoch 590/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.9036 - val_loss: 107.4621\n",
      "Epoch 591/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.5668 - val_loss: 106.9261\n",
      "Epoch 592/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.8875 - val_loss: 104.1864\n",
      "Epoch 593/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.5598 - val_loss: 105.5902\n",
      "Epoch 594/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.6487 - val_loss: 106.4303\n",
      "Epoch 595/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.5873 - val_loss: 105.9246\n",
      "Epoch 596/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.5404 - val_loss: 103.9186\n",
      "Epoch 597/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 110.0581 - val_loss: 105.3738\n",
      "Epoch 598/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.8790 - val_loss: 104.2776\n",
      "Epoch 599/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.6089 - val_loss: 103.1834\n",
      "Epoch 600/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.6468 - val_loss: 104.1189\n",
      "Epoch 601/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.9526 - val_loss: 109.1330\n",
      "Epoch 602/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.3598 - val_loss: 104.1380\n",
      "Epoch 603/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.5232 - val_loss: 104.1364\n",
      "Epoch 604/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.4694 - val_loss: 104.0745\n",
      "Epoch 605/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.8392 - val_loss: 106.9671\n",
      "Epoch 606/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.4073 - val_loss: 103.7543\n",
      "Epoch 607/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.4401 - val_loss: 103.7299\n",
      "Epoch 608/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.4051 - val_loss: 103.8963\n",
      "Epoch 609/900\n",
      "11944/11944 [==============================] - ETA: 0s - loss: 109.481 - 0s 34us/step - loss: 109.2817 - val_loss: 103.4430\n",
      "Epoch 610/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5843 - val_loss: 104.8481\n",
      "Epoch 611/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.7556 - val_loss: 108.8433\n",
      "Epoch 612/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3657 - val_loss: 104.1998\n",
      "Epoch 613/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 109.4962 - val_loss: 105.7524\n",
      "Epoch 614/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2867 - val_loss: 103.2344\n",
      "Epoch 615/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5296 - val_loss: 105.7888\n",
      "Epoch 616/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.7073 - val_loss: 104.1703\n",
      "Epoch 617/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.4942 - val_loss: 104.8168\n",
      "Epoch 618/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 109.4873 - val_loss: 105.0143\n",
      "Epoch 619/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 109.7333 - val_loss: 107.7930\n",
      "Epoch 620/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 109.5917 - val_loss: 104.6942\n",
      "Epoch 621/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.7015 - val_loss: 104.4489\n",
      "Epoch 622/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3992 - val_loss: 103.7628\n",
      "Epoch 623/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.4230 - val_loss: 105.5122\n",
      "Epoch 624/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.4378 - val_loss: 104.6990\n",
      "Epoch 625/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2578 - val_loss: 105.2973\n",
      "Epoch 626/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.5474 - val_loss: 108.0716\n",
      "Epoch 627/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.4898 - val_loss: 105.8393\n",
      "Epoch 628/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.2298 - val_loss: 103.1661\n",
      "Epoch 629/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.6217 - val_loss: 108.2042\n",
      "Epoch 630/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.3879 - val_loss: 103.7072\n",
      "Epoch 631/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3662 - val_loss: 104.4396\n",
      "Epoch 632/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1598 - val_loss: 106.6579\n",
      "Epoch 633/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3625 - val_loss: 104.1261\n",
      "Epoch 634/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2702 - val_loss: 103.2038\n",
      "Epoch 635/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.3920 - val_loss: 105.4580\n",
      "Epoch 636/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2991 - val_loss: 104.6803\n",
      "Epoch 637/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.1983 - val_loss: 105.1158\n",
      "Epoch 638/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.7810 - val_loss: 106.7624\n",
      "Epoch 639/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.4835 - val_loss: 104.1755\n",
      "Epoch 640/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.3503 - val_loss: 104.3782\n",
      "Epoch 641/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 109.3041 - val_loss: 105.0346\n",
      "Epoch 642/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.4700 - val_loss: 104.4105\n",
      "Epoch 643/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.2684 - val_loss: 108.3987\n",
      "Epoch 644/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.3358 - val_loss: 105.9621\n",
      "Epoch 645/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.2754 - val_loss: 106.4090\n",
      "Epoch 646/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.4920 - val_loss: 103.9960\n",
      "Epoch 647/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.4194 - val_loss: 107.7840\n",
      "Epoch 648/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 109.5268 - val_loss: 103.7889\n",
      "Epoch 649/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 109.3858 - val_loss: 108.6428\n",
      "Epoch 650/900\n",
      "11944/11944 [==============================] - 1s 57us/step - loss: 109.7327 - val_loss: 104.8795\n",
      "Epoch 651/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 109.3590 - val_loss: 103.9353\n",
      "Epoch 652/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2233 - val_loss: 105.6893\n",
      "Epoch 653/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 109.4418 - val_loss: 105.3144\n",
      "Epoch 654/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.3303 - val_loss: 103.8176\n",
      "Epoch 655/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.3692 - val_loss: 103.3699\n",
      "Epoch 656/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 109.3711 - val_loss: 104.4605\n",
      "Epoch 657/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 109.1631 - val_loss: 104.2320\n",
      "Epoch 658/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.6785 - val_loss: 108.0320\n",
      "Epoch 659/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 108.9629 - val_loss: 103.4441\n",
      "Epoch 660/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 109.3696 - val_loss: 104.2979\n",
      "Epoch 661/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.3894 - val_loss: 103.6693\n",
      "Epoch 662/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 109.1411 - val_loss: 102.8769\n",
      "Epoch 663/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 109.4485 - val_loss: 105.2306\n",
      "Epoch 664/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 109.4546 - val_loss: 106.1033\n",
      "Epoch 665/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 109.1622 - val_loss: 103.3554\n",
      "Epoch 666/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.7486 - val_loss: 107.7140\n",
      "Epoch 667/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.0707 - val_loss: 103.5433\n",
      "Epoch 668/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.9187 - val_loss: 104.7371\n",
      "Epoch 669/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.0768 - val_loss: 103.8378\n",
      "Epoch 670/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.5401 - val_loss: 103.3962\n",
      "Epoch 671/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2869 - val_loss: 112.9665\n",
      "Epoch 672/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.3104 - val_loss: 102.8925\n",
      "Epoch 673/900\n",
      "11944/11944 [==============================] - 1s 49us/step - loss: 109.1296 - val_loss: 106.4864\n",
      "Epoch 674/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.2691 - val_loss: 103.4388\n",
      "Epoch 675/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.3597 - val_loss: 104.1936\n",
      "Epoch 676/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.5079 - val_loss: 103.4795\n",
      "Epoch 677/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.5865 - val_loss: 103.9505\n",
      "Epoch 678/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.5675 - val_loss: 105.1175\n",
      "Epoch 679/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.3429 - val_loss: 107.5744\n",
      "Epoch 680/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.6620 - val_loss: 104.9066\n",
      "Epoch 681/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.6755 - val_loss: 104.7836\n",
      "Epoch 682/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.6731 - val_loss: 107.0556\n",
      "Epoch 683/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.4711 - val_loss: 104.3766\n",
      "Epoch 684/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.3810 - val_loss: 105.9079\n",
      "Epoch 685/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.3621 - val_loss: 103.8324\n",
      "Epoch 686/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.1254 - val_loss: 108.3060\n",
      "Epoch 687/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.1684 - val_loss: 104.5481\n",
      "Epoch 688/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.5571 - val_loss: 104.0471\n",
      "Epoch 689/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.4462 - val_loss: 103.4886\n",
      "Epoch 690/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.7512 - val_loss: 104.6038\n",
      "Epoch 691/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.1597 - val_loss: 104.5530\n",
      "Epoch 692/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.5273 - val_loss: 105.8529\n",
      "Epoch 693/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.3958 - val_loss: 105.0794\n",
      "Epoch 694/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.3939 - val_loss: 106.1167\n",
      "Epoch 695/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.2482 - val_loss: 103.1900\n",
      "Epoch 696/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.3165 - val_loss: 104.5306\n",
      "Epoch 697/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.1700 - val_loss: 103.7576\n",
      "Epoch 698/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.2519 - val_loss: 104.2717\n",
      "Epoch 699/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.0478 - val_loss: 107.2256\n",
      "Epoch 700/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.6459 - val_loss: 103.8057\n",
      "Epoch 701/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 109.1501 - val_loss: 103.2248\n",
      "Epoch 702/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.4154 - val_loss: 103.1857\n",
      "Epoch 703/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.4107 - val_loss: 107.5573\n",
      "Epoch 704/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3111 - val_loss: 103.3239\n",
      "Epoch 705/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.2717 - val_loss: 103.9447\n",
      "Epoch 706/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.2204 - val_loss: 105.6249\n",
      "Epoch 707/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.7901 - val_loss: 105.2811\n",
      "Epoch 708/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3281 - val_loss: 103.2710\n",
      "Epoch 709/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5187 - val_loss: 104.9237\n",
      "Epoch 710/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.4197 - val_loss: 104.9811\n",
      "Epoch 711/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5114 - val_loss: 105.7888\n",
      "Epoch 712/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.1909 - val_loss: 103.0888\n",
      "Epoch 713/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.4487 - val_loss: 103.7300\n",
      "Epoch 714/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.3334 - val_loss: 104.9095\n",
      "Epoch 715/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.3049 - val_loss: 104.0997\n",
      "Epoch 716/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.3723 - val_loss: 103.6613\n",
      "Epoch 717/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.4965 - val_loss: 103.1800\n",
      "Epoch 718/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2602 - val_loss: 105.7194\n",
      "Epoch 719/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.2286 - val_loss: 103.7579\n",
      "Epoch 720/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 109.5189 - val_loss: 105.9068\n",
      "Epoch 721/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.0553 - val_loss: 105.3397\n",
      "Epoch 722/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.3456 - val_loss: 109.2810\n",
      "Epoch 723/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.3890 - val_loss: 107.0675\n",
      "Epoch 724/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.6582 - val_loss: 104.2834\n",
      "Epoch 725/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.5218 - val_loss: 104.8566\n",
      "Epoch 726/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.4137 - val_loss: 103.3725\n",
      "Epoch 727/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.0944 - val_loss: 103.4033\n",
      "Epoch 728/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.0117 - val_loss: 103.4402\n",
      "Epoch 729/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2501 - val_loss: 104.0269\n",
      "Epoch 730/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.4146 - val_loss: 105.2212\n",
      "Epoch 731/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2564 - val_loss: 103.1450\n",
      "Epoch 732/900\n",
      "11944/11944 [==============================] - 1s 55us/step - loss: 109.3811 - val_loss: 104.1867\n",
      "Epoch 733/900\n",
      "11944/11944 [==============================] - 1s 51us/step - loss: 109.3046 - val_loss: 105.8760\n",
      "Epoch 734/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.3329 - val_loss: 103.6973\n",
      "Epoch 735/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.3455 - val_loss: 104.6017\n",
      "Epoch 736/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.1513 - val_loss: 105.0265\n",
      "Epoch 737/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.2190 - val_loss: 105.1506\n",
      "Epoch 738/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.0397 - val_loss: 105.6369\n",
      "Epoch 739/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.0544 - val_loss: 104.7355\n",
      "Epoch 740/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2661 - val_loss: 103.1834\n",
      "Epoch 741/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.2600 - val_loss: 106.4859\n",
      "Epoch 742/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.0519 - val_loss: 108.2579\n",
      "Epoch 743/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 109.4111 - val_loss: 103.0680\n",
      "Epoch 744/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 109.2189 - val_loss: 105.2389\n",
      "Epoch 745/900\n",
      "11944/11944 [==============================] - 1s 50us/step - loss: 109.2149 - val_loss: 105.0264\n",
      "Epoch 746/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.2349 - val_loss: 105.5382\n",
      "Epoch 747/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 109.1921 - val_loss: 102.7368\n",
      "Epoch 748/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.0618 - val_loss: 103.9009\n",
      "Epoch 749/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 109.0834 - val_loss: 103.1983\n",
      "Epoch 750/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 109.2199 - val_loss: 106.4493\n",
      "Epoch 751/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.3651 - val_loss: 105.0994\n",
      "Epoch 752/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.2819 - val_loss: 104.7384\n",
      "Epoch 753/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1594 - val_loss: 103.9471\n",
      "Epoch 754/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5747 - val_loss: 103.8903\n",
      "Epoch 755/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 108.9718 - val_loss: 105.8383\n",
      "Epoch 756/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 109.0786 - val_loss: 105.9732\n",
      "Epoch 757/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2043 - val_loss: 106.2807\n",
      "Epoch 758/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2182 - val_loss: 104.8406\n",
      "Epoch 759/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3861 - val_loss: 103.8363\n",
      "Epoch 760/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.0459 - val_loss: 106.5780\n",
      "Epoch 761/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 108.9177 - val_loss: 105.7000\n",
      "Epoch 762/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 109.0717 - val_loss: 104.3083\n",
      "Epoch 763/900\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 109.1862 - val_loss: 103.2545\n",
      "Epoch 764/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.2674 - val_loss: 105.2460\n",
      "Epoch 765/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.2232 - val_loss: 105.7272\n",
      "Epoch 766/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.2505 - val_loss: 106.4219\n",
      "Epoch 767/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.3086 - val_loss: 104.3698\n",
      "Epoch 768/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.2846 - val_loss: 103.2469\n",
      "Epoch 769/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 108.9146 - val_loss: 105.7096\n",
      "Epoch 770/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.0172 - val_loss: 103.9975\n",
      "Epoch 771/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.1490 - val_loss: 104.5845\n",
      "Epoch 772/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.4016 - val_loss: 105.1360\n",
      "Epoch 773/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2632 - val_loss: 103.9000\n",
      "Epoch 774/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.4870 - val_loss: 102.9872\n",
      "Epoch 775/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 108.9720 - val_loss: 106.2801\n",
      "Epoch 776/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.1809 - val_loss: 104.1548\n",
      "Epoch 777/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2021 - val_loss: 103.6165\n",
      "Epoch 778/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.5478 - val_loss: 103.9547\n",
      "Epoch 779/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.4398 - val_loss: 102.8211\n",
      "Epoch 780/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1947 - val_loss: 103.0353\n",
      "Epoch 781/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.1011 - val_loss: 103.7961\n",
      "Epoch 782/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.4235 - val_loss: 103.7198\n",
      "Epoch 783/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 108.9626 - val_loss: 106.0563\n",
      "Epoch 784/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2775 - val_loss: 105.0130\n",
      "Epoch 785/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3327 - val_loss: 106.1830\n",
      "Epoch 786/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 109.1062 - val_loss: 106.4584\n",
      "Epoch 787/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3640 - val_loss: 103.5456\n",
      "Epoch 788/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1168 - val_loss: 104.5488\n",
      "Epoch 789/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2160 - val_loss: 104.5237\n",
      "Epoch 790/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.0814 - val_loss: 103.2772\n",
      "Epoch 791/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2672 - val_loss: 104.8379\n",
      "Epoch 792/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1387 - val_loss: 103.0568\n",
      "Epoch 793/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1723 - val_loss: 103.3013\n",
      "Epoch 794/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.1194 - val_loss: 103.3116\n",
      "Epoch 795/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.1660 - val_loss: 104.1043\n",
      "Epoch 796/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1669 - val_loss: 102.8531\n",
      "Epoch 797/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.2952 - val_loss: 104.3918\n",
      "Epoch 798/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.3484 - val_loss: 106.1268\n",
      "Epoch 799/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 108.9893 - val_loss: 102.9126\n",
      "Epoch 800/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 108.8014 - val_loss: 103.1907\n",
      "Epoch 801/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.0345 - val_loss: 103.8785\n",
      "Epoch 802/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 108.9617 - val_loss: 104.3269\n",
      "Epoch 803/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2150 - val_loss: 107.4918\n",
      "Epoch 804/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.1155 - val_loss: 103.1330\n",
      "Epoch 805/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1162 - val_loss: 104.7096\n",
      "Epoch 806/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 108.8627 - val_loss: 106.2911\n",
      "Epoch 807/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.0144 - val_loss: 103.4923\n",
      "Epoch 808/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 109.5122 - val_loss: 105.1273\n",
      "Epoch 809/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 109.0491 - val_loss: 108.0891\n",
      "Epoch 810/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 108.9528 - val_loss: 103.0863\n",
      "Epoch 811/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 109.1694 - val_loss: 103.0826\n",
      "Epoch 812/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.0207 - val_loss: 105.6441\n",
      "Epoch 813/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 108.9176 - val_loss: 103.7690\n",
      "Epoch 814/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.1542 - val_loss: 102.8112\n",
      "Epoch 815/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.2251 - val_loss: 108.3548\n",
      "Epoch 816/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.6850 - val_loss: 103.3376\n",
      "Epoch 817/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.0431 - val_loss: 103.7466\n",
      "Epoch 818/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.0703 - val_loss: 104.1835\n",
      "Epoch 819/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.3497 - val_loss: 103.8251\n",
      "Epoch 820/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.1798 - val_loss: 103.6742\n",
      "Epoch 821/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.1591 - val_loss: 104.2125\n",
      "Epoch 822/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.1940 - val_loss: 102.4958\n",
      "Epoch 823/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 108.8383 - val_loss: 104.7078\n",
      "Epoch 824/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 109.1951 - val_loss: 102.8563\n",
      "Epoch 825/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 108.8621 - val_loss: 103.7529\n",
      "Epoch 826/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 109.0266 - val_loss: 103.0389\n",
      "Epoch 827/900\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 108.8601 - val_loss: 105.8232\n",
      "Epoch 828/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.0271 - val_loss: 103.1485\n",
      "Epoch 829/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2596 - val_loss: 104.7780\n",
      "Epoch 830/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.2134 - val_loss: 102.9817\n",
      "Epoch 831/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.0905 - val_loss: 105.6320\n",
      "Epoch 832/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.0871 - val_loss: 103.2843\n",
      "Epoch 833/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.1439 - val_loss: 103.6651\n",
      "Epoch 834/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 108.9957 - val_loss: 105.2198\n",
      "Epoch 835/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 108.8706 - val_loss: 105.9531\n",
      "Epoch 836/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 108.9372 - val_loss: 103.0013\n",
      "Epoch 837/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.0481 - val_loss: 103.9801\n",
      "Epoch 838/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 108.9792 - val_loss: 103.7870\n",
      "Epoch 839/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 108.8599 - val_loss: 106.3819\n",
      "Epoch 840/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.1277 - val_loss: 103.2449\n",
      "Epoch 841/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.1799 - val_loss: 112.0974\n",
      "Epoch 842/900\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 108.8835 - val_loss: 105.7163\n",
      "Epoch 843/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.1530 - val_loss: 103.2874\n",
      "Epoch 844/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 109.2475 - val_loss: 106.6669\n",
      "Epoch 845/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 108.7820 - val_loss: 102.8250\n",
      "Epoch 846/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.1028 - val_loss: 105.0276\n",
      "Epoch 847/900\n",
      "11944/11944 [==============================] - 1s 63us/step - loss: 108.9561 - val_loss: 103.7286\n",
      "Epoch 848/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 108.9187 - val_loss: 103.3154\n",
      "Epoch 849/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.0089 - val_loss: 104.5534\n",
      "Epoch 850/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 108.9456 - val_loss: 102.8420\n",
      "Epoch 851/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.1109 - val_loss: 104.5571\n",
      "Epoch 852/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 109.0717 - val_loss: 102.7047\n",
      "Epoch 853/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.0130 - val_loss: 103.0113\n",
      "Epoch 854/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.2833 - val_loss: 105.5646\n",
      "Epoch 855/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.2399 - val_loss: 108.5237\n",
      "Epoch 856/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 108.7458 - val_loss: 105.4801\n",
      "Epoch 857/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.1782 - val_loss: 107.1159\n",
      "Epoch 858/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.2663 - val_loss: 104.8773\n",
      "Epoch 859/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 108.9553 - val_loss: 104.4946\n",
      "Epoch 860/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.1034 - val_loss: 104.0515\n",
      "Epoch 861/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.0883 - val_loss: 102.6661\n",
      "Epoch 862/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.4625 - val_loss: 105.5869\n",
      "Epoch 863/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 108.8281 - val_loss: 102.3850\n",
      "Epoch 864/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1529 - val_loss: 103.5890\n",
      "Epoch 865/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 108.7889 - val_loss: 103.8063\n",
      "Epoch 866/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 109.3106 - val_loss: 102.7044\n",
      "Epoch 867/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 108.9008 - val_loss: 104.7146\n",
      "Epoch 868/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.1488 - val_loss: 104.5406\n",
      "Epoch 869/900\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 108.9055 - val_loss: 104.7307\n",
      "Epoch 870/900\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 108.8072 - val_loss: 104.5248\n",
      "Epoch 871/900\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 109.2183 - val_loss: 103.1506\n",
      "Epoch 872/900\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 108.8847 - val_loss: 106.7288\n",
      "Epoch 873/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 109.1039 - val_loss: 104.6959\n",
      "Epoch 874/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.2545 - val_loss: 104.8155\n",
      "Epoch 875/900\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 109.1262 - val_loss: 104.1572\n",
      "Epoch 876/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 108.8671 - val_loss: 104.6871\n",
      "Epoch 877/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 37us/step - loss: 109.0138 - val_loss: 103.2691\n",
      "Epoch 878/900\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 108.9044 - val_loss: 103.7531\n",
      "Epoch 879/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.0552 - val_loss: 104.5580\n",
      "Epoch 880/900\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 108.8924 - val_loss: 103.0965\n",
      "Epoch 881/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 109.1187 - val_loss: 102.8012\n",
      "Epoch 882/900\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 109.1810 - val_loss: 103.6367\n",
      "Epoch 883/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 108.8787 - val_loss: 102.8564\n",
      "Epoch 884/900\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 108.8835 - val_loss: 104.4215\n",
      "Epoch 885/900\n",
      "11944/11944 [==============================] - ETA: 0s - loss: 109.121 - 0s 38us/step - loss: 109.1541 - val_loss: 103.5818\n",
      "Epoch 886/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 109.2068 - val_loss: 106.4835\n",
      "Epoch 887/900\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 108.9759 - val_loss: 105.5557\n",
      "Epoch 888/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2963 - val_loss: 102.9511\n",
      "Epoch 889/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.1102 - val_loss: 103.3963\n",
      "Epoch 890/900\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 109.0148 - val_loss: 103.9283\n",
      "Epoch 891/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.1208 - val_loss: 105.7811\n",
      "Epoch 892/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.0476 - val_loss: 103.8167\n",
      "Epoch 893/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.0685 - val_loss: 107.9316\n",
      "Epoch 894/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 108.9617 - val_loss: 104.4140\n",
      "Epoch 895/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.0073 - val_loss: 102.7492\n",
      "Epoch 896/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.0303 - val_loss: 104.5264\n",
      "Epoch 897/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.2141 - val_loss: 105.5225\n",
      "Epoch 898/900\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 109.2354 - val_loss: 103.4249\n",
      "Epoch 899/900\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 109.1518 - val_loss: 103.2817\n",
      "Epoch 900/900\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 109.0602 - val_loss: 105.3622\n",
      "fridge\n",
      "********************\n",
      "Train on 11944 samples, validate on 1328 samples\n",
      "Epoch 1/400\n",
      "11944/11944 [==============================] - 1s 95us/step - loss: 87.9641 - val_loss: 68.3956\n",
      "Epoch 2/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 56.7119 - val_loss: 43.8609\n",
      "Epoch 3/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 45.0909 - val_loss: 40.0387\n",
      "Epoch 4/400\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 42.3120 - val_loss: 40.0952\n",
      "Epoch 5/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 39.2816 - val_loss: 35.5107\n",
      "Epoch 6/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 37.5629 - val_loss: 36.3968\n",
      "Epoch 7/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 37.0507 - val_loss: 35.2702\n",
      "Epoch 8/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 36.4520 - val_loss: 34.6542\n",
      "Epoch 9/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 36.6211 - val_loss: 35.8873\n",
      "Epoch 10/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 36.0226 - val_loss: 34.5361\n",
      "Epoch 11/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 35.8778 - val_loss: 33.8296\n",
      "Epoch 12/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 35.8476 - val_loss: 35.8991\n",
      "Epoch 13/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 35.6274 - val_loss: 34.2945\n",
      "Epoch 14/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 35.5151 - val_loss: 34.0153\n",
      "Epoch 15/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 35.1515 - val_loss: 34.1003\n",
      "Epoch 16/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 34.9925 - val_loss: 34.0215\n",
      "Epoch 17/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 34.9269 - val_loss: 33.2549\n",
      "Epoch 18/400\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 34.5914 - val_loss: 34.5773\n",
      "Epoch 19/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 34.5957 - val_loss: 32.8519\n",
      "Epoch 20/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 34.4619 - val_loss: 32.8889\n",
      "Epoch 21/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 34.3032 - val_loss: 33.1550\n",
      "Epoch 22/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 34.2277 - val_loss: 33.7724\n",
      "Epoch 23/400\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 33.9925 - val_loss: 32.5878\n",
      "Epoch 24/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 33.6786 - val_loss: 32.7321\n",
      "Epoch 25/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 33.6123 - val_loss: 32.7675\n",
      "Epoch 26/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 33.6332 - val_loss: 32.8053\n",
      "Epoch 27/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 33.6355 - val_loss: 33.1735\n",
      "Epoch 28/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 33.4629 - val_loss: 32.3523\n",
      "Epoch 29/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 33.2947 - val_loss: 32.9833\n",
      "Epoch 30/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 33.3173 - val_loss: 32.6136\n",
      "Epoch 31/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 33.1668 - val_loss: 31.9162\n",
      "Epoch 32/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 33.2835 - val_loss: 33.3585\n",
      "Epoch 33/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 33.0896 - val_loss: 32.5654\n",
      "Epoch 34/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 33.0866 - val_loss: 32.3155\n",
      "Epoch 35/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 33.0667 - val_loss: 31.7770\n",
      "Epoch 36/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 33.1060 - val_loss: 31.8047\n",
      "Epoch 37/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 32.8070 - val_loss: 32.0154\n",
      "Epoch 38/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 32.9943 - val_loss: 31.7663\n",
      "Epoch 39/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 32.8878 - val_loss: 31.8601\n",
      "Epoch 40/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 32.8767 - val_loss: 32.8726\n",
      "Epoch 41/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 32.8457 - val_loss: 32.2346\n",
      "Epoch 42/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 32.7238 - val_loss: 31.8735\n",
      "Epoch 43/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 32.7024 - val_loss: 31.5497\n",
      "Epoch 44/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 32.5985 - val_loss: 32.1080\n",
      "Epoch 45/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 32.6688 - val_loss: 31.6751\n",
      "Epoch 46/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 32.5223 - val_loss: 31.6809\n",
      "Epoch 47/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 32.4421 - val_loss: 31.5205\n",
      "Epoch 48/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 32.4549 - val_loss: 31.7825\n",
      "Epoch 49/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 32.5062 - val_loss: 31.4494\n",
      "Epoch 50/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 32.3783 - val_loss: 31.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 32.4158 - val_loss: 31.6017\n",
      "Epoch 52/400\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 32.4145 - val_loss: 31.4306\n",
      "Epoch 53/400\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 32.2736 - val_loss: 32.6985\n",
      "Epoch 54/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 32.2935 - val_loss: 31.7652\n",
      "Epoch 55/400\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 32.2812 - val_loss: 31.5903\n",
      "Epoch 56/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 32.0937 - val_loss: 32.4709\n",
      "Epoch 57/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 32.0499 - val_loss: 31.6519\n",
      "Epoch 58/400\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 31.9351 - val_loss: 31.2067\n",
      "Epoch 59/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 32.0829 - val_loss: 31.2392\n",
      "Epoch 60/400\n",
      "11944/11944 [==============================] - 1s 49us/step - loss: 31.9695 - val_loss: 31.0576\n",
      "Epoch 61/400\n",
      "11944/11944 [==============================] - 1s 52us/step - loss: 32.0072 - val_loss: 31.3822\n",
      "Epoch 62/400\n",
      "11944/11944 [==============================] - 1s 54us/step - loss: 31.8543 - val_loss: 31.3137\n",
      "Epoch 63/400\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 31.8932 - val_loss: 32.5036\n",
      "Epoch 64/400\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 31.9506 - val_loss: 31.3799\n",
      "Epoch 65/400\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 31.7531 - val_loss: 31.2586\n",
      "Epoch 66/400\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 31.8126 - val_loss: 31.1536\n",
      "Epoch 67/400\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 31.8136 - val_loss: 31.3345\n",
      "Epoch 68/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 31.7207 - val_loss: 31.0536\n",
      "Epoch 69/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 31.7303 - val_loss: 30.9831\n",
      "Epoch 70/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 31.7642 - val_loss: 31.0022\n",
      "Epoch 71/400\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 31.6567 - val_loss: 31.1608\n",
      "Epoch 72/400\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 31.6418 - val_loss: 31.1976\n",
      "Epoch 73/400\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 31.4884 - val_loss: 30.9519\n",
      "Epoch 74/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 31.5498 - val_loss: 31.6168\n",
      "Epoch 75/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 31.5311 - val_loss: 30.9605\n",
      "Epoch 76/400\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 31.5395 - val_loss: 31.1634\n",
      "Epoch 77/400\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 31.3474 - val_loss: 30.9985\n",
      "Epoch 78/400\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 31.4646 - val_loss: 30.7631\n",
      "Epoch 79/400\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 31.4380 - val_loss: 30.7955\n",
      "Epoch 80/400\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 31.3406 - val_loss: 30.8015\n",
      "Epoch 81/400\n",
      "11944/11944 [==============================] - 1s 51us/step - loss: 31.1703 - val_loss: 31.3931\n",
      "Epoch 82/400\n",
      "11944/11944 [==============================] - 1s 51us/step - loss: 31.3614 - val_loss: 30.6585\n",
      "Epoch 83/400\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 31.1663 - val_loss: 31.1033\n",
      "Epoch 84/400\n",
      "11944/11944 [==============================] - 1s 50us/step - loss: 31.3077 - val_loss: 31.1220\n",
      "Epoch 85/400\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 31.1541 - val_loss: 30.7538\n",
      "Epoch 86/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 31.1288 - val_loss: 30.7963\n",
      "Epoch 87/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 31.2241 - val_loss: 30.8460\n",
      "Epoch 88/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 31.1273 - val_loss: 30.7895\n",
      "Epoch 89/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 31.0389 - val_loss: 31.2581\n",
      "Epoch 90/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 31.0248 - val_loss: 30.5064\n",
      "Epoch 91/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 31.0779 - val_loss: 30.4705\n",
      "Epoch 92/400\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 31.0325 - val_loss: 30.5627\n",
      "Epoch 93/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 31.0452 - val_loss: 30.7087\n",
      "Epoch 94/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.9415 - val_loss: 30.8541\n",
      "Epoch 95/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 31.0389 - val_loss: 30.3701\n",
      "Epoch 96/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 30.9357 - val_loss: 30.8676\n",
      "Epoch 97/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.8734 - val_loss: 30.5932\n",
      "Epoch 98/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.9840 - val_loss: 30.6338\n",
      "Epoch 99/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 30.8349 - val_loss: 30.3997\n",
      "Epoch 100/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 30.8421 - val_loss: 30.2828\n",
      "Epoch 101/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.9336 - val_loss: 31.0146\n",
      "Epoch 102/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 30.8055 - val_loss: 30.4043\n",
      "Epoch 103/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.6327 - val_loss: 30.5256\n",
      "Epoch 104/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.8742 - val_loss: 30.9804\n",
      "Epoch 105/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.7832 - val_loss: 30.4236\n",
      "Epoch 106/400\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 30.8025 - val_loss: 30.3649\n",
      "Epoch 107/400\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 30.6206 - val_loss: 30.6750\n",
      "Epoch 108/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 30.7611 - val_loss: 30.0561\n",
      "Epoch 109/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.5714 - val_loss: 30.8173\n",
      "Epoch 110/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 30.3916 - val_loss: 30.1562\n",
      "Epoch 111/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 30.5881 - val_loss: 30.8872\n",
      "Epoch 112/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.5401 - val_loss: 30.5338\n",
      "Epoch 113/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.6229 - val_loss: 30.2886\n",
      "Epoch 114/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.6674 - val_loss: 30.1080\n",
      "Epoch 115/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.4749 - val_loss: 30.2796\n",
      "Epoch 116/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.4930 - val_loss: 30.1963\n",
      "Epoch 117/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.4067 - val_loss: 30.3303\n",
      "Epoch 118/400\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 30.3271 - val_loss: 30.1708\n",
      "Epoch 119/400\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 30.4445 - val_loss: 30.4805\n",
      "Epoch 120/400\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 30.3526 - val_loss: 31.0440\n",
      "Epoch 121/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.3870 - val_loss: 30.9854\n",
      "Epoch 122/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.4139 - val_loss: 29.9593\n",
      "Epoch 123/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.3225 - val_loss: 30.4794\n",
      "Epoch 124/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.3361 - val_loss: 30.1696\n",
      "Epoch 125/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.2466 - val_loss: 30.2833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/400\n",
      "11944/11944 [==============================] - ETA: 0s - loss: 30.35 - 0s 38us/step - loss: 30.3252 - val_loss: 30.1216\n",
      "Epoch 127/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 30.2225 - val_loss: 30.0858\n",
      "Epoch 128/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.2322 - val_loss: 29.9015\n",
      "Epoch 129/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 30.1158 - val_loss: 29.8089\n",
      "Epoch 130/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 30.1487 - val_loss: 30.9837\n",
      "Epoch 131/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.1776 - val_loss: 29.8595\n",
      "Epoch 132/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 30.0931 - val_loss: 30.0725\n",
      "Epoch 133/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 30.0292 - val_loss: 30.2727\n",
      "Epoch 134/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 30.1003 - val_loss: 29.8374\n",
      "Epoch 135/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.9654 - val_loss: 30.0844\n",
      "Epoch 136/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 30.0172 - val_loss: 29.9525\n",
      "Epoch 137/400\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 30.0397 - val_loss: 30.4768\n",
      "Epoch 138/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.9406 - val_loss: 29.6867\n",
      "Epoch 139/400\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 29.9581 - val_loss: 30.2176\n",
      "Epoch 140/400\n",
      "11944/11944 [==============================] - 1s 51us/step - loss: 29.9019 - val_loss: 29.7403\n",
      "Epoch 141/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.8903 - val_loss: 30.1532\n",
      "Epoch 142/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.9221 - val_loss: 30.0315\n",
      "Epoch 143/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.8907 - val_loss: 29.7590\n",
      "Epoch 144/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.8032 - val_loss: 29.7069\n",
      "Epoch 145/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.7582 - val_loss: 29.9058\n",
      "Epoch 146/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.8564 - val_loss: 29.9308\n",
      "Epoch 147/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.7157 - val_loss: 29.8199\n",
      "Epoch 148/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.8388 - val_loss: 29.6575\n",
      "Epoch 149/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.9421 - val_loss: 29.6258\n",
      "Epoch 150/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.8138 - val_loss: 29.7907\n",
      "Epoch 151/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.7395 - val_loss: 29.7251\n",
      "Epoch 152/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.8116 - val_loss: 29.5622\n",
      "Epoch 153/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.6657 - val_loss: 29.5623\n",
      "Epoch 154/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.7745 - val_loss: 29.5809\n",
      "Epoch 155/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.6419 - val_loss: 29.4847\n",
      "Epoch 156/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.7312 - val_loss: 29.5858\n",
      "Epoch 157/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.6762 - val_loss: 29.6213\n",
      "Epoch 158/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.5499 - val_loss: 29.9266\n",
      "Epoch 159/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.6377 - val_loss: 29.3650\n",
      "Epoch 160/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 29.5419 - val_loss: 29.4805\n",
      "Epoch 161/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.5355 - val_loss: 29.3187\n",
      "Epoch 162/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.5665 - val_loss: 29.3568\n",
      "Epoch 163/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.4492 - val_loss: 29.5775\n",
      "Epoch 164/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.5332 - val_loss: 29.3564\n",
      "Epoch 165/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.5446 - val_loss: 29.5005\n",
      "Epoch 166/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 29.4890 - val_loss: 29.6608\n",
      "Epoch 167/400\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 29.3995 - val_loss: 29.3167\n",
      "Epoch 168/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.3782 - val_loss: 29.2229\n",
      "Epoch 169/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.4239 - val_loss: 29.6176\n",
      "Epoch 170/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.4193 - val_loss: 29.2442\n",
      "Epoch 171/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.3770 - val_loss: 29.3888\n",
      "Epoch 172/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.3962 - val_loss: 30.0303\n",
      "Epoch 173/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.2709 - val_loss: 29.2634\n",
      "Epoch 174/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.4504 - val_loss: 29.8262\n",
      "Epoch 175/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.3495 - val_loss: 29.2563\n",
      "Epoch 176/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.2563 - val_loss: 29.2495\n",
      "Epoch 177/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.3571 - val_loss: 29.9871\n",
      "Epoch 178/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.2007 - val_loss: 29.2408\n",
      "Epoch 179/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.3986 - val_loss: 29.7005\n",
      "Epoch 180/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 29.3131 - val_loss: 29.0466\n",
      "Epoch 181/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.2471 - val_loss: 29.4811\n",
      "Epoch 182/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.3176 - val_loss: 29.1064\n",
      "Epoch 183/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.1527 - val_loss: 29.1675\n",
      "Epoch 184/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.1819 - val_loss: 28.9826\n",
      "Epoch 185/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.1078 - val_loss: 29.1629\n",
      "Epoch 186/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 29.2527 - val_loss: 29.5745\n",
      "Epoch 187/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 29.1793 - val_loss: 29.4779\n",
      "Epoch 188/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.1194 - val_loss: 29.5449\n",
      "Epoch 189/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.1983 - val_loss: 29.1419\n",
      "Epoch 190/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.0779 - val_loss: 28.9794\n",
      "Epoch 191/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.2085 - val_loss: 29.0265\n",
      "Epoch 192/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.0079 - val_loss: 29.3294\n",
      "Epoch 193/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.0787 - val_loss: 29.0077\n",
      "Epoch 194/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 29.0263 - val_loss: 28.8891\n",
      "Epoch 195/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.9954 - val_loss: 28.9358\n",
      "Epoch 196/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 29.1260 - val_loss: 29.3695\n",
      "Epoch 197/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 29.0493 - val_loss: 29.0212\n",
      "Epoch 198/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 29.0426 - val_loss: 29.0910\n",
      "Epoch 199/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 29.0607 - val_loss: 29.2149\n",
      "Epoch 200/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 42us/step - loss: 28.9702 - val_loss: 29.1113\n",
      "Epoch 201/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.9610 - val_loss: 28.8413\n",
      "Epoch 202/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.9949 - val_loss: 29.4288\n",
      "Epoch 203/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.9071 - val_loss: 29.4204\n",
      "Epoch 204/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.9195 - val_loss: 28.9343\n",
      "Epoch 205/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.9903 - val_loss: 29.0548\n",
      "Epoch 206/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.9234 - val_loss: 28.8679\n",
      "Epoch 207/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.9015 - val_loss: 28.9138\n",
      "Epoch 208/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.9216 - val_loss: 28.9347\n",
      "Epoch 209/400\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 28.9988 - val_loss: 29.1519\n",
      "Epoch 210/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.8081 - val_loss: 29.0644\n",
      "Epoch 211/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.9109 - val_loss: 28.8807\n",
      "Epoch 212/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.7914 - val_loss: 28.8744\n",
      "Epoch 213/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.7606 - val_loss: 28.6421\n",
      "Epoch 214/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.8955 - val_loss: 29.0454\n",
      "Epoch 215/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.8052 - val_loss: 29.3778\n",
      "Epoch 216/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.8301 - val_loss: 29.5606\n",
      "Epoch 217/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.8963 - val_loss: 29.5086\n",
      "Epoch 218/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.6886 - val_loss: 29.6187\n",
      "Epoch 219/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.7412 - val_loss: 28.7307\n",
      "Epoch 220/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.7823 - val_loss: 28.9827\n",
      "Epoch 221/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.6833 - val_loss: 28.7116\n",
      "Epoch 222/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.7688 - val_loss: 29.0083\n",
      "Epoch 223/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.6766 - val_loss: 28.7262\n",
      "Epoch 224/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.8207 - val_loss: 29.0422\n",
      "Epoch 225/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.7491 - val_loss: 28.7358\n",
      "Epoch 226/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.6546 - val_loss: 28.7039\n",
      "Epoch 227/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.6966 - val_loss: 29.5235\n",
      "Epoch 228/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.6235 - val_loss: 28.7901\n",
      "Epoch 229/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.7657 - val_loss: 29.1268\n",
      "Epoch 230/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5912 - val_loss: 28.7290\n",
      "Epoch 231/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.6302 - val_loss: 28.7938\n",
      "Epoch 232/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5746 - val_loss: 28.8369\n",
      "Epoch 233/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.7431 - val_loss: 30.1803\n",
      "Epoch 234/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.6122 - val_loss: 29.0135\n",
      "Epoch 235/400\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 28.6733 - val_loss: 28.8088\n",
      "Epoch 236/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5391 - val_loss: 28.7657\n",
      "Epoch 237/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5246 - val_loss: 29.3313\n",
      "Epoch 238/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5424 - val_loss: 28.7696\n",
      "Epoch 239/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5666 - val_loss: 28.8322\n",
      "Epoch 240/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.4602 - val_loss: 28.5345\n",
      "Epoch 241/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.4478 - val_loss: 28.7033\n",
      "Epoch 242/400\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 28.5177 - val_loss: 28.8643\n",
      "Epoch 243/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5236 - val_loss: 28.5976\n",
      "Epoch 244/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.4986 - val_loss: 28.8206\n",
      "Epoch 245/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5492 - val_loss: 28.6264\n",
      "Epoch 246/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.4701 - val_loss: 28.9622\n",
      "Epoch 247/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.4496 - val_loss: 29.3612\n",
      "Epoch 248/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.4563 - val_loss: 28.6403\n",
      "Epoch 249/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5564 - val_loss: 28.8410\n",
      "Epoch 250/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.5664 - val_loss: 28.6464\n",
      "Epoch 251/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.4502 - val_loss: 28.5686\n",
      "Epoch 252/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.5376 - val_loss: 28.7864\n",
      "Epoch 253/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.4806 - val_loss: 28.8249\n",
      "Epoch 254/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.4588 - val_loss: 28.9794\n",
      "Epoch 255/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.4747 - val_loss: 29.0316\n",
      "Epoch 256/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.4082 - val_loss: 29.6313\n",
      "Epoch 257/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.5365 - val_loss: 28.6005\n",
      "Epoch 258/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.3404 - val_loss: 28.5121\n",
      "Epoch 259/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.4469 - val_loss: 28.6560\n",
      "Epoch 260/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.3948 - val_loss: 28.6128\n",
      "Epoch 261/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.4128 - val_loss: 28.4846\n",
      "Epoch 262/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.4817 - val_loss: 28.6850\n",
      "Epoch 263/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.4094 - val_loss: 28.5458\n",
      "Epoch 264/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.3843 - val_loss: 29.2889\n",
      "Epoch 265/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 28.4273 - val_loss: 28.4604\n",
      "Epoch 266/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.3794 - val_loss: 28.4921\n",
      "Epoch 267/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.4655 - val_loss: 28.7581\n",
      "Epoch 268/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.3390 - val_loss: 28.5888\n",
      "Epoch 269/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.4099 - val_loss: 28.4504\n",
      "Epoch 270/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.3896 - val_loss: 28.7080\n",
      "Epoch 271/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.3235 - val_loss: 28.5506\n",
      "Epoch 272/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.3772 - val_loss: 28.4382\n",
      "Epoch 273/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.3802 - val_loss: 28.4621\n",
      "Epoch 274/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.2618 - val_loss: 28.4375\n",
      "Epoch 275/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.3289 - val_loss: 29.1007\n",
      "Epoch 276/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.3344 - val_loss: 28.4663\n",
      "Epoch 277/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.3079 - val_loss: 28.9851\n",
      "Epoch 278/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.2850 - val_loss: 28.3642\n",
      "Epoch 279/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.3185 - val_loss: 28.5956\n",
      "Epoch 280/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.3274 - val_loss: 28.4435\n",
      "Epoch 281/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.3113 - val_loss: 28.7900\n",
      "Epoch 282/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.3559 - val_loss: 28.4274\n",
      "Epoch 283/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.2604 - val_loss: 28.6480\n",
      "Epoch 284/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.3664 - val_loss: 28.5885\n",
      "Epoch 285/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.2805 - val_loss: 28.6527\n",
      "Epoch 286/400\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 28.3406 - val_loss: 28.4831\n",
      "Epoch 287/400\n",
      "11944/11944 [==============================] - 1s 53us/step - loss: 28.2578 - val_loss: 28.8340\n",
      "Epoch 288/400\n",
      "11944/11944 [==============================] - 1s 53us/step - loss: 28.3003 - val_loss: 28.7287\n",
      "Epoch 289/400\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 28.2576 - val_loss: 28.4856\n",
      "Epoch 290/400\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 28.2467 - val_loss: 28.6256\n",
      "Epoch 291/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.2774 - val_loss: 28.4564\n",
      "Epoch 292/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.2724 - val_loss: 28.5618\n",
      "Epoch 293/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.2632 - val_loss: 29.1798\n",
      "Epoch 294/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.2478 - val_loss: 28.5221\n",
      "Epoch 295/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.2603 - val_loss: 28.3745\n",
      "Epoch 296/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.1882 - val_loss: 28.4782\n",
      "Epoch 297/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1984 - val_loss: 28.8965\n",
      "Epoch 298/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.2875 - val_loss: 29.6281\n",
      "Epoch 299/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.2481 - val_loss: 29.1426\n",
      "Epoch 300/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.2226 - val_loss: 28.8027\n",
      "Epoch 301/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.1708 - val_loss: 28.6157\n",
      "Epoch 302/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.2452 - val_loss: 28.6341\n",
      "Epoch 303/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.1831 - val_loss: 28.4054\n",
      "Epoch 304/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1700 - val_loss: 28.8921\n",
      "Epoch 305/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1981 - val_loss: 28.3763\n",
      "Epoch 306/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.2144 - val_loss: 28.3498\n",
      "Epoch 307/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.2264 - val_loss: 28.3971\n",
      "Epoch 308/400\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 28.1585 - val_loss: 28.4689\n",
      "Epoch 309/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.1901 - val_loss: 28.4061\n",
      "Epoch 310/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.1331 - val_loss: 28.3504\n",
      "Epoch 311/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.2023 - val_loss: 28.3531\n",
      "Epoch 312/400\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 28.3116 - val_loss: 29.3047\n",
      "Epoch 313/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.2290 - val_loss: 29.4380\n",
      "Epoch 314/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.1316 - val_loss: 28.4727\n",
      "Epoch 315/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.1915 - val_loss: 28.3815\n",
      "Epoch 316/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1399 - val_loss: 28.3330\n",
      "Epoch 317/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1018 - val_loss: 28.3861\n",
      "Epoch 318/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1598 - val_loss: 29.8299\n",
      "Epoch 319/400\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 28.1578 - val_loss: 28.5594\n",
      "Epoch 320/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0993 - val_loss: 28.4974\n",
      "Epoch 321/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.1653 - val_loss: 28.7553\n",
      "Epoch 322/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1544 - val_loss: 28.3524\n",
      "Epoch 323/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0988 - val_loss: 28.5552\n",
      "Epoch 324/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.1079 - val_loss: 28.6232\n",
      "Epoch 325/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.0864 - val_loss: 28.3772\n",
      "Epoch 326/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1165 - val_loss: 28.3286\n",
      "Epoch 327/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.1218 - val_loss: 28.7185\n",
      "Epoch 328/400\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 28.1080 - val_loss: 28.6160\n",
      "Epoch 329/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1248 - val_loss: 28.4532\n",
      "Epoch 330/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.1448 - val_loss: 28.3296\n",
      "Epoch 331/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.0901 - val_loss: 28.3755\n",
      "Epoch 332/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.1027 - val_loss: 28.3521\n",
      "Epoch 333/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.0703 - val_loss: 28.4357\n",
      "Epoch 334/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0275 - val_loss: 28.3783\n",
      "Epoch 335/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.0356 - val_loss: 28.7879\n",
      "Epoch 336/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0735 - val_loss: 28.3081\n",
      "Epoch 337/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0019 - val_loss: 28.4147\n",
      "Epoch 338/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0737 - val_loss: 28.3125\n",
      "Epoch 339/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.1075 - val_loss: 28.2828\n",
      "Epoch 340/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.0795 - val_loss: 28.8437\n",
      "Epoch 341/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0649 - val_loss: 28.5263\n",
      "Epoch 342/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.0673 - val_loss: 28.9248\n",
      "Epoch 343/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.0972 - val_loss: 28.4994\n",
      "Epoch 344/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 27.9932 - val_loss: 28.2913\n",
      "Epoch 345/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.1098 - val_loss: 28.5137\n",
      "Epoch 346/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.0768 - val_loss: 28.3669\n",
      "Epoch 347/400\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 28.0396 - val_loss: 28.2923\n",
      "Epoch 348/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0755 - val_loss: 28.4516\n",
      "Epoch 349/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0135 - val_loss: 28.5400\n",
      "Epoch 350/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0295 - val_loss: 28.6245\n",
      "Epoch 351/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0798 - val_loss: 28.4113\n",
      "Epoch 352/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 27.9957 - val_loss: 28.2936\n",
      "Epoch 353/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.0045 - val_loss: 28.3282\n",
      "Epoch 354/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 27.9659 - val_loss: 28.3494\n",
      "Epoch 355/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0112 - val_loss: 28.2331\n",
      "Epoch 356/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 28.0659 - val_loss: 28.5776\n",
      "Epoch 357/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.0363 - val_loss: 28.6793\n",
      "Epoch 358/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 27.9527 - val_loss: 28.3449\n",
      "Epoch 359/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 27.9859 - val_loss: 28.5363\n",
      "Epoch 360/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 28.0288 - val_loss: 28.6193\n",
      "Epoch 361/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.0343 - val_loss: 28.3792\n",
      "Epoch 362/400\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 27.9130 - val_loss: 28.8333\n",
      "Epoch 363/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 28.0065 - val_loss: 28.4274\n",
      "Epoch 364/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 27.9944 - val_loss: 28.3133\n",
      "Epoch 365/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 27.9279 - val_loss: 28.3784\n",
      "Epoch 366/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 27.9991 - val_loss: 28.5382\n",
      "Epoch 367/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 27.9916 - val_loss: 28.3364\n",
      "Epoch 368/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 27.9758 - val_loss: 28.1963\n",
      "Epoch 369/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 27.9947 - val_loss: 28.7275\n",
      "Epoch 370/400\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 27.9410 - val_loss: 28.2629\n",
      "Epoch 371/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 27.9554 - val_loss: 28.4879\n",
      "Epoch 372/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 27.9659 - val_loss: 28.3056\n",
      "Epoch 373/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.8883 - val_loss: 28.5125\n",
      "Epoch 374/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.9344 - val_loss: 28.3515\n",
      "Epoch 375/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.9915 - val_loss: 28.2551\n",
      "Epoch 376/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.9032 - val_loss: 28.3509\n",
      "Epoch 377/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.9351 - val_loss: 28.4338\n",
      "Epoch 378/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.9284 - val_loss: 28.4200\n",
      "Epoch 379/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.8480 - val_loss: 28.4329\n",
      "Epoch 380/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 27.9296 - val_loss: 28.2188\n",
      "Epoch 381/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.9289 - val_loss: 28.6123\n",
      "Epoch 382/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 27.9433 - val_loss: 28.4809\n",
      "Epoch 383/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.8927 - val_loss: 28.2889\n",
      "Epoch 384/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.9729 - val_loss: 28.7547\n",
      "Epoch 385/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 27.9368 - val_loss: 28.2308\n",
      "Epoch 386/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.9342 - val_loss: 28.5341\n",
      "Epoch 387/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.8854 - val_loss: 28.2608\n",
      "Epoch 388/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 27.9545 - val_loss: 28.3030\n",
      "Epoch 389/400\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 27.9402 - val_loss: 28.1677\n",
      "Epoch 390/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.9005 - val_loss: 28.3986\n",
      "Epoch 391/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 27.9154 - val_loss: 28.4585\n",
      "Epoch 392/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 27.9772 - val_loss: 28.5792\n",
      "Epoch 393/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 27.9145 - val_loss: 28.1823\n",
      "Epoch 394/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 27.9016 - val_loss: 28.2123\n",
      "Epoch 395/400\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 27.9228 - val_loss: 28.2946\n",
      "Epoch 396/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 27.9358 - val_loss: 28.2570\n",
      "Epoch 397/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 27.9027 - val_loss: 28.5025\n",
      "Epoch 398/400\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 27.9078 - val_loss: 28.3021\n",
      "Epoch 399/400\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 27.8669 - val_loss: 28.2771\n",
      "Epoch 400/400\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 27.8910 - val_loss: 28.2898\n",
      "mw\n",
      "********************\n",
      "Train on 11944 samples, validate on 1328 samples\n",
      "Epoch 1/250\n",
      "11944/11944 [==============================] - 1s 102us/step - loss: 24.2900 - val_loss: 6.2320\n",
      "Epoch 2/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.5387 - val_loss: 6.1690\n",
      "Epoch 3/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3915 - val_loss: 6.1611\n",
      "Epoch 4/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3458 - val_loss: 6.1611\n",
      "Epoch 5/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3433 - val_loss: 6.1611\n",
      "Epoch 6/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 6.3369 - val_loss: 6.1611\n",
      "Epoch 7/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3318 - val_loss: 6.1611\n",
      "Epoch 8/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3279 - val_loss: 6.1611\n",
      "Epoch 9/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3286 - val_loss: 6.1611\n",
      "Epoch 10/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3237 - val_loss: 6.1611\n",
      "Epoch 11/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3233 - val_loss: 6.1611\n",
      "Epoch 12/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3226 - val_loss: 6.1611\n",
      "Epoch 13/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3207 - val_loss: 6.1611\n",
      "Epoch 14/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3208 - val_loss: 6.1611\n",
      "Epoch 15/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3222 - val_loss: 6.1611\n",
      "Epoch 16/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3215 - val_loss: 6.1611\n",
      "Epoch 17/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3201 - val_loss: 6.1611\n",
      "Epoch 18/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3221 - val_loss: 6.1611\n",
      "Epoch 19/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3203 - val_loss: 6.1611\n",
      "Epoch 20/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 21/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3203 - val_loss: 6.1611\n",
      "Epoch 22/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 23/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3203 - val_loss: 6.1611\n",
      "Epoch 24/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3201 - val_loss: 6.1611\n",
      "Epoch 25/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3202 - val_loss: 6.1611\n",
      "Epoch 26/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 27/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3194 - val_loss: 6.1611\n",
      "Epoch 28/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3206 - val_loss: 6.1611\n",
      "Epoch 29/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 30/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 31/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 32/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3201 - val_loss: 6.1611\n",
      "Epoch 33/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3206 - val_loss: 6.1611\n",
      "Epoch 34/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3199 - val_loss: 6.1611\n",
      "Epoch 35/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3194 - val_loss: 6.1611\n",
      "Epoch 36/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 37/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3197 - val_loss: 6.1611\n",
      "Epoch 38/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 39/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3197 - val_loss: 6.1611\n",
      "Epoch 40/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 41/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 42/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 43/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 44/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 45/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 46/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3230 - val_loss: 6.1611\n",
      "Epoch 47/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 48/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3197 - val_loss: 6.1611\n",
      "Epoch 49/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 50/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 51/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 52/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 53/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 54/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 55/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3200 - val_loss: 6.1611\n",
      "Epoch 56/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 57/250\n",
      "11944/11944 [==============================] - 1s 62us/step - loss: 6.3207 - val_loss: 6.1611\n",
      "Epoch 58/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 59/250\n",
      "11944/11944 [==============================] - 1s 50us/step - loss: 6.3197 - val_loss: 6.1611\n",
      "Epoch 60/250\n",
      "11944/11944 [==============================] - 1s 56us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 61/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 62/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 63/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 64/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3200 - val_loss: 6.1611\n",
      "Epoch 65/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 66/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 67/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 68/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 69/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 70/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 71/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 72/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3208 - val_loss: 6.1611\n",
      "Epoch 73/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 74/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3201 - val_loss: 6.1611\n",
      "Epoch 75/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 76/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 77/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 78/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 79/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 80/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 81/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 82/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 83/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 84/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 85/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3199 - val_loss: 6.1611\n",
      "Epoch 86/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 87/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 88/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 89/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 90/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 91/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 92/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 93/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 94/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 95/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 96/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 97/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 98/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 99/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 100/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 101/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 102/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 103/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 104/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3197 - val_loss: 6.1611\n",
      "Epoch 105/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 106/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 107/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 108/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 109/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 110/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 111/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 112/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 113/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 114/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 115/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 116/250\n",
      "11944/11944 [==============================] - ETA: 0s - loss: 6.283 - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 117/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 118/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 119/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 120/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 121/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 122/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 123/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 124/250\n",
      "11944/11944 [==============================] - 1s 56us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 125/250\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 126/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3203 - val_loss: 6.1611\n",
      "Epoch 127/250\n",
      "11944/11944 [==============================] - 1s 51us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 128/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 129/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 130/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 131/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 132/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 133/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 134/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 135/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 136/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 137/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 138/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 139/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 140/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 141/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 142/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 143/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 144/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 145/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 146/250\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 147/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 148/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 149/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 150/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 151/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 152/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 153/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 154/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 155/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 156/250\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 157/250\n",
      "11944/11944 [==============================] - 1s 55us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 158/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 159/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 160/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 161/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 162/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 163/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 164/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 165/250\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 166/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 167/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 168/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 169/250\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 6.3199 - val_loss: 6.1611\n",
      "Epoch 170/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 171/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 172/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 173/250\n",
      "11944/11944 [==============================] - ETA: 0s - loss: 6.311 - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 175/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 176/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 177/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 178/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 179/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 180/250\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 181/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 182/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 183/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 184/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 185/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3198 - val_loss: 6.1611\n",
      "Epoch 186/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 187/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 188/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3206 - val_loss: 6.1611\n",
      "Epoch 189/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 190/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 191/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 192/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 193/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3196 - val_loss: 6.1611\n",
      "Epoch 194/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 195/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 196/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 197/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3197 - val_loss: 6.1611\n",
      "Epoch 198/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 199/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 200/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 201/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 202/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 203/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 204/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 205/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 206/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 207/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 208/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 209/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 210/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 211/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 212/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 213/250\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 214/250\n",
      "11944/11944 [==============================] - 1s 56us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 215/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 216/250\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 217/250\n",
      "11944/11944 [==============================] - 1s 49us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 218/250\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 219/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3198 - val_loss: 6.1611\n",
      "Epoch 220/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 221/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 222/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 223/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 224/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 225/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 226/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 227/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 228/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 229/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 230/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 231/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 232/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 233/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 234/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 235/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 236/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 237/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 238/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 239/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 240/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 241/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 242/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 243/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 244/250\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 245/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 246/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 247/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 248/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "Epoch 249/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 6.3195 - val_loss: 6.1611\n",
      "dw\n",
      "********************\n",
      "Train on 11944 samples, validate on 1328 samples\n",
      "Epoch 1/250\n",
      "11944/11944 [==============================] - 2s 178us/step - loss: 31.4685 - val_loss: 15.6622\n",
      "Epoch 2/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.8034 - val_loss: 15.5843\n",
      "Epoch 3/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 13.5642 - val_loss: 15.5814\n",
      "Epoch 4/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.5152 - val_loss: 15.5814\n",
      "Epoch 5/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.5159 - val_loss: 15.5814\n",
      "Epoch 6/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.5108 - val_loss: 15.5814\n",
      "Epoch 7/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.5035 - val_loss: 15.5814\n",
      "Epoch 8/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.5022 - val_loss: 15.5814\n",
      "Epoch 9/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.5051 - val_loss: 15.5814\n",
      "Epoch 10/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.5012 - val_loss: 15.5814\n",
      "Epoch 11/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4988 - val_loss: 15.5814\n",
      "Epoch 12/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.5000 - val_loss: 15.5814\n",
      "Epoch 13/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4984 - val_loss: 15.5814\n",
      "Epoch 14/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4977 - val_loss: 15.5814\n",
      "Epoch 15/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4999 - val_loss: 15.5814\n",
      "Epoch 16/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4988 - val_loss: 15.5814\n",
      "Epoch 17/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4972 - val_loss: 15.5814\n",
      "Epoch 18/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 13.4986 - val_loss: 15.5814\n",
      "Epoch 19/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4979 - val_loss: 15.5814\n",
      "Epoch 20/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 21/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4976 - val_loss: 15.5814\n",
      "Epoch 22/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 23/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4976 - val_loss: 15.5814\n",
      "Epoch 24/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 13.4986 - val_loss: 15.5814\n",
      "Epoch 25/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4971 - val_loss: 15.5814\n",
      "Epoch 26/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4972 - val_loss: 15.5814\n",
      "Epoch 27/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 28/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4975 - val_loss: 15.5814\n",
      "Epoch 29/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4970 - val_loss: 15.5814\n",
      "Epoch 30/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4974 - val_loss: 15.5814\n",
      "Epoch 31/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 32/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4978 - val_loss: 15.5814\n",
      "Epoch 33/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4978 - val_loss: 15.5814\n",
      "Epoch 34/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4970 - val_loss: 15.5814\n",
      "Epoch 35/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 36/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 37/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4974 - val_loss: 15.5814\n",
      "Epoch 38/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 39/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 40/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 41/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 42/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 43/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 44/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 45/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4970 - val_loss: 15.5814\n",
      "Epoch 46/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4976 - val_loss: 15.5814\n",
      "Epoch 47/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4972 - val_loss: 15.5814\n",
      "Epoch 48/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4972 - val_loss: 15.5814\n",
      "Epoch 49/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4970 - val_loss: 15.5814\n",
      "Epoch 50/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4972 - val_loss: 15.5814\n",
      "Epoch 51/250\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 52/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 53/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 54/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 55/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 56/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 57/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 58/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 59/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 60/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 61/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 62/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 63/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 64/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 65/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 66/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 67/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4970 - val_loss: 15.5814\n",
      "Epoch 68/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4976 - val_loss: 15.5814\n",
      "Epoch 69/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 70/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4970 - val_loss: 15.5814\n",
      "Epoch 71/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 72/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4973 - val_loss: 15.5814\n",
      "Epoch 73/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 74/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 75/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 76/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 77/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 78/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 79/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4972 - val_loss: 15.5814\n",
      "Epoch 80/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 81/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 82/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 83/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 84/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 85/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 86/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 87/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 88/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 89/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 90/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 91/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 92/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 93/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 94/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 95/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 96/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4972 - val_loss: 15.5814\n",
      "Epoch 97/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 98/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 99/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 100/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 101/250\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 102/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 103/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 104/250\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 13.4972 - val_loss: 15.5814\n",
      "Epoch 105/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 106/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 107/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 108/250\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 109/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 110/250\n",
      "11944/11944 [==============================] - 1s 71us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 111/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 112/250\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 113/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 114/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 115/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 116/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 117/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 118/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 119/250\n",
      "11944/11944 [==============================] - 1s 54us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 120/250\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 121/250\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 13.4971 - val_loss: 15.5814\n",
      "Epoch 122/250\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 123/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 124/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 125/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4970 - val_loss: 15.5814\n",
      "Epoch 126/250\n",
      "11944/11944 [==============================] - 1s 60us/step - loss: 13.4987 - val_loss: 15.5814\n",
      "Epoch 127/250\n",
      "11944/11944 [==============================] - 1s 53us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 128/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 129/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 130/250\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 131/250\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 132/250\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 133/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 134/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 135/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 136/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 137/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 138/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 139/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 140/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 141/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 142/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 143/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 144/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 145/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 146/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 147/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 148/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 150/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 151/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 152/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 153/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 154/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 155/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 156/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 157/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 158/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 159/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 160/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 161/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 162/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 163/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 164/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 165/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 166/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 167/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 168/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 169/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4970 - val_loss: 15.5814\n",
      "Epoch 170/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 171/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 172/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 173/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 174/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 175/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 176/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 177/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 178/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 179/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 180/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 181/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 182/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 183/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 184/250\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 185/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4981 - val_loss: 15.5814\n",
      "Epoch 186/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 187/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 188/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4975 - val_loss: 15.5814\n",
      "Epoch 189/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 190/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 191/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 192/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 193/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 194/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 195/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 196/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 197/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 198/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 199/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 200/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 201/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 202/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 203/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 204/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 205/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 206/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 207/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 208/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 209/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 210/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 211/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 212/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 213/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 214/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 215/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 216/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 217/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 218/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 219/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4977 - val_loss: 15.5814\n",
      "Epoch 220/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 221/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 222/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 223/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 224/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 225/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 226/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 227/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 228/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 229/250\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 230/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.4973 - val_loss: 15.5814\n",
      "Epoch 231/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 232/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 233/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 234/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 235/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4970 - val_loss: 15.5814\n",
      "Epoch 236/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 237/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 238/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 239/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 240/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 241/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 242/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 243/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 244/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 245/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 246/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 247/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 248/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 249/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "Epoch 250/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.4969 - val_loss: 15.5814\n",
      "wm\n",
      "********************\n",
      "Train on 11944 samples, validate on 1328 samples\n",
      "Epoch 1/300\n",
      "11944/11944 [==============================] - 1s 100us/step - loss: 22.9398 - val_loss: 4.7568\n",
      "Epoch 2/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.8621 - val_loss: 4.6853\n",
      "Epoch 3/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.7093 - val_loss: 4.6829\n",
      "Epoch 4/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6669 - val_loss: 4.6829\n",
      "Epoch 5/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6663 - val_loss: 4.6829\n",
      "Epoch 6/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6586 - val_loss: 4.6829\n",
      "Epoch 7/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6544 - val_loss: 4.6829\n",
      "Epoch 8/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6508 - val_loss: 4.6829\n",
      "Epoch 9/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6521 - val_loss: 4.6829\n",
      "Epoch 10/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6451 - val_loss: 4.6829\n",
      "Epoch 11/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6461 - val_loss: 4.6829\n",
      "Epoch 12/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6454 - val_loss: 4.6829\n",
      "Epoch 13/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6438 - val_loss: 4.6829\n",
      "Epoch 14/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6432 - val_loss: 4.6829\n",
      "Epoch 15/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6454 - val_loss: 4.6829\n",
      "Epoch 16/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6433 - val_loss: 4.6829\n",
      "Epoch 17/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6429 - val_loss: 4.6829\n",
      "Epoch 18/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6450 - val_loss: 4.6829\n",
      "Epoch 19/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6431 - val_loss: 4.6829\n",
      "Epoch 20/300\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 4.6426 - val_loss: 4.6829\n",
      "Epoch 21/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6432 - val_loss: 4.6829\n",
      "Epoch 22/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6427 - val_loss: 4.6829\n",
      "Epoch 23/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6431 - val_loss: 4.6829\n",
      "Epoch 24/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6431 - val_loss: 4.6829\n",
      "Epoch 25/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6430 - val_loss: 4.6829\n",
      "Epoch 26/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6427 - val_loss: 4.6829\n",
      "Epoch 27/300\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 28/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6426 - val_loss: 4.6829\n",
      "Epoch 29/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6424 - val_loss: 4.6829\n",
      "Epoch 30/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 31/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 32/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6437 - val_loss: 4.6829\n",
      "Epoch 33/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6438 - val_loss: 4.6829\n",
      "Epoch 34/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 35/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6429 - val_loss: 4.6829\n",
      "Epoch 36/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6427 - val_loss: 4.6829\n",
      "Epoch 37/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6431 - val_loss: 4.6829\n",
      "Epoch 38/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 39/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 40/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 41/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 42/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 43/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 44/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 45/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 46/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6441 - val_loss: 4.6829\n",
      "Epoch 47/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6429 - val_loss: 4.6829\n",
      "Epoch 48/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6428 - val_loss: 4.6829\n",
      "Epoch 49/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6427 - val_loss: 4.6829\n",
      "Epoch 50/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6428 - val_loss: 4.6829\n",
      "Epoch 51/300\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 52/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 53/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 54/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6426 - val_loss: 4.6829\n",
      "Epoch 55/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6428 - val_loss: 4.6829\n",
      "Epoch 56/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 57/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6426 - val_loss: 4.6829\n",
      "Epoch 58/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6427 - val_loss: 4.6829\n",
      "Epoch 59/300\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 60/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 61/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 62/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 63/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 64/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 65/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 66/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 67/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 68/300\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 4.6429 - val_loss: 4.6829\n",
      "Epoch 69/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 70/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6431 - val_loss: 4.6829\n",
      "Epoch 71/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 72/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 73/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 74/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 75/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 76/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 77/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 78/300\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 79/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6434 - val_loss: 4.6829\n",
      "Epoch 80/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 81/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 82/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 83/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 84/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 85/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 86/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 87/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6426 - val_loss: 4.6829\n",
      "Epoch 88/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 89/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 90/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 91/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 92/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 93/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 94/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 95/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 96/300\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 4.6427 - val_loss: 4.6829\n",
      "Epoch 97/300\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 98/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 99/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 100/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6427 - val_loss: 4.6829\n",
      "Epoch 101/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 102/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 103/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 104/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6428 - val_loss: 4.6829\n",
      "Epoch 105/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 106/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 107/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 108/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 109/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 110/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 111/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 112/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 113/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 114/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 115/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 116/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 117/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 118/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 119/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 120/300\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 4.6427 - val_loss: 4.6829\n",
      "Epoch 121/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 122/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 123/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 124/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 125/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 126/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 127/300\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 128/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 129/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 130/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 131/300\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 132/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 133/300\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 134/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 135/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 136/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 137/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 138/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 139/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 140/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 141/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 142/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 143/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 144/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 145/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 146/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 147/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 148/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 149/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 150/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 151/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 152/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 153/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 154/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 155/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 156/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 157/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6428 - val_loss: 4.6829\n",
      "Epoch 158/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 159/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 160/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 161/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 162/300\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 163/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 164/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 165/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 166/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 167/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 168/300\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 169/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6428 - val_loss: 4.6829\n",
      "Epoch 170/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 171/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 172/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 173/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 174/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 175/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 176/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 177/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 178/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 179/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 180/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 181/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 182/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 183/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 184/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 185/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6438 - val_loss: 4.6829\n",
      "Epoch 186/300\n",
      "11944/11944 [==============================] - 1s 52us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 187/300\n",
      "11944/11944 [==============================] - 1s 65us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 188/300\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 189/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 190/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 191/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 192/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 193/300\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 194/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 195/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 196/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 197/300\n",
      "11944/11944 [==============================] - 1s 51us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 198/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 199/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 201/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 202/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 203/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 204/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 205/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 206/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 207/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 208/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 209/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 210/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 211/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 212/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 213/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 214/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 215/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 216/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 217/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 218/300\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 219/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6436 - val_loss: 4.6829\n",
      "Epoch 220/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 221/300\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 222/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 223/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 224/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 225/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 226/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 227/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 228/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 229/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 230/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6437 - val_loss: 4.6829\n",
      "Epoch 231/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 232/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 233/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 234/300\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 235/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 236/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 237/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 238/300\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 239/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 240/300\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 241/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 242/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6428 - val_loss: 4.6829\n",
      "Epoch 243/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 244/300\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 245/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 246/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 247/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 248/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 249/300\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 250/300\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 251/300\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 252/300\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 253/300\n",
      "11944/11944 [==============================] - ETA: 0s - loss: 4.643 - 1s 46us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 254/300\n",
      "11944/11944 [==============================] - 1s 50us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 255/300\n",
      "11944/11944 [==============================] - 1s 50us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 256/300\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 257/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 258/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 259/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 260/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 261/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 262/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 263/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6444 - val_loss: 4.6829\n",
      "Epoch 264/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 265/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 266/300\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 4.6429 - val_loss: 4.6829\n",
      "Epoch 267/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 268/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 269/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 270/300\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 271/300\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 272/300\n",
      "11944/11944 [==============================] - 1s 49us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 273/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 274/300\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 275/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 276/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 277/300\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 278/300\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 279/300\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 280/300\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 281/300\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 282/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 283/300\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 284/300\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 285/300\n",
      "11944/11944 [==============================] - 1s 49us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 286/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 287/300\n",
      "11944/11944 [==============================] - 1s 48us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 288/300\n",
      "11944/11944 [==============================] - 1s 53us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 289/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 290/300\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 291/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 292/300\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 293/300\n",
      "11944/11944 [==============================] - 1s 45us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 294/300\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 295/300\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 296/300\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 297/300\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 298/300\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 299/300\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "Epoch 300/300\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 4.6425 - val_loss: 4.6829\n",
      "oven\n",
      "********************\n",
      "Train on 11944 samples, validate on 1328 samples\n",
      "Epoch 1/250\n",
      "11944/11944 [==============================] - 1s 107us/step - loss: 31.5121 - val_loss: 13.9865\n",
      "Epoch 2/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 14.2261 - val_loss: 13.9116\n",
      "Epoch 3/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 14.0636 - val_loss: 13.9008\n",
      "Epoch 4/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 14.0172 - val_loss: 13.9008\n",
      "Epoch 5/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 14.0171 - val_loss: 13.9008\n",
      "Epoch 6/250\n",
      "11944/11944 [==============================] - 1s 49us/step - loss: 14.0120 - val_loss: 13.9008\n",
      "Epoch 7/250\n",
      "11944/11944 [==============================] - 1s 52us/step - loss: 14.0096 - val_loss: 13.9008\n",
      "Epoch 8/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 14.0019 - val_loss: 13.9008\n",
      "Epoch 9/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 14.0015 - val_loss: 13.9008\n",
      "Epoch 10/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.9959 - val_loss: 13.9008\n",
      "Epoch 11/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.9942 - val_loss: 13.9008\n",
      "Epoch 12/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.9890 - val_loss: 13.9008\n",
      "Epoch 13/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 13.9807 - val_loss: 13.9003\n",
      "Epoch 14/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.9618 - val_loss: 13.8940\n",
      "Epoch 15/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.9431 - val_loss: 13.8895\n",
      "Epoch 16/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 13.9329 - val_loss: 13.8674\n",
      "Epoch 17/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.9213 - val_loss: 13.8319\n",
      "Epoch 18/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 13.9143 - val_loss: 13.8700\n",
      "Epoch 19/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.8683 - val_loss: 13.8212\n",
      "Epoch 20/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.8265 - val_loss: 13.7959\n",
      "Epoch 21/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.8422 - val_loss: 13.7872\n",
      "Epoch 22/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.8183 - val_loss: 13.8095\n",
      "Epoch 23/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.7951 - val_loss: 13.8312\n",
      "Epoch 24/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.7860 - val_loss: 13.8131\n",
      "Epoch 25/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.7870 - val_loss: 13.7882\n",
      "Epoch 26/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.7816 - val_loss: 13.7446\n",
      "Epoch 27/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.7530 - val_loss: 13.7857\n",
      "Epoch 28/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.6898 - val_loss: 13.7190\n",
      "Epoch 29/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.6877 - val_loss: 13.7315\n",
      "Epoch 30/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.6845 - val_loss: 13.7882\n",
      "Epoch 31/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.6910 - val_loss: 13.8131\n",
      "Epoch 32/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.6917 - val_loss: 13.7240\n",
      "Epoch 33/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.6806 - val_loss: 13.7455\n",
      "Epoch 34/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 13.6858 - val_loss: 13.7138\n",
      "Epoch 35/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.6820 - val_loss: 13.7307\n",
      "Epoch 36/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 13.6438 - val_loss: 13.7832\n",
      "Epoch 37/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 13.6421 - val_loss: 13.7030\n",
      "Epoch 38/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 13.6676 - val_loss: 13.7093\n",
      "Epoch 39/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.6299 - val_loss: 13.6455\n",
      "Epoch 40/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.6041 - val_loss: 13.5039\n",
      "Epoch 41/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.5089 - val_loss: 13.3404\n",
      "Epoch 42/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.3840 - val_loss: 13.2785\n",
      "Epoch 43/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 13.2717 - val_loss: 13.2801\n",
      "Epoch 44/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.2005 - val_loss: 13.0713\n",
      "Epoch 45/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.0777 - val_loss: 13.1042\n",
      "Epoch 46/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 13.0657 - val_loss: 12.9711\n",
      "Epoch 47/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.9653 - val_loss: 12.8339\n",
      "Epoch 48/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 13.0055 - val_loss: 13.1219\n",
      "Epoch 49/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.9541 - val_loss: 12.7429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.9552 - val_loss: 12.7831\n",
      "Epoch 51/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.9497 - val_loss: 12.6925\n",
      "Epoch 52/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.8944 - val_loss: 12.7747\n",
      "Epoch 53/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.8249 - val_loss: 12.7852\n",
      "Epoch 54/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 12.8141 - val_loss: 12.6506\n",
      "Epoch 55/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.8837 - val_loss: 12.7168\n",
      "Epoch 56/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.8074 - val_loss: 12.6416\n",
      "Epoch 57/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.8168 - val_loss: 12.7386\n",
      "Epoch 58/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.7863 - val_loss: 12.7003\n",
      "Epoch 59/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.8050 - val_loss: 12.8725\n",
      "Epoch 60/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 12.7660 - val_loss: 12.6086\n",
      "Epoch 61/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.7882 - val_loss: 12.5785\n",
      "Epoch 62/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.8022 - val_loss: 12.7510\n",
      "Epoch 63/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.7464 - val_loss: 12.7530\n",
      "Epoch 64/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.7575 - val_loss: 12.6978\n",
      "Epoch 65/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.7615 - val_loss: 12.8067\n",
      "Epoch 66/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.7467 - val_loss: 12.6963\n",
      "Epoch 67/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6707 - val_loss: 12.7625\n",
      "Epoch 68/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.7309 - val_loss: 12.5924\n",
      "Epoch 69/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.6957 - val_loss: 12.7772\n",
      "Epoch 70/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.7050 - val_loss: 12.8257\n",
      "Epoch 71/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 12.7036 - val_loss: 12.6601\n",
      "Epoch 72/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.7176 - val_loss: 12.7733\n",
      "Epoch 73/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6881 - val_loss: 12.7169\n",
      "Epoch 74/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.6684 - val_loss: 12.5488\n",
      "Epoch 75/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6747 - val_loss: 12.6808\n",
      "Epoch 76/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.7079 - val_loss: 12.6078\n",
      "Epoch 77/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6890 - val_loss: 12.7136\n",
      "Epoch 78/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.6413 - val_loss: 12.7088\n",
      "Epoch 79/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6659 - val_loss: 12.5978\n",
      "Epoch 80/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6453 - val_loss: 12.5760\n",
      "Epoch 81/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 12.6497 - val_loss: 12.5169\n",
      "Epoch 82/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 12.6664 - val_loss: 12.5949\n",
      "Epoch 83/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.6338 - val_loss: 12.7030\n",
      "Epoch 84/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.6652 - val_loss: 12.4779\n",
      "Epoch 85/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.6097 - val_loss: 12.7184\n",
      "Epoch 86/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6194 - val_loss: 12.5778\n",
      "Epoch 87/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.6109 - val_loss: 12.6441\n",
      "Epoch 88/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6062 - val_loss: 12.6972\n",
      "Epoch 89/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5747 - val_loss: 12.5225\n",
      "Epoch 90/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5889 - val_loss: 12.5547\n",
      "Epoch 91/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5776 - val_loss: 12.5405\n",
      "Epoch 92/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.6528 - val_loss: 12.5725\n",
      "Epoch 93/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6270 - val_loss: 12.5242\n",
      "Epoch 94/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5752 - val_loss: 12.6251\n",
      "Epoch 95/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5943 - val_loss: 12.5271\n",
      "Epoch 96/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6203 - val_loss: 12.5167\n",
      "Epoch 97/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5910 - val_loss: 12.4628\n",
      "Epoch 98/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.6215 - val_loss: 12.5558\n",
      "Epoch 99/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.6019 - val_loss: 12.7064\n",
      "Epoch 100/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5696 - val_loss: 12.6304\n",
      "Epoch 101/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.6095 - val_loss: 12.6246\n",
      "Epoch 102/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.6123 - val_loss: 12.6307\n",
      "Epoch 103/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.5514 - val_loss: 12.4897\n",
      "Epoch 104/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.6087 - val_loss: 12.5664\n",
      "Epoch 105/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 12.5510 - val_loss: 12.5955\n",
      "Epoch 106/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.5782 - val_loss: 12.4835\n",
      "Epoch 107/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5814 - val_loss: 12.5129\n",
      "Epoch 108/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5539 - val_loss: 12.5586\n",
      "Epoch 109/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5573 - val_loss: 12.5938\n",
      "Epoch 110/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5803 - val_loss: 12.5051\n",
      "Epoch 111/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.5645 - val_loss: 12.6412\n",
      "Epoch 112/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5837 - val_loss: 12.4187\n",
      "Epoch 113/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5578 - val_loss: 12.6678\n",
      "Epoch 114/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5713 - val_loss: 12.5074\n",
      "Epoch 115/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5413 - val_loss: 12.5422\n",
      "Epoch 116/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5308 - val_loss: 12.5359\n",
      "Epoch 117/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5373 - val_loss: 12.6313\n",
      "Epoch 118/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5302 - val_loss: 12.5810\n",
      "Epoch 119/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5503 - val_loss: 12.5917\n",
      "Epoch 120/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.6019 - val_loss: 12.4765\n",
      "Epoch 121/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5259 - val_loss: 12.4838\n",
      "Epoch 122/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5410 - val_loss: 12.4921\n",
      "Epoch 123/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5484 - val_loss: 12.5219\n",
      "Epoch 124/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.4906 - val_loss: 12.5296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.5344 - val_loss: 12.5171\n",
      "Epoch 126/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5255 - val_loss: 12.4303\n",
      "Epoch 127/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.4819 - val_loss: 12.5137\n",
      "Epoch 128/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5232 - val_loss: 12.4868\n",
      "Epoch 129/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5429 - val_loss: 12.5178\n",
      "Epoch 130/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5081 - val_loss: 12.5026\n",
      "Epoch 131/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5295 - val_loss: 12.5593\n",
      "Epoch 132/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5542 - val_loss: 12.5828\n",
      "Epoch 133/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5019 - val_loss: 12.4928\n",
      "Epoch 134/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.4979 - val_loss: 12.4882\n",
      "Epoch 135/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5106 - val_loss: 12.5260\n",
      "Epoch 136/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5371 - val_loss: 12.4888\n",
      "Epoch 137/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.5618 - val_loss: 12.4897\n",
      "Epoch 138/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5297 - val_loss: 12.4184\n",
      "Epoch 139/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.4939 - val_loss: 12.5377\n",
      "Epoch 140/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.5252 - val_loss: 12.4231\n",
      "Epoch 141/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 12.4925 - val_loss: 12.4760\n",
      "Epoch 142/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.4797 - val_loss: 12.6673\n",
      "Epoch 143/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.4625 - val_loss: 12.5270\n",
      "Epoch 144/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 12.4690 - val_loss: 12.6659\n",
      "Epoch 145/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.4722 - val_loss: 12.4424\n",
      "Epoch 146/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.5124 - val_loss: 12.4652\n",
      "Epoch 147/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.4596 - val_loss: 12.4605\n",
      "Epoch 148/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 12.5030 - val_loss: 12.4998\n",
      "Epoch 149/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.5496 - val_loss: 12.5256\n",
      "Epoch 150/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.4763 - val_loss: 12.6077\n",
      "Epoch 151/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 12.4788 - val_loss: 12.5435\n",
      "Epoch 152/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.4712 - val_loss: 12.5354\n",
      "Epoch 153/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 12.5412 - val_loss: 12.4565\n",
      "Epoch 154/250\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 12.4735 - val_loss: 12.5101\n",
      "Epoch 155/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 12.4494 - val_loss: 12.4894\n",
      "Epoch 156/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 12.5045 - val_loss: 12.5297\n",
      "Epoch 157/250\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 12.5620 - val_loss: 12.4863\n",
      "Epoch 158/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 12.4884 - val_loss: 12.6262\n",
      "Epoch 159/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 12.5018 - val_loss: 12.4356\n",
      "Epoch 160/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.4864 - val_loss: 12.5834\n",
      "Epoch 161/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 12.4998 - val_loss: 12.4681\n",
      "Epoch 162/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.4897 - val_loss: 12.5092\n",
      "Epoch 163/250\n",
      "11944/11944 [==============================] - 1s 43us/step - loss: 12.4691 - val_loss: 12.5079\n",
      "Epoch 164/250\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 12.5278 - val_loss: 12.4728\n",
      "Epoch 165/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.4770 - val_loss: 12.5910\n",
      "Epoch 166/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.4728 - val_loss: 12.5253\n",
      "Epoch 167/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.4786 - val_loss: 12.4771\n",
      "Epoch 168/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.4125 - val_loss: 12.5120\n",
      "Epoch 169/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 12.4428 - val_loss: 12.4653\n",
      "Epoch 170/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 12.4193 - val_loss: 12.5039\n",
      "Epoch 171/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 12.4035 - val_loss: 12.5287\n",
      "Epoch 172/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.4224 - val_loss: 12.4789\n",
      "Epoch 173/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.3941 - val_loss: 12.4937\n",
      "Epoch 174/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.3557 - val_loss: 12.4772\n",
      "Epoch 175/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.3791 - val_loss: 12.5051\n",
      "Epoch 176/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3433 - val_loss: 12.4318\n",
      "Epoch 177/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 12.4249 - val_loss: 12.4972\n",
      "Epoch 178/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3827 - val_loss: 12.4955\n",
      "Epoch 179/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 12.4053 - val_loss: 12.4529\n",
      "Epoch 180/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.3951 - val_loss: 12.5217\n",
      "Epoch 181/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 12.3844 - val_loss: 12.4956\n",
      "Epoch 182/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.4325 - val_loss: 12.4919\n",
      "Epoch 183/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 12.4395 - val_loss: 12.3870\n",
      "Epoch 184/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3350 - val_loss: 12.4848\n",
      "Epoch 185/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.3665 - val_loss: 12.3913\n",
      "Epoch 186/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.4099 - val_loss: 12.3908\n",
      "Epoch 187/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.4001 - val_loss: 12.4483\n",
      "Epoch 188/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.4186 - val_loss: 12.6303\n",
      "Epoch 189/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.4082 - val_loss: 12.5756\n",
      "Epoch 190/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3766 - val_loss: 12.6046\n",
      "Epoch 191/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3655 - val_loss: 12.4648\n",
      "Epoch 192/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.3822 - val_loss: 12.4220\n",
      "Epoch 193/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3749 - val_loss: 12.4310\n",
      "Epoch 194/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3583 - val_loss: 12.4242\n",
      "Epoch 195/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.3564 - val_loss: 12.5685\n",
      "Epoch 196/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3810 - val_loss: 12.4390\n",
      "Epoch 197/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.3263 - val_loss: 12.4916\n",
      "Epoch 198/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3779 - val_loss: 12.4681\n",
      "Epoch 199/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.3492 - val_loss: 12.4186\n",
      "Epoch 200/250\n",
      "11944/11944 [==============================] - 0s 41us/step - loss: 12.3284 - val_loss: 12.6186\n",
      "Epoch 201/250\n",
      "11944/11944 [==============================] - 0s 42us/step - loss: 12.4010 - val_loss: 12.5512\n",
      "Epoch 202/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.3764 - val_loss: 12.4849\n",
      "Epoch 203/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.4159 - val_loss: 12.5876\n",
      "Epoch 204/250\n",
      "11944/11944 [==============================] - 1s 44us/step - loss: 12.3806 - val_loss: 12.4222\n",
      "Epoch 205/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.3134 - val_loss: 12.5427\n",
      "Epoch 206/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.3527 - val_loss: 12.5000\n",
      "Epoch 207/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 12.3556 - val_loss: 12.5166\n",
      "Epoch 208/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.4129 - val_loss: 12.5080\n",
      "Epoch 209/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.3394 - val_loss: 12.5385\n",
      "Epoch 210/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.3679 - val_loss: 12.5227\n",
      "Epoch 211/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.3526 - val_loss: 12.5893\n",
      "Epoch 212/250\n",
      "11944/11944 [==============================] - 1s 47us/step - loss: 12.3522 - val_loss: 12.4657\n",
      "Epoch 213/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.3052 - val_loss: 12.4824\n",
      "Epoch 214/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.3650 - val_loss: 12.4724\n",
      "Epoch 215/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3789 - val_loss: 12.4929\n",
      "Epoch 216/250\n",
      "11944/11944 [==============================] - 0s 40us/step - loss: 12.3705 - val_loss: 12.5439\n",
      "Epoch 217/250\n",
      "11944/11944 [==============================] - 0s 39us/step - loss: 12.4027 - val_loss: 12.4292\n",
      "Epoch 218/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.3593 - val_loss: 12.6154\n",
      "Epoch 219/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.3704 - val_loss: 12.5971\n",
      "Epoch 220/250\n",
      "11944/11944 [==============================] - 1s 51us/step - loss: 12.3820 - val_loss: 12.4926\n",
      "Epoch 221/250\n",
      "11944/11944 [==============================] - 1s 42us/step - loss: 12.3409 - val_loss: 12.5491\n",
      "Epoch 222/250\n",
      "11944/11944 [==============================] - 1s 51us/step - loss: 12.3427 - val_loss: 12.4920\n",
      "Epoch 223/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.2959 - val_loss: 12.5621\n",
      "Epoch 224/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.3189 - val_loss: 12.4641\n",
      "Epoch 225/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.3457 - val_loss: 12.4769\n",
      "Epoch 226/250\n",
      "11944/11944 [==============================] - 0s 37us/step - loss: 12.3656 - val_loss: 12.5004\n",
      "Epoch 227/250\n",
      "11944/11944 [==============================] - 1s 46us/step - loss: 12.3514 - val_loss: 12.4491\n",
      "Epoch 228/250\n",
      "11944/11944 [==============================] - 0s 38us/step - loss: 12.3648 - val_loss: 12.4879\n",
      "Epoch 229/250\n",
      "11944/11944 [==============================] - 0s 36us/step - loss: 12.3286 - val_loss: 12.5619\n",
      "Epoch 230/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3684 - val_loss: 12.4426\n",
      "Epoch 231/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.3952 - val_loss: 12.3886\n",
      "Epoch 232/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3064 - val_loss: 12.5376\n",
      "Epoch 233/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3324 - val_loss: 12.4303\n",
      "Epoch 234/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3080 - val_loss: 12.5975\n",
      "Epoch 235/250\n",
      "11944/11944 [==============================] - 0s 33us/step - loss: 12.3945 - val_loss: 12.5057\n",
      "Epoch 236/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3294 - val_loss: 12.5583\n",
      "Epoch 237/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3222 - val_loss: 12.4468\n",
      "Epoch 238/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3067 - val_loss: 12.4396\n",
      "Epoch 239/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3381 - val_loss: 12.4717\n",
      "Epoch 240/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.3491 - val_loss: 12.4575\n",
      "Epoch 241/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3787 - val_loss: 12.4352\n",
      "Epoch 242/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3508 - val_loss: 12.4568\n",
      "Epoch 243/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.2695 - val_loss: 12.4799\n",
      "Epoch 244/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3537 - val_loss: 12.4652\n",
      "Epoch 245/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3353 - val_loss: 12.4573\n",
      "Epoch 246/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3447 - val_loss: 12.4257\n",
      "Epoch 247/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3267 - val_loss: 12.5793\n",
      "Epoch 248/250\n",
      "11944/11944 [==============================] - 0s 35us/step - loss: 12.3634 - val_loss: 12.5359\n",
      "Epoch 249/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.2778 - val_loss: 12.4598\n",
      "Epoch 250/250\n",
      "11944/11944 [==============================] - 0s 34us/step - loss: 12.3129 - val_loss: 12.4506\n"
     ]
    }
   ],
   "source": [
    "pred_appliance = {}\n",
    "num_iterations_dictionary = {'hvac':900,'fridge':400,'mw':250,'dw':250,'oven':250, 'wm':300}\n",
    "for appliance in APPLIANCES_ORDER[1:]:\n",
    "    print(appliance)\n",
    "    print(\"*\"*20)\n",
    "    np.random.seed(0)\n",
    "    from keras.layers.merge import Subtract, Minimum\n",
    "    from keras import regularizers\n",
    "    agg_input = keras.layers.Input(shape=[24],name='Aggregate')\n",
    "    appliance_dense_1 = keras.layers.Dense(units=20,name='Appliance-layer-1',activation='relu')(agg_input)\n",
    "    #appliance_bn = keras.layers.BatchNormalization()(appliance_dense_1)\n",
    "    dropout = keras.layers.Dropout(rate=0.1,name='Droput-Appliance')(appliance_dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = keras.layers.Dense(units=24,name='Appliance-output',activation='relu')(dropout)\n",
    "    out = Minimum(name='Clip-to-agg')([out, agg_input])\n",
    "\n",
    "\n",
    "    model = keras.Model(agg_input, out)\n",
    "    model.compile('adam','mean_absolute_error')\n",
    "    model.fit(train_agg, train_appliance[appliance], epochs=num_iterations_dictionary[appliance], validation_split=0.1)\n",
    "    pred_appliance[appliance] = model.predict(test_agg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('per-appliance.pdf','wb') as f:\n",
    "    f.write(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='pdf'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Aggregate (InputLayer)          (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Appliance-layer-1 (Dense)       (None, 20)           500         Aggregate[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Droput-Appliance (Dropout)      (None, 20)           0           Appliance-layer-1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Appliance-output (Dense)        (None, 24)           504         Droput-Appliance[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Clip-to-agg (Minimum)           (None, 24)           0           Appliance-output[0][0]           \n",
      "                                                                 Aggregate[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,004\n",
      "Trainable params: 1,004\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = {}\n",
    "for appliance in APPLIANCES_ORDER[1:]:\n",
    "    try:\n",
    "        mae[appliance] = mean_absolute_error(test_appliance[appliance], pred_appliance[appliance])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dw         14.499116\n",
       "fridge     44.341256\n",
       "hvac      146.353407\n",
       "mw          6.300214\n",
       "oven       21.165846\n",
       "wm          5.617521\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2000)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsIRARESDJQQiIhrsvwFvDG/XxfdJYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3276d9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(pred_appliance['oven']).T.plot(legend=False, color='k',alpha=0.2)\n",
    "plt.title(\"Predicted Oven [Indivial appliance DNN]\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "plt.ylim((0, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 24)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_hvac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963.700018687\n",
      "36.514444202\n"
     ]
    }
   ],
   "source": [
    "pred_hvac = model.predict(test_agg)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(pred_hvac, test_fridge))\n",
    "print(mean_absolute_error(pred_hvac, test_agg))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.000061\n",
       "1     0.000060\n",
       "2     0.000058\n",
       "3     0.000058\n",
       "4     0.000079\n",
       "5     0.000116\n",
       "6     0.000062\n",
       "7    -7.088656\n",
       "8     0.000038\n",
       "9     0.000054\n",
       "10    0.000099\n",
       "11    0.000114\n",
       "12    0.000116\n",
       "13    0.000116\n",
       "14    0.000242\n",
       "15    0.000233\n",
       "16    0.000221\n",
       "17    0.000226\n",
       "18    0.000233\n",
       "19    0.000233\n",
       "20    0.000221\n",
       "21    0.000099\n",
       "22    0.000094\n",
       "23    0.000115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(pred_hvac) - pd.DataFrame(test_agg)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  352.51669312,   340.69998169,   359.05001831, ...,\n",
       "          334.5166626 ,   290.18334961,    43.63333511],\n",
       "       [  307.41827393,    79.71666718,     0.        , ...,\n",
       "          538.0166626 ,   184.31666565,   338.09088135],\n",
       "       [   71.69999695,    86.25      ,   354.18331909, ...,\n",
       "          539.9833374 ,   657.95001221,   390.2666626 ],\n",
       "       ..., \n",
       "       [  889.60003662,   882.86669922,   487.75      , ...,\n",
       "          808.75      ,   904.4666748 ,  1699.83776855],\n",
       "       [ 1292.09997559,  1368.68334961,  1103.33337402, ...,\n",
       "          852.31671143,  1971.55493164,  1216.26672363],\n",
       "       [ 1143.51672363,  1097.15002441,   831.14996338, ...,\n",
       "          941.18334961,  2303.64990234,  1493.20007324]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_appliance['hvac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a407a37b8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nySnoRUSSU9CLiCSnoBcRSe4LPTdDdq83zIEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a401c0898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(test_fridge[1, :]).plot(label='GT')\n",
    "#pd.Series(test_agg[1, :]).plot(label='GT')\n",
    "\n",
    "\n",
    "pd.Series(pred_appliance['fridge'][1]).plot(label='Pred')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
