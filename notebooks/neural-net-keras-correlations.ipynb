{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "from common import APPLIANCES_ORDER\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor = np.load('../1H-input.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_subset_dataset(tensor):\n",
    "    t_subset = tensor[:, :, 180:194, :]\n",
    "    all_indices = np.array(list(range(320)))\n",
    "    for i in range(1, 7):\n",
    "        valid_homes = pd.DataFrame(t_subset[:, i, :].reshape(320, 14*24)).dropna().index\n",
    "        all_indices = np.intersect1d(all_indices, valid_homes)\n",
    "    t_subset = t_subset[all_indices, :, :, :].reshape(52, 7, 14*24)\n",
    "    \n",
    "    # Create artificial aggregate\n",
    "    t_subset[:, 0, :] = 0.0\n",
    "    for i in range(1, 7):\n",
    "        t_subset[:, 0, :] = t_subset[:, 0, :] + t_subset[:, i, :]\n",
    "    # t_subset is of shape (#home, appliance, days*hours)\n",
    "    return t_subset, all_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 7, 336)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all, valid_homes = create_subset_dataset(tensor)\n",
    "t_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 7, 336)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_objective(y_pred, y_true):\n",
    "    with tf.name_scope(None):\n",
    "        return tf.losses.absolute_difference(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/nipun/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "n_movies = 3\n",
    "n_users=3\n",
    "n_latent_factors=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggregate', 'hvac', 'fridge', 'mw', 'dw', 'wm', 'oven']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPLIANCES_ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_agg = t_all[:30, 0, :].reshape(30*14, 24)\n",
    "train_appliance = {}\n",
    "test_appliance = {}\n",
    "for appliance_num, appliance in enumerate(APPLIANCES_ORDER[1:]):\n",
    "    train_appliance[appliance] = t_all[:30, appliance_num+1, :].reshape(30*14, 24)\n",
    "    test_appliance[appliance] = t_all[30:, appliance_num+1, :].reshape(22*14, 24)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_hvac = t_all[30:, 1, :].reshape(22*14, 24)\n",
    "test_fridge = t_all[30:, 2, :].reshape(22*14, 24)\n",
    "\n",
    "test_mw = t_all[30:, 3, :].reshape(22*14, 24)\n",
    "\n",
    "\n",
    "\n",
    "test_agg = t_all[30:, 0, :].reshape(22*14, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oven\n",
      "********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nipun/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/nipun/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"458pt\" viewBox=\"0.00 0.00 609.76 458.00\" width=\"610pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 454)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-454 605.756,-454 605.756,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 112661724072 -->\n",
       "<g class=\"node\" id=\"node1\"><title>112661724072</title>\n",
       "<polygon fill=\"none\" points=\"325.552,-405.5 325.552,-449.5 601.756,-449.5 601.756,-405.5 325.552,-405.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.495\" y=\"-423.3\">Aggregate: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"469.438,-405.5 469.438,-449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497.273\" y=\"-434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"469.438,-427.5 525.107,-427.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497.273\" y=\"-412.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"525.107,-405.5 525.107,-449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"563.432\" y=\"-434.3\">(None, 24)</text>\n",
       "<polyline fill=\"none\" points=\"525.107,-427.5 601.756,-427.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"563.432\" y=\"-412.3\">(None, 24)</text>\n",
       "</g>\n",
       "<!-- 112661724688 -->\n",
       "<g class=\"node\" id=\"node3\"><title>112661724688</title>\n",
       "<polygon fill=\"none\" points=\"127.34,-324.5 127.34,-368.5 435.967,-368.5 435.967,-324.5 127.34,-324.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177.009\" y=\"-342.3\">Concat: Merge</text>\n",
       "<polyline fill=\"none\" points=\"226.677,-324.5 226.677,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254.512\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"226.677,-346.5 282.346,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254.512\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"282.346,-324.5 282.346,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.157\" y=\"-353.3\">[(None, 24), (None, 24)]</text>\n",
       "<polyline fill=\"none\" points=\"282.346,-346.5 435.967,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"358.67\" y=\"-331.3\">(None, 48)</text>\n",
       "</g>\n",
       "<!-- 112661724072&#45;&gt;112661724688 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>112661724072-&gt;112661724688</title>\n",
       "<path d=\"M414.881,-405.329C391.735,-395.283 363.906,-383.203 339.682,-372.688\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"340.812,-369.363 330.245,-368.592 338.025,-375.784 340.812,-369.363\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 112661723848 -->\n",
       "<g class=\"node\" id=\"node7\"><title>112661723848</title>\n",
       "<polygon fill=\"none\" points=\"199.038,-0.5 199.038,-44.5 552.27,-44.5 552.27,-0.5 199.038,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.009\" y=\"-18.3\">Clip-to-agg: Minimum</text>\n",
       "<polyline fill=\"none\" points=\"342.979,-0.5 342.979,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"370.814\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"342.979,-22.5 398.648,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"370.814\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"398.648,-0.5 398.648,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"475.459\" y=\"-29.3\">[(None, 24), (None, 24)]</text>\n",
       "<polyline fill=\"none\" points=\"398.648,-22.5 552.27,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"474.973\" y=\"-7.3\">(None, 24)</text>\n",
       "</g>\n",
       "<!-- 112661724072&#45;&gt;112661723848 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>112661724072-&gt;112661723848</title>\n",
       "<path d=\"M463.654,-405.277C463.654,-374.636 463.654,-316.222 463.654,-266.5 463.654,-266.5 463.654,-266.5 463.654,-183.5 463.654,-136.812 464.403,-121.197 440.654,-81 434.062,-69.8434 424.563,-59.693 414.854,-51.1321\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"416.988,-48.3542 407.074,-44.6182 412.494,-53.7214 416.988,-48.3542\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 112661724128 -->\n",
       "<g class=\"node\" id=\"node2\"><title>112661724128</title>\n",
       "<polygon fill=\"none\" points=\"0,-405.5 0,-449.5 307.308,-449.5 307.308,-405.5 0,-405.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"87.4951\" y=\"-423.3\">OtherAppliance: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"174.99,-405.5 174.99,-449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.825\" y=\"-434.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"174.99,-427.5 230.659,-427.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.825\" y=\"-412.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"230.659,-405.5 230.659,-449.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268.983\" y=\"-434.3\">(None, 24)</text>\n",
       "<polyline fill=\"none\" points=\"230.659,-427.5 307.308,-427.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268.983\" y=\"-412.3\">(None, 24)</text>\n",
       "</g>\n",
       "<!-- 112661724128&#45;&gt;112661724688 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>112661724128-&gt;112661724688</title>\n",
       "<path d=\"M187.955,-405.329C203.451,-395.766 221.931,-384.36 238.368,-374.215\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"240.586,-376.96 247.257,-368.729 236.909,-371.003 240.586,-376.96\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 112661724184 -->\n",
       "<g class=\"node\" id=\"node4\"><title>112661724184</title>\n",
       "<polygon fill=\"none\" points=\"136.526,-243.5 136.526,-287.5 428.781,-287.5 428.781,-243.5 136.526,-243.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216.495\" y=\"-261.3\">Appliance-layer-1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"296.464,-243.5 296.464,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.298\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"296.464,-265.5 352.133,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.298\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"352.133,-243.5 352.133,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390.457\" y=\"-272.3\">(None, 48)</text>\n",
       "<polyline fill=\"none\" points=\"352.133,-265.5 428.781,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390.457\" y=\"-250.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 112661724688&#45;&gt;112661724184 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>112661724688-&gt;112661724184</title>\n",
       "<path d=\"M281.922,-324.329C282.025,-316.183 282.145,-306.699 282.258,-297.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"285.758,-297.773 282.385,-287.729 278.759,-297.684 285.758,-297.773\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 112661724296 -->\n",
       "<g class=\"node\" id=\"node5\"><title>112661724296</title>\n",
       "<polygon fill=\"none\" points=\"131.542,-162.5 131.542,-206.5 435.766,-206.5 435.766,-162.5 131.542,-162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.495\" y=\"-180.3\">Droput-Appliance: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"303.449,-162.5 303.449,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"331.283\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"303.449,-184.5 359.118,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"331.283\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"359.118,-162.5 359.118,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.442\" y=\"-191.3\">(None, 20)</text>\n",
       "<polyline fill=\"none\" points=\"359.118,-184.5 435.766,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.442\" y=\"-169.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 112661724184&#45;&gt;112661724296 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>112661724184-&gt;112661724296</title>\n",
       "<path d=\"M282.922,-243.329C283.025,-235.183 283.145,-225.699 283.258,-216.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"286.758,-216.773 283.385,-206.729 279.759,-216.684 286.758,-216.773\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 112661725136 -->\n",
       "<g class=\"node\" id=\"node6\"><title>112661725136</title>\n",
       "<polygon fill=\"none\" points=\"143.321,-81.5 143.321,-125.5 431.987,-125.5 431.987,-81.5 143.321,-81.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.495\" y=\"-99.3\">Appliance-output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"299.669,-81.5 299.669,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327.504\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"299.669,-103.5 355.338,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327.504\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"355.338,-81.5 355.338,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393.663\" y=\"-110.3\">(None, 20)</text>\n",
       "<polyline fill=\"none\" points=\"355.338,-103.5 431.987,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393.663\" y=\"-88.3\">(None, 24)</text>\n",
       "</g>\n",
       "<!-- 112661724296&#45;&gt;112661725136 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>112661724296-&gt;112661725136</title>\n",
       "<path d=\"M284.726,-162.329C285.138,-154.183 285.618,-144.699 286.069,-135.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"289.569,-135.893 286.579,-125.729 282.578,-135.539 289.569,-135.893\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 112661725136&#45;&gt;112661723848 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>112661725136-&gt;112661723848</title>\n",
       "<path d=\"M311.236,-81.3294C321.396,-72.2085 333.422,-61.4122 344.317,-51.6322\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"346.903,-54.0138 352.006,-44.729 342.227,-48.8048 346.903,-54.0138\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(appliance)\n",
    "print(\"*\"*20)\n",
    "np.random.seed(0)\n",
    "from keras.layers.merge import Subtract, Minimum, Concatenate\n",
    "from keras import regularizers\n",
    "agg_input = keras.layers.Input(shape=[24],name='Aggregate')\n",
    "\n",
    "appliance_input = keras.layers.Input(shape=[24],name='OtherAppliance')\n",
    "\n",
    "concat = keras.layers.merge([agg_input, appliance_input], mode='concat',name='Concat')\n",
    "appliance_dense_1 = keras.layers.Dense(units=20,name='Appliance-layer-1',activation='relu')(concat)\n",
    "#appliance_batch = keras.layers.BatchNormalization()(appliance_dense_1)\n",
    "\n",
    "\n",
    "dropout = keras.layers.Dropout(rate=0.3,name='Droput-Appliance')(appliance_dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = keras.layers.Dense(units=24,name='Appliance-output',activation='relu')(dropout)\n",
    "out = Minimum(name='Clip-to-agg')([out, agg_input])\n",
    "\n",
    "\n",
    "model = keras.Model([agg_input,appliance_input], out)\n",
    "SVG(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvac fridge\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 205.1245 - val_loss: 150.7324\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 138.9586 - val_loss: 124.0574\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 115.4814 - val_loss: 110.7931\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 100.1590 - val_loss: 104.0491\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 90.7163 - val_loss: 99.0927\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 85.3656 - val_loss: 96.4105\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 83.2403 - val_loss: 95.1660\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 82.1400 - val_loss: 95.0346\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 81.4671 - val_loss: 94.9945\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 80.3306 - val_loss: 94.2974\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 81.8548 - val_loss: 93.7057\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 80.1370 - val_loss: 93.8676\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 85.35 - 0s 60us/step - loss: 79.5735 - val_loss: 93.0302\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 80.4805 - val_loss: 92.5503\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 78.7663 - val_loss: 91.4137\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 78.8068 - val_loss: 90.8005\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 77.74 - 0s 59us/step - loss: 77.7073 - val_loss: 91.0942\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 77.5614 - val_loss: 90.6310\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 73.20 - 0s 61us/step - loss: 74.9803 - val_loss: 90.4032\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 74.7548 - val_loss: 88.7923\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 73.3329 - val_loss: 87.6081\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 72.4953 - val_loss: 87.2926\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 71.4275 - val_loss: 85.8904\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 70.1359 - val_loss: 84.8200\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 69.1910 - val_loss: 84.4412\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 67.2266 - val_loss: 82.5680\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 66.1862 - val_loss: 81.3174\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 65.2541 - val_loss: 81.3568\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 65.4083 - val_loss: 81.1615\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 62.9136 - val_loss: 78.9361\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 62.3565 - val_loss: 78.1103\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 61.6129 - val_loss: 76.1309\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 62.8698 - val_loss: 75.1984\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 60.5060 - val_loss: 73.2638\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 58.2618 - val_loss: 74.2373\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 59.3209 - val_loss: 72.0370\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 57.2814 - val_loss: 73.1033\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 55.4729 - val_loss: 69.0061\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 55.4817 - val_loss: 69.4102\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 52.4269 - val_loss: 65.4029\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 52.2296 - val_loss: 64.0610\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 51.0665 - val_loss: 64.9355\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 51.7736 - val_loss: 61.4099\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 49.2740 - val_loss: 64.8618\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 51.0336 - val_loss: 58.4893\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 50.6186 - val_loss: 62.2019\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 48.4640 - val_loss: 61.4592\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 49.3480 - val_loss: 58.0547\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.9600 - val_loss: 57.7059\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 47.4482 - val_loss: 54.9261\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 45.8357 - val_loss: 55.2507\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 46.2350 - val_loss: 53.5426\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 43.8382 - val_loss: 50.9836\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 44.3931 - val_loss: 52.2106\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 45.1866 - val_loss: 47.8667\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 46.3885 - val_loss: 52.4053\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 44.4978 - val_loss: 49.0603\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 43.9428 - val_loss: 49.9238\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 46.3224 - val_loss: 49.3460\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 43.7200 - val_loss: 49.5030\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 44.2264 - val_loss: 48.7438\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 43.6042 - val_loss: 47.8121\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 40.8749 - val_loss: 45.0582\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 44.3503 - val_loss: 47.5379\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 42.2870 - val_loss: 45.0411\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 42.1273 - val_loss: 50.8542\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 39.1774 - val_loss: 43.6506\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 41.1814 - val_loss: 48.1060\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 40.8877 - val_loss: 44.4981\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 41.0591 - val_loss: 48.7596\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 40.0533 - val_loss: 42.6458\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 40.0510 - val_loss: 48.6262\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 39.5423 - val_loss: 43.7837\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 41.3085 - val_loss: 46.6426\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 37.9075 - val_loss: 45.8473\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 37.7217 - val_loss: 45.2738\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 39.6876 - val_loss: 44.4609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 39.2219 - val_loss: 43.7275\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 38.5748 - val_loss: 45.6668\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 37.6065 - val_loss: 46.1802\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 39.9059 - val_loss: 45.1521\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 39.4404 - val_loss: 41.0128\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 38.3555 - val_loss: 44.5764\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 37.3976 - val_loss: 41.2310\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 38.7269 - val_loss: 43.4175\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 37.0919 - val_loss: 41.4270\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 36.7543 - val_loss: 43.7176\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 37.7252 - val_loss: 43.9027\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 37.0464 - val_loss: 41.6699\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 37.1363 - val_loss: 41.9901\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 37.0945 - val_loss: 42.0119\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 35.7499 - val_loss: 42.4786\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 38.0896 - val_loss: 37.4063\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 38.0702 - val_loss: 42.5020\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 37.6405 - val_loss: 43.3020\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 35.8308 - val_loss: 39.0070\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 35.8556 - val_loss: 40.3026\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 38.1484 - val_loss: 40.9179\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 36.4293 - val_loss: 41.7230\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 34.6537 - val_loss: 38.5510\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 37.9830 - val_loss: 42.4633\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 35.9345 - val_loss: 38.4538\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 36.1155 - val_loss: 37.8189\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 36.1728 - val_loss: 38.7804\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 36.1990 - val_loss: 38.1869\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 36.6514 - val_loss: 37.3649\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 36.2195 - val_loss: 39.9264\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 35.7267 - val_loss: 37.0870\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 34.5967 - val_loss: 40.8222\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 36.1652 - val_loss: 40.7069\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 37.3828 - val_loss: 35.7722\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 36.1762 - val_loss: 38.9483\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 39.1475 - val_loss: 37.3818\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 35.9350 - val_loss: 38.0949\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 36.1341 - val_loss: 41.1647\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 35.2362 - val_loss: 39.5225\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 34.6142 - val_loss: 39.9166\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 34.2198 - val_loss: 36.8299\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 36.5293 - val_loss: 41.7901\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 35.1403 - val_loss: 37.3028\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 34.9699 - val_loss: 40.8584\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 34.1206 - val_loss: 36.1330\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 33.4994 - val_loss: 38.3383\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 33.3527 - val_loss: 37.9471\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 35.7251 - val_loss: 36.8238\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 33.3111 - val_loss: 36.1625\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 33.8303 - val_loss: 40.8496\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 35.9884 - val_loss: 36.0301\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 35.4817 - val_loss: 39.3522\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 35.1760 - val_loss: 37.1656\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 34.8362 - val_loss: 36.4173\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 33.4562 - val_loss: 40.6851\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 33.7685 - val_loss: 35.6974\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 33.9964 - val_loss: 35.6853\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 34.7958 - val_loss: 38.0220\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 33.2558 - val_loss: 34.0358\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 87us/step - loss: 35.6053 - val_loss: 36.8136\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 33.2869 - val_loss: 37.8032\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 33.0849 - val_loss: 38.4019\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 34.6097 - val_loss: 38.4761\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 34.2733 - val_loss: 34.9801\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 35.3073 - val_loss: 37.7544\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 32.5241 - val_loss: 36.3384\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 33.9010 - val_loss: 38.6717\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 31.29 - 0s 64us/step - loss: 33.5558 - val_loss: 37.1202\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 36.8060 - val_loss: 37.7475\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 33.6205 - val_loss: 37.4534\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 34.8922 - val_loss: 35.3450\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 33.8174 - val_loss: 33.8589\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 33.0649 - val_loss: 38.3131\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 34.7600 - val_loss: 34.6797\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 35.7039 - val_loss: 36.7783\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 34.0061 - val_loss: 36.8640\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 34.5650 - val_loss: 35.4716\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 80us/step - loss: 33.1221 - val_loss: 38.6400\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 33.8878 - val_loss: 36.6033\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 33.0058 - val_loss: 37.1039\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 33.8049 - val_loss: 35.4381\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 33.4228 - val_loss: 37.0247\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 33.9400 - val_loss: 36.9076\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 33.4725 - val_loss: 34.7024\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 32.4608 - val_loss: 35.7385\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 32.4950 - val_loss: 35.1903\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 32.9529 - val_loss: 34.6377\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 34.8400 - val_loss: 37.9395\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 32.3579 - val_loss: 36.3402\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 33.8049 - val_loss: 36.9861\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 33.4665 - val_loss: 37.1698\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 33.2330 - val_loss: 34.9351\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 32.7887 - val_loss: 35.5125\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 33.4476 - val_loss: 36.4813\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 32.5763 - val_loss: 38.4016\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 30.9779 - val_loss: 34.6920\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 33.5604 - val_loss: 37.0690\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 31.9648 - val_loss: 34.9952\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 32.2050 - val_loss: 34.7314\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 32.5639 - val_loss: 36.7129\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 32.0993 - val_loss: 38.0904\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 34.1802 - val_loss: 35.3946\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 32.7675 - val_loss: 35.0670\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 33.0704 - val_loss: 35.6085\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 33.0854 - val_loss: 36.8804\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 31.8989 - val_loss: 35.7322\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 31.6920 - val_loss: 35.6720\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 32.0720 - val_loss: 35.2940\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 33.1582 - val_loss: 38.7079\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 35.3513 - val_loss: 36.0536\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 34.1881 - val_loss: 34.3313\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 32.1750 - val_loss: 34.8764\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 32.9508 - val_loss: 37.0756\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 31.6091 - val_loss: 33.3071\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 32.2036 - val_loss: 34.7882\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 32.9806 - val_loss: 34.5796\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 31.9245 - val_loss: 35.3134\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 32.8779 - val_loss: 32.3166\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 31.9227 - val_loss: 36.7153\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 32.4266 - val_loss: 36.2945\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 31.5947 - val_loss: 35.6980\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 31.3414 - val_loss: 33.8193\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 33.4049 - val_loss: 36.1405\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 31.9609 - val_loss: 34.0561\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 33.3837 - val_loss: 35.1067\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 34.3136 - val_loss: 36.6650\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 30.5813 - val_loss: 33.8506\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 32.0212 - val_loss: 34.4212\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 31.7721 - val_loss: 35.1401\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 32.2137 - val_loss: 35.0311\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 33.0597 - val_loss: 34.1149\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 33.1275 - val_loss: 35.4675\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 33.3234 - val_loss: 33.3488\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 31.4955 - val_loss: 35.2685\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 32.5471 - val_loss: 34.8166\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 32.8028 - val_loss: 34.0591\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 32.8788 - val_loss: 36.2403\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 31.4149 - val_loss: 35.5766\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 31.5167 - val_loss: 34.6404\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 33.0383 - val_loss: 34.4053\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 34.0369 - val_loss: 36.0006\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 32.2273 - val_loss: 34.9375\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 32.5123 - val_loss: 35.4300\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 32.7113 - val_loss: 36.0198\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 31.0886 - val_loss: 33.2244\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 31.60 - 0s 77us/step - loss: 32.3255 - val_loss: 35.8774\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 33.1997 - val_loss: 35.3022\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 32.5023 - val_loss: 36.3539\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 32.7494 - val_loss: 34.1129\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 30.6827 - val_loss: 35.3645\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 31.6274 - val_loss: 34.1617\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 33.1634 - val_loss: 35.4727\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 32.6925 - val_loss: 35.3926\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 31.7380 - val_loss: 35.3442\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 65us/step - loss: 31.5897 - val_loss: 34.4214\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 30.8578 - val_loss: 34.9235\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 32.4636 - val_loss: 38.1432\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 30.6374 - val_loss: 36.7190\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 31.9168 - val_loss: 33.5875\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 32.9801 - val_loss: 32.9412\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 33.8998 - val_loss: 36.1205\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 33.1257 - val_loss: 34.5310\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 30.5069 - val_loss: 34.1425\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 33.0112 - val_loss: 35.6019\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 31.1182 - val_loss: 34.7993\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 32.8526 - val_loss: 33.9594\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 32.4019 - val_loss: 35.2972\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 30.8677 - val_loss: 36.9223\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 30.8085 - val_loss: 33.9316\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 31.9341 - val_loss: 33.6415\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 32.0727 - val_loss: 38.8768\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 31.4780 - val_loss: 33.2095\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 30.7202 - val_loss: 34.2622\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 31.7379 - val_loss: 36.5289\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 31.3549 - val_loss: 37.5943\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 31.8076 - val_loss: 34.2296\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 31.6068 - val_loss: 35.4838\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 31.3782 - val_loss: 33.0521\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 30.9514 - val_loss: 33.3106\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 32.2927 - val_loss: 32.6734\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 31.5895 - val_loss: 33.3277\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 31.8334 - val_loss: 31.9229\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 31.8285 - val_loss: 33.7003\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 32.4086 - val_loss: 33.0414\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 30.8674 - val_loss: 32.9652\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 33.2438 - val_loss: 34.1412\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 31.9754 - val_loss: 36.2291\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 32.4045 - val_loss: 37.2203\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 31.1657 - val_loss: 34.4573\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 32.3377 - val_loss: 35.0807\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 32.4260 - val_loss: 34.5988\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 32.2934 - val_loss: 34.4353\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 32.2041 - val_loss: 33.2527\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 31.9223 - val_loss: 32.8078\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 31.7238 - val_loss: 35.3386\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 29.2942 - val_loss: 34.4680\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 31.7456 - val_loss: 32.5610\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 32.7178 - val_loss: 35.9388\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 31.1107 - val_loss: 34.3424\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 32.4736 - val_loss: 33.2652\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 32.2239 - val_loss: 35.2799\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 31.4209 - val_loss: 35.2621\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 31.9328 - val_loss: 34.2877\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 31.7583 - val_loss: 33.5327\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 30.5851 - val_loss: 34.0123\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 31.4940 - val_loss: 33.7203\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 32.3336 - val_loss: 34.3201\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 31.3184 - val_loss: 34.2346\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 31.3479 - val_loss: 34.1216\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 30.7167 - val_loss: 36.1928\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 32.1199 - val_loss: 35.0751\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 31.1529 - val_loss: 32.2905\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 33.0329 - val_loss: 34.4278\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 31.6226 - val_loss: 35.5552\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 31.0314 - val_loss: 32.6847\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 32.1932 - val_loss: 33.9735\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 30.4302 - val_loss: 35.4739\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 31.4219 - val_loss: 35.7620\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 31.7208 - val_loss: 33.3513\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 30.7273 - val_loss: 34.4421\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 30.9764 - val_loss: 35.4666\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 30.8439 - val_loss: 35.5962\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 32.0516 - val_loss: 35.6350\n",
      "hvac mw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 36.9232 - val_loss: 15.0371\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 10.3073 - val_loss: 9.7094\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 8.0591 - val_loss: 9.4957\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 7.6442 - val_loss: 9.3076\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 7.1237 - val_loss: 9.1917\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 7.3510 - val_loss: 9.1013\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.9642 - val_loss: 9.0368\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 6.6341 - val_loss: 9.0024\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 58us/step - loss: 6.6212 - val_loss: 8.9684\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 6.5760 - val_loss: 8.9437\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.5190 - val_loss: 8.9387\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 6.5152 - val_loss: 8.9474\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.3435 - val_loss: 8.9463\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2898 - val_loss: 8.9513\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1695 - val_loss: 8.9401\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 6.0359 - val_loss: 8.9166\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.8710 - val_loss: 8.8907\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.9044 - val_loss: 8.8637\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.7573 - val_loss: 8.8404\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.6064 - val_loss: 8.8228\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.6162 - val_loss: 8.8194\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.5667 - val_loss: 8.8163\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.4759 - val_loss: 8.8140\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.4750 - val_loss: 8.8099\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.4021 - val_loss: 8.8065\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.3888 - val_loss: 8.8036\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.3990 - val_loss: 8.8007\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.3428 - val_loss: 8.7986\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.3932 - val_loss: 8.7948\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.3601 - val_loss: 8.7924\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.3437 - val_loss: 8.7971\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.3212 - val_loss: 8.7979\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.3390 - val_loss: 8.7930\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.3299 - val_loss: 8.7837\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 5.3055 - val_loss: 8.7823\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.2987 - val_loss: 8.7923\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.2996 - val_loss: 8.7954\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 5.3180 - val_loss: 8.7791\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.3097 - val_loss: 8.7780\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.3027 - val_loss: 8.7768\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.3045 - val_loss: 8.7828\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.3116 - val_loss: 8.7843\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.3144 - val_loss: 8.7801\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.3131 - val_loss: 8.7860\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 5.2921 - val_loss: 8.7793\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 5.2800 - val_loss: 8.7813\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.3084 - val_loss: 8.7786\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.2973 - val_loss: 8.7794\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 5.3064 - val_loss: 8.7807\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.2894 - val_loss: 8.7888\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.2789 - val_loss: 8.7850\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.2959 - val_loss: 8.7824\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.3229 - val_loss: 8.7835\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.3090 - val_loss: 8.7880\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.2994 - val_loss: 8.7935\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.3152 - val_loss: 8.7862\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.2972 - val_loss: 8.7921\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 5.2883 - val_loss: 8.8158\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.2943 - val_loss: 8.8181\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.3077 - val_loss: 8.8353\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 5.2562 - val_loss: 8.8753\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 5.2627 - val_loss: 8.8759\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.2192 - val_loss: 8.9398\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.2635 - val_loss: 8.9733\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.2229 - val_loss: 8.9988\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.2337 - val_loss: 8.9473\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.2726 - val_loss: 8.9239\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.2406 - val_loss: 8.9094\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.2530 - val_loss: 8.9091\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.2435 - val_loss: 8.8912\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.2242 - val_loss: 8.8594\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.2469 - val_loss: 8.8601\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.2148 - val_loss: 8.8889\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.2474 - val_loss: 9.0244\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.2598 - val_loss: 8.9052\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.2411 - val_loss: 8.9133\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.2404 - val_loss: 8.9895\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.2229 - val_loss: 8.8679\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.1786 - val_loss: 8.9154\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.2267 - val_loss: 8.9587\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.2144 - val_loss: 8.9244\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.2280 - val_loss: 8.9911\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.2204 - val_loss: 8.8693\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.2186 - val_loss: 8.8621\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1965 - val_loss: 8.9187\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.2347 - val_loss: 8.9023\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.2233 - val_loss: 8.8930\n",
      "Epoch 88/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 66us/step - loss: 5.2204 - val_loss: 8.9082\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.1829 - val_loss: 8.9417\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.1694 - val_loss: 8.9388\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.1733 - val_loss: 8.8940\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.2088 - val_loss: 8.8891\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.2226 - val_loss: 8.9256\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.1836 - val_loss: 8.9333\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 5.765 - 0s 70us/step - loss: 5.2050 - val_loss: 8.9224\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.1808 - val_loss: 8.8994\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.1805 - val_loss: 8.9557\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.2100 - val_loss: 8.9447\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.2010 - val_loss: 8.9007\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.2091 - val_loss: 8.9467\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.1625 - val_loss: 8.9140\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.2184 - val_loss: 8.9329\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1759 - val_loss: 8.9341\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.1842 - val_loss: 8.9010\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.1615 - val_loss: 8.9277\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.1547 - val_loss: 8.9104\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.1940 - val_loss: 8.9230\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.1529 - val_loss: 8.9246\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1650 - val_loss: 8.9271\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.1835 - val_loss: 8.9245\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.1886 - val_loss: 8.9305\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.1739 - val_loss: 8.9326\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.2058 - val_loss: 8.9286\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.1500 - val_loss: 8.9241\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.1693 - val_loss: 8.9343\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.1481 - val_loss: 8.9279\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.1854 - val_loss: 8.9299\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.1843 - val_loss: 8.9302\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.1551 - val_loss: 8.9275\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1675 - val_loss: 8.9276\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.1960 - val_loss: 8.9332\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.1545 - val_loss: 8.9315\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1714 - val_loss: 8.9424\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.1739 - val_loss: 8.9467\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.1813 - val_loss: 8.9520\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 5.1967 - val_loss: 8.9560\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.1556 - val_loss: 8.9361\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1530 - val_loss: 8.9448\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.1542 - val_loss: 8.9405\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.1722 - val_loss: 8.9455\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.1920 - val_loss: 8.9603\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 5.1664 - val_loss: 8.9752\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 5.1638 - val_loss: 8.9666\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.1407 - val_loss: 8.9764\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.1650 - val_loss: 8.9522\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.1566 - val_loss: 8.9587\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.1458 - val_loss: 8.9922\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.1350 - val_loss: 8.9597\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.1651 - val_loss: 8.9793\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.1521 - val_loss: 8.9817\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1698 - val_loss: 8.9928\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.1818 - val_loss: 8.9660\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1690 - val_loss: 8.9825\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1514 - val_loss: 9.0081\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1549 - val_loss: 9.0063\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 5.1420 - val_loss: 9.0012\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.1408 - val_loss: 9.0167\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.1641 - val_loss: 8.9846\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1376 - val_loss: 9.0162\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1475 - val_loss: 8.9919\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 5.1677 - val_loss: 9.0160\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1649 - val_loss: 9.0138\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1794 - val_loss: 8.9774\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1710 - val_loss: 9.0020\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1471 - val_loss: 8.9777\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1575 - val_loss: 8.9706\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.1394 - val_loss: 8.9927\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.1377 - val_loss: 8.9619\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1430 - val_loss: 8.9660\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.1547 - val_loss: 9.0186\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1476 - val_loss: 8.9938\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1548 - val_loss: 9.0108\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.1425 - val_loss: 8.9804\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1622 - val_loss: 9.0890\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.1633 - val_loss: 9.0056\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.1141 - val_loss: 9.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.1382 - val_loss: 9.0011\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 5.1494 - val_loss: 8.9742\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.1185 - val_loss: 8.9529\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.1181 - val_loss: 8.9848\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1216 - val_loss: 8.9962\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1151 - val_loss: 9.0094\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.1383 - val_loss: 8.9700\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.1065 - val_loss: 8.9855\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1053 - val_loss: 8.9678\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.1452 - val_loss: 9.0594\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 5.1269 - val_loss: 9.0328\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 5.1166 - val_loss: 9.0473\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 5.1193 - val_loss: 9.0305\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.1215 - val_loss: 8.9899\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 5.1348 - val_loss: 8.9739\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.1034 - val_loss: 9.0199\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 4.185 - 0s 58us/step - loss: 5.1484 - val_loss: 9.0277\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.1542 - val_loss: 9.0086\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1466 - val_loss: 8.9481\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.1466 - val_loss: 9.0089\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.1186 - val_loss: 9.0087\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.1656 - val_loss: 9.0080\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.1355 - val_loss: 9.1241\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.1351 - val_loss: 8.9352\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.1304 - val_loss: 9.1329\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.1467 - val_loss: 9.0364\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 5.1357 - val_loss: 9.0292\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.1465 - val_loss: 9.0335\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.1050 - val_loss: 9.0588\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.1616 - val_loss: 9.0450\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.1347 - val_loss: 9.0296\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1308 - val_loss: 9.0789\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.1163 - val_loss: 8.8779\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.1451 - val_loss: 9.1146\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1671 - val_loss: 8.9595\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 5.1030 - val_loss: 9.0135\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.1552 - val_loss: 9.1217\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.1190 - val_loss: 8.9616\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.1328 - val_loss: 9.1423\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 5.1204 - val_loss: 8.9909\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.1437 - val_loss: 9.2361\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.1643 - val_loss: 8.9195\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.1667 - val_loss: 8.9434\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1230 - val_loss: 9.1341\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1428 - val_loss: 8.9673\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.1028 - val_loss: 8.9418\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.1097 - val_loss: 9.0312\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.1479 - val_loss: 9.0496\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.0637 - val_loss: 9.0042\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.0778 - val_loss: 8.9461\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 5.1066 - val_loss: 9.0496\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.1094 - val_loss: 9.0058\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.1072 - val_loss: 8.9389\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 5.1184 - val_loss: 8.9418\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.1175 - val_loss: 9.0171\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.0899 - val_loss: 9.0663\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.1259 - val_loss: 9.0784\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.0963 - val_loss: 8.9795\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.0969 - val_loss: 9.0001\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.1209 - val_loss: 9.0130\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.0961 - val_loss: 9.0286\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.1023 - val_loss: 9.0522\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.0783 - val_loss: 9.1943\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1193 - val_loss: 9.1458\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 5.0903 - val_loss: 9.1636\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 5.0923 - val_loss: 9.0568\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.0725 - val_loss: 9.0952\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.0709 - val_loss: 9.0455\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.1171 - val_loss: 9.0478\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.1062 - val_loss: 9.0992\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.0769 - val_loss: 9.1067\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.1121 - val_loss: 9.0533\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.1247 - val_loss: 9.0501\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.0899 - val_loss: 9.1479\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.0933 - val_loss: 9.1812\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 5.0881 - val_loss: 9.0549\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.0661 - val_loss: 9.0728\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.0707 - val_loss: 9.1605\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 68us/step - loss: 5.0970 - val_loss: 9.2280\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 5.0969 - val_loss: 9.2779\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 5.1116 - val_loss: 9.3187\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1250 - val_loss: 9.2253\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.0851 - val_loss: 9.1048\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.0963 - val_loss: 9.0511\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.0939 - val_loss: 9.0561\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 5.0939 - val_loss: 9.1670\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.0972 - val_loss: 9.1679\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.1087 - val_loss: 9.0615\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 5.1031 - val_loss: 9.1079\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.0848 - val_loss: 9.1568\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.1160 - val_loss: 9.1021\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 5.0953 - val_loss: 9.1760\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1001 - val_loss: 9.1806\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.0674 - val_loss: 9.1341\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 5.0915 - val_loss: 9.1103\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.0824 - val_loss: 9.1365\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.0931 - val_loss: 9.1699\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.1061 - val_loss: 9.2658\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.0884 - val_loss: 9.1547\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.1203 - val_loss: 9.1239\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1165 - val_loss: 9.0908\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.1444 - val_loss: 9.1199\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 6.680 - 0s 51us/step - loss: 5.1149 - val_loss: 9.1719\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.0562 - val_loss: 9.2080\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.1105 - val_loss: 9.2042\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.0931 - val_loss: 9.2136\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.0810 - val_loss: 9.2125\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 5.1008 - val_loss: 9.2101\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 5.0972 - val_loss: 9.2161\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 5.1099 - val_loss: 9.1609\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.1169 - val_loss: 9.1613\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.0938 - val_loss: 9.2419\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.0951 - val_loss: 9.1985\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 5.1318 - val_loss: 9.2417\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.0903 - val_loss: 9.1507\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.1356 - val_loss: 8.9827\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.0812 - val_loss: 9.0790\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.0879 - val_loss: 9.1722\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.0733 - val_loss: 9.1314\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.0681 - val_loss: 9.1444\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.0866 - val_loss: 9.0474\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.0981 - val_loss: 9.1609\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.0960 - val_loss: 9.1944\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.0875 - val_loss: 9.1856\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 5.0911 - val_loss: 9.2345\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 92us/step - loss: 5.0828 - val_loss: 9.2159\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 107us/step - loss: 5.0830 - val_loss: 9.2395\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 5.0805 - val_loss: 9.1860\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 93us/step - loss: 5.0952 - val_loss: 9.2149\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 5.1044 - val_loss: 9.2963\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.0789 - val_loss: 9.1317\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 5.0817 - val_loss: 9.1764\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 5.0943 - val_loss: 9.2558\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.0756 - val_loss: 9.2634\n",
      "hvac dw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 15.1040 - val_loss: 18.9836\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.2199 - val_loss: 17.8729\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 13.8003 - val_loss: 17.2374\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.6016 - val_loss: 17.0583\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.7224 - val_loss: 17.0097\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.6667 - val_loss: 16.9048\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.6106 - val_loss: 16.7306\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.5147 - val_loss: 16.6790\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4816 - val_loss: 16.6785\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.5048 - val_loss: 16.6737\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.5168 - val_loss: 16.6729\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4910 - val_loss: 16.6653\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.5191 - val_loss: 16.6432\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4936 - val_loss: 16.7138\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4935 - val_loss: 16.7550\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5218 - val_loss: 16.7180\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4483 - val_loss: 16.7039\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.5174 - val_loss: 16.7042\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 9.268 - 0s 62us/step - loss: 13.5221 - val_loss: 16.6597\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4925 - val_loss: 16.5542\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.5100 - val_loss: 16.3805\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4912 - val_loss: 16.2390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4696 - val_loss: 16.0957\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4600 - val_loss: 16.0466\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4692 - val_loss: 15.9606\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.4488 - val_loss: 15.9073\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4839 - val_loss: 15.8908\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.4572 - val_loss: 15.8860\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4689 - val_loss: 15.8846\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.4588 - val_loss: 15.8842\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4617 - val_loss: 15.8840\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4602 - val_loss: 15.8839\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4708 - val_loss: 15.8838\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4682 - val_loss: 15.8838\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4607 - val_loss: 15.8838\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4594 - val_loss: 15.8848\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4868 - val_loss: 15.8851\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4452 - val_loss: 15.8851\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.4829 - val_loss: 15.8851\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4594 - val_loss: 15.8851\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4703 - val_loss: 15.8851\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4684 - val_loss: 15.8851\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4516 - val_loss: 15.8851\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4685 - val_loss: 15.8849\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4489 - val_loss: 15.8848\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4728 - val_loss: 15.8847\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4703 - val_loss: 15.8847\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4710 - val_loss: 15.8847\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4684 - val_loss: 15.8846\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4709 - val_loss: 15.8846\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4605 - val_loss: 15.8846\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4649 - val_loss: 15.8846\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4591 - val_loss: 15.8846\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4670 - val_loss: 15.8846\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4663 - val_loss: 15.8846\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4747 - val_loss: 15.8846\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4527 - val_loss: 15.8845\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4745 - val_loss: 15.8845\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4478 - val_loss: 15.8845\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4727 - val_loss: 15.8309\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4671 - val_loss: 15.8125\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4613 - val_loss: 15.7805\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4529 - val_loss: 15.7454\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4600 - val_loss: 15.7360\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4604 - val_loss: 15.7333\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4684 - val_loss: 15.7326\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4750 - val_loss: 15.7323\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4529 - val_loss: 15.7323\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4500 - val_loss: 15.7322\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4728 - val_loss: 15.7322\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4613 - val_loss: 15.7322\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4753 - val_loss: 15.7322\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4655 - val_loss: 15.7322\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4674 - val_loss: 15.7682\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4685 - val_loss: 15.8050\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4748 - val_loss: 15.8049\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4586 - val_loss: 15.8049\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 13.4663 - val_loss: 15.8049\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4426 - val_loss: 15.8049\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4949 - val_loss: 15.8049\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4759 - val_loss: 15.8049\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4746 - val_loss: 15.8048\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 13.4509 - val_loss: 15.8048\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 13.4760 - val_loss: 15.8048\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4439 - val_loss: 15.8048\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4605 - val_loss: 15.8048\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4529 - val_loss: 15.8048\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4598 - val_loss: 15.8048\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4573 - val_loss: 15.8047\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4591 - val_loss: 15.8037\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4601 - val_loss: 15.8034\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4478 - val_loss: 15.8034\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4655 - val_loss: 15.8047\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4452 - val_loss: 15.8047\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4781 - val_loss: 15.8047\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.4523 - val_loss: 15.8047\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4837 - val_loss: 15.8046\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4686 - val_loss: 15.8046\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4736 - val_loss: 15.8046\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4804 - val_loss: 15.8046\n",
      "Epoch 101/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 76us/step - loss: 13.4585 - val_loss: 15.8045\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4911 - val_loss: 15.8045\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4602 - val_loss: 15.8045\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.4904 - val_loss: 15.8045\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4777 - val_loss: 15.8044\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4926 - val_loss: 15.8044\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4926 - val_loss: 15.8043\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5087 - val_loss: 15.8043\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4668 - val_loss: 15.8043\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4452 - val_loss: 15.8042\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4583 - val_loss: 15.8042\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4559 - val_loss: 15.8042\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.4708 - val_loss: 15.8042\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 13.4525 - val_loss: 15.7929\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4496 - val_loss: 15.7934\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4451 - val_loss: 15.7882\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4410 - val_loss: 15.7839\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4540 - val_loss: 15.7530\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.4403 - val_loss: 15.6995\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4622 - val_loss: 15.6741\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4579 - val_loss: 15.6658\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4525 - val_loss: 15.6641\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4527 - val_loss: 15.6636\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4452 - val_loss: 15.6635\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.4452 - val_loss: 15.6634\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4458 - val_loss: 15.6634\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4813 - val_loss: 15.6634\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4527 - val_loss: 15.6634\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 14.38 - 0s 66us/step - loss: 13.4399 - val_loss: 15.6634\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4550 - val_loss: 15.6654\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4562 - val_loss: 15.6672\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4452 - val_loss: 15.6673\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4455 - val_loss: 15.6649\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4453 - val_loss: 15.6633\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4524 - val_loss: 15.6430\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4586 - val_loss: 15.6233\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 13.4452 - val_loss: 15.6189\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 13.4450 - val_loss: 15.6177\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.4649 - val_loss: 15.6174\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.4466 - val_loss: 15.6173\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4589 - val_loss: 15.6173\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4601 - val_loss: 15.6172\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4452 - val_loss: 15.6172\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 13.39 - 0s 74us/step - loss: 13.4492 - val_loss: 15.6172\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4527 - val_loss: 15.6172\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4574 - val_loss: 15.6172\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4530 - val_loss: 15.6172\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4578 - val_loss: 15.6172\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4452 - val_loss: 15.6172\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4526 - val_loss: 15.6172\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4525 - val_loss: 15.6172\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.4526 - val_loss: 15.6172\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4501 - val_loss: 15.6172\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4579 - val_loss: 15.6172\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4616 - val_loss: 15.6172\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4495 - val_loss: 15.6172\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4526 - val_loss: 15.6172\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4452 - val_loss: 15.6172\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4632 - val_loss: 15.4497\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4452 - val_loss: 15.3862\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4518 - val_loss: 15.3658\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4553 - val_loss: 15.3599\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4581 - val_loss: 15.3582\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 13.4516 - val_loss: 15.3577\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 87us/step - loss: 13.4582 - val_loss: 15.3576\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4518 - val_loss: 15.3575\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 84us/step - loss: 13.4586 - val_loss: 15.3575\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4466 - val_loss: 15.3575\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4582 - val_loss: 15.3575\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4452 - val_loss: 15.3565\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4452 - val_loss: 15.3562\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4452 - val_loss: 15.3561\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4589 - val_loss: 15.3560\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4517 - val_loss: 15.3560\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4452 - val_loss: 15.3560\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4592 - val_loss: 15.3560\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4520 - val_loss: 15.3560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4505 - val_loss: 15.3560\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.4581 - val_loss: 15.3560\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4426 - val_loss: 15.3560\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4526 - val_loss: 15.3560\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4452 - val_loss: 15.3560\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4526 - val_loss: 15.3560\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.4496 - val_loss: 15.3560\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4526 - val_loss: 15.3560\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4515 - val_loss: 15.3560\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4452 - val_loss: 15.3560\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.4507 - val_loss: 15.3560\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.4526 - val_loss: 15.3560\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4507 - val_loss: 15.3560\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4597 - val_loss: 15.3560\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4452 - val_loss: 15.3560\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4598 - val_loss: 15.3560\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4509 - val_loss: 15.3559\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4455 - val_loss: 15.3559\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4606 - val_loss: 15.3559\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4511 - val_loss: 15.3559\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4513 - val_loss: 15.3559\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4513 - val_loss: 15.3559\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4598 - val_loss: 15.3559\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.4525 - val_loss: 15.3559\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.4669 - val_loss: 15.3559\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4680 - val_loss: 15.3559\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.4509 - val_loss: 15.3559\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4463 - val_loss: 15.3559\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4525 - val_loss: 15.3559\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4452 - val_loss: 15.3559\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4591 - val_loss: 15.3559\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4525 - val_loss: 15.3558\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4580 - val_loss: 15.3558\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4597 - val_loss: 15.3558\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4525 - val_loss: 15.3558\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4579 - val_loss: 15.3558\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4380 - val_loss: 15.3558\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4429 - val_loss: 15.3558\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4597 - val_loss: 15.3558\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4645 - val_loss: 15.3558\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4525 - val_loss: 15.3558\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4596 - val_loss: 15.3558\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4452 - val_loss: 15.3558\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 13.4524 - val_loss: 15.3558\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 13.4381 - val_loss: 15.3558\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4452 - val_loss: 15.3558\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4452 - val_loss: 15.3558\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4596 - val_loss: 15.3558\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4309 - val_loss: 15.3558\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4452 - val_loss: 15.3558\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4435 - val_loss: 15.3558\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 13.4524 - val_loss: 15.3558\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4452 - val_loss: 15.3558\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4524 - val_loss: 15.3558\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4524 - val_loss: 15.3557\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4650 - val_loss: 15.3557\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4524 - val_loss: 15.3557\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 255/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 67us/step - loss: 13.4506 - val_loss: 15.3557\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4524 - val_loss: 15.3557\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.4546 - val_loss: 15.3557\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4518 - val_loss: 15.3557\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.4459 - val_loss: 15.3557\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4664 - val_loss: 15.3557\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.4452 - val_loss: 15.3557\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4594 - val_loss: 15.3557\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4503 - val_loss: 15.3556\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4713 - val_loss: 15.3556\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4452 - val_loss: 15.3556\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4596 - val_loss: 15.3556\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4452 - val_loss: 15.3556\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4452 - val_loss: 15.3556\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4521 - val_loss: 15.3556\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4593 - val_loss: 15.3556\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4523 - val_loss: 15.3556\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4452 - val_loss: 15.3555\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4572 - val_loss: 15.3555\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4543 - val_loss: 15.3555\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.4653 - val_loss: 15.3555\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.4587 - val_loss: 15.3555\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4505 - val_loss: 15.3555\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4452 - val_loss: 15.3555\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.4516 - val_loss: 15.3555\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4452 - val_loss: 15.3555\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.4452 - val_loss: 15.3555\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4452 - val_loss: 15.3555\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4452 - val_loss: 15.3555\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.4563 - val_loss: 15.3555\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4452 - val_loss: 15.3555\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4452 - val_loss: 15.3555\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 13.4452 - val_loss: 15.3555\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 13.4466 - val_loss: 15.3554\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 98us/step - loss: 13.4523 - val_loss: 15.3554\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 87us/step - loss: 13.4557 - val_loss: 15.3554\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 13.4452 - val_loss: 15.3554\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4505 - val_loss: 15.3554\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4568 - val_loss: 15.3554\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4452 - val_loss: 15.3554\n",
      "hvac wm\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 4.7344 - val_loss: 4.6317\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.6316\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.6316\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 4.7374 - val_loss: 4.6316\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7415 - val_loss: 4.6316\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 4.7315 - val_loss: 4.6316\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7385 - val_loss: 4.6316\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 4.7315 - val_loss: 4.6316\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7315 - val_loss: 4.6316\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7315 - val_loss: 4.6316\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7425 - val_loss: 4.6316\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7315 - val_loss: 4.6315\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7385 - val_loss: 4.6315\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 4.7315 - val_loss: 4.6315\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7359 - val_loss: 4.6315\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7398 - val_loss: 4.6315\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7384 - val_loss: 4.6314\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 90us/step - loss: 4.7384 - val_loss: 4.6314\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7315 - val_loss: 4.6314\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 4.7384 - val_loss: 4.6314\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 4.7315 - val_loss: 4.6314\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7362 - val_loss: 4.6314\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 4.7413 - val_loss: 4.6313\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7384 - val_loss: 4.6313\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7486 - val_loss: 4.6313\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7377 - val_loss: 4.6312\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7383 - val_loss: 4.6312\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7366 - val_loss: 4.6312\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7405 - val_loss: 4.6312\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7315 - val_loss: 4.6312\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.6312\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7383 - val_loss: 4.6312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7383 - val_loss: 4.6311\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.6311\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7383 - val_loss: 4.6311\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7439 - val_loss: 4.6311\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7411 - val_loss: 4.6311\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7360 - val_loss: 4.6311\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 4.7382 - val_loss: 4.6310\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7313 - val_loss: 4.6310\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.6310\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.6310\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7315 - val_loss: 4.6310\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.6310\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7315 - val_loss: 4.6310\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.6310\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7327 - val_loss: 4.6310\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.6310\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7315 - val_loss: 4.6310\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7382 - val_loss: 4.6310\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7434 - val_loss: 4.6310\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.6310\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7382 - val_loss: 4.6310\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7365 - val_loss: 4.6309\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7381 - val_loss: 4.6309\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.6309\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7371 - val_loss: 4.6309\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7341 - val_loss: 4.6309\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 4.7381 - val_loss: 4.6309\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7369 - val_loss: 4.6309\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7359 - val_loss: 4.6308\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7381 - val_loss: 4.6308\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7315 - val_loss: 4.6308\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7315 - val_loss: 4.6308\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7428 - val_loss: 4.6308\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7315 - val_loss: 4.6308\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 3.837 - 0s 65us/step - loss: 4.7304 - val_loss: 4.6308\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.6308\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7435 - val_loss: 4.6308\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7302 - val_loss: 4.6307\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.6307\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7380 - val_loss: 4.6307\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7446 - val_loss: 4.6307\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7380 - val_loss: 4.6307\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7380 - val_loss: 4.6307\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7380 - val_loss: 4.6307\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7368 - val_loss: 4.6306\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7315 - val_loss: 4.6306\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7315 - val_loss: 4.6306\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 4.7369 - val_loss: 4.6306\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7380 - val_loss: 4.6306\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7333 - val_loss: 4.6306\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7342 - val_loss: 4.6306\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 6.502 - 0s 61us/step - loss: 4.7315 - val_loss: 4.6306\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7315 - val_loss: 4.6306\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7358 - val_loss: 4.6306\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7369 - val_loss: 4.6305\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.6305\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7315 - val_loss: 4.6305\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7315 - val_loss: 4.6305\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7444 - val_loss: 4.6305\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7330 - val_loss: 4.6305\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7315 - val_loss: 4.6305\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7315 - val_loss: 4.6305\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7347 - val_loss: 4.6305\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7417 - val_loss: 4.6304\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7379 - val_loss: 4.6304\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.6304\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7315 - val_loss: 4.6304\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7353 - val_loss: 4.6304\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7368 - val_loss: 4.6304\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7559 - val_loss: 4.6303\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7426 - val_loss: 4.6303\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7315 - val_loss: 4.6303\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7315 - val_loss: 4.6303\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7431 - val_loss: 4.6303\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7315 - val_loss: 4.6303\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7336 - val_loss: 4.6303\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7315 - val_loss: 4.6303\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7430 - val_loss: 4.6302\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7315 - val_loss: 4.6302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.6302\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7477 - val_loss: 4.6302\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7315 - val_loss: 4.6302\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7367 - val_loss: 4.6302\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7315 - val_loss: 4.6302\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7315 - val_loss: 4.6301\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7387 - val_loss: 4.6301\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7315 - val_loss: 4.6301\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7315 - val_loss: 4.6301\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7377 - val_loss: 4.6301\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7315 - val_loss: 4.6301\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7440 - val_loss: 4.6301\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7501 - val_loss: 4.6301\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7361 - val_loss: 4.6300\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7438 - val_loss: 4.6300\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7377 - val_loss: 4.6300\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7388 - val_loss: 4.6299\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7315 - val_loss: 4.6299\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7371 - val_loss: 4.6299\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7315 - val_loss: 4.6299\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7370 - val_loss: 4.6299\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7477 - val_loss: 4.6299\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7421 - val_loss: 4.6298\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7315 - val_loss: 4.6298\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7315 - val_loss: 4.6298\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7307 - val_loss: 4.6298\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7375 - val_loss: 4.6298\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7315 - val_loss: 4.6298\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7315 - val_loss: 4.6298\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 4.7338 - val_loss: 4.6298\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7351 - val_loss: 4.6298\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7342 - val_loss: 4.6297\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7315 - val_loss: 4.6297\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7307 - val_loss: 4.6297\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7315 - val_loss: 4.6297\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7315 - val_loss: 4.6298\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7350 - val_loss: 4.6297\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7315 - val_loss: 4.6297\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7370 - val_loss: 4.6297\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7375 - val_loss: 4.6297\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7315 - val_loss: 4.6297\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7425 - val_loss: 4.6297\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7375 - val_loss: 4.6297\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7315 - val_loss: 4.6297\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7375 - val_loss: 4.6297\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7355 - val_loss: 4.6296\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7363 - val_loss: 4.6296\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.6296\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7315 - val_loss: 4.6296\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7365 - val_loss: 4.6296\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7375 - val_loss: 4.6296\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7355 - val_loss: 4.6296\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7304 - val_loss: 4.6295\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7315 - val_loss: 4.6295\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 4.7359 - val_loss: 4.6295\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7315 - val_loss: 4.6295\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7315 - val_loss: 4.6295\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7433 - val_loss: 4.6295\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7422 - val_loss: 4.6295\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7374 - val_loss: 4.6294\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7374 - val_loss: 4.6294\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7315 - val_loss: 4.6294\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7322 - val_loss: 4.6294\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7374 - val_loss: 4.6294\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 4.7315 - val_loss: 4.6294\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7315 - val_loss: 4.6294\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7432 - val_loss: 4.6294\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7315 - val_loss: 4.6294\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7373 - val_loss: 4.6293\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7373 - val_loss: 4.6293\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 7.491 - 0s 65us/step - loss: 4.7315 - val_loss: 4.6293\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7315 - val_loss: 4.6293\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7363 - val_loss: 4.6293\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7374 - val_loss: 4.6293\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.6293\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7315 - val_loss: 4.6293\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7315 - val_loss: 4.6293\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7315 - val_loss: 4.6293\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 76us/step - loss: 4.7294 - val_loss: 4.6293\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 4.7315 - val_loss: 4.6293\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7373 - val_loss: 4.6293\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7411 - val_loss: 4.6293\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7363 - val_loss: 4.6292\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7395 - val_loss: 4.6292\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.6292\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7367 - val_loss: 4.6292\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7373 - val_loss: 4.6292\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7315 - val_loss: 4.6292\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7269 - val_loss: 4.6292\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7389 - val_loss: 4.6292\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 4.7429 - val_loss: 4.6292\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 4.7315 - val_loss: 4.6291\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7315 - val_loss: 4.6291\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7372 - val_loss: 4.6291\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7333 - val_loss: 4.6291\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7315 - val_loss: 4.6291\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7367 - val_loss: 4.6291\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7362 - val_loss: 4.6291\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.6291\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7372 - val_loss: 4.6291\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7352 - val_loss: 4.6291\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7362 - val_loss: 4.6291\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7315 - val_loss: 4.6291\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7439 - val_loss: 4.6290\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7315 - val_loss: 4.6290\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 4.069 - 0s 70us/step - loss: 4.7362 - val_loss: 4.6290\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7418 - val_loss: 4.6290\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7362 - val_loss: 4.6290\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7315 - val_loss: 4.6290\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7315 - val_loss: 4.6289\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7426 - val_loss: 4.6289\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7371 - val_loss: 4.6289\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7327 - val_loss: 4.6289\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7407 - val_loss: 4.6289\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7315 - val_loss: 4.6288\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7370 - val_loss: 4.6288\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7401 - val_loss: 4.6288\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7315 - val_loss: 4.6288\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7386 - val_loss: 4.6288\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7315 - val_loss: 4.6288\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7580 - val_loss: 4.6287\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7375 - val_loss: 4.6287\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.6287\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7385 - val_loss: 4.6286\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7414 - val_loss: 4.6286\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7369 - val_loss: 4.6286\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 4.7369 - val_loss: 4.6286\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7315 - val_loss: 4.6286\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7315 - val_loss: 4.6286\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 4.7315 - val_loss: 4.6286\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7344 - val_loss: 4.6286\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7315 - val_loss: 4.6286\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7360 - val_loss: 4.6286\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7413 - val_loss: 4.6285\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7390 - val_loss: 4.6285\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7315 - val_loss: 4.6285\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7369 - val_loss: 4.6285\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7315 - val_loss: 4.6285\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7408 - val_loss: 4.6285\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 4.7368 - val_loss: 4.6284\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7368 - val_loss: 4.6284\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7421 - val_loss: 4.6284\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7403 - val_loss: 4.6284\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7416 - val_loss: 4.6283\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7315 - val_loss: 4.6283\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7337 - val_loss: 4.6283\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.6283\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7434 - val_loss: 4.6283\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7349 - val_loss: 4.6283\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7315 - val_loss: 4.6283\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7367 - val_loss: 4.6282\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7388 - val_loss: 4.6282\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7396 - val_loss: 4.6282\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7410 - val_loss: 4.6282\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7340 - val_loss: 4.6282\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7367 - val_loss: 4.6281\n",
      "Epoch 268/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 70us/step - loss: 4.7315 - val_loss: 4.6281\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7273 - val_loss: 4.6281\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7367 - val_loss: 4.6281\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7388 - val_loss: 4.6281\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7281 - val_loss: 4.6281\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7315 - val_loss: 4.6281\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 4.7427 - val_loss: 4.6281\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7315 - val_loss: 4.6280\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7357 - val_loss: 4.6280\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7417 - val_loss: 4.6280\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 4.7366 - val_loss: 4.6280\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.6280\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7467 - val_loss: 4.6280\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7366 - val_loss: 4.6279\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7416 - val_loss: 4.6279\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7315 - val_loss: 4.6279\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.6279\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 4.7315 - val_loss: 4.6279\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7365 - val_loss: 4.6279\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 4.7365 - val_loss: 4.6279\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 4.7407 - val_loss: 4.6278\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7400 - val_loss: 4.6278\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7315 - val_loss: 4.6278\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 4.7315 - val_loss: 4.6278\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 4.7415 - val_loss: 4.6278\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7270 - val_loss: 4.6278\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7411 - val_loss: 4.6278\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7365 - val_loss: 4.6277\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 4.7315 - val_loss: 4.6277\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7315 - val_loss: 4.6277\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 4.7315 - val_loss: 4.6277\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 4.7365 - val_loss: 4.6277\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 4.7393 - val_loss: 4.6277\n",
      "hvac oven\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 14.4587 - val_loss: 13.7774\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 14.4654 - val_loss: 13.7774\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 14.4587 - val_loss: 13.7774\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.4587 - val_loss: 13.7774\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.4587 - val_loss: 13.7774\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.4489 - val_loss: 13.7774\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.4587 - val_loss: 13.7774\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4586 - val_loss: 13.7774\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 14.4538 - val_loss: 13.7774\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4612 - val_loss: 13.7774\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.4538 - val_loss: 13.7774\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4538 - val_loss: 13.7774\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4587 - val_loss: 13.7774\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4564 - val_loss: 13.7775\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.4538 - val_loss: 13.7775\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.4554 - val_loss: 13.7775\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.4579 - val_loss: 13.7775\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 17.09 - 0s 75us/step - loss: 14.4538 - val_loss: 13.7775\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.4624 - val_loss: 13.7775\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.4538 - val_loss: 13.7775\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.4538 - val_loss: 13.7775\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4538 - val_loss: 13.7775\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.4570 - val_loss: 13.7775\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.4488 - val_loss: 13.7775\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 14.4530 - val_loss: 13.7776\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.4620 - val_loss: 13.7776\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.4620 - val_loss: 13.7776\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 14.4639 - val_loss: 13.7775\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.4587 - val_loss: 13.7775\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.4444 - val_loss: 13.7775\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 14.4588 - val_loss: 13.7775\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.4538 - val_loss: 13.7775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4538 - val_loss: 13.7776\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4487 - val_loss: 13.7776\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4632 - val_loss: 13.7776\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4563 - val_loss: 13.7776\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4537 - val_loss: 13.7776\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4620 - val_loss: 13.7776\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4553 - val_loss: 13.7776\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4537 - val_loss: 13.7776\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4537 - val_loss: 13.7776\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4638 - val_loss: 13.7776\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4537 - val_loss: 13.7776\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 14.4523 - val_loss: 13.7776\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4583 - val_loss: 13.7776\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7776\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4486 - val_loss: 13.7777\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4570 - val_loss: 13.7777\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7777\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4506 - val_loss: 13.7777\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7777\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4638 - val_loss: 13.7777\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4585 - val_loss: 13.7777\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4490 - val_loss: 13.7777\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4588 - val_loss: 13.7777\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.7777\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4537 - val_loss: 13.7777\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7777\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4638 - val_loss: 13.7777\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4537 - val_loss: 13.7777\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4536 - val_loss: 13.7777\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4485 - val_loss: 13.7778\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4518 - val_loss: 13.7778\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4690 - val_loss: 13.7778\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4536 - val_loss: 13.7778\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4545 - val_loss: 13.7778\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4639 - val_loss: 13.7778\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4522 - val_loss: 13.7778\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4639 - val_loss: 13.7778\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4485 - val_loss: 13.7778\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4609 - val_loss: 13.7778\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4536 - val_loss: 13.7778\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4536 - val_loss: 13.7778\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4639 - val_loss: 13.7778\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4552 - val_loss: 13.7778\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4543 - val_loss: 13.7778\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4536 - val_loss: 13.7778\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4484 - val_loss: 13.7779\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4537 - val_loss: 13.7779\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7779\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4690 - val_loss: 13.7778\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7778\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4573 - val_loss: 13.7778\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4536 - val_loss: 13.7778\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4591 - val_loss: 13.7778\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4538 - val_loss: 13.7778\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4539 - val_loss: 13.7778\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4484 - val_loss: 13.7779\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4639 - val_loss: 13.7779\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4617 - val_loss: 13.7779\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.7779\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.7779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4550 - val_loss: 13.7779\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4484 - val_loss: 13.7779\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7779\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4535 - val_loss: 13.7779\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4587 - val_loss: 13.7779\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4594 - val_loss: 13.7779\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4535 - val_loss: 13.7779\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4564 - val_loss: 13.7779\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4483 - val_loss: 13.7779\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4574 - val_loss: 13.7780\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7780\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4640 - val_loss: 13.7780\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4640 - val_loss: 13.7779\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7779\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 14.4522 - val_loss: 13.7779\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4694 - val_loss: 13.7779\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4535 - val_loss: 13.7779\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.7779\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4483 - val_loss: 13.7779\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4644 - val_loss: 13.7779\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.7779\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.7779\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7779\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4535 - val_loss: 13.7779\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4574 - val_loss: 13.7779\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4555 - val_loss: 13.7779\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4535 - val_loss: 13.7779\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4535 - val_loss: 13.7779\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 14.4604 - val_loss: 13.7780\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4466 - val_loss: 13.7780\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.7780\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4614 - val_loss: 13.7780\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4571 - val_loss: 13.7780\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4482 - val_loss: 13.7780\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7780\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4535 - val_loss: 13.7780\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4523 - val_loss: 13.7780\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4535 - val_loss: 13.7780\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4599 - val_loss: 13.7780\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4626 - val_loss: 13.7780\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4482 - val_loss: 13.7780\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4534 - val_loss: 13.7781\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4641 - val_loss: 13.7781\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.7781\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.7781\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4573 - val_loss: 13.7781\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7780\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4534 - val_loss: 13.7780\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4532 - val_loss: 13.7781\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4536 - val_loss: 13.7781\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4636 - val_loss: 13.7781\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4534 - val_loss: 13.7781\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4580 - val_loss: 13.7781\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4588 - val_loss: 13.7781\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4476 - val_loss: 13.7781\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.7781\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7781\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4534 - val_loss: 13.7781\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4591 - val_loss: 13.7781\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4534 - val_loss: 13.7782\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4636 - val_loss: 13.7781\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4547 - val_loss: 13.7781\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.7781\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4641 - val_loss: 13.7781\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4481 - val_loss: 13.7782\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4481 - val_loss: 13.7782\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4426 - val_loss: 13.7782\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4624 - val_loss: 13.7782\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4581 - val_loss: 13.7782\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4534 - val_loss: 13.7782\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4641 - val_loss: 13.7782\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4534 - val_loss: 13.7782\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4601 - val_loss: 13.7782\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7782\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4532 - val_loss: 13.7782\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.7782\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4732 - val_loss: 13.7782\n",
      "Epoch 201/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7782\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.7782\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4447 - val_loss: 13.7782\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4480 - val_loss: 13.7782\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.7782\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7782\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4583 - val_loss: 13.7782\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4543 - val_loss: 13.7782\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.4588 - val_loss: 13.7782\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.7782\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 14.4587 - val_loss: 13.7782\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4537 - val_loss: 13.7782\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4533 - val_loss: 13.7782\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.7782\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4556 - val_loss: 13.7783\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4479 - val_loss: 13.7783\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4603 - val_loss: 13.7783\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4614 - val_loss: 13.7783\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4498 - val_loss: 13.7783\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4631 - val_loss: 13.7783\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4642 - val_loss: 13.7783\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4573 - val_loss: 13.7783\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4533 - val_loss: 13.7784\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4642 - val_loss: 13.7784\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4478 - val_loss: 13.7784\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4583 - val_loss: 13.7784\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4727 - val_loss: 13.7784\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4642 - val_loss: 13.7783\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4537 - val_loss: 13.7783\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4584 - val_loss: 13.7783\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4499 - val_loss: 13.7783\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4628 - val_loss: 13.7783\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4571 - val_loss: 13.7783\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 14.4474 - val_loss: 13.7783\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4588 - val_loss: 13.7783\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4642 - val_loss: 13.7783\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4528 - val_loss: 13.7783\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 14.4642 - val_loss: 13.7783\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 87us/step - loss: 14.4478 - val_loss: 13.7783\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.4642 - val_loss: 13.7783\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 14.4534 - val_loss: 13.7783\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4478 - val_loss: 13.7783\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4628 - val_loss: 13.7784\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4625 - val_loss: 13.7783\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 278/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 58us/step - loss: 14.4543 - val_loss: 13.7783\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4555 - val_loss: 13.7783\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4633 - val_loss: 13.7783\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4533 - val_loss: 13.7783\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7783\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4487 - val_loss: 13.7784\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4604 - val_loss: 13.7784\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4642 - val_loss: 13.7784\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4566 - val_loss: 13.7784\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 8.491 - 0s 55us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4533 - val_loss: 13.7784\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 27.19 - 0s 54us/step - loss: 14.4637 - val_loss: 13.7784\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4533 - val_loss: 13.7784\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4636 - val_loss: 13.7784\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.7784\n",
      "fridge hvac\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 861.9165 - val_loss: 874.6758\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.9091 - val_loss: 874.6758\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8713 - val_loss: 874.5449\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.7770 - val_loss: 872.8424\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 860.5169 - val_loss: 868.4946\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 852.7668 - val_loss: 852.2995\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 832.8916 - val_loss: 825.5123\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 803.9387 - val_loss: 798.4786\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 770.1006 - val_loss: 774.7627\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 685.0279 - val_loss: 671.5198\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 534.7706 - val_loss: 507.7240\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 402.3435 - val_loss: 341.2363\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 297.1427 - val_loss: 241.0582\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 237.6874 - val_loss: 190.8063\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 223.0572 - val_loss: 163.9138\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 201.5436 - val_loss: 150.8494\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 202.7064 - val_loss: 145.0667\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 179.6670 - val_loss: 141.4931\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 193.9356 - val_loss: 140.0917\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 169.7916 - val_loss: 139.8138\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 156.5623 - val_loss: 140.3178\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 152.4463 - val_loss: 140.8368\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 145.6862 - val_loss: 140.4966\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 143.1872 - val_loss: 140.1729\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 135.8830 - val_loss: 139.8170\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 131.7799 - val_loss: 139.6131\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 132.0960 - val_loss: 139.5110\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 131.9774 - val_loss: 139.5082\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 137.7972 - val_loss: 139.5174\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.4510 - val_loss: 139.4868\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 130.8782 - val_loss: 139.4360\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 132.0243 - val_loss: 139.3768\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 129.1723 - val_loss: 139.3293\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.1981 - val_loss: 139.3074\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 129.8190 - val_loss: 139.3434\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 131.5869 - val_loss: 139.3551\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.5236 - val_loss: 139.3657\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 133.2009 - val_loss: 139.3657\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.4143 - val_loss: 139.3657\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 129.3856 - val_loss: 139.3657\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 130.0293 - val_loss: 139.3657\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 130.1650 - val_loss: 139.3657\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 130.0929 - val_loss: 139.3657\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 128.4712 - val_loss: 139.3657\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 130.4052 - val_loss: 139.3657\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.4422 - val_loss: 139.3657\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 128.4515 - val_loss: 139.3657\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.9710 - val_loss: 139.3657\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 130.3621 - val_loss: 139.3657\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 130.6272 - val_loss: 139.3657\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.9203 - val_loss: 139.3657\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.8693 - val_loss: 139.3657\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 135.8441 - val_loss: 139.3657\n",
      "Epoch 54/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 58us/step - loss: 129.7917 - val_loss: 139.3657\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 128.2519 - val_loss: 139.3657\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 128.0978 - val_loss: 139.3657\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 128.4980 - val_loss: 139.3657\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 128.7594 - val_loss: 139.3657\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 131.2867 - val_loss: 139.3657\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 130.6450 - val_loss: 139.3657\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 128.5253 - val_loss: 139.3657\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.8989 - val_loss: 139.3657\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.8261 - val_loss: 139.3657\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 128.8340 - val_loss: 139.3657\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.1323 - val_loss: 139.3657\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.6649 - val_loss: 139.3657\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 129.4317 - val_loss: 139.3657\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 120.036 - 0s 61us/step - loss: 128.0662 - val_loss: 139.3657\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 132.4744 - val_loss: 139.3657\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 131.6412 - val_loss: 139.3657\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.6919 - val_loss: 139.3657\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 128.2001 - val_loss: 139.3657\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 128.1648 - val_loss: 139.3657\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 130.9193 - val_loss: 139.3657\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 129.8678 - val_loss: 139.3657\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 130.4848 - val_loss: 139.3657\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 130.6792 - val_loss: 139.3657\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 128.5343 - val_loss: 139.3657\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.5861 - val_loss: 139.3657\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 130.4505 - val_loss: 139.3657\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.7921 - val_loss: 139.3657\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 129.4565 - val_loss: 139.3657\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5625 - val_loss: 139.3657\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 128.6679 - val_loss: 139.3657\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 134.5115 - val_loss: 139.3657\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 128.0778 - val_loss: 139.3657\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.2580 - val_loss: 139.3657\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 129.5182 - val_loss: 139.3657\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.9447 - val_loss: 139.3657\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.9688 - val_loss: 139.3657\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.1260 - val_loss: 139.3657\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 130.1065 - val_loss: 139.3657\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 129.7134 - val_loss: 139.3657\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.4754 - val_loss: 139.3657\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 130.6217 - val_loss: 139.3657\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.8953 - val_loss: 139.3657\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 128.2768 - val_loss: 139.3657\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 128.2220 - val_loss: 139.3657\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 130.4029 - val_loss: 139.3657\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.7196 - val_loss: 139.3657\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.1059 - val_loss: 139.3657\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.2799 - val_loss: 139.3657\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.3188 - val_loss: 139.3657\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4108 - val_loss: 139.3657\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5785 - val_loss: 139.3657\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.8177 - val_loss: 139.3657\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 130.7677 - val_loss: 139.3657\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 130.9050 - val_loss: 139.3657\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.6039 - val_loss: 139.3657\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.5121 - val_loss: 139.3657\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.7151 - val_loss: 139.3657\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.4086 - val_loss: 139.3657\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.6765 - val_loss: 139.3657\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.3964 - val_loss: 139.3657\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.9019 - val_loss: 139.3657\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.7305 - val_loss: 139.3657\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 128.3988 - val_loss: 139.3657\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 132.2215 - val_loss: 139.3657\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.9334 - val_loss: 139.3657\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.8907 - val_loss: 139.3657\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 131.3493 - val_loss: 139.3657\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.8779 - val_loss: 139.3657\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.7363 - val_loss: 139.3657\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5033 - val_loss: 139.3657\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4029 - val_loss: 139.3657\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.8303 - val_loss: 139.3657\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4819 - val_loss: 139.3657\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4817 - val_loss: 139.3657\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.9377 - val_loss: 139.3657\n",
      "Epoch 130/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 127.4490 - val_loss: 139.3657\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.5203 - val_loss: 139.3657\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.8706 - val_loss: 139.3657\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.5236 - val_loss: 139.3657\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6623 - val_loss: 139.3657\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.8484 - val_loss: 139.3657\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 130.3260 - val_loss: 139.3657\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.9882 - val_loss: 139.3657\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5840 - val_loss: 139.3657\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.4781 - val_loss: 139.3657\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.4971 - val_loss: 139.3657\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6980 - val_loss: 139.3657\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.5141 - val_loss: 139.3657\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.8424 - val_loss: 139.3657\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4916 - val_loss: 139.3657\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.6142 - val_loss: 139.3657\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4913 - val_loss: 139.3657\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.6746 - val_loss: 139.3657\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 128.2981 - val_loss: 139.3657\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.6474 - val_loss: 139.3657\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.3607 - val_loss: 139.3657\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.2291 - val_loss: 139.3657\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.0475 - val_loss: 139.3657\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.6955 - val_loss: 139.3657\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5286 - val_loss: 139.3657\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.8763 - val_loss: 139.3657\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4660 - val_loss: 139.3657\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 129.3243 - val_loss: 139.3657\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.4224 - val_loss: 139.3657\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4452 - val_loss: 139.3657\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.4475 - val_loss: 139.3657\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.5895 - val_loss: 139.3657\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.8585 - val_loss: 139.3657\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.5977 - val_loss: 139.3657\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.6910 - val_loss: 139.3657\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.6683 - val_loss: 139.3657\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.7550 - val_loss: 139.3657\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.8851 - val_loss: 139.3657\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.9102 - val_loss: 139.3657\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.7586 - val_loss: 139.3657\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.3560 - val_loss: 139.3657\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 131.3519 - val_loss: 139.3657\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.5284 - val_loss: 139.3657\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.3005 - val_loss: 139.3657\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.0241 - val_loss: 139.3657\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.5732 - val_loss: 139.3657\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6026 - val_loss: 139.3657\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4653 - val_loss: 139.3657\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.3999 - val_loss: 139.3657\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.5442 - val_loss: 139.3657\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.7155 - val_loss: 139.3657\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4602 - val_loss: 139.3657\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.0610 - val_loss: 139.3657\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4643 - val_loss: 139.3657\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4563 - val_loss: 139.3657\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4448 - val_loss: 139.3657\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 128.3264 - val_loss: 139.3657\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4803 - val_loss: 139.3657\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.7710 - val_loss: 139.3657\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.6550 - val_loss: 139.3657\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6223 - val_loss: 139.3657\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4625 - val_loss: 139.3657\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4731 - val_loss: 139.3657\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5872 - val_loss: 139.3657\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.7609 - val_loss: 139.3657\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.5817 - val_loss: 139.3657\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4706 - val_loss: 139.3657\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4706 - val_loss: 139.3657\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6883 - val_loss: 139.3657\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4695 - val_loss: 139.3657\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.8677 - val_loss: 139.3657\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5013 - val_loss: 139.3657\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4731 - val_loss: 139.3657\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 129.4105 - val_loss: 139.3657\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5238 - val_loss: 139.3657\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4312 - val_loss: 139.3657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 122.304 - 0s 51us/step - loss: 128.5846 - val_loss: 139.3657\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.4432 - val_loss: 139.3657\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4639 - val_loss: 139.3657\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4731 - val_loss: 139.3657\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.3608 - val_loss: 139.3657\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.4302 - val_loss: 139.3657\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.2907 - val_loss: 139.3657\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4467 - val_loss: 139.3657\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5872 - val_loss: 139.3657\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4734 - val_loss: 139.3657\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6157 - val_loss: 139.3657\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.5784 - val_loss: 139.3657\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5221 - val_loss: 139.3657\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.3444 - val_loss: 139.3657\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.8752 - val_loss: 139.3657\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5001 - val_loss: 139.3657\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4731 - val_loss: 139.3657\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4621 - val_loss: 139.3657\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 127.4686 - val_loss: 139.3657\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5734 - val_loss: 139.3657\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.1238 - val_loss: 139.3657\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.6544 - val_loss: 139.3657\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.5230 - val_loss: 139.3657\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4670 - val_loss: 139.3657\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6482 - val_loss: 139.3657\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 127.4401 - val_loss: 139.3657\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.7630 - val_loss: 139.3657\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 140.667 - 0s 57us/step - loss: 127.3641 - val_loss: 139.3657\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.5456 - val_loss: 139.3657\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 127.4329 - val_loss: 139.3657\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4457 - val_loss: 139.3657\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5315 - val_loss: 139.3657\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.8315 - val_loss: 139.3657\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4734 - val_loss: 139.3657\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4629 - val_loss: 139.3657\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4417 - val_loss: 139.3657\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.5376 - val_loss: 139.3657\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.6432 - val_loss: 139.3657\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4306 - val_loss: 139.3657\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.4625 - val_loss: 139.3657\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.5483 - val_loss: 139.3657\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4929 - val_loss: 139.3657\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4731 - val_loss: 139.3657\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4628 - val_loss: 139.3657\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5772 - val_loss: 139.3657\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4731 - val_loss: 139.3657\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3841 - val_loss: 139.3657\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.3934 - val_loss: 139.3657\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.5533 - val_loss: 139.3657\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4906 - val_loss: 139.3657\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 128.2781 - val_loss: 139.3657\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.3131 - val_loss: 139.3657\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.7184 - val_loss: 139.3657\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4731 - val_loss: 139.3657\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4651 - val_loss: 139.3657\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.8333 - val_loss: 139.3657\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4591 - val_loss: 139.3657\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.0074 - val_loss: 139.3657\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4725 - val_loss: 139.3657\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4693 - val_loss: 139.3657\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.2525 - val_loss: 139.3657\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 127.8277 - val_loss: 139.3657\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4769 - val_loss: 139.3657\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 126.655 - 0s 55us/step - loss: 127.4342 - val_loss: 139.3657\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.7082 - val_loss: 139.3657\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.7075 - val_loss: 139.3657\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3893 - val_loss: 139.3657\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3883 - val_loss: 139.3657\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.2284 - val_loss: 139.3657\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5413 - val_loss: 139.3657\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.5818 - val_loss: 139.3657\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5939 - val_loss: 139.3657\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4730 - val_loss: 139.3657\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4167 - val_loss: 139.3657\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4311 - val_loss: 139.3657\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 127.4473 - val_loss: 139.3657\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4825 - val_loss: 139.3657\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.4148 - val_loss: 139.3657\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4621 - val_loss: 139.3657\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4716 - val_loss: 139.3657\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5312 - val_loss: 139.3657\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5845 - val_loss: 139.3657\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.2976 - val_loss: 139.3657\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 127.4965 - val_loss: 139.3657\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4920 - val_loss: 139.3657\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3958 - val_loss: 139.3657\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.3177 - val_loss: 139.3657\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.3387 - val_loss: 139.3657\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.3991 - val_loss: 139.3657\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5314 - val_loss: 139.3657\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.5217 - val_loss: 139.3657\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3816 - val_loss: 139.3657\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.3881 - val_loss: 139.3657\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4037 - val_loss: 139.3657\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 127.7626 - val_loss: 139.3657\n",
      "fridge mw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 983.0150 - val_loss: 1005.7111\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 982.1001 - val_loss: 1005.7111\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 981.7078 - val_loss: 1005.7111\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 982.0893 - val_loss: 1005.7111\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 978.5855 - val_loss: 1005.7111\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 977.0853 - val_loss: 1002.4192\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 973.2849 - val_loss: 991.6585\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 964.1000 - val_loss: 991.6446\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 964.4305 - val_loss: 991.6446\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 964.0547 - val_loss: 991.6446\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 958.8432 - val_loss: 991.6446\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 963.6231 - val_loss: 991.6446\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 962.7325 - val_loss: 991.6446\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 960.8257 - val_loss: 991.6446\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 952.6706 - val_loss: 988.1665\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 931.3718 - val_loss: 969.4837\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 881.1126 - val_loss: 901.7737\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 735.0506 - val_loss: 542.4398\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 487.9562 - val_loss: 261.3243\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 320.7267 - val_loss: 183.0943\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 217.9470 - val_loss: 166.2241\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 156.9372 - val_loss: 154.8167\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 123.0616 - val_loss: 136.3610\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 105.0620 - val_loss: 127.9956\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 94.3376 - val_loss: 126.7620\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 94.8201 - val_loss: 125.0697\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 96.8438 - val_loss: 122.6927\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 90.3988 - val_loss: 117.7281\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 90.8520 - val_loss: 108.4931\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 82.5090 - val_loss: 94.2133\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 71.7794 - val_loss: 89.8067\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.8698 - val_loss: 89.4986\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 67.1107 - val_loss: 89.0209\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 65.2998 - val_loss: 88.1331\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 71.5453 - val_loss: 85.7379\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 67.3633 - val_loss: 82.5911\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 66.5197 - val_loss: 76.4733\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 60.1942 - val_loss: 65.4804\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 61.29 - 0s 58us/step - loss: 52.6464 - val_loss: 48.4915\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 36.0017 - val_loss: 31.7882\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 27.4923 - val_loss: 31.6845\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 26.1007 - val_loss: 31.6845\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 25.6392 - val_loss: 31.4555\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 24.9821 - val_loss: 31.2640\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 23.7854 - val_loss: 31.1456\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 23.5788 - val_loss: 31.0267\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 23.8944 - val_loss: 30.9317\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 23.8686 - val_loss: 30.6982\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 24.2330 - val_loss: 30.3655\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 23.6448 - val_loss: 29.7350\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 25.1948 - val_loss: 27.4387\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 21.3784 - val_loss: 21.6112\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.8542 - val_loss: 8.3483\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.8301 - val_loss: 8.3305\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.3487 - val_loss: 8.3305\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.6926 - val_loss: 8.3305\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 59us/step - loss: 6.4177 - val_loss: 8.3305\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.3196 - val_loss: 8.3305\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.3272 - val_loss: 8.3305\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3434 - val_loss: 8.3305\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2149 - val_loss: 8.3305\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2738 - val_loss: 8.3305\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.5511 - val_loss: 8.3305\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.3262 - val_loss: 8.3305\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2855 - val_loss: 8.3305\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.3319 - val_loss: 8.3305\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 49us/step - loss: 6.2762 - val_loss: 8.3305\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2001 - val_loss: 8.3305\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.4745 - val_loss: 8.3305\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.3313 - val_loss: 8.3305\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2408 - val_loss: 8.3305\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2367 - val_loss: 8.3305\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2787 - val_loss: 8.3305\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 6.225 - 0s 59us/step - loss: 6.2283 - val_loss: 8.3305\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2310 - val_loss: 8.3305\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3721 - val_loss: 8.3305\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.3434 - val_loss: 8.3305\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2978 - val_loss: 8.3305\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.4914 - val_loss: 8.3305\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2762 - val_loss: 8.3305\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.3053 - val_loss: 8.3305\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3484 - val_loss: 8.3305\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.4393 - val_loss: 8.3305\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2964 - val_loss: 8.3305\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2448 - val_loss: 8.3305\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 6.2060 - val_loss: 8.3305\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.4561 - val_loss: 8.3305\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2275 - val_loss: 8.3305\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.1658 - val_loss: 8.3305\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2918 - val_loss: 8.3305\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2979 - val_loss: 8.3305\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2438 - val_loss: 8.3305\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2616 - val_loss: 8.3305\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2649 - val_loss: 8.3305\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.4394 - val_loss: 8.3305\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.3342 - val_loss: 8.3305\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.1937 - val_loss: 8.3305\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.4050 - val_loss: 8.3305\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2689 - val_loss: 8.3305\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2418 - val_loss: 8.3305\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3227 - val_loss: 8.3305\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.3060 - val_loss: 8.3305\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.3844 - val_loss: 8.3305\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2909 - val_loss: 8.3305\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3483 - val_loss: 8.3305\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.1458 - val_loss: 8.3305\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2316 - val_loss: 8.3305\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.2217 - val_loss: 8.3305\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2091 - val_loss: 8.3305\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2465 - val_loss: 8.3305\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.2374 - val_loss: 8.3305\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2517 - val_loss: 8.3305\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3006 - val_loss: 8.3305\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2733 - val_loss: 8.3305\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2442 - val_loss: 8.3305\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2462 - val_loss: 8.3305\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3186 - val_loss: 8.3305\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2547 - val_loss: 8.3305\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2268 - val_loss: 8.3305\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2491 - val_loss: 8.3305\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2564 - val_loss: 8.3305\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.3442 - val_loss: 8.3305\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2222 - val_loss: 8.3305\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2210 - val_loss: 8.3305\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.3198 - val_loss: 8.3305\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2545 - val_loss: 8.3305\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.3167 - val_loss: 8.3305\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2595 - val_loss: 8.3305\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2458 - val_loss: 8.3305\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.2729 - val_loss: 8.3305\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.3813 - val_loss: 8.3305\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2595 - val_loss: 8.3305\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2484 - val_loss: 8.3305\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.3125 - val_loss: 8.3305\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2608 - val_loss: 8.3305\n",
      "Epoch 136/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 53us/step - loss: 6.1914 - val_loss: 8.3305\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2497 - val_loss: 8.3305\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2287 - val_loss: 8.3305\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2309 - val_loss: 8.3305\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3295 - val_loss: 8.3305\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2321 - val_loss: 8.3305\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3388 - val_loss: 8.3305\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2715 - val_loss: 8.3305\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.1746 - val_loss: 8.3305\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2058 - val_loss: 8.3305\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2909 - val_loss: 8.3305\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 6.223 - 0s 51us/step - loss: 6.2770 - val_loss: 8.3305\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2321 - val_loss: 8.3305\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2243 - val_loss: 8.3305\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2222 - val_loss: 8.3305\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2398 - val_loss: 8.3305\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2497 - val_loss: 8.3305\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2392 - val_loss: 8.3305\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2205 - val_loss: 8.3305\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.2582 - val_loss: 8.3305\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2720 - val_loss: 8.3305\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2864 - val_loss: 8.3305\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2362 - val_loss: 8.3305\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2063 - val_loss: 8.3305\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2462 - val_loss: 8.3305\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2692 - val_loss: 8.3305\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2091 - val_loss: 8.3305\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2361 - val_loss: 8.3305\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2494 - val_loss: 8.3305\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2952 - val_loss: 8.3305\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2512 - val_loss: 8.3305\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2947 - val_loss: 8.3305\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2274 - val_loss: 8.3305\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.2138 - val_loss: 8.3305\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2262 - val_loss: 8.3305\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2265 - val_loss: 8.3305\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.2174 - val_loss: 8.3305\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1704 - val_loss: 8.3305\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.3182 - val_loss: 8.3305\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2871 - val_loss: 8.3305\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 6.1682 - val_loss: 8.3305\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2432 - val_loss: 8.3305\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3114 - val_loss: 8.3305\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.1680 - val_loss: 8.3305\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2687 - val_loss: 8.3305\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1471 - val_loss: 8.3305\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2609 - val_loss: 8.3305\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.2483 - val_loss: 8.3305\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2227 - val_loss: 8.3305\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2711 - val_loss: 8.3305\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2670 - val_loss: 8.3305\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2390 - val_loss: 8.3305\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.3157 - val_loss: 8.3305\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2957 - val_loss: 8.3305\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2176 - val_loss: 8.3305\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2702 - val_loss: 8.3305\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.3953 - val_loss: 8.3305\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2409 - val_loss: 8.3305\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2297 - val_loss: 8.3305\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2366 - val_loss: 8.3305\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2511 - val_loss: 8.3305\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2123 - val_loss: 8.3305\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2166 - val_loss: 8.3305\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3128 - val_loss: 8.3305\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.2175 - val_loss: 8.3305\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2927 - val_loss: 8.3305\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3690 - val_loss: 8.3305\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.1868 - val_loss: 8.3305\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2205 - val_loss: 8.3305\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2267 - val_loss: 8.3305\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2502 - val_loss: 8.3305\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2573 - val_loss: 8.3305\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.2527 - val_loss: 8.3305\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3107 - val_loss: 8.3305\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2838 - val_loss: 8.3305\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.2466 - val_loss: 8.3305\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.3658 - val_loss: 8.3305\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1997 - val_loss: 8.3305\n",
      "Epoch 214/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 6.2421 - val_loss: 8.3305\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2537 - val_loss: 8.3305\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2345 - val_loss: 8.3305\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1774 - val_loss: 8.3305\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2076 - val_loss: 8.3305\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2368 - val_loss: 8.3305\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2030 - val_loss: 8.3305\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2200 - val_loss: 8.3305\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.2269 - val_loss: 8.3305\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2041 - val_loss: 8.3305\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2283 - val_loss: 8.3305\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2204 - val_loss: 8.3305\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2026 - val_loss: 8.3305\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2536 - val_loss: 8.3305\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.1745 - val_loss: 8.3305\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2630 - val_loss: 8.3305\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.2719 - val_loss: 8.3305\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.1902 - val_loss: 8.3305\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2079 - val_loss: 8.3305\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2448 - val_loss: 8.3305\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2728 - val_loss: 8.3305\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.1839 - val_loss: 8.3305\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 6.2339 - val_loss: 8.3305\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2197 - val_loss: 8.3305\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2028 - val_loss: 8.3305\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.2696 - val_loss: 8.3305\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 5.369 - 0s 59us/step - loss: 6.2343 - val_loss: 8.3305\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1943 - val_loss: 8.3305\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2301 - val_loss: 8.3305\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2267 - val_loss: 8.3305\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 6.2792 - val_loss: 8.3305\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2614 - val_loss: 8.3305\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2436 - val_loss: 8.3305\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2372 - val_loss: 8.3305\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1735 - val_loss: 8.3305\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2290 - val_loss: 8.3305\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.2018 - val_loss: 8.3305\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2192 - val_loss: 8.3305\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.1700 - val_loss: 8.3305\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 6.2276 - val_loss: 8.3305\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.1980 - val_loss: 8.3305\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2428 - val_loss: 8.3305\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.1719 - val_loss: 8.3305\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2421 - val_loss: 8.3305\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.1909 - val_loss: 8.3305\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2677 - val_loss: 8.3305\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2707 - val_loss: 8.3305\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 6.2377 - val_loss: 8.3305\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2387 - val_loss: 8.3305\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2325 - val_loss: 8.3305\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2218 - val_loss: 8.3305\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2006 - val_loss: 8.3305\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2280 - val_loss: 8.3305\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2000 - val_loss: 8.3305\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2084 - val_loss: 8.3305\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2525 - val_loss: 8.3305\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2691 - val_loss: 8.3305\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2196 - val_loss: 8.3305\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2079 - val_loss: 8.3305\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1643 - val_loss: 8.3305\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2366 - val_loss: 8.3305\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2681 - val_loss: 8.3305\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2091 - val_loss: 8.3305\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.2079 - val_loss: 8.3305\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2079 - val_loss: 8.3305\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2611 - val_loss: 8.3305\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.2155 - val_loss: 8.3305\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2339 - val_loss: 8.3305\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1902 - val_loss: 8.3305\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2871 - val_loss: 8.3305\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2866 - val_loss: 8.3305\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.1437 - val_loss: 8.3305\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2528 - val_loss: 8.3305\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2947 - val_loss: 8.3305\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2111 - val_loss: 8.3305\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2026 - val_loss: 8.3305\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2492 - val_loss: 8.3305\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.1830 - val_loss: 8.3305\n",
      "Epoch 292/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 6.2340 - val_loss: 8.3305\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.1909 - val_loss: 8.3305\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.1638 - val_loss: 8.3305\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1570 - val_loss: 8.3305\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2512 - val_loss: 8.3305\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2413 - val_loss: 8.3305\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1446 - val_loss: 8.3305\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.1795 - val_loss: 8.3305\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2532 - val_loss: 8.3305\n",
      "fridge dw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 13.6057 - val_loss: 15.0648\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5837 - val_loss: 15.0648\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.6303 - val_loss: 15.0648\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6357 - val_loss: 15.0648\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5823 - val_loss: 15.0648\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6955 - val_loss: 15.0648\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.6503 - val_loss: 15.0648\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6636 - val_loss: 15.0648\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.6200 - val_loss: 15.0648\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.6787 - val_loss: 15.0648\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6224 - val_loss: 15.0648\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6189 - val_loss: 15.0648\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.6330 - val_loss: 15.0648\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5634 - val_loss: 15.0648\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.6162 - val_loss: 15.0648\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6548 - val_loss: 15.0648\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.6768 - val_loss: 15.0648\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.6399 - val_loss: 15.0648\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6304 - val_loss: 15.0648\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.6358 - val_loss: 15.0648\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.6656 - val_loss: 15.0648\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5721 - val_loss: 15.0648\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 19.72 - 0s 63us/step - loss: 13.6347 - val_loss: 15.0648\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5913 - val_loss: 15.0648\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5974 - val_loss: 15.0648\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5880 - val_loss: 15.0648\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.6756 - val_loss: 15.0648\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5912 - val_loss: 15.0648\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5646 - val_loss: 15.0648\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5781 - val_loss: 15.0648\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.6558 - val_loss: 15.0648\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.6400 - val_loss: 15.0648\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5760 - val_loss: 15.0648\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6232 - val_loss: 15.0648\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.7029 - val_loss: 15.0648\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6790 - val_loss: 15.0648\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5744 - val_loss: 15.0648\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5733 - val_loss: 15.0648\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.6025 - val_loss: 15.0648\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5678 - val_loss: 15.0648\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6103 - val_loss: 15.0648\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5600 - val_loss: 15.0648\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6666 - val_loss: 15.0648\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6309 - val_loss: 15.0648\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.6338 - val_loss: 15.0648\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.5601 - val_loss: 15.0648\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6466 - val_loss: 15.0648\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6219 - val_loss: 15.0648\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.6288 - val_loss: 15.0648\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.5870 - val_loss: 15.0648\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6091 - val_loss: 15.0648\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5762 - val_loss: 15.0648\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5891 - val_loss: 15.0648\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.6636 - val_loss: 15.0648\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6271 - val_loss: 15.0648\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.6346 - val_loss: 15.0648\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5280 - val_loss: 15.0648\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5904 - val_loss: 15.0648\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5851 - val_loss: 15.0648\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.6568 - val_loss: 15.0648\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5459 - val_loss: 15.0648\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5780 - val_loss: 15.0648\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5992 - val_loss: 15.0648\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.6383 - val_loss: 15.0648\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.6015 - val_loss: 15.0648\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5753 - val_loss: 15.0648\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5885 - val_loss: 15.0648\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5961 - val_loss: 15.0648\n",
      "Epoch 69/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 13.6322 - val_loss: 15.0648\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.6038 - val_loss: 15.0648\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6241 - val_loss: 15.0648\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.6630 - val_loss: 15.0648\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6291 - val_loss: 15.0648\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.6571 - val_loss: 15.0648\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5843 - val_loss: 15.0648\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5814 - val_loss: 15.0648\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5929 - val_loss: 15.0648\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5809 - val_loss: 15.0648\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6078 - val_loss: 15.0648\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5755 - val_loss: 15.0648\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5753 - val_loss: 15.0648\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5773 - val_loss: 15.0648\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5630 - val_loss: 15.0648\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5744 - val_loss: 15.0648\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5999 - val_loss: 15.0648\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5893 - val_loss: 15.0648\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.5833 - val_loss: 15.0648\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5420 - val_loss: 15.0648\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5494 - val_loss: 15.0648\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5924 - val_loss: 15.0648\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5342 - val_loss: 15.0648\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5962 - val_loss: 15.0648\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5935 - val_loss: 15.0648\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.6031 - val_loss: 15.0648\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5798 - val_loss: 15.0648\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5723 - val_loss: 15.0648\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5829 - val_loss: 15.0648\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5820 - val_loss: 15.0648\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5678 - val_loss: 15.0648\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5782 - val_loss: 15.0648\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5755 - val_loss: 15.0648\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5886 - val_loss: 15.0648\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6016 - val_loss: 15.0648\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 13.6141 - val_loss: 15.0648\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5669 - val_loss: 15.0648\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5525 - val_loss: 15.0648\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5712 - val_loss: 15.0648\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5563 - val_loss: 15.0648\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5766 - val_loss: 15.0648\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5464 - val_loss: 15.0648\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5161 - val_loss: 15.0648\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5563 - val_loss: 15.0648\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5624 - val_loss: 15.0648\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5374 - val_loss: 15.0648\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5499 - val_loss: 15.0648\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5523 - val_loss: 15.0648\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5328 - val_loss: 15.0648\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5419 - val_loss: 15.0648\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5549 - val_loss: 15.0648\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5365 - val_loss: 15.0648\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5562 - val_loss: 15.0648\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.5635 - val_loss: 15.0648\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5961 - val_loss: 15.0648\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5726 - val_loss: 15.0648\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5543 - val_loss: 15.0648\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5798 - val_loss: 15.0648\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5323 - val_loss: 15.0648\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.5600 - val_loss: 15.0648\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5844 - val_loss: 15.0648\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 12.17 - 0s 57us/step - loss: 13.5629 - val_loss: 15.0648\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.5607 - val_loss: 15.0648\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5656 - val_loss: 15.0648\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5724 - val_loss: 15.0648\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5579 - val_loss: 15.0648\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5278 - val_loss: 15.0648\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5402 - val_loss: 15.0648\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5406 - val_loss: 15.0648\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5667 - val_loss: 15.0648\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5740 - val_loss: 15.0648\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5510 - val_loss: 15.0648\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5654 - val_loss: 15.0648\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5172 - val_loss: 15.0648\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5711 - val_loss: 15.0648\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5137 - val_loss: 15.0648\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5731 - val_loss: 15.0648\n",
      "Epoch 146/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 58us/step - loss: 13.5437 - val_loss: 15.0648\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.5447 - val_loss: 15.0648\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4939 - val_loss: 15.0648\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5603 - val_loss: 15.0648\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5330 - val_loss: 15.0648\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5575 - val_loss: 15.0648\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5359 - val_loss: 15.0648\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5513 - val_loss: 15.0648\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5333 - val_loss: 15.0648\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5247 - val_loss: 15.0648\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5144 - val_loss: 15.0648\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.5395 - val_loss: 15.0648\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.5224 - val_loss: 15.0648\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5381 - val_loss: 15.0648\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5460 - val_loss: 15.0648\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5330 - val_loss: 15.0648\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5591 - val_loss: 15.0648\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5415 - val_loss: 15.0648\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5264 - val_loss: 15.0648\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5582 - val_loss: 15.0648\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5309 - val_loss: 15.0648\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5237 - val_loss: 15.0648\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.5475 - val_loss: 15.0648\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5292 - val_loss: 15.0648\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5380 - val_loss: 15.0648\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4987 - val_loss: 15.0648\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5244 - val_loss: 15.0648\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5277 - val_loss: 15.0648\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5187 - val_loss: 15.0648\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4890 - val_loss: 15.0648\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5236 - val_loss: 15.0648\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5321 - val_loss: 15.0648\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4980 - val_loss: 15.0648\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5299 - val_loss: 15.0648\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5166 - val_loss: 15.0648\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5036 - val_loss: 15.0648\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5355 - val_loss: 15.0648\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5131 - val_loss: 15.0648\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5242 - val_loss: 15.0648\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4962 - val_loss: 15.0648\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5589 - val_loss: 15.0648\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4853 - val_loss: 15.0648\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5252 - val_loss: 15.0648\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5219 - val_loss: 15.0648\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5365 - val_loss: 15.0648\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5207 - val_loss: 15.0648\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5154 - val_loss: 15.0648\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5363 - val_loss: 15.0648\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4915 - val_loss: 15.0648\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5302 - val_loss: 15.0648\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5242 - val_loss: 15.0648\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4881 - val_loss: 15.0648\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5044 - val_loss: 15.0648\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5001 - val_loss: 15.0648\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5015 - val_loss: 15.0648\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5445 - val_loss: 15.0648\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5005 - val_loss: 15.0648\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5202 - val_loss: 15.0648\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5119 - val_loss: 15.0648\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5231 - val_loss: 15.0648\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4853 - val_loss: 15.0648\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5162 - val_loss: 15.0648\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.5001 - val_loss: 15.0648\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5070 - val_loss: 15.0648\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4980 - val_loss: 15.0648\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.4978 - val_loss: 15.0648\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4998 - val_loss: 15.0648\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5122 - val_loss: 15.0648\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.5247 - val_loss: 15.0648\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5024 - val_loss: 15.0648\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4932 - val_loss: 15.0648\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.4919 - val_loss: 15.0648\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5005 - val_loss: 15.0648\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4986 - val_loss: 15.0648\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5002 - val_loss: 15.0648\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4852 - val_loss: 15.0648\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4875 - val_loss: 15.0648\n",
      "Epoch 223/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 59us/step - loss: 13.4945 - val_loss: 15.0648\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5169 - val_loss: 15.0648\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4815 - val_loss: 15.0648\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4894 - val_loss: 15.0648\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4920 - val_loss: 15.0648\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5020 - val_loss: 15.0648\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4942 - val_loss: 15.0648\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4890 - val_loss: 15.0648\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4884 - val_loss: 15.0648\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4979 - val_loss: 15.0648\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4950 - val_loss: 15.0648\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4974 - val_loss: 15.0648\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4844 - val_loss: 15.0648\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 13.4924 - val_loss: 15.0648\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4857 - val_loss: 15.0648\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4771 - val_loss: 15.0648\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5042 - val_loss: 15.0648\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4728 - val_loss: 15.0648\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4936 - val_loss: 15.0648\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4850 - val_loss: 15.0648\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4801 - val_loss: 15.0648\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4884 - val_loss: 15.0648\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4759 - val_loss: 15.0648\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4794 - val_loss: 15.0648\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 13.4869 - val_loss: 15.0648\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4796 - val_loss: 15.0648\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4845 - val_loss: 15.0648\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4905 - val_loss: 15.0648\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4695 - val_loss: 15.0648\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4752 - val_loss: 15.0648\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4759 - val_loss: 15.0648\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4834 - val_loss: 15.0648\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4836 - val_loss: 15.0648\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4752 - val_loss: 15.0648\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4838 - val_loss: 15.0648\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4723 - val_loss: 15.0648\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4891 - val_loss: 15.0648\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4766 - val_loss: 15.0648\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4626 - val_loss: 15.0648\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4695 - val_loss: 15.0648\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4765 - val_loss: 15.0648\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4660 - val_loss: 15.0648\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4729 - val_loss: 15.0648\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4660 - val_loss: 15.0648\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4707 - val_loss: 15.0648\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4619 - val_loss: 15.0648\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4673 - val_loss: 15.0648\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.4650 - val_loss: 15.0648\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4763 - val_loss: 15.0648\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4657 - val_loss: 15.0648\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4698 - val_loss: 15.0648\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4676 - val_loss: 15.0648\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4651 - val_loss: 15.0648\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4559 - val_loss: 15.0648\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4671 - val_loss: 15.0648\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4625 - val_loss: 15.0648\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4605 - val_loss: 15.0648\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4556 - val_loss: 15.0648\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4621 - val_loss: 15.0648\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 13.4637 - val_loss: 15.0648\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4602 - val_loss: 15.0648\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4615 - val_loss: 15.0648\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4591 - val_loss: 15.0648\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4606 - val_loss: 15.0648\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4552 - val_loss: 15.0648\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4569 - val_loss: 15.0648\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4556 - val_loss: 15.0648\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4536 - val_loss: 15.0648\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4561 - val_loss: 15.0648\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4547 - val_loss: 15.0648\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4540 - val_loss: 15.0648\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4503 - val_loss: 15.0648\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4526 - val_loss: 15.0648\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4555 - val_loss: 15.0648\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4546 - val_loss: 15.0648\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4518 - val_loss: 15.0648\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4497 - val_loss: 15.0648\n",
      "Epoch 300/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 13.4497 - val_loss: 15.0648\n",
      "fridge wm\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 4.7385 - val_loss: 4.3410\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7369 - val_loss: 4.3410\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7349 - val_loss: 4.3410\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7368 - val_loss: 4.3410\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7366 - val_loss: 4.3410\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7362 - val_loss: 4.3410\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7357 - val_loss: 4.3410\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7354 - val_loss: 4.3410\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7341 - val_loss: 4.3410\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7347 - val_loss: 4.3410\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7335 - val_loss: 4.3410\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7333 - val_loss: 4.3410\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7341 - val_loss: 4.3410\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7345 - val_loss: 4.3410\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7335 - val_loss: 4.3410\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7342 - val_loss: 4.3410\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7340 - val_loss: 4.3410\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7338 - val_loss: 4.3410\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 4.7343 - val_loss: 4.3410\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7330 - val_loss: 4.3410\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7334 - val_loss: 4.3410\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7333 - val_loss: 4.3410\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7326 - val_loss: 4.3410\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7329 - val_loss: 4.3410\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7326 - val_loss: 4.3410\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7327 - val_loss: 4.3410\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7324 - val_loss: 4.3410\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7320 - val_loss: 4.3410\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7323 - val_loss: 4.3410\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7323 - val_loss: 4.3410\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7322 - val_loss: 4.3410\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7321 - val_loss: 4.3410\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7318 - val_loss: 4.3410\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7318 - val_loss: 4.3410\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7320 - val_loss: 4.3410\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7320 - val_loss: 4.3410\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7319 - val_loss: 4.3410\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.7318 - val_loss: 4.3410\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7320 - val_loss: 4.3410\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7319 - val_loss: 4.3410\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7317 - val_loss: 4.3410\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7316 - val_loss: 4.3410\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 51us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 5.249 - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7315 - val_loss: 4.3410\n",
      "fridge oven\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 14/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 14.83 - 0s 51us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4587 - val_loss: 13.5165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 15.65 - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 12.20 - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 246/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5165\n",
      "mw hvac\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 861.9242 - val_loss: 874.6758\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 861.9762 - val_loss: 874.6758\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.7585 - val_loss: 874.6758\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 861.6186 - val_loss: 874.6758\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 860.6112 - val_loss: 874.6758\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 858.0036 - val_loss: 874.6758\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 852.9926 - val_loss: 871.7752\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 832.8286 - val_loss: 846.5845\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 794.5749 - val_loss: 799.9317\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 758.5405 - val_loss: 770.9293\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 727.7193 - val_loss: 749.2180\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 662.3269 - val_loss: 676.9463\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 532.7935 - val_loss: 586.8433\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 427.1943 - val_loss: 442.7379\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 358.0813 - val_loss: 265.8217\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 237.9787 - val_loss: 169.9199\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 177.7497 - val_loss: 157.3127\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 156.5977 - val_loss: 151.8613\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 146.8122 - val_loss: 142.1826\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 138.3236 - val_loss: 139.2422\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 139.7172 - val_loss: 139.3657\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 131.3387 - val_loss: 139.3657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 131.0964 - val_loss: 139.3657\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 129.2928 - val_loss: 139.3657\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 135.3942 - val_loss: 139.3657\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 131.5997 - val_loss: 139.3657\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.6124 - val_loss: 139.3657\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.9947 - val_loss: 139.3657\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 129.4012 - val_loss: 139.3657\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.2727 - val_loss: 139.3657\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 130.2130 - val_loss: 139.3657\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.1137 - val_loss: 139.3657\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 128.6601 - val_loss: 139.3657\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 129.0375 - val_loss: 139.3657\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 128.1764 - val_loss: 139.3657\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 131.6646 - val_loss: 139.3657\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.9632 - val_loss: 139.3657\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.8731 - val_loss: 139.3657\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 128.4449 - val_loss: 139.3657\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 129.6453 - val_loss: 139.3657\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.7840 - val_loss: 139.3657\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 129.2250 - val_loss: 139.3657\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 129.4821 - val_loss: 139.3657\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.9248 - val_loss: 139.3657\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6860 - val_loss: 139.3657\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 129.5856 - val_loss: 139.3657\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 130.1164 - val_loss: 139.3657\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.2300 - val_loss: 139.3657\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.6738 - val_loss: 139.3657\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.2180 - val_loss: 139.3657\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 129.1075 - val_loss: 139.3657\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.9589 - val_loss: 139.3657\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.8085 - val_loss: 139.3657\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 129.2697 - val_loss: 139.3657\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 128.5500 - val_loss: 139.3657\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.6560 - val_loss: 139.3657\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.2979 - val_loss: 139.3657\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.6382 - val_loss: 139.3657\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.5196 - val_loss: 139.3657\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.4210 - val_loss: 139.3657\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 127.6996 - val_loss: 139.3657\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.8927 - val_loss: 139.3657\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.0786 - val_loss: 139.3657\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 131.6182 - val_loss: 139.3657\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.6287 - val_loss: 139.3657\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5730 - val_loss: 139.3657\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.0741 - val_loss: 139.3657\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.6932 - val_loss: 139.3657\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 129.2492 - val_loss: 139.3657\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.6184 - val_loss: 139.3657\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.5177 - val_loss: 139.3657\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.6294 - val_loss: 139.3657\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4911 - val_loss: 139.3657\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.7034 - val_loss: 139.3657\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.7583 - val_loss: 139.3657\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 129.1776 - val_loss: 139.3657\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.6712 - val_loss: 139.3657\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.3036 - val_loss: 139.3657\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 128.1023 - val_loss: 139.3657\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.2881 - val_loss: 139.3657\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5256 - val_loss: 139.3657\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.8639 - val_loss: 139.3657\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.4597 - val_loss: 139.3657\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4486 - val_loss: 139.3657\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.5249 - val_loss: 139.3657\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.6207 - val_loss: 139.3657\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.2483 - val_loss: 139.3657\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.7172 - val_loss: 139.3657\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.8696 - val_loss: 139.3657\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.3072 - val_loss: 139.3657\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.7839 - val_loss: 139.3657\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 129.0030 - val_loss: 139.3657\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 129.1125 - val_loss: 139.3657\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 129.7017 - val_loss: 139.3657\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 127.2231 - val_loss: 139.3657\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.5206 - val_loss: 139.3657\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 127.5746 - val_loss: 139.3657\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 128.3374 - val_loss: 139.3657\n",
      "Epoch 99/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 63us/step - loss: 127.3595 - val_loss: 139.3657\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.9808 - val_loss: 139.3657\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 127.5661 - val_loss: 139.3657\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.5685 - val_loss: 139.3657\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 128.4905 - val_loss: 139.3657\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.8537 - val_loss: 139.3657\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.7330 - val_loss: 139.3657\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.3695 - val_loss: 139.3657\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.0555 - val_loss: 139.3657\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.1138 - val_loss: 139.3657\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.9423 - val_loss: 139.3657\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.3830 - val_loss: 139.3657\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.7310 - val_loss: 139.3657\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4085 - val_loss: 139.3657\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.5350 - val_loss: 139.3657\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.8939 - val_loss: 139.3657\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.5625 - val_loss: 139.3657\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 137.055 - 0s 51us/step - loss: 127.8785 - val_loss: 139.3657\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.4285 - val_loss: 139.3657\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5884 - val_loss: 139.3657\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.3830 - val_loss: 139.3657\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.1480 - val_loss: 139.3657\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.3336 - val_loss: 139.3657\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4553 - val_loss: 139.3657\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.9494 - val_loss: 139.3657\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.4014 - val_loss: 139.3657\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.7654 - val_loss: 139.3657\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3247 - val_loss: 139.3657\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 128.1073 - val_loss: 139.3657\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3763 - val_loss: 139.3657\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5711 - val_loss: 139.3657\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.5793 - val_loss: 139.3657\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.2317 - val_loss: 139.3657\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.5377 - val_loss: 139.3657\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.5336 - val_loss: 139.3657\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4254 - val_loss: 139.3657\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.7193 - val_loss: 139.3657\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.6848 - val_loss: 139.3657\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3656 - val_loss: 139.3657\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 129.2205 - val_loss: 139.3657\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.3775 - val_loss: 139.3657\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.7124 - val_loss: 139.3657\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4504 - val_loss: 139.3657\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.3674 - val_loss: 139.3657\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.7378 - val_loss: 139.3657\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.5455 - val_loss: 139.3657\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5031 - val_loss: 139.3657\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.9603 - val_loss: 139.3657\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4805 - val_loss: 139.3657\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6637 - val_loss: 139.3657\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.9090 - val_loss: 139.3657\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.7404 - val_loss: 139.3657\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.3438 - val_loss: 139.3657\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4463 - val_loss: 139.3657\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5849 - val_loss: 139.3657\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.5335 - val_loss: 139.3657\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4465 - val_loss: 139.3657\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.2934 - val_loss: 139.3657\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.6017 - val_loss: 139.3657\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.1913 - val_loss: 139.3657\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.6548 - val_loss: 139.3657\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.1938 - val_loss: 139.3657\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.3325 - val_loss: 139.3657\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.4011 - val_loss: 139.3657\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.7150 - val_loss: 139.3657\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4462 - val_loss: 139.3657\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.5710 - val_loss: 139.3657\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4975 - val_loss: 139.3657\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6044 - val_loss: 139.3657\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.3994 - val_loss: 139.3657\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 127.3779 - val_loss: 139.3657\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5012 - val_loss: 139.3657\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4163 - val_loss: 139.3657\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4425 - val_loss: 139.3657\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.6507 - val_loss: 139.3657\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 127.4637 - val_loss: 139.3657\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 129.8448 - val_loss: 139.3657\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.3785 - val_loss: 139.3657\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.3725 - val_loss: 139.3657\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5214 - val_loss: 139.3657\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 128.0179 - val_loss: 139.3657\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.7565 - val_loss: 139.3657\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.7934 - val_loss: 139.3657\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5383 - val_loss: 139.3657\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 128.4609 - val_loss: 139.3657\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.7191 - val_loss: 139.3657\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4994 - val_loss: 139.3657\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.1475 - val_loss: 139.3657\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.5705 - val_loss: 139.3657\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5232 - val_loss: 139.3657\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 127.4726 - val_loss: 139.3657\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 128.0635 - val_loss: 139.3657\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4461 - val_loss: 139.3657\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4175 - val_loss: 139.3657\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4237 - val_loss: 139.3657\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.6278 - val_loss: 139.3657\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.5477 - val_loss: 139.3657\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4518 - val_loss: 139.3657\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.4690 - val_loss: 139.3657\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.5166 - val_loss: 139.3657\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4216 - val_loss: 139.3657\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.9335 - val_loss: 139.3657\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4461 - val_loss: 139.3657\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3204 - val_loss: 139.3657\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.6500 - val_loss: 139.3657\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4453 - val_loss: 139.3657\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.6520 - val_loss: 139.3657\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.5108 - val_loss: 139.3657\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4440 - val_loss: 139.3657\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.4637 - val_loss: 139.3657\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4066 - val_loss: 139.3657\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.6739 - val_loss: 139.3657\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 127.3512 - val_loss: 139.3657\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4316 - val_loss: 139.3657\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 127.4802 - val_loss: 139.3657\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 131.9085 - val_loss: 139.3657\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5437 - val_loss: 139.3657\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.6340 - val_loss: 139.3657\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.4530 - val_loss: 139.3657\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.3698 - val_loss: 139.3657\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4696 - val_loss: 139.3657\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.3831 - val_loss: 139.3657\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.5440 - val_loss: 139.3657\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3689 - val_loss: 139.3657\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5305 - val_loss: 139.3657\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.3529 - val_loss: 139.3657\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.3262 - val_loss: 139.3657\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.3139 - val_loss: 139.1920\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.6201 - val_loss: 139.1118\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.3290 - val_loss: 139.1266\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.3456 - val_loss: 139.1382\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.2189 - val_loss: 139.0810\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 127.9494 - val_loss: 139.1262\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.3989 - val_loss: 139.1281\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.6996 - val_loss: 139.1688\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5135 - val_loss: 139.1722\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.7279 - val_loss: 139.1656\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 126.9933 - val_loss: 139.0866\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3939 - val_loss: 140.3312\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.4234 - val_loss: 141.0215\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.2935 - val_loss: 141.0457\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5332 - val_loss: 139.9375\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.6832 - val_loss: 139.2540\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.3061 - val_loss: 139.1459\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 127.3859 - val_loss: 139.2283\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.1520 - val_loss: 139.2670\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 129.9097 - val_loss: 139.1612\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4777 - val_loss: 139.1497\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.5915 - val_loss: 139.1833\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.2936 - val_loss: 139.1852\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4868 - val_loss: 139.1073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 128.8834 - val_loss: 139.1428\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.7272 - val_loss: 139.1119\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.5029 - val_loss: 139.0904\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 131.2331 - val_loss: 139.0903\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5221 - val_loss: 139.0783\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.5815 - val_loss: 139.1541\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.2644 - val_loss: 139.2012\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3773 - val_loss: 139.2542\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.4205 - val_loss: 139.3657\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.4609 - val_loss: 139.3657\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 128.2034 - val_loss: 139.3657\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.3435 - val_loss: 139.3657\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.6662 - val_loss: 139.3657\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4011 - val_loss: 139.3657\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.4527 - val_loss: 139.3657\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.5007 - val_loss: 139.3657\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.6127 - val_loss: 139.3657\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5176 - val_loss: 139.3657\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 127.4289 - val_loss: 139.3657\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.3512 - val_loss: 139.3657\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.3231 - val_loss: 139.3657\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.6915 - val_loss: 139.3657\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.3840 - val_loss: 139.3657\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 130.1877 - val_loss: 139.3657\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.4167 - val_loss: 139.3657\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.5948 - val_loss: 139.3657\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.4383 - val_loss: 139.3657\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.4371 - val_loss: 139.3657\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 127.3205 - val_loss: 139.3657\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.3111 - val_loss: 139.3657\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4545 - val_loss: 139.3657\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3797 - val_loss: 139.3657\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.6243 - val_loss: 139.3657\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.2964 - val_loss: 139.3657\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.4999 - val_loss: 139.3657\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.3027 - val_loss: 139.3657\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.2263 - val_loss: 139.3023\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.3575 - val_loss: 139.3509\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.3014 - val_loss: 139.3657\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.3249 - val_loss: 139.3657\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.4282 - val_loss: 139.3657\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.2539 - val_loss: 139.3657\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.2471 - val_loss: 139.3657\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 127.4950 - val_loss: 139.3657\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 127.4503 - val_loss: 139.3612\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.5480 - val_loss: 139.3395\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.1731 - val_loss: 139.2501\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.2618 - val_loss: 139.1578\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 127.3091 - val_loss: 139.1345\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 127.0875 - val_loss: 139.1542\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.5305 - val_loss: 139.2887\n",
      "mw fridge\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 899.6856 - val_loss: 909.0709\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 896.2944 - val_loss: 899.4527\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 885.0230 - val_loss: 882.9043\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 878.1151 - val_loss: 885.4178\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 878.3248 - val_loss: 885.4178\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 877.9866 - val_loss: 885.4178\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 878.1672 - val_loss: 885.4178\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 877.9830 - val_loss: 885.4178\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 877.7551 - val_loss: 885.4178\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 877.9886 - val_loss: 885.4178\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 878.0585 - val_loss: 885.4178\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 878.1326 - val_loss: 885.3522\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 878.2513 - val_loss: 885.4064\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 877.9535 - val_loss: 885.4178\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 878.0454 - val_loss: 885.2334\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 877.5765 - val_loss: 884.4876\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 877.1343 - val_loss: 882.8983\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 874.2546 - val_loss: 877.0625\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 864.7391 - val_loss: 874.5499\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 862.0431 - val_loss: 874.1509\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 851.7357 - val_loss: 868.6561\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 801.0521 - val_loss: 679.8313\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 470.0714 - val_loss: 200.7441\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 225.8159 - val_loss: 138.8659\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 133.8350 - val_loss: 95.8715\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.6024 - val_loss: 94.5328\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 79.7490 - val_loss: 95.4102\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 78.9344 - val_loss: 95.2704\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 77.3920 - val_loss: 95.2044\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 77.6847 - val_loss: 95.3411\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 77.7800 - val_loss: 95.1055\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 77.8557 - val_loss: 95.4133\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 78.4696 - val_loss: 95.0919\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 77.1050 - val_loss: 95.4550\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 77.1425 - val_loss: 95.1983\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 78.0838 - val_loss: 95.0995\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 76.0154 - val_loss: 95.1782\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 75.5752 - val_loss: 95.0806\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 76.6021 - val_loss: 95.2878\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 75.2000 - val_loss: 94.2865\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 76.0540 - val_loss: 93.5102\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 75.6548 - val_loss: 93.4577\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 73.6281 - val_loss: 93.3908\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 73.9426 - val_loss: 93.0498\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 75.1680 - val_loss: 93.2164\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 72.8164 - val_loss: 92.9809\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 75.0926 - val_loss: 92.8523\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 74.5949 - val_loss: 92.9704\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 73.6727 - val_loss: 92.8725\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 73.6936 - val_loss: 92.8636\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 74.0597 - val_loss: 92.9866\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 72.4562 - val_loss: 93.0591\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 74.5686 - val_loss: 93.1115\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 73.4961 - val_loss: 92.8869\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 73.3627 - val_loss: 92.9031\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 73.1885 - val_loss: 93.1757\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 74.3827 - val_loss: 92.9404\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 74.0595 - val_loss: 93.2736\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 73.2876 - val_loss: 92.9044\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 71.4875 - val_loss: 92.8798\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 73.9504 - val_loss: 93.0608\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 75.6032 - val_loss: 92.7528\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 74.3711 - val_loss: 93.0873\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 73.4306 - val_loss: 93.0732\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 75.1370 - val_loss: 92.8189\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 74.1088 - val_loss: 92.8545\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 73.2984 - val_loss: 93.0189\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 72.1545 - val_loss: 93.0958\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 74.3557 - val_loss: 92.9234\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 72.7731 - val_loss: 93.0262\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 72.4270 - val_loss: 93.0623\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 73.4237 - val_loss: 92.9373\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 74.2627 - val_loss: 93.0574\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 73.9015 - val_loss: 93.0267\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 72.0760 - val_loss: 92.9825\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 74.4726 - val_loss: 92.9184\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 71.6565 - val_loss: 93.1866\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 74.7675 - val_loss: 92.8824\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 73.6146 - val_loss: 92.9591\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 71.7531 - val_loss: 93.1918\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 73.1607 - val_loss: 92.8227\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 73.0686 - val_loss: 93.1289\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 73.9844 - val_loss: 92.9749\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 74.2491 - val_loss: 92.7834\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 72.3434 - val_loss: 92.8712\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 74.3965 - val_loss: 93.0394\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 73.2674 - val_loss: 92.7352\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 73.6597 - val_loss: 92.8996\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 73.0438 - val_loss: 92.8090\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 71.9200 - val_loss: 92.8767\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 74.5048 - val_loss: 92.8518\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 74.2419 - val_loss: 92.6508\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 71.2084 - val_loss: 92.6583\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 73.8347 - val_loss: 92.7770\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 72.5289 - val_loss: 92.5765\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 72.3739 - val_loss: 92.8041\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 72.6077 - val_loss: 92.7536\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 74.3079 - val_loss: 92.6525\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 73.0007 - val_loss: 92.6703\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 72.5587 - val_loss: 93.0082\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 73.5905 - val_loss: 92.5178\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 73.2936 - val_loss: 92.3289\n",
      "Epoch 103/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 54us/step - loss: 71.6105 - val_loss: 91.6383\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 71.7387 - val_loss: 92.4535\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 73.9159 - val_loss: 91.5790\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 73.2915 - val_loss: 91.8919\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 73.6737 - val_loss: 92.7364\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 72.9479 - val_loss: 92.7038\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 72.4011 - val_loss: 92.4770\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 73.3299 - val_loss: 91.8882\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 71.9485 - val_loss: 89.9436\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 72.3991 - val_loss: 90.1328\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 72.6288 - val_loss: 90.1047\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 72.8841 - val_loss: 90.1877\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 71.3033 - val_loss: 89.6007\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 70.9653 - val_loss: 89.5046\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.5923 - val_loss: 88.0564\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.4334 - val_loss: 87.8376\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 68.9120 - val_loss: 88.2086\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 69.9737 - val_loss: 87.7931\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 70.7531 - val_loss: 87.8242\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 71.8187 - val_loss: 87.9136\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 69.4693 - val_loss: 87.7983\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 68.6581 - val_loss: 87.9701\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 70.7078 - val_loss: 87.6709\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.7397 - val_loss: 87.6245\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 68.2369 - val_loss: 88.3138\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 69.2953 - val_loss: 88.4809\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 69.4592 - val_loss: 88.2767\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.0700 - val_loss: 88.5263\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 70.1990 - val_loss: 88.5436\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 69.9243 - val_loss: 87.9932\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 70.1250 - val_loss: 87.8083\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 69.3896 - val_loss: 87.9447\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 70.9353 - val_loss: 87.6557\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.9441 - val_loss: 88.2565\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 71.3457 - val_loss: 88.6949\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 69.9447 - val_loss: 88.2551\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 70.0091 - val_loss: 88.7108\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 69.6676 - val_loss: 87.7936\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 69.6219 - val_loss: 87.9557\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.8085 - val_loss: 87.6897\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 69.1682 - val_loss: 88.5012\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.0336 - val_loss: 88.4431\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 71.2455 - val_loss: 88.0464\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.0705 - val_loss: 87.8150\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 70.4550 - val_loss: 88.0438\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.3761 - val_loss: 87.9557\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.4601 - val_loss: 87.7779\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 70.0935 - val_loss: 87.7113\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 69.8076 - val_loss: 87.6455\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.8599 - val_loss: 87.9550\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 69.4053 - val_loss: 88.1660\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 69.6502 - val_loss: 87.8756\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 71.8357 - val_loss: 88.0372\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 70.2753 - val_loss: 87.7189\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 70.4534 - val_loss: 87.6902\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 67.3268 - val_loss: 88.1308\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.6657 - val_loss: 87.6832\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 69.1435 - val_loss: 87.9274\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 69.7878 - val_loss: 87.7055\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.8255 - val_loss: 88.3491\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 68.5513 - val_loss: 88.3229\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 71.0913 - val_loss: 88.0580\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 69.1048 - val_loss: 87.9864\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.2934 - val_loss: 87.5070\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 69.7734 - val_loss: 87.8206\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 69.1524 - val_loss: 87.4829\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 66.9118 - val_loss: 87.5609\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 70.3476 - val_loss: 87.8271\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 69.0225 - val_loss: 87.9608\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.1021 - val_loss: 88.0886\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 68.1928 - val_loss: 88.2982\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 71.3694 - val_loss: 87.8077\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.9765 - val_loss: 88.0471\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 70.8157 - val_loss: 88.3366\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.4606 - val_loss: 87.9280\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.6692 - val_loss: 87.9067\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 67.6104 - val_loss: 88.1151\n",
      "Epoch 180/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 59us/step - loss: 69.3019 - val_loss: 87.7322\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 70.5027 - val_loss: 87.3635\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 69.7444 - val_loss: 87.9248\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 70.6707 - val_loss: 87.3920\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 67.9682 - val_loss: 87.5634\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.0498 - val_loss: 87.5725\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.5160 - val_loss: 87.5535\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 70.0152 - val_loss: 87.7841\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.8743 - val_loss: 88.0590\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 69.2803 - val_loss: 88.1388\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 68.7576 - val_loss: 88.0720\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.9549 - val_loss: 87.8966\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 70.1992 - val_loss: 87.8482\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 68.4904 - val_loss: 87.8643\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 69.0670 - val_loss: 88.0847\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 69.0103 - val_loss: 88.0581\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 70.1126 - val_loss: 88.1858\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.6992 - val_loss: 88.0542\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 66.5882 - val_loss: 87.9256\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.3588 - val_loss: 87.7262\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.0969 - val_loss: 88.0774\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 68.7143 - val_loss: 87.7316\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 69.2357 - val_loss: 87.5896\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 69.5919 - val_loss: 87.8343\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 70.5224 - val_loss: 87.6966\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.3559 - val_loss: 88.0429\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.2636 - val_loss: 88.1482\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 70.1609 - val_loss: 87.9260\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.0175 - val_loss: 87.8939\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 69.6178 - val_loss: 87.9720\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.5115 - val_loss: 87.9061\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 68.3734 - val_loss: 88.0886\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 68.6250 - val_loss: 87.8963\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 68.7701 - val_loss: 88.6905\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 69.1974 - val_loss: 88.2642\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 68.2215 - val_loss: 87.8758\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.8948 - val_loss: 87.8144\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 66.0724 - val_loss: 87.6850\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 69.5615 - val_loss: 87.9210\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 67.9552 - val_loss: 87.7687\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.6422 - val_loss: 87.9706\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 69.1338 - val_loss: 87.9669\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 69.2947 - val_loss: 87.8872\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.8829 - val_loss: 87.9091\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 66.7974 - val_loss: 87.8810\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 67.5793 - val_loss: 87.6613\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.2640 - val_loss: 87.7126\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 65.9257 - val_loss: 87.8787\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.1966 - val_loss: 87.4497\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 67.8236 - val_loss: 87.8004\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 67.5234 - val_loss: 87.6920\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.3423 - val_loss: 87.9987\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 70.5418 - val_loss: 88.3083\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 67.9295 - val_loss: 88.2488\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 66.1161 - val_loss: 87.8478\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.8284 - val_loss: 87.8198\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 67.6466 - val_loss: 87.7382\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 67.3225 - val_loss: 88.1341\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 67.8854 - val_loss: 88.2811\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 68.1350 - val_loss: 88.2992\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 66.5065 - val_loss: 88.1307\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 67.4567 - val_loss: 87.7690\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.9407 - val_loss: 87.9122\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 65.7492 - val_loss: 88.1007\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 67.0815 - val_loss: 88.3317\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 66.7594 - val_loss: 88.3874\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 66.4145 - val_loss: 87.8486\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.7658 - val_loss: 87.9702\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.5131 - val_loss: 87.8718\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.0263 - val_loss: 87.6525\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 67.0247 - val_loss: 87.8326\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.4121 - val_loss: 87.9268\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 69.4530 - val_loss: 87.8424\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.8312 - val_loss: 87.8558\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 69.3874 - val_loss: 88.2291\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.6907 - val_loss: 88.8354\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 68.4686 - val_loss: 88.7676\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 65.6508 - val_loss: 88.3310\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.4470 - val_loss: 88.0045\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 66.6262 - val_loss: 88.1841\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.8431 - val_loss: 88.0720\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 67.2532 - val_loss: 88.2099\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 67.9342 - val_loss: 87.7816\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.7509 - val_loss: 87.6550\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 65.6376 - val_loss: 87.8749\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 67.8276 - val_loss: 88.7764\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.9700 - val_loss: 88.1677\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 67.7905 - val_loss: 87.8556\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.3346 - val_loss: 87.9406\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 66.9576 - val_loss: 87.8332\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 68.4573 - val_loss: 87.6094\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 65.9427 - val_loss: 87.3056\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.7582 - val_loss: 85.3556\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 67.2607 - val_loss: 85.1863\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 66.1724 - val_loss: 85.0423\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 65.8525 - val_loss: 85.1306\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.1897 - val_loss: 85.2567\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.2186 - val_loss: 85.5586\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 65.2496 - val_loss: 84.8771\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 67.5241 - val_loss: 84.9501\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 67.2072 - val_loss: 85.4231\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 64.9787 - val_loss: 85.7802\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 65.4399 - val_loss: 85.3629\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 67.0065 - val_loss: 85.4113\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 66.6722 - val_loss: 85.6733\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 66.8962 - val_loss: 85.1872\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 68.0475 - val_loss: 85.6809\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 66.6211 - val_loss: 85.7032\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 67.5148 - val_loss: 85.3993\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 63.0314 - val_loss: 85.2737\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 66.0915 - val_loss: 85.3040\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 64.9446 - val_loss: 84.7890\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 63.4910 - val_loss: 85.1551\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 65.2217 - val_loss: 85.2826\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 66.3702 - val_loss: 85.5405\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 64.7045 - val_loss: 85.2673\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 66.1654 - val_loss: 85.1004\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 65.4566 - val_loss: 85.1594\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 66.2454 - val_loss: 85.1194\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 65.8022 - val_loss: 85.4176\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 65.9717 - val_loss: 85.1591\n",
      "mw dw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 30.4744 - val_loss: 18.0321\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.8787 - val_loss: 15.5098\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.8607 - val_loss: 15.2835\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.1052 - val_loss: 15.2536\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.1050 - val_loss: 15.2351\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.9379 - val_loss: 15.2171\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.8523 - val_loss: 15.2115\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.7259 - val_loss: 15.2096\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.8008 - val_loss: 15.2090\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.7189 - val_loss: 15.2087\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.7237 - val_loss: 15.2085\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.7145 - val_loss: 15.2083\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.7009 - val_loss: 15.2081\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.6830 - val_loss: 15.2080\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.7186 - val_loss: 15.2079\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.6293 - val_loss: 15.2078\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.6278 - val_loss: 15.2077\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5959 - val_loss: 15.2076\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5867 - val_loss: 15.2075\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.6515 - val_loss: 15.2075\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5554 - val_loss: 15.2074\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5987 - val_loss: 15.2073\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.6036 - val_loss: 15.2073\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6266 - val_loss: 15.2072\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6533 - val_loss: 15.2071\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.6138 - val_loss: 15.2071\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5949 - val_loss: 15.2070\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.6114 - val_loss: 15.2069\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.6551 - val_loss: 15.2068\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5953 - val_loss: 15.2066\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.6699 - val_loss: 15.2065\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.6031 - val_loss: 15.2064\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5745 - val_loss: 15.2060\n",
      "Epoch 34/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 13.5888 - val_loss: 15.2055\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5937 - val_loss: 15.2052\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.6073 - val_loss: 15.2050\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5838 - val_loss: 15.2046\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5750 - val_loss: 15.2044\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5624 - val_loss: 15.2041\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5762 - val_loss: 15.2039\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5898 - val_loss: 15.2037\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5766 - val_loss: 15.2035\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5689 - val_loss: 15.2033\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.5383 - val_loss: 15.2031\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.6070 - val_loss: 15.2030\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5805 - val_loss: 15.2029\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5759 - val_loss: 15.2027\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.5798 - val_loss: 15.2026\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5640 - val_loss: 15.2025\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5441 - val_loss: 15.2023\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5620 - val_loss: 15.2021\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.5492 - val_loss: 15.2018\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5820 - val_loss: 15.2014\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.5275 - val_loss: 15.2011\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.5646 - val_loss: 15.2008\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5862 - val_loss: 15.2003\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.5443 - val_loss: 15.1997\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4987 - val_loss: 15.1990\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5081 - val_loss: 15.1982\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4661 - val_loss: 15.1979\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4794 - val_loss: 15.1977\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5066 - val_loss: 15.1975\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5025 - val_loss: 15.1973\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4841 - val_loss: 15.1970\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4860 - val_loss: 15.1969\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4640 - val_loss: 15.1967\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.4622 - val_loss: 15.1966\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4903 - val_loss: 15.1964\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4592 - val_loss: 15.1964\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5113 - val_loss: 15.1962\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4963 - val_loss: 15.1961\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.5014 - val_loss: 15.1960\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4895 - val_loss: 15.1959\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4841 - val_loss: 15.1958\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5005 - val_loss: 15.1956\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4702 - val_loss: 15.1954\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4766 - val_loss: 15.1951\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4792 - val_loss: 15.1948\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4769 - val_loss: 15.1946\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4670 - val_loss: 15.1945\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4811 - val_loss: 15.1944\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4821 - val_loss: 15.1943\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4717 - val_loss: 15.1941\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4724 - val_loss: 15.1938\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4761 - val_loss: 15.1937\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4562 - val_loss: 15.1936\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4653 - val_loss: 15.1934\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.5051 - val_loss: 15.1932\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4685 - val_loss: 15.1931\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4716 - val_loss: 15.1928\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4729 - val_loss: 15.1924\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4766 - val_loss: 15.1923\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4694 - val_loss: 15.1921\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4958 - val_loss: 15.1920\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4918 - val_loss: 15.1918\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4500 - val_loss: 15.1916\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4712 - val_loss: 15.1915\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4837 - val_loss: 15.1914\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4880 - val_loss: 15.1912\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4847 - val_loss: 15.1910\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4816 - val_loss: 15.1908\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4758 - val_loss: 15.1906\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4865 - val_loss: 15.1903\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4780 - val_loss: 15.1901\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.5006 - val_loss: 15.1899\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.4866 - val_loss: 15.1897\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4792 - val_loss: 15.1896\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4756 - val_loss: 15.1894\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4637 - val_loss: 15.1892\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4896 - val_loss: 15.1889\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4907 - val_loss: 15.1882\n",
      "Epoch 112/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 13.4860 - val_loss: 15.1878\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4682 - val_loss: 15.1877\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4721 - val_loss: 15.1876\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4911 - val_loss: 15.1877\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4697 - val_loss: 15.1875\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4847 - val_loss: 15.1873\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4730 - val_loss: 15.1867\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4878 - val_loss: 15.1863\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4480 - val_loss: 15.1860\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4765 - val_loss: 15.1858\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4841 - val_loss: 15.1860\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4804 - val_loss: 15.1855\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4701 - val_loss: 15.1851\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4870 - val_loss: 15.1848\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4608 - val_loss: 15.1844\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4628 - val_loss: 15.1840\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4593 - val_loss: 15.1834\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4813 - val_loss: 15.1831\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4696 - val_loss: 15.1819\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4575 - val_loss: 15.1811\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4511 - val_loss: 15.1807\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4638 - val_loss: 15.1804\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4493 - val_loss: 15.1799\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4574 - val_loss: 15.1793\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4532 - val_loss: 15.1789\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4640 - val_loss: 15.1785\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4492 - val_loss: 15.1783\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4488 - val_loss: 15.1782\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4638 - val_loss: 15.1780\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4510 - val_loss: 15.1775\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4583 - val_loss: 15.1770\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4506 - val_loss: 15.1767\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.4535 - val_loss: 15.1764\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4552 - val_loss: 15.1763\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4458 - val_loss: 15.1762\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4536 - val_loss: 15.1760\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4645 - val_loss: 15.1758\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.4644 - val_loss: 15.1756\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4616 - val_loss: 15.1756\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4566 - val_loss: 15.1755\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4549 - val_loss: 15.1754\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4721 - val_loss: 15.1754\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4586 - val_loss: 15.1754\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4647 - val_loss: 15.1754\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4591 - val_loss: 15.1751\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4553 - val_loss: 15.1750\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4500 - val_loss: 15.1750\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4535 - val_loss: 15.1750\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.4705 - val_loss: 15.1750\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4613 - val_loss: 15.1749\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4565 - val_loss: 15.1748\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4593 - val_loss: 15.1747\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.4563 - val_loss: 15.1745\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4643 - val_loss: 15.1744\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4718 - val_loss: 15.1744\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4526 - val_loss: 15.1742\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4614 - val_loss: 15.1738\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4592 - val_loss: 15.1737\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4494 - val_loss: 15.1736\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4585 - val_loss: 15.1735\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 12.08 - 0s 59us/step - loss: 13.4481 - val_loss: 15.1734\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.4535 - val_loss: 15.1733\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.4462 - val_loss: 15.1729\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4575 - val_loss: 15.1725\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.4583 - val_loss: 15.1722\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.4503 - val_loss: 15.1722\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4552 - val_loss: 15.1721\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4575 - val_loss: 15.1720\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4521 - val_loss: 15.1716\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4546 - val_loss: 15.1715\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4452 - val_loss: 15.1714\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4530 - val_loss: 15.1714\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.4619 - val_loss: 15.1714\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4525 - val_loss: 15.1713\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4586 - val_loss: 15.1713\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4580 - val_loss: 15.1713\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4667 - val_loss: 15.1713\n",
      "Epoch 189/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 13.4608 - val_loss: 15.1713\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4575 - val_loss: 15.1713\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4669 - val_loss: 15.1712\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4617 - val_loss: 15.1710\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4494 - val_loss: 15.1708\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4619 - val_loss: 15.1708\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4556 - val_loss: 15.1707\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4635 - val_loss: 15.1707\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4533 - val_loss: 15.1707\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4514 - val_loss: 15.1706\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4588 - val_loss: 15.1702\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4657 - val_loss: 15.1699\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4613 - val_loss: 15.1699\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4518 - val_loss: 15.1697\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4528 - val_loss: 15.1697\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4491 - val_loss: 15.1695\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4588 - val_loss: 15.1691\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4543 - val_loss: 15.1690\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4517 - val_loss: 15.1690\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4407 - val_loss: 15.1690\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4572 - val_loss: 15.1690\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4452 - val_loss: 15.1690\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4731 - val_loss: 15.1690\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4621 - val_loss: 15.1690\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4497 - val_loss: 15.1690\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4585 - val_loss: 15.1689\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4584 - val_loss: 15.1687\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4565 - val_loss: 15.1686\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4628 - val_loss: 15.1686\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4708 - val_loss: 15.1685\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4667 - val_loss: 15.1684\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4573 - val_loss: 15.1683\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4620 - val_loss: 15.1683\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4541 - val_loss: 15.1682\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4549 - val_loss: 15.1682\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4577 - val_loss: 15.1682\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4519 - val_loss: 15.1682\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4645 - val_loss: 15.1682\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4548 - val_loss: 15.1680\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4557 - val_loss: 15.1678\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4543 - val_loss: 15.1675\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4511 - val_loss: 15.1673\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4611 - val_loss: 15.1673\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4529 - val_loss: 15.1673\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4592 - val_loss: 15.1671\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4755 - val_loss: 15.1670\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4516 - val_loss: 15.1669\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4571 - val_loss: 15.1669\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4616 - val_loss: 15.1669\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4581 - val_loss: 15.1668\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4525 - val_loss: 15.1666\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4595 - val_loss: 15.1666\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4523 - val_loss: 15.1663\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4556 - val_loss: 15.1662\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4490 - val_loss: 15.1659\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4546 - val_loss: 15.1656\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4511 - val_loss: 15.1655\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4481 - val_loss: 15.1655\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4462 - val_loss: 15.1654\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4659 - val_loss: 15.1654\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4506 - val_loss: 15.1654\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4648 - val_loss: 15.1652\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4476 - val_loss: 15.1650\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4601 - val_loss: 15.1649\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4633 - val_loss: 15.1648\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4488 - val_loss: 15.1647\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4546 - val_loss: 15.1647\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4537 - val_loss: 15.1647\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4606 - val_loss: 15.1647\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4562 - val_loss: 15.1646\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4530 - val_loss: 15.1643\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4577 - val_loss: 15.1643\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4692 - val_loss: 15.1642\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4554 - val_loss: 15.1642\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4535 - val_loss: 15.1642\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4612 - val_loss: 15.1642\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4524 - val_loss: 15.1642\n",
      "Epoch 266/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 13.4567 - val_loss: 15.1642\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4538 - val_loss: 15.1639\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4600 - val_loss: 15.1638\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 13.4496 - val_loss: 15.1638\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4456 - val_loss: 15.1637\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4574 - val_loss: 15.1637\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4517 - val_loss: 15.1637\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4431 - val_loss: 15.1635\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4564 - val_loss: 15.1634\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4570 - val_loss: 15.1634\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4582 - val_loss: 15.1629\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.4605 - val_loss: 15.1626\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4625 - val_loss: 15.1625\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4518 - val_loss: 15.1625\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 13.4640 - val_loss: 15.1624\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.4532 - val_loss: 15.1624\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4534 - val_loss: 15.1624\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4639 - val_loss: 15.1624\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4599 - val_loss: 15.1624\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4571 - val_loss: 15.1623\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4602 - val_loss: 15.1622\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4483 - val_loss: 15.1622\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4531 - val_loss: 15.1622\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4609 - val_loss: 15.1622\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4703 - val_loss: 15.1622\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4520 - val_loss: 15.1622\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4632 - val_loss: 15.1621\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.4551 - val_loss: 15.1620\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4513 - val_loss: 15.1620\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4679 - val_loss: 15.1620\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4529 - val_loss: 15.1620\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.4616 - val_loss: 15.1620\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.4618 - val_loss: 15.1620\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.4567 - val_loss: 15.1620\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.4638 - val_loss: 15.1620\n",
      "mw wm\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 4.7391 - val_loss: 4.4382\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7466 - val_loss: 4.4382\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7372 - val_loss: 4.4382\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7318 - val_loss: 4.4333\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7349 - val_loss: 4.4316\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7408 - val_loss: 4.4265\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7352 - val_loss: 4.4204\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7424 - val_loss: 4.4192\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7383 - val_loss: 4.4188\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7389 - val_loss: 4.4187\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7400 - val_loss: 4.4186\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7279 - val_loss: 4.4186\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7412 - val_loss: 4.4186\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7482 - val_loss: 4.4186\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7333 - val_loss: 4.4186\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7387 - val_loss: 4.4186\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7530 - val_loss: 4.4186\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7377 - val_loss: 4.4186\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7355 - val_loss: 4.4186\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7330 - val_loss: 4.4186\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7363 - val_loss: 4.4144\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7365 - val_loss: 4.4055\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7380 - val_loss: 4.4027\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7385 - val_loss: 4.4019\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7337 - val_loss: 4.4017\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7441 - val_loss: 4.4016\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7350 - val_loss: 4.4016\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7432 - val_loss: 4.4015\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7441 - val_loss: 4.4015\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7371 - val_loss: 4.4015\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7434 - val_loss: 4.4015\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7371 - val_loss: 4.4015\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7383 - val_loss: 4.4015\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.4015\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7349 - val_loss: 4.4015\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.4015\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7315 - val_loss: 4.4015\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7438 - val_loss: 4.4015\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7349 - val_loss: 4.4015\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7457 - val_loss: 4.4015\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7355 - val_loss: 4.4015\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7471 - val_loss: 4.4015\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7305 - val_loss: 4.4015\n",
      "Epoch 44/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 4.7363 - val_loss: 4.4015\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7421 - val_loss: 4.4015\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7445 - val_loss: 4.4015\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7380 - val_loss: 4.4015\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7425 - val_loss: 4.4015\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7469 - val_loss: 4.4015\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7380 - val_loss: 4.4014\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7347 - val_loss: 4.4014\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7437 - val_loss: 4.4014\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7404 - val_loss: 4.4014\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.4014\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 4.7328 - val_loss: 4.4014\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7364 - val_loss: 4.4014\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7343 - val_loss: 4.4014\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7350 - val_loss: 4.4014\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7375 - val_loss: 4.4014\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7366 - val_loss: 4.4014\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7397 - val_loss: 4.4014\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7426 - val_loss: 4.4014\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7397 - val_loss: 4.4014\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7462 - val_loss: 4.4014\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7398 - val_loss: 4.4014\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7370 - val_loss: 4.4014\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7406 - val_loss: 4.4014\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7339 - val_loss: 4.4014\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7345 - val_loss: 4.4014\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7371 - val_loss: 4.4014\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7402 - val_loss: 4.4014\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7375 - val_loss: 4.4014\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7366 - val_loss: 4.4014\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7434 - val_loss: 4.4014\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7394 - val_loss: 4.4014\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7432 - val_loss: 4.4014\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7393 - val_loss: 4.4013\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7394 - val_loss: 4.4013\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7402 - val_loss: 4.4013\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7394 - val_loss: 4.4013\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7372 - val_loss: 4.4013\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7381 - val_loss: 4.4013\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7347 - val_loss: 4.4013\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7396 - val_loss: 4.4013\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7345 - val_loss: 4.4013\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7468 - val_loss: 4.4013\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7351 - val_loss: 4.4013\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7371 - val_loss: 4.4013\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7359 - val_loss: 4.4013\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7368 - val_loss: 4.4013\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7345 - val_loss: 4.4013\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7364 - val_loss: 4.4013\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.4013\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7302 - val_loss: 4.4013\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7381 - val_loss: 4.4013\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7356 - val_loss: 4.4013\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7362 - val_loss: 4.4013\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7430 - val_loss: 4.4013\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.4013\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7359 - val_loss: 4.4013\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7430 - val_loss: 4.4013\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7354 - val_loss: 4.4013\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7339 - val_loss: 4.4013\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7394 - val_loss: 4.4013\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7468 - val_loss: 4.4013\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7436 - val_loss: 4.4012\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7408 - val_loss: 4.4012\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7359 - val_loss: 4.4012\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7339 - val_loss: 4.4012\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7347 - val_loss: 4.4012\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7438 - val_loss: 4.4012\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7431 - val_loss: 4.4012\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7341 - val_loss: 4.4012\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7325 - val_loss: 4.4012\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7383 - val_loss: 4.4012\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7395 - val_loss: 4.4012\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7340 - val_loss: 4.4012\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7349 - val_loss: 4.4012\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7376 - val_loss: 4.4012\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7364 - val_loss: 4.4012\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7363 - val_loss: 4.4012\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7315 - val_loss: 4.4012\n",
      "Epoch 123/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 4.7428 - val_loss: 4.4012\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7348 - val_loss: 4.4012\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7367 - val_loss: 4.4012\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7384 - val_loss: 4.4012\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7399 - val_loss: 4.4012\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7392 - val_loss: 4.4012\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 4.7383 - val_loss: 4.4012\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7351 - val_loss: 4.4012\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7367 - val_loss: 4.4011\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7399 - val_loss: 4.4011\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7354 - val_loss: 4.4011\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7383 - val_loss: 4.4011\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7352 - val_loss: 4.4011\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7374 - val_loss: 4.4011\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.4011\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7332 - val_loss: 4.4011\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7337 - val_loss: 4.4011\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7359 - val_loss: 4.4011\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7425 - val_loss: 4.4011\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7355 - val_loss: 4.4011\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7364 - val_loss: 4.4011\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7357 - val_loss: 4.4011\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7379 - val_loss: 4.4011\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7361 - val_loss: 4.4011\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7349 - val_loss: 4.4011\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7335 - val_loss: 4.4011\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7360 - val_loss: 4.4011\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7378 - val_loss: 4.4011\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7333 - val_loss: 4.4011\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7388 - val_loss: 4.4011\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7388 - val_loss: 4.4011\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7430 - val_loss: 4.4011\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7346 - val_loss: 4.4010\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7335 - val_loss: 4.4010\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7421 - val_loss: 4.4010\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7322 - val_loss: 4.4010\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7425 - val_loss: 4.4010\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7351 - val_loss: 4.4010\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7405 - val_loss: 4.4010\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7332 - val_loss: 4.4010\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7358 - val_loss: 4.4010\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7382 - val_loss: 4.4010\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7364 - val_loss: 4.4010\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7386 - val_loss: 4.4010\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7398 - val_loss: 4.4010\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7328 - val_loss: 4.4010\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7315 - val_loss: 4.4010\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7397 - val_loss: 4.4010\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7369 - val_loss: 4.4010\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7369 - val_loss: 4.4010\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7314 - val_loss: 4.4010\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7371 - val_loss: 4.4010\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7298 - val_loss: 4.4010\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7376 - val_loss: 4.4010\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7385 - val_loss: 4.4010\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7330 - val_loss: 4.4009\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7358 - val_loss: 4.4009\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7340 - val_loss: 4.4009\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7345 - val_loss: 4.4009\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.4009\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7388 - val_loss: 4.4009\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7347 - val_loss: 4.4009\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7332 - val_loss: 4.4009\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7313 - val_loss: 4.4009\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7412 - val_loss: 4.4009\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7364 - val_loss: 4.4009\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7363 - val_loss: 4.4009\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7335 - val_loss: 4.4009\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7329 - val_loss: 4.4009\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7391 - val_loss: 4.4009\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7326 - val_loss: 4.4009\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7348 - val_loss: 4.4009\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7346 - val_loss: 4.4009\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7346 - val_loss: 4.4009\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7371 - val_loss: 4.4009\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7315 - val_loss: 4.4009\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7315 - val_loss: 4.4009\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7330 - val_loss: 4.4009\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7358 - val_loss: 4.4009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7339 - val_loss: 4.4009\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7357 - val_loss: 4.4009\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7336 - val_loss: 4.4009\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7355 - val_loss: 4.4009\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7353 - val_loss: 4.4008\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7337 - val_loss: 4.4008\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7341 - val_loss: 4.4008\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7351 - val_loss: 4.4008\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7329 - val_loss: 4.4008\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7365 - val_loss: 4.4008\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7315 - val_loss: 4.4008\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7301 - val_loss: 4.4008\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7329 - val_loss: 4.4008\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7351 - val_loss: 4.4008\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7363 - val_loss: 4.4008\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7351 - val_loss: 4.4008\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7325 - val_loss: 4.4008\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7359 - val_loss: 4.4008\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7372 - val_loss: 4.4008\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7313 - val_loss: 4.4008\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.4008\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7366 - val_loss: 4.4008\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7332 - val_loss: 4.4008\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7341 - val_loss: 4.4008\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7322 - val_loss: 4.4008\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7358 - val_loss: 4.4008\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7361 - val_loss: 4.4008\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7345 - val_loss: 4.4008\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7300 - val_loss: 4.4008\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7315 - val_loss: 4.4008\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7334 - val_loss: 4.4008\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7340 - val_loss: 4.4008\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7359 - val_loss: 4.4008\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7334 - val_loss: 4.4008\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7316 - val_loss: 4.4008\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7324 - val_loss: 4.4008\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7361 - val_loss: 4.4008\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7353 - val_loss: 4.4007\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7335 - val_loss: 4.4007\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7355 - val_loss: 4.4007\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7360 - val_loss: 4.4007\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7326 - val_loss: 4.4007\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7352 - val_loss: 4.4007\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7367 - val_loss: 4.4007\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7335 - val_loss: 4.4007\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7353 - val_loss: 4.4007\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7340 - val_loss: 4.4007\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7372 - val_loss: 4.4007\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7333 - val_loss: 4.4007\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7318 - val_loss: 4.4007\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7346 - val_loss: 4.4007\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7316 - val_loss: 4.4007\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7325 - val_loss: 4.4007\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7342 - val_loss: 4.4007\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7362 - val_loss: 4.4007\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7352 - val_loss: 4.4007\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7348 - val_loss: 4.4006\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7339 - val_loss: 4.4006\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7340 - val_loss: 4.4006\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7355 - val_loss: 4.4006\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7356 - val_loss: 4.4006\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.4006\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7320 - val_loss: 4.4006\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7312 - val_loss: 4.4006\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7323 - val_loss: 4.4006\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7337 - val_loss: 4.4006\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7327 - val_loss: 4.4006\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7335 - val_loss: 4.4006\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7340 - val_loss: 4.4006\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7351 - val_loss: 4.4006\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7348 - val_loss: 4.4006\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7326 - val_loss: 4.4006\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7328 - val_loss: 4.4006\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7320 - val_loss: 4.4006\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7326 - val_loss: 4.4006\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7342 - val_loss: 4.4006\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7335 - val_loss: 4.4006\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7327 - val_loss: 4.4005\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7317 - val_loss: 4.4005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7315 - val_loss: 4.4005\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7326 - val_loss: 4.4005\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7334 - val_loss: 4.4005\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7327 - val_loss: 4.4005\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7318 - val_loss: 4.4005\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7325 - val_loss: 4.4005\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7329 - val_loss: 4.4005\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7338 - val_loss: 4.4005\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7316 - val_loss: 4.4005\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7339 - val_loss: 4.4005\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7328 - val_loss: 4.4005\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7325 - val_loss: 4.4005\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7343 - val_loss: 4.4005\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7315 - val_loss: 4.4005\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7329 - val_loss: 4.4005\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7321 - val_loss: 4.4005\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7336 - val_loss: 4.4005\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7334 - val_loss: 4.4005\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7325 - val_loss: 4.4005\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7328 - val_loss: 4.4005\n",
      "mw oven\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 14.4576 - val_loss: 13.5760\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4557 - val_loss: 13.5760\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.4572 - val_loss: 13.5760\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4578 - val_loss: 13.5760\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4561 - val_loss: 13.5760\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4567 - val_loss: 13.5760\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4587 - val_loss: 13.5760\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4557 - val_loss: 13.5760\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4577 - val_loss: 13.5760\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4576 - val_loss: 13.5760\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4574 - val_loss: 13.5760\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4586 - val_loss: 13.5760\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4581 - val_loss: 13.5760\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4575 - val_loss: 13.5760\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4581 - val_loss: 13.5760\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4593 - val_loss: 13.5760\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4563 - val_loss: 13.5760\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4577 - val_loss: 13.5760\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4557 - val_loss: 13.5760\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5760\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4583 - val_loss: 13.5760\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4575 - val_loss: 13.5760\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4595 - val_loss: 13.5760\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4566 - val_loss: 13.5761\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4581 - val_loss: 13.5761\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4581 - val_loss: 13.5761\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4585 - val_loss: 13.5761\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4574 - val_loss: 13.5761\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4568 - val_loss: 13.5761\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4581 - val_loss: 13.5761\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4581 - val_loss: 13.5761\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5761\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5761\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4586 - val_loss: 13.5761\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4567 - val_loss: 13.5761\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4574 - val_loss: 13.5761\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4574 - val_loss: 13.5761\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4591 - val_loss: 13.5761\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5761\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4580 - val_loss: 13.5761\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4580 - val_loss: 13.5761\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4552 - val_loss: 13.5761\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4558 - val_loss: 13.5761\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4592 - val_loss: 13.5761\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4594 - val_loss: 13.5761\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4565 - val_loss: 13.5761\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4584 - val_loss: 13.5761\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4580 - val_loss: 13.5761\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4592 - val_loss: 13.5761\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5761\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4558 - val_loss: 13.5761\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4563 - val_loss: 13.5761\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4572 - val_loss: 13.5761\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4580 - val_loss: 13.5761\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4533 - val_loss: 13.5761\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4580 - val_loss: 13.5761\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4579 - val_loss: 13.5761\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4581 - val_loss: 13.5762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4571 - val_loss: 13.5762\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4595 - val_loss: 13.5762\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4563 - val_loss: 13.5762\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4583 - val_loss: 13.5762\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4571 - val_loss: 13.5762\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4591 - val_loss: 13.5762\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4575 - val_loss: 13.5762\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4602 - val_loss: 13.5762\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4576 - val_loss: 13.5762\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4596 - val_loss: 13.5762\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4578 - val_loss: 13.5762\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4596 - val_loss: 13.5762\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4579 - val_loss: 13.5762\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4596 - val_loss: 13.5762\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4567 - val_loss: 13.5762\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4571 - val_loss: 13.5762\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4563 - val_loss: 13.5762\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4575 - val_loss: 13.5762\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4570 - val_loss: 13.5762\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4579 - val_loss: 13.5762\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4553 - val_loss: 13.5762\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5762\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4578 - val_loss: 13.5762\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4574 - val_loss: 13.5762\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4558 - val_loss: 13.5762\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4586 - val_loss: 13.5762\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4585 - val_loss: 13.5762\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4572 - val_loss: 13.5762\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5762\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4582 - val_loss: 13.5762\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4590 - val_loss: 13.5762\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4541 - val_loss: 13.5762\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4576 - val_loss: 13.5762\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4582 - val_loss: 13.5762\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4566 - val_loss: 13.5762\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4609 - val_loss: 13.5762\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4583 - val_loss: 13.5762\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4562 - val_loss: 13.5762\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4574 - val_loss: 13.5762\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4550 - val_loss: 13.5762\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5762\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4568 - val_loss: 13.5762\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4578 - val_loss: 13.5762\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4615 - val_loss: 13.5762\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4578 - val_loss: 13.5762\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4592 - val_loss: 13.5762\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4597 - val_loss: 13.5762\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4585 - val_loss: 13.5762\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4568 - val_loss: 13.5762\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4566 - val_loss: 13.5762\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4568 - val_loss: 13.5763\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4587 - val_loss: 13.5763\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4595 - val_loss: 13.5763\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4568 - val_loss: 13.5763\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4539 - val_loss: 13.5763\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4558 - val_loss: 13.5763\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4577 - val_loss: 13.5763\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4574 - val_loss: 13.5763\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4569 - val_loss: 13.5763\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4579 - val_loss: 13.5763\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4536 - val_loss: 13.5763\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4562 - val_loss: 13.5763\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5763\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4577 - val_loss: 13.5763\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4572 - val_loss: 13.5763\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4554 - val_loss: 13.5763\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4598 - val_loss: 13.5763\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4566 - val_loss: 13.5763\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4573 - val_loss: 13.5763\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4583 - val_loss: 13.5763\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4571 - val_loss: 13.5763\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4570 - val_loss: 13.5763\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4566 - val_loss: 13.5763\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4555 - val_loss: 13.5763\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4566 - val_loss: 13.5763\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4557 - val_loss: 13.5763\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4550 - val_loss: 13.5763\n",
      "Epoch 136/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 14.4551 - val_loss: 13.5763\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5764\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4578 - val_loss: 13.5764\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4565 - val_loss: 13.5764\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5764\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4576 - val_loss: 13.5764\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4576 - val_loss: 13.5764\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4542 - val_loss: 13.5764\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4564 - val_loss: 13.5764\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5764\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4573 - val_loss: 13.5764\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4600 - val_loss: 13.5764\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4572 - val_loss: 13.5764\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4573 - val_loss: 13.5764\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4564 - val_loss: 13.5764\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4570 - val_loss: 13.5764\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4581 - val_loss: 13.5764\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4564 - val_loss: 13.5764\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4563 - val_loss: 13.5764\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4564 - val_loss: 13.5764\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4557 - val_loss: 13.5764\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4573 - val_loss: 13.5764\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4583 - val_loss: 13.5764\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4582 - val_loss: 13.5764\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4551 - val_loss: 13.5764\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4538 - val_loss: 13.5764\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4572 - val_loss: 13.5764\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4563 - val_loss: 13.5764\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4580 - val_loss: 13.5764\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4553 - val_loss: 13.5764\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4524 - val_loss: 13.5764\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4569 - val_loss: 13.5764\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4564 - val_loss: 13.5764\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4549 - val_loss: 13.5765\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4599 - val_loss: 13.5765\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4611 - val_loss: 13.5765\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4557 - val_loss: 13.5765\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4568 - val_loss: 13.5765\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4561 - val_loss: 13.5765\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4600 - val_loss: 13.5765\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4574 - val_loss: 13.5765\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4569 - val_loss: 13.5765\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4597 - val_loss: 13.5765\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4589 - val_loss: 13.5765\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4548 - val_loss: 13.5765\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4639 - val_loss: 13.5765\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4591 - val_loss: 13.5765\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4615 - val_loss: 13.5765\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4592 - val_loss: 13.5765\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4569 - val_loss: 13.5765\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4562 - val_loss: 13.5765\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4548 - val_loss: 13.5765\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4567 - val_loss: 13.5765\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4549 - val_loss: 13.5765\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4584 - val_loss: 13.5765\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4534 - val_loss: 13.5765\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4547 - val_loss: 13.5765\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4550 - val_loss: 13.5765\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4560 - val_loss: 13.5765\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4598 - val_loss: 13.5765\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4553 - val_loss: 13.5765\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4579 - val_loss: 13.5765\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4556 - val_loss: 13.5765\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4574 - val_loss: 13.5765\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4587 - val_loss: 13.5765\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4566 - val_loss: 13.5765\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4546 - val_loss: 13.5765\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4580 - val_loss: 13.5765\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4560 - val_loss: 13.5765\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4580 - val_loss: 13.5765\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4559 - val_loss: 13.5765\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5765\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4581 - val_loss: 13.5765\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4559 - val_loss: 13.5765\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4559 - val_loss: 13.5765\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4573 - val_loss: 13.5765\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4602 - val_loss: 13.5765\n",
      "Epoch 213/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 62us/step - loss: 14.4537 - val_loss: 13.5765\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4593 - val_loss: 13.5765\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4557 - val_loss: 13.5765\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4526 - val_loss: 13.5765\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4563 - val_loss: 13.5766\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4602 - val_loss: 13.5766\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4584 - val_loss: 13.5766\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4549 - val_loss: 13.5766\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4555 - val_loss: 13.5766\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4574 - val_loss: 13.5766\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4498 - val_loss: 13.5766\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4544 - val_loss: 13.5766\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 14.4610 - val_loss: 13.5766\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4567 - val_loss: 13.5766\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4567 - val_loss: 13.5766\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4569 - val_loss: 13.5766\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4567 - val_loss: 13.5766\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4565 - val_loss: 13.5766\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4546 - val_loss: 13.5766\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4535 - val_loss: 13.5766\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4579 - val_loss: 13.5766\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4587 - val_loss: 13.5766\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4586 - val_loss: 13.5766\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4581 - val_loss: 13.5766\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4493 - val_loss: 13.5766\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4594 - val_loss: 13.5766\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4584 - val_loss: 13.5766\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4584 - val_loss: 13.5766\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4594 - val_loss: 13.5766\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4572 - val_loss: 13.5766\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4541 - val_loss: 13.5766\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4566 - val_loss: 13.5766\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5766\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4584 - val_loss: 13.5766\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4546 - val_loss: 13.5766\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4558 - val_loss: 13.5766\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4545 - val_loss: 13.5766\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4597 - val_loss: 13.5766\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4520 - val_loss: 13.5766\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.4539 - val_loss: 13.5766\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4587 - val_loss: 13.5766\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4558 - val_loss: 13.5766\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4582 - val_loss: 13.5766\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4539 - val_loss: 13.5766\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4571 - val_loss: 13.5767\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4553 - val_loss: 13.5767\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4571 - val_loss: 13.5767\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4559 - val_loss: 13.5767\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4538 - val_loss: 13.5767\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4542 - val_loss: 13.5767\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4582 - val_loss: 13.5767\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4538 - val_loss: 13.5767\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4523 - val_loss: 13.5767\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4535 - val_loss: 13.5767\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4571 - val_loss: 13.5767\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4571 - val_loss: 13.5767\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4575 - val_loss: 13.5767\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4543 - val_loss: 13.5767\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4558 - val_loss: 13.5767\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4531 - val_loss: 13.5767\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4565 - val_loss: 13.5767\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4553 - val_loss: 13.5767\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4553 - val_loss: 13.5767\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4622 - val_loss: 13.5767\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4546 - val_loss: 13.5767\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4589 - val_loss: 13.5767\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4605 - val_loss: 13.5767\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4540 - val_loss: 13.5767\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4553 - val_loss: 13.5767\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4580 - val_loss: 13.5767\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4562 - val_loss: 13.5767\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4583 - val_loss: 13.5767\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4552 - val_loss: 13.5767\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4570 - val_loss: 13.5767\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4599 - val_loss: 13.5767\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4542 - val_loss: 13.5767\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4549 - val_loss: 13.5767\n",
      "Epoch 290/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 54us/step - loss: 14.4566 - val_loss: 13.5767\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4587 - val_loss: 13.5767\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4534 - val_loss: 13.5767\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4517 - val_loss: 13.5768\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4584 - val_loss: 13.5768\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4607 - val_loss: 13.5768\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4534 - val_loss: 13.5768\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4583 - val_loss: 13.5768\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4553 - val_loss: 13.5768\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4578 - val_loss: 13.5768\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4586 - val_loss: 13.5768\n",
      "dw hvac\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 861.9235 - val_loss: 874.7399\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 861.9211 - val_loss: 874.7399\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.9225 - val_loss: 874.7399\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9187 - val_loss: 874.7399\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.9262 - val_loss: 874.7399\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.9187 - val_loss: 874.7399\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9186 - val_loss: 874.7400\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.9225 - val_loss: 874.7400\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 861.9214 - val_loss: 874.7400\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9232 - val_loss: 874.7400\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9185 - val_loss: 874.7400\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9245 - val_loss: 874.7400\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9222 - val_loss: 874.7400\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9159 - val_loss: 874.7400\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.9162 - val_loss: 874.7400\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9212 - val_loss: 874.7400\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9194 - val_loss: 874.7400\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.9193 - val_loss: 874.7400\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.9240 - val_loss: 874.7400\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.9206 - val_loss: 874.7400\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9251 - val_loss: 874.7400\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9168 - val_loss: 874.7400\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.9216 - val_loss: 874.7400\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9201 - val_loss: 874.7400\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9251 - val_loss: 874.7400\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9231 - val_loss: 874.7401\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9231 - val_loss: 874.7401\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.9251 - val_loss: 874.7401\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9212 - val_loss: 874.7401\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9187 - val_loss: 874.7401\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.9204 - val_loss: 874.7401\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.9251 - val_loss: 874.7401\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9164 - val_loss: 874.7401\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9219 - val_loss: 874.7401\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9249 - val_loss: 874.7401\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.9142 - val_loss: 874.7401\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9214 - val_loss: 874.7401\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9190 - val_loss: 874.7401\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9127 - val_loss: 874.7401\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.9193 - val_loss: 874.7401\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9232 - val_loss: 874.7401\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.9196 - val_loss: 874.7401\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 861.9159 - val_loss: 874.7401\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9208 - val_loss: 874.7401\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9209 - val_loss: 874.7401\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9251 - val_loss: 874.7402\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9179 - val_loss: 874.7402\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.9165 - val_loss: 874.7402\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9228 - val_loss: 874.7402\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9187 - val_loss: 874.7402\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.9178 - val_loss: 874.7402\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9091 - val_loss: 874.7402\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9047 - val_loss: 874.7402\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9187 - val_loss: 874.7402\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.9144 - val_loss: 874.7438\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.9149 - val_loss: 874.7461\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9212 - val_loss: 874.7469\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9334 - val_loss: 874.7471\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.9158 - val_loss: 874.7472\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.9243 - val_loss: 874.7472\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.9197 - val_loss: 874.7473\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.9179 - val_loss: 874.7630\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9202 - val_loss: 874.7627\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9224 - val_loss: 874.7620\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9234 - val_loss: 874.7618\n",
      "Epoch 66/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 861.9203 - val_loss: 874.7618\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.9251 - val_loss: 874.7617\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9149 - val_loss: 874.7618\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9205 - val_loss: 874.7618\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9170 - val_loss: 874.7618\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.9153 - val_loss: 874.7618\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.9220 - val_loss: 874.7618\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9193 - val_loss: 874.7618\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 861.9206 - val_loss: 874.7618\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9167 - val_loss: 874.7618\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9155 - val_loss: 874.7618\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9219 - val_loss: 874.7618\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.9168 - val_loss: 874.7621\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.2745 - val_loss: 874.7629\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 856.0289 - val_loss: 874.7495\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 850.8211 - val_loss: 863.3612\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 819.2619 - val_loss: 813.7344\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 797.2730 - val_loss: 784.0274\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 728.4395 - val_loss: 695.1776\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 549.9630 - val_loss: 442.0134\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 364.1104 - val_loss: 284.2938\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 237.9959 - val_loss: 204.5708\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 193.2717 - val_loss: 159.1443\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 155.6710 - val_loss: 139.7582\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 158.7347 - val_loss: 139.8432\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 149.9886 - val_loss: 139.8601\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 156.1361 - val_loss: 139.7987\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 171.3425 - val_loss: 139.6974\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 149.8091 - val_loss: 139.5764\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 153.9395 - val_loss: 139.5279\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 147.1973 - val_loss: 139.4950\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 169.0305 - val_loss: 139.4649\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 144.2892 - val_loss: 139.4551\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 147.8362 - val_loss: 139.4015\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 151.9181 - val_loss: 139.3699\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 153.8610 - val_loss: 139.3458\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 142.1579 - val_loss: 139.3319\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 139.7617 - val_loss: 139.3346\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 156.4140 - val_loss: 139.3503\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 144.3589 - val_loss: 139.3550\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 149.8516 - val_loss: 139.3581\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 156.2244 - val_loss: 139.3507\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 143.3865 - val_loss: 139.3609\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 160.1196 - val_loss: 139.3725\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 150.7765 - val_loss: 139.3763\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 147.1791 - val_loss: 139.3715\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 149.8690 - val_loss: 139.3729\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 143.2893 - val_loss: 139.3954\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 140.3292 - val_loss: 139.3881\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 157.8941 - val_loss: 139.4007\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 141.6958 - val_loss: 139.4182\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 140.2337 - val_loss: 139.4619\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 153.4481 - val_loss: 139.4860\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 149.4980 - val_loss: 139.3966\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 142.6395 - val_loss: 139.3640\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 147.9524 - val_loss: 139.3089\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 140.3424 - val_loss: 139.3181\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 135.4950 - val_loss: 139.3657\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 140.7357 - val_loss: 139.3657\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 139.4929 - val_loss: 139.3657\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 145.1706 - val_loss: 139.3657\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 139.7387 - val_loss: 139.3657\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 141.9992 - val_loss: 139.3657\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 137.3016 - val_loss: 139.3657\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 132.0228 - val_loss: 139.3657\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 143.4700 - val_loss: 139.3657\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 132.7154 - val_loss: 139.3657\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 135.0901 - val_loss: 139.3657\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 134.6453 - val_loss: 139.3657\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 132.1150 - val_loss: 139.3657\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 131.7138 - val_loss: 139.3657\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 132.2522 - val_loss: 139.3657\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 131.3266 - val_loss: 139.3657\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 133.4746 - val_loss: 139.3657\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 135.6297 - val_loss: 139.3657\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 138.8938 - val_loss: 139.3657\n",
      "Epoch 142/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 144.9650 - val_loss: 139.3657\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 139.0095 - val_loss: 139.3657\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 134.2741 - val_loss: 139.3657\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 129.6738 - val_loss: 139.3657\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 139.4922 - val_loss: 139.3657\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 132.3607 - val_loss: 139.3657\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 139.5179 - val_loss: 139.3657\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 134.3814 - val_loss: 139.3657\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 136.2983 - val_loss: 139.3657\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 128.4917 - val_loss: 139.3657\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 141.0575 - val_loss: 139.3657\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 136.5170 - val_loss: 139.3657\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 142.5452 - val_loss: 139.3657\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 136.4516 - val_loss: 139.3657\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 136.3900 - val_loss: 139.3657\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 132.6070 - val_loss: 139.3657\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 129.2538 - val_loss: 139.3657\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 135.6330 - val_loss: 139.3657\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 134.2868 - val_loss: 139.3657\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 129.7929 - val_loss: 139.3657\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 130.5830 - val_loss: 139.3657\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 130.8837 - val_loss: 139.3657\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 133.0191 - val_loss: 139.3657\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 133.8406 - val_loss: 139.3657\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 136.7497 - val_loss: 139.3657\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 134.6391 - val_loss: 139.3657\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 136.7148 - val_loss: 139.3657\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 129.3577 - val_loss: 139.3657\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 135.8768 - val_loss: 139.3657\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 144.7235 - val_loss: 139.3657\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 138.9854 - val_loss: 139.3657\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 137.6396 - val_loss: 139.3657\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 131.9182 - val_loss: 139.3657\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 136.0550 - val_loss: 139.3657\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 137.4355 - val_loss: 139.3657\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 135.7352 - val_loss: 139.3657\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 140.0730 - val_loss: 139.3657\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 143.0782 - val_loss: 139.3657\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 140.9565 - val_loss: 139.3657\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 138.0224 - val_loss: 139.3657\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 133.4501 - val_loss: 139.3657\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 135.1863 - val_loss: 139.3657\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 138.3667 - val_loss: 139.3657\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 139.7624 - val_loss: 139.2337\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 132.8093 - val_loss: 139.2536\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 129.9900 - val_loss: 139.2784\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 128.9239 - val_loss: 139.2523\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 137.9497 - val_loss: 139.2762\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 130.3988 - val_loss: 139.3112\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 129.6666 - val_loss: 139.2649\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 128.1527 - val_loss: 139.3071\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 129.5875 - val_loss: 139.3453\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 137.1109 - val_loss: 139.3280\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 136.8767 - val_loss: 139.3308\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 131.9385 - val_loss: 139.3456\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 132.8389 - val_loss: 139.2948\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 131.1526 - val_loss: 139.2871\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 130.2890 - val_loss: 139.2645\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 131.0919 - val_loss: 139.2830\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 136.2416 - val_loss: 139.2973\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 137.5288 - val_loss: 139.3105\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 134.4859 - val_loss: 139.3223\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 136.4300 - val_loss: 139.3198\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 135.7886 - val_loss: 139.2678\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 135.8989 - val_loss: 139.3288\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 144.3130 - val_loss: 139.3657\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 137.4950 - val_loss: 139.3657\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 129.4784 - val_loss: 139.3657\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 130.3890 - val_loss: 139.3657\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 136.5139 - val_loss: 139.3657\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 136.7079 - val_loss: 139.3657\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 130.5141 - val_loss: 139.3657\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 130.8077 - val_loss: 139.3657\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 132.7555 - val_loss: 139.3657\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 135.9887 - val_loss: 139.3657\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 133.5871 - val_loss: 139.3657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 130.4752 - val_loss: 139.3657\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 130.4403 - val_loss: 139.3657\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.6741 - val_loss: 139.2831\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 134.0346 - val_loss: 139.3001\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 129.1111 - val_loss: 139.2721\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 131.0187 - val_loss: 139.2544\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 133.2675 - val_loss: 139.3825\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 129.9981 - val_loss: 139.3670\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 131.1355 - val_loss: 139.5012\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 137.6062 - val_loss: 139.4179\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 131.4330 - val_loss: 139.2918\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 130.0301 - val_loss: 139.3057\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 127.6753 - val_loss: 139.2638\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 127.6963 - val_loss: 139.2928\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 134.4908 - val_loss: 139.3203\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 132.7132 - val_loss: 139.2473\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 136.8735 - val_loss: 139.2277\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 138.3132 - val_loss: 139.2814\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 127.8953 - val_loss: 139.3129\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 134.8242 - val_loss: 139.2277\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 143.1924 - val_loss: 139.2706\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 137.8711 - val_loss: 139.3196\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 130.4253 - val_loss: 139.3431\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 137.3335 - val_loss: 139.2979\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 135.7867 - val_loss: 139.2570\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 132.6351 - val_loss: 139.2539\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 130.4919 - val_loss: 139.2729\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 144.6452 - val_loss: 139.2837\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 133.1770 - val_loss: 139.2792\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 134.0035 - val_loss: 139.3184\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 130.9943 - val_loss: 139.3256\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 141.4128 - val_loss: 139.3254\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 131.2093 - val_loss: 139.3125\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 130.1025 - val_loss: 139.2997\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 139.0062 - val_loss: 139.3142\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 145.2141 - val_loss: 139.2907\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 137.2630 - val_loss: 139.2284\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 130.6695 - val_loss: 139.2457\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 137.0452 - val_loss: 139.3349\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 129.5478 - val_loss: 139.3657\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 127.2169 - val_loss: 139.3657\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 131.3018 - val_loss: 139.3563\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 133.3058 - val_loss: 139.2652\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 128.1713 - val_loss: 139.2286\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 132.2711 - val_loss: 139.2391\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 133.2683 - val_loss: 139.2275\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 135.7536 - val_loss: 139.2514\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 134.7832 - val_loss: 139.2538\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 132.2108 - val_loss: 139.2824\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 134.1259 - val_loss: 139.3501\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 134.0423 - val_loss: 139.3268\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 131.3585 - val_loss: 139.3385\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 137.5670 - val_loss: 139.3192\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 137.8122 - val_loss: 139.3010\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 129.1765 - val_loss: 139.3072\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 135.7912 - val_loss: 139.2957\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 134.1771 - val_loss: 139.2963\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 134.6808 - val_loss: 139.3127\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 137.1955 - val_loss: 139.2850\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 135.1123 - val_loss: 139.2816\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 135.4983 - val_loss: 139.2627\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 132.4569 - val_loss: 139.2354\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 137.0568 - val_loss: 139.2897\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 130.5574 - val_loss: 139.3230\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 132.3896 - val_loss: 139.3046\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 133.2528 - val_loss: 139.2772\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 131.1182 - val_loss: 139.3747\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 135.0200 - val_loss: 139.4272\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 134.0034 - val_loss: 139.2916\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 128.7647 - val_loss: 139.3980\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 127.4764 - val_loss: 139.4236\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 132.3670 - val_loss: 139.4225\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 138.4441 - val_loss: 139.4752\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 142.5632 - val_loss: 139.4077\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 132.9416 - val_loss: 139.3419\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 131.0504 - val_loss: 139.2725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 145.3003 - val_loss: 139.2642\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 128.4039 - val_loss: 139.2850\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 131.0568 - val_loss: 139.2771\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 137.5317 - val_loss: 139.2900\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 131.6208 - val_loss: 139.3244\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 133.0360 - val_loss: 139.3024\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 136.9633 - val_loss: 139.3022\n",
      "dw fridge\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 894.1860 - val_loss: 915.1782\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 891.4570 - val_loss: 913.6342\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 892.9589 - val_loss: 910.4135\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 877.2698 - val_loss: 907.7287\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 879.0900 - val_loss: 907.6354\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 882.4493 - val_loss: 907.4970\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 877.6315 - val_loss: 907.3213\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 873.4431 - val_loss: 906.9806\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 878.7099 - val_loss: 905.5461\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 863.5400 - val_loss: 898.8092\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 851.2999 - val_loss: 881.6731\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 836.9905 - val_loss: 839.1388\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 792.2077 - val_loss: 792.4205\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 732.8464 - val_loss: 726.5053\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 621.1232 - val_loss: 518.6764\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 444.4371 - val_loss: 329.5811\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 309.5796 - val_loss: 246.1932\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 229.1950 - val_loss: 151.5148\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 133.8906 - val_loss: 94.2698\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 101.2165 - val_loss: 97.9480\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 95.7272 - val_loss: 97.8751\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 93.9901 - val_loss: 97.8249\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 93.9031 - val_loss: 97.8241\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 91.9935 - val_loss: 97.8667\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 88.7249 - val_loss: 97.8371\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.4951 - val_loss: 97.7353\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 86.2701 - val_loss: 97.3542\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 85.2532 - val_loss: 96.9307\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 83.9624 - val_loss: 96.6397\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 82.4668 - val_loss: 96.5573\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 82.0692 - val_loss: 96.3706\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 80.2477 - val_loss: 96.1816\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 80.0336 - val_loss: 96.1094\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 78.4582 - val_loss: 96.0535\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.1084 - val_loss: 96.0022\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 79.3062 - val_loss: 96.0119\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.9856 - val_loss: 95.9020\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.5884 - val_loss: 95.9853\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 78.8701 - val_loss: 95.8866\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.9269 - val_loss: 95.9554\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 79.5209 - val_loss: 95.9295\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 78.7534 - val_loss: 95.8689\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 77.5819 - val_loss: 95.9120\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 78.3604 - val_loss: 95.9508\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.3868 - val_loss: 95.8890\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 77.5995 - val_loss: 95.9622\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 77.9290 - val_loss: 95.9888\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 77.3175 - val_loss: 95.8816\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 78.0087 - val_loss: 95.9261\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.2518 - val_loss: 95.8958\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 77.2892 - val_loss: 96.0149\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 77.3550 - val_loss: 95.8937\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 78.7767 - val_loss: 95.9620\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 77.0430 - val_loss: 95.9165\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 77.9842 - val_loss: 95.9959\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 76.9900 - val_loss: 95.8701\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 77.4004 - val_loss: 95.9662\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 76.7570 - val_loss: 95.8785\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 78.3217 - val_loss: 95.8904\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 75.8012 - val_loss: 95.8749\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 76.5155 - val_loss: 95.8304\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 77.4236 - val_loss: 95.9053\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 76.5394 - val_loss: 95.8519\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 75.7195 - val_loss: 95.9766\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 78.0658 - val_loss: 95.9185\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 77.7112 - val_loss: 95.8725\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 76.8140 - val_loss: 95.8204\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 76.9752 - val_loss: 95.8663\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 76.1614 - val_loss: 95.8977\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.1628 - val_loss: 95.8354\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 58us/step - loss: 78.2424 - val_loss: 95.8631\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 75.8568 - val_loss: 95.8662\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 77.0128 - val_loss: 95.8520\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 76.1543 - val_loss: 95.9149\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.4995 - val_loss: 95.9537\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 76.7257 - val_loss: 95.6980\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 76.8749 - val_loss: 95.6935\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 75.7948 - val_loss: 95.6465\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 76.2119 - val_loss: 92.7267\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 75.0213 - val_loss: 93.4564\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 76.3322 - val_loss: 92.6138\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 75.6274 - val_loss: 93.1570\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 73.9298 - val_loss: 92.6843\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 74.2038 - val_loss: 93.4101\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 74.8299 - val_loss: 92.5034\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 75.2823 - val_loss: 93.0872\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 74.3142 - val_loss: 92.4554\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 73.9237 - val_loss: 92.7244\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 75.7384 - val_loss: 92.6463\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 74.1103 - val_loss: 92.7087\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 74.0381 - val_loss: 92.6573\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 74.0631 - val_loss: 92.6692\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 73.8955 - val_loss: 92.9975\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 75.7870 - val_loss: 92.6069\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 74.9240 - val_loss: 92.7319\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 74.8229 - val_loss: 92.4824\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 74.1399 - val_loss: 92.7090\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 75.9564 - val_loss: 92.5562\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 75.5321 - val_loss: 92.9368\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 75.1100 - val_loss: 92.7122\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 74.6378 - val_loss: 92.7811\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 73.1592 - val_loss: 92.3234\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 74.5437 - val_loss: 92.5140\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 73.6731 - val_loss: 92.5667\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 74.5375 - val_loss: 92.5671\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 75.6779 - val_loss: 92.4271\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 72.6667 - val_loss: 92.7452\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 73.7710 - val_loss: 92.4210\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 74.3021 - val_loss: 92.9847\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 73.3669 - val_loss: 92.3208\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 72.9012 - val_loss: 92.4724\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 74.8547 - val_loss: 92.5405\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 74.0525 - val_loss: 92.6530\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 74.4760 - val_loss: 92.4103\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 73.8681 - val_loss: 92.5965\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 73.2725 - val_loss: 92.4906\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 72.4279 - val_loss: 92.4263\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 71.9080 - val_loss: 90.7347\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 72.5188 - val_loss: 88.1220\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 71.1093 - val_loss: 88.5397\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 70.7662 - val_loss: 88.2882\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 71.7472 - val_loss: 88.3687\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 70.4051 - val_loss: 88.5424\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 71.0614 - val_loss: 88.1447\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 71.2645 - val_loss: 88.1478\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 69.6412 - val_loss: 88.5593\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 71.7900 - val_loss: 87.9105\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 71.3862 - val_loss: 88.3813\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.2743 - val_loss: 88.4408\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 72.0497 - val_loss: 88.1899\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.7753 - val_loss: 88.4854\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 72.1421 - val_loss: 87.9116\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.7248 - val_loss: 88.1373\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.1383 - val_loss: 88.3028\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.1089 - val_loss: 88.1619\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 71.2498 - val_loss: 88.2810\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 71.3853 - val_loss: 88.3993\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.0618 - val_loss: 88.1891\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 69.6183 - val_loss: 88.5747\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.8564 - val_loss: 88.0150\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 71.2293 - val_loss: 88.6999\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 70.6632 - val_loss: 88.0110\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 70.1628 - val_loss: 88.3297\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 72.2034 - val_loss: 88.0615\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 70.3544 - val_loss: 88.0221\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 71.7593 - val_loss: 87.8507\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 69.7686 - val_loss: 88.2073\n",
      "Epoch 148/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 61us/step - loss: 70.3751 - val_loss: 88.7555\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 69.5458 - val_loss: 87.7760\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 70.5722 - val_loss: 87.7430\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 71.8219 - val_loss: 88.0638\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 70.1008 - val_loss: 88.2025\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 70.9918 - val_loss: 87.8784\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 70.9907 - val_loss: 88.3038\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 69.6081 - val_loss: 88.1519\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 69.3685 - val_loss: 88.3102\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 70.6419 - val_loss: 88.7519\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 70.5570 - val_loss: 87.7920\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.0701 - val_loss: 88.2838\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 69.0731 - val_loss: 87.9302\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 71.5680 - val_loss: 88.2059\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.7890 - val_loss: 87.9999\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 71.2765 - val_loss: 88.0792\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 70.3946 - val_loss: 87.7778\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 69.8522 - val_loss: 88.2715\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 70.4604 - val_loss: 87.5901\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.8894 - val_loss: 88.4411\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 71.2463 - val_loss: 85.9750\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.9059 - val_loss: 85.4402\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 68.4667 - val_loss: 85.6986\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 69.7522 - val_loss: 85.6860\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 68.3202 - val_loss: 85.5499\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 69.3044 - val_loss: 85.9389\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.2354 - val_loss: 85.6009\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 69.7004 - val_loss: 85.8534\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 69.7200 - val_loss: 85.3325\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.2036 - val_loss: 85.3640\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 68.7287 - val_loss: 85.8859\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 69.1827 - val_loss: 85.1488\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 68.3671 - val_loss: 86.0715\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 70.8404 - val_loss: 85.2541\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.3788 - val_loss: 85.7298\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.8773 - val_loss: 85.4991\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 68.6973 - val_loss: 86.2042\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 69.4748 - val_loss: 85.0535\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 70.7420 - val_loss: 86.2671\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 69.0099 - val_loss: 85.0015\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.4900 - val_loss: 85.6094\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 71.0019 - val_loss: 86.0609\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.5310 - val_loss: 85.3837\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 69.3442 - val_loss: 85.6663\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 69.5178 - val_loss: 85.4479\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.3934 - val_loss: 85.7784\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 70.1060 - val_loss: 85.8148\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 70.0227 - val_loss: 85.6553\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.2770 - val_loss: 85.4332\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 70.4595 - val_loss: 85.8308\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 67.5061 - val_loss: 85.0902\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 69.1340 - val_loss: 85.8345\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.9321 - val_loss: 85.4081\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 69.1917 - val_loss: 85.8441\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.6174 - val_loss: 85.9476\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 68.1710 - val_loss: 84.8787\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 69.9933 - val_loss: 85.9270\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 66.9993 - val_loss: 85.3114\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 66.7450 - val_loss: 85.6635\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 67.3962 - val_loss: 85.5820\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.5586 - val_loss: 86.1079\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.6855 - val_loss: 84.9780\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.4650 - val_loss: 85.9228\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 66.2885 - val_loss: 85.1232\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 67.6449 - val_loss: 85.6320\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 70.9581 - val_loss: 86.0174\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 68.3916 - val_loss: 85.1014\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 69.1835 - val_loss: 85.3564\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 68.3535 - val_loss: 85.2324\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.9631 - val_loss: 85.6410\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.3485 - val_loss: 85.4468\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.4561 - val_loss: 85.5346\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.7991 - val_loss: 85.4366\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 67.6256 - val_loss: 84.8386\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 67.7190 - val_loss: 85.6253\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 68.7402 - val_loss: 85.2019\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.9364 - val_loss: 85.5042\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 66.9127 - val_loss: 85.3151\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 67.0350 - val_loss: 85.4565\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 67.0296 - val_loss: 85.5342\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 68.0920 - val_loss: 85.2077\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.6247 - val_loss: 85.7786\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 66.5391 - val_loss: 85.1006\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.8706 - val_loss: 85.2367\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.0517 - val_loss: 85.5183\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 67.9897 - val_loss: 85.8582\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 68.0448 - val_loss: 85.0073\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 68.1218 - val_loss: 85.5820\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.7074 - val_loss: 85.4056\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.4231 - val_loss: 85.5103\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 65.6850 - val_loss: 85.6548\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.0918 - val_loss: 85.6036\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 67.1798 - val_loss: 85.3852\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 66.0122 - val_loss: 85.9099\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 65.6249 - val_loss: 85.0105\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.9835 - val_loss: 85.5459\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 69.0310 - val_loss: 85.2824\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 66.8513 - val_loss: 85.8503\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 63.85 - 0s 71us/step - loss: 68.6161 - val_loss: 85.2042\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 66.9990 - val_loss: 85.8417\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.9828 - val_loss: 85.1742\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.4630 - val_loss: 85.8656\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 71.26 - 0s 57us/step - loss: 66.0678 - val_loss: 85.4090\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 65.6572 - val_loss: 84.8151\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 66.3882 - val_loss: 86.0934\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 68.7683 - val_loss: 85.2890\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 65.3505 - val_loss: 84.9572\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 68.0716 - val_loss: 85.5639\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.0827 - val_loss: 85.7202\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 66.9748 - val_loss: 84.9106\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.2685 - val_loss: 84.9164\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 67.3126 - val_loss: 85.2233\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.4827 - val_loss: 85.2361\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 67.8395 - val_loss: 85.2365\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 67.9776 - val_loss: 85.4743\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 68.2986 - val_loss: 85.1329\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 68.2205 - val_loss: 85.2980\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 66.3401 - val_loss: 85.2133\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.8950 - val_loss: 84.9379\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.7413 - val_loss: 85.2289\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.6204 - val_loss: 85.4953\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 67.2008 - val_loss: 85.3340\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 66.5720 - val_loss: 85.1019\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 67.5864 - val_loss: 85.4553\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.4310 - val_loss: 85.1652\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.7908 - val_loss: 85.5039\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 66.0218 - val_loss: 84.7825\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 68.5821 - val_loss: 85.3923\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.3638 - val_loss: 85.3888\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 68.8241 - val_loss: 85.5355\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 66.5760 - val_loss: 85.2998\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 66.3392 - val_loss: 84.7834\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 67.1652 - val_loss: 85.4559\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 66.7862 - val_loss: 85.2375\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 67.4514 - val_loss: 85.0157\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.1552 - val_loss: 85.0549\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 67.1099 - val_loss: 85.5657\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.3302 - val_loss: 85.2449\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 65.2717 - val_loss: 85.0362\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 68.6907 - val_loss: 85.3845\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 64.8452 - val_loss: 85.2766\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 67.1737 - val_loss: 85.7028\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 69.3928 - val_loss: 85.5341\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 68.3054 - val_loss: 85.1686\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 67.3905 - val_loss: 85.4909\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 66.6966 - val_loss: 85.7655\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 66.3328 - val_loss: 84.8235\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 68.4083 - val_loss: 85.5567\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 67.3405 - val_loss: 85.1834\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 66.7319 - val_loss: 85.7895\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 66.7156 - val_loss: 84.9618\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 66.9687 - val_loss: 85.8821\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 68.0221 - val_loss: 85.1753\n",
      "dw mw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 4ms/step - loss: 22.6843 - val_loss: 9.0514\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 9.2047 - val_loss: 8.6089\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.7579 - val_loss: 8.5386\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.6473 - val_loss: 8.4987\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.5599 - val_loss: 8.4720\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.4201 - val_loss: 8.4614\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.3216 - val_loss: 8.4478\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2898 - val_loss: 8.4403\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.4208 - val_loss: 8.4361\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.3958 - val_loss: 8.4375\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.3832 - val_loss: 8.4399\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.3292 - val_loss: 8.4414\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.4314 - val_loss: 8.4423\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3512 - val_loss: 8.4421\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3365 - val_loss: 8.4416\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.3186 - val_loss: 8.4412\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2671 - val_loss: 8.4412\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3533 - val_loss: 8.4412\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2869 - val_loss: 8.4412\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3721 - val_loss: 8.4412\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2995 - val_loss: 8.4412\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.3052 - val_loss: 8.4413\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2856 - val_loss: 8.4412\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.1853 - val_loss: 8.4411\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.3082 - val_loss: 8.4410\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 6.2849 - val_loss: 8.4408\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2935 - val_loss: 8.4407\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.3065 - val_loss: 8.4406\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.3212 - val_loss: 8.4406\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3581 - val_loss: 8.4403\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2616 - val_loss: 8.4402\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2616 - val_loss: 8.4402\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2493 - val_loss: 8.4400\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3288 - val_loss: 8.4400\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2379 - val_loss: 8.4399\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2533 - val_loss: 8.4400\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2703 - val_loss: 8.4402\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2808 - val_loss: 8.4404\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2082 - val_loss: 8.4406\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 6.2104 - val_loss: 8.4405\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 6.3356 - val_loss: 8.4404\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 93us/step - loss: 6.2482 - val_loss: 8.4403\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 89us/step - loss: 6.2020 - val_loss: 8.4403\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 6.2007 - val_loss: 8.4402\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 98us/step - loss: 6.3332 - val_loss: 8.4401\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2366 - val_loss: 8.4401\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 6.3242 - val_loss: 8.4400\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2934 - val_loss: 8.4400\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.3257 - val_loss: 8.4400\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 6.2427 - val_loss: 8.4401\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 6.2267 - val_loss: 8.4402\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.3207 - val_loss: 8.4401\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2973 - val_loss: 8.4400\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.3676 - val_loss: 8.4399\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.1513 - val_loss: 8.4399\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 6.2864 - val_loss: 8.4399\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1636 - val_loss: 8.4398\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 6.2068 - val_loss: 8.4397\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2898 - val_loss: 8.4397\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.2019 - val_loss: 8.4399\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3837 - val_loss: 8.4399\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 6.1830 - val_loss: 8.4398\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.1971 - val_loss: 8.4397\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 6.2070 - val_loss: 8.4396\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.2699 - val_loss: 8.4396\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 6.2470 - val_loss: 8.4396\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2509 - val_loss: 8.4397\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1728 - val_loss: 8.4397\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.1875 - val_loss: 8.4399\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2332 - val_loss: 8.4400\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2732 - val_loss: 8.4400\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2532 - val_loss: 8.4400\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2837 - val_loss: 8.4401\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2191 - val_loss: 8.4403\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.1918 - val_loss: 8.4402\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.1871 - val_loss: 8.4400\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2959 - val_loss: 8.4399\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1836 - val_loss: 8.4398\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2118 - val_loss: 8.4397\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 6.2600 - val_loss: 8.4396\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.3104 - val_loss: 8.4396\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3051 - val_loss: 8.4396\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2581 - val_loss: 8.4396\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2055 - val_loss: 8.4396\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2517 - val_loss: 8.4396\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2883 - val_loss: 8.4395\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.1539 - val_loss: 8.4395\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2306 - val_loss: 8.4395\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2902 - val_loss: 8.4395\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.1841 - val_loss: 8.4395\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1797 - val_loss: 8.4395\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3333 - val_loss: 8.4395\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2268 - val_loss: 8.4394\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1839 - val_loss: 8.4393\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2403 - val_loss: 8.4393\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.2325 - val_loss: 8.4393\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2169 - val_loss: 8.4393\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2346 - val_loss: 8.4393\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1807 - val_loss: 8.4394\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.3136 - val_loss: 8.4394\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2479 - val_loss: 8.4394\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2711 - val_loss: 8.4393\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2539 - val_loss: 8.4392\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2144 - val_loss: 8.4391\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2725 - val_loss: 8.4391\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2184 - val_loss: 8.4390\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2392 - val_loss: 8.4390\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2559 - val_loss: 8.4391\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2161 - val_loss: 8.4391\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.1983 - val_loss: 8.4389\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2238 - val_loss: 8.4389\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1969 - val_loss: 8.4387\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.3004 - val_loss: 8.4387\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2290 - val_loss: 8.4384\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 6.2825 - val_loss: 8.4383\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2777 - val_loss: 8.4385\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1568 - val_loss: 8.4386\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2261 - val_loss: 8.4384\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1797 - val_loss: 8.4384\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2460 - val_loss: 8.4389\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2558 - val_loss: 8.4391\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2742 - val_loss: 8.4391\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1931 - val_loss: 8.4391\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2494 - val_loss: 8.4390\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2240 - val_loss: 8.4390\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2634 - val_loss: 8.4389\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2254 - val_loss: 8.4390\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1801 - val_loss: 8.4389\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2468 - val_loss: 8.4386\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1771 - val_loss: 8.4384\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2092 - val_loss: 8.4385\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2151 - val_loss: 8.4384\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2341 - val_loss: 8.4384\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2433 - val_loss: 8.4379\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2194 - val_loss: 8.4379\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2757 - val_loss: 8.4377\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2498 - val_loss: 8.4377\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1809 - val_loss: 8.4378\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2116 - val_loss: 8.4379\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.3082 - val_loss: 8.4379\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.1997 - val_loss: 8.4379\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.1596 - val_loss: 8.4380\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2052 - val_loss: 8.4380\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1910 - val_loss: 8.4380\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1791 - val_loss: 8.4380\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2069 - val_loss: 8.4380\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2992 - val_loss: 8.4380\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2085 - val_loss: 8.4380\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2496 - val_loss: 8.4381\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2390 - val_loss: 8.4380\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2586 - val_loss: 8.4380\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2211 - val_loss: 8.4380\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2787 - val_loss: 8.4380\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2313 - val_loss: 8.4380\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2094 - val_loss: 8.4381\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2658 - val_loss: 8.4381\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1076 - val_loss: 8.4382\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.2435 - val_loss: 8.4383\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 59us/step - loss: 6.2166 - val_loss: 8.4383\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2510 - val_loss: 8.4383\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1644 - val_loss: 8.4383\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2024 - val_loss: 8.4383\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2592 - val_loss: 8.4382\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2517 - val_loss: 8.4382\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2633 - val_loss: 8.4382\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2607 - val_loss: 8.4383\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2756 - val_loss: 8.4384\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2360 - val_loss: 8.4384\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1579 - val_loss: 8.4383\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2756 - val_loss: 8.4382\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2036 - val_loss: 8.4381\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2269 - val_loss: 8.4382\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2074 - val_loss: 8.4383\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2413 - val_loss: 8.4384\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1672 - val_loss: 8.4384\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2034 - val_loss: 8.4384\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.2707 - val_loss: 8.4383\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.1721 - val_loss: 8.4383\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2474 - val_loss: 8.4383\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.1748 - val_loss: 8.4384\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2944 - val_loss: 8.4384\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2586 - val_loss: 8.4383\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1733 - val_loss: 8.4383\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.1967 - val_loss: 8.4382\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.2794 - val_loss: 8.4382\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1244 - val_loss: 8.4382\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1445 - val_loss: 8.4382\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.1821 - val_loss: 8.4383\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 6.2188 - val_loss: 8.4383\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2141 - val_loss: 8.4382\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 6.2170 - val_loss: 8.4381\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 6.2325 - val_loss: 8.4381\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1775 - val_loss: 8.4381\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2706 - val_loss: 8.4381\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.1451 - val_loss: 8.4381\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2370 - val_loss: 8.4382\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 6.2304 - val_loss: 8.4383\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2504 - val_loss: 8.4382\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 6.3141 - val_loss: 8.4382\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1917 - val_loss: 8.4382\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.1582 - val_loss: 8.4383\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.3044 - val_loss: 8.4383\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2511 - val_loss: 8.4383\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2727 - val_loss: 8.4386\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2445 - val_loss: 8.4385\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2773 - val_loss: 8.4386\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2178 - val_loss: 8.4386\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2248 - val_loss: 8.4384\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2703 - val_loss: 8.4384\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1789 - val_loss: 8.4383\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1934 - val_loss: 8.4383\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1907 - val_loss: 8.4383\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2891 - val_loss: 8.4382\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.2005 - val_loss: 8.4382\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2033 - val_loss: 8.4381\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2423 - val_loss: 8.4382\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2129 - val_loss: 8.4383\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2211 - val_loss: 8.4383\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.1633 - val_loss: 8.4391\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.1940 - val_loss: 8.4399\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2463 - val_loss: 8.4409\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2058 - val_loss: 8.4421\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1929 - val_loss: 8.4430\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.1109 - val_loss: 8.4432\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1332 - val_loss: 8.4432\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2349 - val_loss: 8.4447\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.1249 - val_loss: 8.4485\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.0521 - val_loss: 8.4485\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.1702 - val_loss: 8.4485\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2245 - val_loss: 8.4485\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0488 - val_loss: 8.4485\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0639 - val_loss: 8.4485\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.1302 - val_loss: 8.4485\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0400 - val_loss: 8.4484\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.9617 - val_loss: 8.4484\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.1328 - val_loss: 8.4484\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.1153 - val_loss: 8.4484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0760 - val_loss: 8.4484\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.0158 - val_loss: 8.4483\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.1079 - val_loss: 8.4483\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.9404 - val_loss: 8.4483\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.0774 - val_loss: 8.4483\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.1624 - val_loss: 8.4483\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.0120 - val_loss: 8.4483\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.0880 - val_loss: 8.4483\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0081 - val_loss: 8.4482\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.0499 - val_loss: 8.4482\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.0843 - val_loss: 8.4482\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.0262 - val_loss: 8.4482\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.0193 - val_loss: 8.4482\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.9717 - val_loss: 8.4482\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.0068 - val_loss: 8.4482\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.9598 - val_loss: 8.4481\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0263 - val_loss: 8.4481\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.0699 - val_loss: 8.4481\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.0442 - val_loss: 8.4481\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.9975 - val_loss: 8.4481\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0494 - val_loss: 8.4481\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.9896 - val_loss: 8.4481\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.0691 - val_loss: 8.4481\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.1012 - val_loss: 8.4480\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 5.9260 - val_loss: 8.4480\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0481 - val_loss: 8.4480\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.0931 - val_loss: 8.4480\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.9536 - val_loss: 8.4480\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0065 - val_loss: 8.4480\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.9915 - val_loss: 8.4480\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.0534 - val_loss: 8.4480\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.0250 - val_loss: 8.4479\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.9769 - val_loss: 8.4479\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.0115 - val_loss: 8.4479\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.0107 - val_loss: 8.4479\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.9717 - val_loss: 8.4479\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.9819 - val_loss: 8.4479\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.0153 - val_loss: 8.4479\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.0410 - val_loss: 8.4479\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 6.0093 - val_loss: 8.4478\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.0813 - val_loss: 8.4478\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.9156 - val_loss: 8.4478\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.0171 - val_loss: 8.4478\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.8429 - val_loss: 8.4478\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.8625 - val_loss: 8.4478\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.0186 - val_loss: 8.4478\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.0052 - val_loss: 8.4478\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.0986 - val_loss: 8.4478\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 5.9027 - val_loss: 8.4478\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.8380 - val_loss: 8.4478\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.9725 - val_loss: 8.4478\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.0171 - val_loss: 8.4478\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.0910 - val_loss: 8.4478\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.0597 - val_loss: 8.4478\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.9910 - val_loss: 8.4478\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.9674 - val_loss: 8.4478\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.0324 - val_loss: 8.4478\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.9917 - val_loss: 8.4478\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.8742 - val_loss: 8.4478\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.0050 - val_loss: 8.4478\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.0440 - val_loss: 8.4478\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 6.0080 - val_loss: 8.4478\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.9212 - val_loss: 8.4478\n",
      "dw wm\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 5.4526 - val_loss: 4.4980\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.4148 - val_loss: 4.4980\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.3765 - val_loss: 4.4980\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.3903 - val_loss: 4.4979\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.2036 - val_loss: 4.4979\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.2248 - val_loss: 4.4961\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.0894 - val_loss: 4.4824\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.8974 - val_loss: 4.4690\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.8793 - val_loss: 4.4623\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.8269 - val_loss: 4.4601\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.8765 - val_loss: 4.4609\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7860 - val_loss: 4.4604\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.8694 - val_loss: 4.4592\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7909 - val_loss: 4.4580\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.8254 - val_loss: 4.4576\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 4.8031 - val_loss: 4.4575\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.8185 - val_loss: 4.4569\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.8533 - val_loss: 4.4566\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.8589 - val_loss: 4.4558\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.8261 - val_loss: 4.4552\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.8448 - val_loss: 4.4551\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7732 - val_loss: 4.4550\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.8429 - val_loss: 4.4550\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.8272 - val_loss: 4.4544\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.8274 - val_loss: 4.4535\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.8680 - val_loss: 4.4533\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.8498 - val_loss: 4.4520\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7904 - val_loss: 4.4514\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.8609 - val_loss: 4.4512\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.8289 - val_loss: 4.4512\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7600 - val_loss: 4.4505\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.8137 - val_loss: 4.4493\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.8139 - val_loss: 4.4470\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7936 - val_loss: 4.4428\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.8163 - val_loss: 4.4303\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7930 - val_loss: 4.4214\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7943 - val_loss: 4.4181\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7851 - val_loss: 4.4154\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7578 - val_loss: 4.4145\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.8530 - val_loss: 4.4142\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.8083 - val_loss: 4.4141\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7559 - val_loss: 4.4141\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.8143 - val_loss: 4.4141\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7699 - val_loss: 4.4141\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7807 - val_loss: 4.4141\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7704 - val_loss: 4.4141\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.8192 - val_loss: 4.4141\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7645 - val_loss: 4.4141\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7945 - val_loss: 4.4141\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.8007 - val_loss: 4.4134\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.8261 - val_loss: 4.4113\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.8070 - val_loss: 4.4106\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7877 - val_loss: 4.4105\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.8199 - val_loss: 4.4104\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.8126 - val_loss: 4.4104\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.8050 - val_loss: 4.4104\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.8322 - val_loss: 4.4104\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7748 - val_loss: 4.4104\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7913 - val_loss: 4.4104\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.8001 - val_loss: 4.4104\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.8181 - val_loss: 4.4103\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7722 - val_loss: 4.4103\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7436 - val_loss: 4.4103\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.8104 - val_loss: 4.4103\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7992 - val_loss: 4.4103\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7734 - val_loss: 4.4103\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7888 - val_loss: 4.4103\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7696 - val_loss: 4.4103\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.8137 - val_loss: 4.4103\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7585 - val_loss: 4.4103\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7715 - val_loss: 4.4103\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.8027 - val_loss: 4.4103\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7794 - val_loss: 4.4103\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.8008 - val_loss: 4.4103\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7829 - val_loss: 4.4103\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7714 - val_loss: 4.4103\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7615 - val_loss: 4.4103\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7765 - val_loss: 4.4103\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7864 - val_loss: 4.4103\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.8071 - val_loss: 4.4103\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7972 - val_loss: 4.4103\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7733 - val_loss: 4.4103\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7745 - val_loss: 4.4103\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7504 - val_loss: 4.4103\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7858 - val_loss: 4.4103\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7743 - val_loss: 4.4103\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7974 - val_loss: 4.4103\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7998 - val_loss: 4.4103\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7750 - val_loss: 4.4103\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7467 - val_loss: 4.4103\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.8020 - val_loss: 4.4103\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7976 - val_loss: 4.4102\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7615 - val_loss: 4.4102\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7751 - val_loss: 4.4102\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 4.7637 - val_loss: 4.4102\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.8087 - val_loss: 4.4102\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7626 - val_loss: 4.4102\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7772 - val_loss: 4.4102\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7718 - val_loss: 4.4102\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7563 - val_loss: 4.4102\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7512 - val_loss: 4.4102\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7954 - val_loss: 4.4102\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7790 - val_loss: 4.4102\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.8031 - val_loss: 4.4102\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7745 - val_loss: 4.4102\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7864 - val_loss: 4.4102\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7880 - val_loss: 4.4102\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7815 - val_loss: 4.4102\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7721 - val_loss: 4.4102\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7750 - val_loss: 4.4102\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7869 - val_loss: 4.4102\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7957 - val_loss: 4.4102\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7823 - val_loss: 4.4102\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7876 - val_loss: 4.4102\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7954 - val_loss: 4.4102\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7640 - val_loss: 4.4102\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 4.8031 - val_loss: 4.4102\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7776 - val_loss: 4.4102\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7760 - val_loss: 4.4101\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7789 - val_loss: 4.4101\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7770 - val_loss: 4.4101\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7832 - val_loss: 4.4101\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7793 - val_loss: 4.4101\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7578 - val_loss: 4.4101\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7464 - val_loss: 4.4101\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7749 - val_loss: 4.4101\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7795 - val_loss: 4.4101\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7920 - val_loss: 4.4101\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7673 - val_loss: 4.4101\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7474 - val_loss: 4.4101\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.8198 - val_loss: 4.4101\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7773 - val_loss: 4.4101\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.8073 - val_loss: 4.4101\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7705 - val_loss: 4.4101\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.8174 - val_loss: 4.4101\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7861 - val_loss: 4.4101\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7645 - val_loss: 4.4101\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7964 - val_loss: 4.4101\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7948 - val_loss: 4.4101\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7522 - val_loss: 4.4101\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7813 - val_loss: 4.4101\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7633 - val_loss: 4.4100\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7848 - val_loss: 4.4100\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.8055 - val_loss: 4.4100\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7870 - val_loss: 4.4100\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7664 - val_loss: 4.4100\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.8084 - val_loss: 4.4100\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.8101 - val_loss: 4.4100\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7620 - val_loss: 4.4100\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7749 - val_loss: 4.4100\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7752 - val_loss: 4.4100\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7777 - val_loss: 4.4100\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.8000 - val_loss: 4.4100\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.8156 - val_loss: 4.4100\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.8060 - val_loss: 4.4100\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7851 - val_loss: 4.4100\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.8018 - val_loss: 4.4100\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7693 - val_loss: 4.4100\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7870 - val_loss: 4.4099\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7942 - val_loss: 4.4099\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.8053 - val_loss: 4.4099\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7549 - val_loss: 4.4099\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7619 - val_loss: 4.4099\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7844 - val_loss: 4.4099\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7786 - val_loss: 4.4099\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7974 - val_loss: 4.4099\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7828 - val_loss: 4.4099\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.8064 - val_loss: 4.4099\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7743 - val_loss: 4.4099\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7874 - val_loss: 4.4099\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.8105 - val_loss: 4.4099\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7775 - val_loss: 4.4099\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7811 - val_loss: 4.4099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7680 - val_loss: 4.4098\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7850 - val_loss: 4.4098\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7618 - val_loss: 4.4098\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.8038 - val_loss: 4.4098\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7753 - val_loss: 4.4098\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7431 - val_loss: 4.4098\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7608 - val_loss: 4.4098\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7798 - val_loss: 4.4098\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7620 - val_loss: 4.4098\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7673 - val_loss: 4.4098\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7860 - val_loss: 4.4098\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7721 - val_loss: 4.4098\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7572 - val_loss: 4.4098\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7762 - val_loss: 4.4098\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7758 - val_loss: 4.4098\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7527 - val_loss: 4.4098\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7798 - val_loss: 4.4098\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7587 - val_loss: 4.4098\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7679 - val_loss: 4.4098\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7681 - val_loss: 4.4098\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7965 - val_loss: 4.4098\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7643 - val_loss: 4.4097\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7398 - val_loss: 4.4097\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.8006 - val_loss: 4.4097\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7719 - val_loss: 4.4097\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7927 - val_loss: 4.4097\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7609 - val_loss: 4.4097\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7582 - val_loss: 4.4097\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7873 - val_loss: 4.4097\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7665 - val_loss: 4.4097\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7747 - val_loss: 4.4097\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7685 - val_loss: 4.4097\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7584 - val_loss: 4.4097\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7763 - val_loss: 4.4097\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7706 - val_loss: 4.4097\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7721 - val_loss: 4.4097\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7882 - val_loss: 4.4097\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7970 - val_loss: 4.4097\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7929 - val_loss: 4.4097\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7799 - val_loss: 4.4096\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7866 - val_loss: 4.4096\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7666 - val_loss: 4.4096\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 4.7656 - val_loss: 4.4096\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.8031 - val_loss: 4.4096\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7739 - val_loss: 4.4096\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.8038 - val_loss: 4.4096\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7569 - val_loss: 4.4096\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7681 - val_loss: 4.4096\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7557 - val_loss: 4.4096\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7638 - val_loss: 4.4096\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7609 - val_loss: 4.4096\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7663 - val_loss: 4.4096\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7504 - val_loss: 4.4096\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7678 - val_loss: 4.4096\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7528 - val_loss: 4.4096\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7448 - val_loss: 4.4096\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7575 - val_loss: 4.4096\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7632 - val_loss: 4.4096\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7692 - val_loss: 4.4095\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7829 - val_loss: 4.4095\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7548 - val_loss: 4.4095\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7592 - val_loss: 4.4095\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7598 - val_loss: 4.4095\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7838 - val_loss: 4.4095\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7688 - val_loss: 4.4095\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7615 - val_loss: 4.4095\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7627 - val_loss: 4.4095\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7682 - val_loss: 4.4095\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7830 - val_loss: 4.4095\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7806 - val_loss: 4.4095\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7802 - val_loss: 4.4095\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7851 - val_loss: 4.4095\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7622 - val_loss: 4.4095\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7787 - val_loss: 4.4095\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7788 - val_loss: 4.4094\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 4.7652 - val_loss: 4.4094\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7583 - val_loss: 4.4094\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7523 - val_loss: 4.4094\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 4.7728 - val_loss: 4.4094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7576 - val_loss: 4.4094\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7665 - val_loss: 4.4094\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7356 - val_loss: 4.4094\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7604 - val_loss: 4.4094\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7699 - val_loss: 4.4094\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7711 - val_loss: 4.4094\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7655 - val_loss: 4.4094\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7679 - val_loss: 4.4094\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7911 - val_loss: 4.4094\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7567 - val_loss: 4.4094\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7458 - val_loss: 4.4094\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7767 - val_loss: 4.4094\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7588 - val_loss: 4.4094\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7693 - val_loss: 4.4094\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7543 - val_loss: 4.4093\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7869 - val_loss: 4.4093\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7450 - val_loss: 4.4093\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7710 - val_loss: 4.4093\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 4.7747 - val_loss: 4.4093\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7606 - val_loss: 4.4093\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7601 - val_loss: 4.4093\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7411 - val_loss: 4.4093\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7607 - val_loss: 4.4093\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7729 - val_loss: 4.4093\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7575 - val_loss: 4.4093\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7547 - val_loss: 4.4093\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7511 - val_loss: 4.4093\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7556 - val_loss: 4.4093\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7702 - val_loss: 4.4093\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7622 - val_loss: 4.4093\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7624 - val_loss: 4.4093\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7678 - val_loss: 4.4093\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7660 - val_loss: 4.4092\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 4.7704 - val_loss: 4.4092\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7630 - val_loss: 4.4092\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7566 - val_loss: 4.4092\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 4.7606 - val_loss: 4.4092\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7541 - val_loss: 4.4092\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7626 - val_loss: 4.4092\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7699 - val_loss: 4.4092\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 4.7542 - val_loss: 4.4092\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7457 - val_loss: 4.4092\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 4.7688 - val_loss: 4.4092\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 4.7666 - val_loss: 4.4092\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 4.7615 - val_loss: 4.4092\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 4.7594 - val_loss: 4.4092\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 4.7741 - val_loss: 4.4092\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 4.7583 - val_loss: 4.4091\n",
      "dw oven\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 14.4358 - val_loss: 13.5847\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4608 - val_loss: 13.5846\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4510 - val_loss: 13.5846\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4208 - val_loss: 13.5847\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4262 - val_loss: 13.5847\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4626 - val_loss: 13.5847\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4047 - val_loss: 13.5847\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4189 - val_loss: 13.5847\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4310 - val_loss: 13.5847\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4546 - val_loss: 13.5847\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4353 - val_loss: 13.5847\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4409 - val_loss: 13.5847\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4405 - val_loss: 13.5847\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4571 - val_loss: 13.5847\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4590 - val_loss: 13.5847\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4353 - val_loss: 13.5847\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4256 - val_loss: 13.5847\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4537 - val_loss: 13.5847\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4403 - val_loss: 13.5847\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4252 - val_loss: 13.5847\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4374 - val_loss: 13.5847\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4460 - val_loss: 13.5847\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4494 - val_loss: 13.5847\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4460 - val_loss: 13.5848\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4295 - val_loss: 13.5848\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4306 - val_loss: 13.5848\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4327 - val_loss: 13.5848\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4364 - val_loss: 13.5848\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4385 - val_loss: 13.5848\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4412 - val_loss: 13.5848\n",
      "Epoch 31/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 14.4361 - val_loss: 13.5848\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4432 - val_loss: 13.5848\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4539 - val_loss: 13.5848\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4593 - val_loss: 13.5848\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4400 - val_loss: 13.5848\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4280 - val_loss: 13.5848\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4628 - val_loss: 13.5848\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4336 - val_loss: 13.5848\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4219 - val_loss: 13.5848\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4387 - val_loss: 13.5848\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4182 - val_loss: 13.5848\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4455 - val_loss: 13.5848\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4199 - val_loss: 13.5848\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4629 - val_loss: 13.5848\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4602 - val_loss: 13.5848\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4488 - val_loss: 13.5848\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4378 - val_loss: 13.5849\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4245 - val_loss: 13.5849\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4462 - val_loss: 13.5849\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4357 - val_loss: 13.5849\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4449 - val_loss: 13.5849\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4541 - val_loss: 13.5849\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4326 - val_loss: 13.5849\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4388 - val_loss: 13.5849\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4487 - val_loss: 13.5849\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4192 - val_loss: 13.5849\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 14.4282 - val_loss: 13.5849\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4453 - val_loss: 13.5849\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4352 - val_loss: 13.5849\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4431 - val_loss: 13.5849\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4195 - val_loss: 13.5849\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4354 - val_loss: 13.5849\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4474 - val_loss: 13.5849\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4201 - val_loss: 13.5849\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4369 - val_loss: 13.5849\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4605 - val_loss: 13.5849\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4378 - val_loss: 13.5849\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4443 - val_loss: 13.5849\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4348 - val_loss: 13.5849\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4438 - val_loss: 13.5850\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4303 - val_loss: 13.5850\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4492 - val_loss: 13.5850\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4530 - val_loss: 13.5850\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4542 - val_loss: 13.5850\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4403 - val_loss: 13.5850\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4565 - val_loss: 13.5850\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4464 - val_loss: 13.5850\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4407 - val_loss: 13.5850\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4424 - val_loss: 13.5850\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4573 - val_loss: 13.5850\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4322 - val_loss: 13.5850\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4718 - val_loss: 13.5850\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4290 - val_loss: 13.5850\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4411 - val_loss: 13.5850\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4315 - val_loss: 13.5850\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4190 - val_loss: 13.5850\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4252 - val_loss: 13.5850\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4350 - val_loss: 13.5850\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4293 - val_loss: 13.5850\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4386 - val_loss: 13.5850\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4241 - val_loss: 13.5850\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4299 - val_loss: 13.5850\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4260 - val_loss: 13.5850\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4382 - val_loss: 13.5850\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4333 - val_loss: 13.5851\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4335 - val_loss: 13.5851\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4583 - val_loss: 13.5851\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4543 - val_loss: 13.5851\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4385 - val_loss: 13.5851\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4374 - val_loss: 13.5851\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4418 - val_loss: 13.5851\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4400 - val_loss: 13.5851\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4245 - val_loss: 13.5851\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4136 - val_loss: 13.5851\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4474 - val_loss: 13.5851\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4437 - val_loss: 13.5851\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4523 - val_loss: 13.5851\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4321 - val_loss: 13.5851\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 14.4280 - val_loss: 13.5851\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4235 - val_loss: 13.5851\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4078 - val_loss: 13.5851\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4536 - val_loss: 13.5851\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4399 - val_loss: 13.5851\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4339 - val_loss: 13.5851\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4071 - val_loss: 13.5851\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4501 - val_loss: 13.5851\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4289 - val_loss: 13.5851\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4439 - val_loss: 13.5851\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4451 - val_loss: 13.5852\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4404 - val_loss: 13.5852\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4521 - val_loss: 13.5852\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4570 - val_loss: 13.5852\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4342 - val_loss: 13.5852\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4395 - val_loss: 13.5852\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 14.4111 - val_loss: 13.5852\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4246 - val_loss: 13.5852\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4475 - val_loss: 13.5852\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4525 - val_loss: 13.5852\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4267 - val_loss: 13.5852\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4333 - val_loss: 13.5852\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4647 - val_loss: 13.5852\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4196 - val_loss: 13.5852\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4245 - val_loss: 13.5852\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4476 - val_loss: 13.5852\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4251 - val_loss: 13.5852\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4341 - val_loss: 13.5852\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4262 - val_loss: 13.5852\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4495 - val_loss: 13.5852\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4296 - val_loss: 13.5852\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4517 - val_loss: 13.5852\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4432 - val_loss: 13.5852\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4345 - val_loss: 13.5852\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4388 - val_loss: 13.5852\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4372 - val_loss: 13.5852\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4508 - val_loss: 13.5852\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4251 - val_loss: 13.5852\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4406 - val_loss: 13.5852\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4444 - val_loss: 13.5853\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4294 - val_loss: 13.5853\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4483 - val_loss: 13.5853\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4228 - val_loss: 13.5853\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4376 - val_loss: 13.5853\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4136 - val_loss: 13.5853\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4370 - val_loss: 13.5853\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4162 - val_loss: 13.5853\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4350 - val_loss: 13.5853\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4259 - val_loss: 13.5853\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4434 - val_loss: 13.5853\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4395 - val_loss: 13.5853\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4370 - val_loss: 13.5853\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4356 - val_loss: 13.5853\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4054 - val_loss: 13.5853\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4515 - val_loss: 13.5853\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4025 - val_loss: 13.5853\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4104 - val_loss: 13.5853\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4477 - val_loss: 13.5853\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4551 - val_loss: 13.5853\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4284 - val_loss: 13.5853\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.3995 - val_loss: 13.5853\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4764 - val_loss: 13.5853\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4296 - val_loss: 13.5853\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4371 - val_loss: 13.5854\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4316 - val_loss: 13.5854\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4523 - val_loss: 13.5854\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4291 - val_loss: 13.5854\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4249 - val_loss: 13.5854\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4166 - val_loss: 13.5854\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4250 - val_loss: 13.5854\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4346 - val_loss: 13.5854\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4439 - val_loss: 13.5854\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4313 - val_loss: 13.5854\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.3825 - val_loss: 13.5854\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4407 - val_loss: 13.5854\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4649 - val_loss: 13.5854\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4524 - val_loss: 13.5854\n",
      "Epoch 186/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 14.4266 - val_loss: 13.5854\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4318 - val_loss: 13.5854\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4432 - val_loss: 13.5854\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4346 - val_loss: 13.5854\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4154 - val_loss: 13.5854\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4541 - val_loss: 13.5854\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4423 - val_loss: 13.5854\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4416 - val_loss: 13.5854\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4415 - val_loss: 13.5854\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4306 - val_loss: 13.5854\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4275 - val_loss: 13.5855\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4515 - val_loss: 13.5855\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4225 - val_loss: 13.5855\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4332 - val_loss: 13.5855\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4533 - val_loss: 13.5855\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4271 - val_loss: 13.5855\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4337 - val_loss: 13.5855\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4543 - val_loss: 13.5855\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4439 - val_loss: 13.5855\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4323 - val_loss: 13.5855\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4511 - val_loss: 13.5855\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4201 - val_loss: 13.5855\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4672 - val_loss: 13.5855\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4301 - val_loss: 13.5855\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4361 - val_loss: 13.5855\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4571 - val_loss: 13.5855\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4325 - val_loss: 13.5855\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4419 - val_loss: 13.5855\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4158 - val_loss: 13.5855\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4544 - val_loss: 13.5855\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4247 - val_loss: 13.5855\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.3930 - val_loss: 13.5855\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4198 - val_loss: 13.5855\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4431 - val_loss: 13.5855\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.4246 - val_loss: 13.5855\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4410 - val_loss: 13.5855\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4390 - val_loss: 13.5855\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4357 - val_loss: 13.5855\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4303 - val_loss: 13.5855\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4231 - val_loss: 13.5856\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4294 - val_loss: 13.5856\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4448 - val_loss: 13.5856\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4385 - val_loss: 13.5856\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4610 - val_loss: 13.5856\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4150 - val_loss: 13.5856\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4392 - val_loss: 13.5856\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4239 - val_loss: 13.5856\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4569 - val_loss: 13.5856\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4524 - val_loss: 13.5856\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4401 - val_loss: 13.5856\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4312 - val_loss: 13.5856\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4078 - val_loss: 13.5856\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4420 - val_loss: 13.5856\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4122 - val_loss: 13.5856\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.3941 - val_loss: 13.5856\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4208 - val_loss: 13.5856\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4470 - val_loss: 13.5856\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4116 - val_loss: 13.5856\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4418 - val_loss: 13.5856\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4402 - val_loss: 13.5856\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4472 - val_loss: 13.5856\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4386 - val_loss: 13.5856\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4138 - val_loss: 13.5856\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4629 - val_loss: 13.5856\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4309 - val_loss: 13.5856\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4196 - val_loss: 13.5856\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4161 - val_loss: 13.5857\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4328 - val_loss: 13.5857\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4229 - val_loss: 13.5857\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4047 - val_loss: 13.5857\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4525 - val_loss: 13.5857\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4256 - val_loss: 13.5857\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4633 - val_loss: 13.5857\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4297 - val_loss: 13.5857\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4311 - val_loss: 13.5857\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 14.4798 - val_loss: 13.5857\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.4352 - val_loss: 13.5857\n",
      "Epoch 263/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 14.4094 - val_loss: 13.5857\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4413 - val_loss: 13.5857\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4416 - val_loss: 13.5857\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4105 - val_loss: 13.5857\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 14.3948 - val_loss: 13.5857\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4400 - val_loss: 13.5857\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4233 - val_loss: 13.5857\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4603 - val_loss: 13.5857\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4537 - val_loss: 13.5857\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4341 - val_loss: 13.5857\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.4395 - val_loss: 13.5857\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4327 - val_loss: 13.5857\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4184 - val_loss: 13.5857\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4531 - val_loss: 13.5857\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 14.4274 - val_loss: 13.5857\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4135 - val_loss: 13.5857\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4234 - val_loss: 13.5857\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 14.4455 - val_loss: 13.5857\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4044 - val_loss: 13.5858\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4484 - val_loss: 13.5858\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4512 - val_loss: 13.5858\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4587 - val_loss: 13.5858\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4460 - val_loss: 13.5858\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4414 - val_loss: 13.5858\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4243 - val_loss: 13.5858\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4398 - val_loss: 13.5858\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 14.4464 - val_loss: 13.5858\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.4390 - val_loss: 13.5858\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4378 - val_loss: 13.5858\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.3982 - val_loss: 13.5858\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4395 - val_loss: 13.5858\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 14.4335 - val_loss: 13.5858\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 14.4451 - val_loss: 13.5858\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 14.4284 - val_loss: 13.5858\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 14.4505 - val_loss: 13.5858\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4190 - val_loss: 13.5858\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.3819 - val_loss: 13.5858\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 14.4321 - val_loss: 13.5858\n",
      "wm hvac\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 861.8813 - val_loss: 874.7451\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8932 - val_loss: 874.7451\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 861.8602 - val_loss: 874.7451\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8866 - val_loss: 874.7452\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8950 - val_loss: 874.7452\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8504 - val_loss: 874.7452\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8765 - val_loss: 874.7452\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8740 - val_loss: 874.7452\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8983 - val_loss: 874.7452\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8701 - val_loss: 874.7452\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8193 - val_loss: 874.7452\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8640 - val_loss: 874.7452\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8600 - val_loss: 874.7452\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8999 - val_loss: 874.7452\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8565 - val_loss: 874.7452\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8874 - val_loss: 874.7453\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.9020 - val_loss: 874.7453\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8733 - val_loss: 874.7453\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8934 - val_loss: 874.7453\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8532 - val_loss: 874.7453\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8963 - val_loss: 874.7453\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8884 - val_loss: 874.7453\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8925 - val_loss: 874.7453\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8698 - val_loss: 874.7453\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8857 - val_loss: 874.7453\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8818 - val_loss: 874.7453\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8831 - val_loss: 874.7453\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.9107 - val_loss: 874.7453\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8907 - val_loss: 874.7453\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8665 - val_loss: 874.7453\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8749 - val_loss: 874.7453\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8827 - val_loss: 874.7453\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8487 - val_loss: 874.7453\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8804 - val_loss: 874.7453\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8783 - val_loss: 874.7453\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8525 - val_loss: 874.7453\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8690 - val_loss: 874.7454\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8852 - val_loss: 874.7454\n",
      "Epoch 39/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 55us/step - loss: 861.8800 - val_loss: 874.7454\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8640 - val_loss: 874.7454\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8623 - val_loss: 874.7454\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8912 - val_loss: 874.7454\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8772 - val_loss: 874.7454\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8636 - val_loss: 874.7454\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8857 - val_loss: 874.7454\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8825 - val_loss: 874.7454\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8433 - val_loss: 874.7454\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8321 - val_loss: 874.7454\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8780 - val_loss: 874.7455\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8608 - val_loss: 874.7455\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8662 - val_loss: 874.7455\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8786 - val_loss: 874.7455\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8422 - val_loss: 874.7455\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8493 - val_loss: 874.7455\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8590 - val_loss: 874.7455\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8915 - val_loss: 874.7455\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8616 - val_loss: 874.7455\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8852 - val_loss: 874.7455\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8834 - val_loss: 874.7456\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8654 - val_loss: 874.7456\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8450 - val_loss: 874.7456\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.8869 - val_loss: 874.7456\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8931 - val_loss: 874.7456\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8799 - val_loss: 874.7456\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8551 - val_loss: 874.7456\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8930 - val_loss: 874.7456\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8544 - val_loss: 874.7456\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8970 - val_loss: 874.7456\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8813 - val_loss: 874.7456\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8658 - val_loss: 874.7456\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8724 - val_loss: 874.7456\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8477 - val_loss: 874.7456\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8539 - val_loss: 874.7457\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8683 - val_loss: 874.7457\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.9157 - val_loss: 874.7457\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8914 - val_loss: 874.7457\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8692 - val_loss: 874.7457\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8977 - val_loss: 874.7457\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8901 - val_loss: 874.7457\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8672 - val_loss: 874.7394\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8508 - val_loss: 874.7329\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8782 - val_loss: 874.7311\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8728 - val_loss: 874.7305\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8600 - val_loss: 874.7304\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8653 - val_loss: 874.7304\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8420 - val_loss: 874.7304\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8818 - val_loss: 874.7304\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.9064 - val_loss: 874.7304\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8744 - val_loss: 874.7304\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.8427 - val_loss: 874.7304\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8775 - val_loss: 874.7304\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8592 - val_loss: 874.7304\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8828 - val_loss: 874.7304\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8798 - val_loss: 874.7304\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8736 - val_loss: 874.7304\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8746 - val_loss: 874.7304\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8744 - val_loss: 874.7304\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8582 - val_loss: 874.7304\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8875 - val_loss: 874.7305\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8743 - val_loss: 874.7305\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8516 - val_loss: 874.7305\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8818 - val_loss: 874.7305\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.8658 - val_loss: 874.7305\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8984 - val_loss: 874.7305\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8723 - val_loss: 874.7305\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8504 - val_loss: 874.7305\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.8960 - val_loss: 874.7305\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8729 - val_loss: 874.7305\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8834 - val_loss: 874.7305\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8725 - val_loss: 874.7305\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8708 - val_loss: 874.7305\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8881 - val_loss: 874.7306\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8955 - val_loss: 874.7306\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8714 - val_loss: 874.7306\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 61us/step - loss: 861.8587 - val_loss: 874.7306\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8466 - val_loss: 874.7306\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8786 - val_loss: 874.7306\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8613 - val_loss: 874.7306\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8566 - val_loss: 874.7306\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.9136 - val_loss: 874.7306\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8497 - val_loss: 874.7306\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8641 - val_loss: 874.7306\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8956 - val_loss: 874.7306\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8936 - val_loss: 874.7306\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8764 - val_loss: 874.7306\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8213 - val_loss: 874.7306\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.9043 - val_loss: 874.7306\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8820 - val_loss: 874.7306\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.8964 - val_loss: 874.7306\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8762 - val_loss: 874.7306\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.8450 - val_loss: 874.7306\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 861.8846 - val_loss: 874.7306\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8923 - val_loss: 874.7306\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8642 - val_loss: 874.7307\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.8173 - val_loss: 874.7307\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8624 - val_loss: 874.7307\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8609 - val_loss: 874.7307\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8221 - val_loss: 874.7307\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8224 - val_loss: 874.7307\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8708 - val_loss: 874.7307\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8962 - val_loss: 874.7307\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8539 - val_loss: 874.7307\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8835 - val_loss: 874.7307\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8548 - val_loss: 874.7307\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8372 - val_loss: 874.7308\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8407 - val_loss: 874.7308\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8820 - val_loss: 874.7308\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8856 - val_loss: 874.7308\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.8375 - val_loss: 874.7308\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8302 - val_loss: 874.7308\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8468 - val_loss: 874.7308\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8468 - val_loss: 874.7308\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 861.8438 - val_loss: 874.7308\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8671 - val_loss: 874.7308\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9135 - val_loss: 874.7308\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8803 - val_loss: 874.7308\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8532 - val_loss: 874.7309\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8689 - val_loss: 874.7309\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8596 - val_loss: 874.7309\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.8384 - val_loss: 874.7309\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8425 - val_loss: 874.7309\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8698 - val_loss: 874.7309\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8622 - val_loss: 874.7309\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8752 - val_loss: 874.7309\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8554 - val_loss: 874.7309\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8647 - val_loss: 874.7309\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8463 - val_loss: 874.7309\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8582 - val_loss: 874.7309\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8555 - val_loss: 874.7309\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8791 - val_loss: 874.7310\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8405 - val_loss: 874.7310\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8860 - val_loss: 874.7310\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8819 - val_loss: 874.7310\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.8497 - val_loss: 874.7310\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8889 - val_loss: 874.7310\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8688 - val_loss: 874.7310\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8915 - val_loss: 874.7310\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8460 - val_loss: 874.7310\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8679 - val_loss: 874.7310\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8892 - val_loss: 874.7310\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8157 - val_loss: 874.7310\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8680 - val_loss: 874.7310\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8806 - val_loss: 874.7311\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8501 - val_loss: 874.7311\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8646 - val_loss: 874.7311\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8891 - val_loss: 874.7311\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8015 - val_loss: 874.7311\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8636 - val_loss: 874.7311\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.9055 - val_loss: 874.7311\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8906 - val_loss: 874.7311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8737 - val_loss: 874.7311\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8679 - val_loss: 874.7311\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8427 - val_loss: 874.7311\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8548 - val_loss: 874.7311\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8911 - val_loss: 874.7311\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8460 - val_loss: 874.7311\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8741 - val_loss: 874.7311\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8390 - val_loss: 874.7312\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8116 - val_loss: 874.7312\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8804 - val_loss: 874.7312\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8066 - val_loss: 874.7312\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8563 - val_loss: 874.7312\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8723 - val_loss: 874.7312\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8408 - val_loss: 874.7312\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8518 - val_loss: 874.7312\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8606 - val_loss: 874.7312\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8963 - val_loss: 874.7312\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8931 - val_loss: 874.7312\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9049 - val_loss: 874.7312\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8455 - val_loss: 874.7312\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8172 - val_loss: 874.7313\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8474 - val_loss: 874.7313\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8216 - val_loss: 874.7313\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.8418 - val_loss: 874.7313\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8795 - val_loss: 874.7313\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8325 - val_loss: 874.7313\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8595 - val_loss: 874.7313\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8751 - val_loss: 874.7313\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8181 - val_loss: 874.7313\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8695 - val_loss: 874.7313\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8284 - val_loss: 874.7313\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8729 - val_loss: 874.7313\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8488 - val_loss: 874.7313\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8394 - val_loss: 874.7313\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8670 - val_loss: 874.7313\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8933 - val_loss: 874.7313\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8479 - val_loss: 874.7314\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8297 - val_loss: 874.7314\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8907 - val_loss: 874.7314\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8526 - val_loss: 874.7314\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.8713 - val_loss: 874.7314\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8676 - val_loss: 874.7314\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8461 - val_loss: 874.7314\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8147 - val_loss: 874.7314\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8311 - val_loss: 874.7314\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8361 - val_loss: 874.7314\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8505 - val_loss: 874.7314\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8582 - val_loss: 874.7314\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8510 - val_loss: 874.7315\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.8675 - val_loss: 874.7315\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8788 - val_loss: 874.7315\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8615 - val_loss: 874.7315\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8629 - val_loss: 874.7315\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8156 - val_loss: 874.7315\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8564 - val_loss: 874.7315\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8654 - val_loss: 874.7315\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 861.8315 - val_loss: 874.7315\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8220 - val_loss: 874.7315\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8570 - val_loss: 874.7315\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.9059 - val_loss: 874.7315\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8369 - val_loss: 874.7316\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8066 - val_loss: 874.7316\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 861.7838 - val_loss: 874.7171\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8360 - val_loss: 874.7171\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8562 - val_loss: 874.7171\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8576 - val_loss: 874.7171\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8706 - val_loss: 874.7171\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8398 - val_loss: 874.7171\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8804 - val_loss: 874.7171\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8720 - val_loss: 874.7171\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8355 - val_loss: 874.7171\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8897 - val_loss: 874.7171\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8300 - val_loss: 874.7171\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8314 - val_loss: 874.7171\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8697 - val_loss: 874.7171\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.7963 - val_loss: 874.7171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8157 - val_loss: 874.7171\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8384 - val_loss: 874.7171\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.7983 - val_loss: 874.7171\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8343 - val_loss: 874.7171\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8546 - val_loss: 874.7171\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8648 - val_loss: 874.7171\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.8274 - val_loss: 874.7171\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.7998 - val_loss: 874.7171\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 861.8463 - val_loss: 874.7171\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8367 - val_loss: 874.7171\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.7974 - val_loss: 874.7171\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8450 - val_loss: 874.7171\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8738 - val_loss: 874.7171\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8616 - val_loss: 874.7171\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8104 - val_loss: 874.7171\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8494 - val_loss: 874.7171\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8395 - val_loss: 874.7171\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8477 - val_loss: 874.7171\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8770 - val_loss: 874.7171\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8488 - val_loss: 874.7171\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8523 - val_loss: 874.7171\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 861.8204 - val_loss: 874.7171\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 861.8454 - val_loss: 874.7171\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8493 - val_loss: 874.7171\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 861.8365 - val_loss: 874.7171\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 861.8271 - val_loss: 874.7171\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8505 - val_loss: 874.7171\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 861.8664 - val_loss: 874.7171\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8164 - val_loss: 874.7171\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 861.8766 - val_loss: 874.7171\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.7830 - val_loss: 874.7171\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 861.8557 - val_loss: 874.7171\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 861.8862 - val_loss: 874.7171\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 861.8519 - val_loss: 874.7171\n",
      "wm fridge\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 88.4132 - val_loss: 98.0796\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 88.4578 - val_loss: 98.0796\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 88.3566 - val_loss: 98.0796\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 88.3786 - val_loss: 98.0796\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.4573 - val_loss: 98.0796\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.4345 - val_loss: 98.0796\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4797 - val_loss: 98.0796\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4685 - val_loss: 98.0796\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.4227 - val_loss: 98.0796\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.4567 - val_loss: 98.0796\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.4112 - val_loss: 98.0796\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4108 - val_loss: 98.0796\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.4106 - val_loss: 98.0796\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.4331 - val_loss: 98.0796\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3869 - val_loss: 98.0796\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.3981 - val_loss: 98.0796\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 88.4094 - val_loss: 98.0796\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 88.4091 - val_loss: 98.0796\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 88.4206 - val_loss: 98.0796\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.3969 - val_loss: 98.0796\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 88.4549 - val_loss: 98.0796\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 88.4198 - val_loss: 98.0796\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.3845 - val_loss: 98.0796\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.4545 - val_loss: 98.0796\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 88.5247 - val_loss: 98.0796\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 88.4190 - val_loss: 98.0796\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4071 - val_loss: 98.0796\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 88.4540 - val_loss: 98.0796\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 88.4303 - val_loss: 98.0796\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.4065 - val_loss: 98.0796\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 88.4299 - val_loss: 98.0796\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4060 - val_loss: 98.0796\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 88.4414 - val_loss: 98.0796\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4531 - val_loss: 98.0796\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 88.3933 - val_loss: 98.0796\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.3219 - val_loss: 98.0796\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.4406 - val_loss: 98.0796\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 90.56 - 0s 64us/step - loss: 88.3323 - val_loss: 98.0796\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.4522 - val_loss: 98.0796\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.4159 - val_loss: 98.0796\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 88.4519 - val_loss: 98.0796\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4037 - val_loss: 98.0796\n",
      "Epoch 43/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 59us/step - loss: 88.4033 - val_loss: 98.0796\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3910 - val_loss: 98.0796\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.4513 - val_loss: 98.0796\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4271 - val_loss: 98.0796\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4388 - val_loss: 98.0796\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4754 - val_loss: 98.0796\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 88.3652 - val_loss: 98.0796\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4138 - val_loss: 98.0796\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.4384 - val_loss: 98.0796\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.3519 - val_loss: 98.0796\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.3515 - val_loss: 98.0796\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4623 - val_loss: 98.0796\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 88.4374 - val_loss: 98.0796\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 88.3638 - val_loss: 98.0796\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.3749 - val_loss: 98.0796\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 88.4368 - val_loss: 98.0796\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4616 - val_loss: 98.0796\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.4490 - val_loss: 98.0796\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4240 - val_loss: 98.0796\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 88.3987 - val_loss: 98.0796\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3357 - val_loss: 98.0796\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 88.4233 - val_loss: 98.0796\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.4231 - val_loss: 98.0796\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 88.3346 - val_loss: 98.0796\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.3847 - val_loss: 98.0796\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.3729 - val_loss: 98.0796\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3967 - val_loss: 98.0796\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.3718 - val_loss: 98.0796\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3962 - val_loss: 98.0796\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4726 - val_loss: 98.0796\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.4219 - val_loss: 98.0796\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 88.4084 - val_loss: 98.0796\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.3445 - val_loss: 98.0796\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4338 - val_loss: 98.0796\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4077 - val_loss: 98.0796\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 88.3302 - val_loss: 98.0796\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.3943 - val_loss: 98.0796\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3940 - val_loss: 98.0796\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.3678 - val_loss: 98.0796\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.4585 - val_loss: 98.0796\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.4193 - val_loss: 98.0796\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3426 - val_loss: 98.0796\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 88.4450 - val_loss: 98.0796\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.3664 - val_loss: 98.0796\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3792 - val_loss: 98.0796\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.3660 - val_loss: 98.0796\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3787 - val_loss: 98.0796\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.4184 - val_loss: 98.0796\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3780 - val_loss: 98.0796\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4175 - val_loss: 98.0796\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3775 - val_loss: 98.0796\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 88.2848 - val_loss: 98.0796\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.3638 - val_loss: 98.0796\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 88.4037 - val_loss: 98.0796\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.3094 - val_loss: 98.0796\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3628 - val_loss: 98.0796\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3353 - val_loss: 98.0796\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3886 - val_loss: 98.0796\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3754 - val_loss: 98.0796\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4016 - val_loss: 98.0796\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 88.4419 - val_loss: 98.0796\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3877 - val_loss: 98.0796\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.3197 - val_loss: 98.0796\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 88.3464 - val_loss: 98.0796\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 88.3330 - val_loss: 98.0796\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 88.4008 - val_loss: 98.0796\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3862 - val_loss: 98.0796\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3591 - val_loss: 98.0796\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.3729 - val_loss: 98.0796\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4404 - val_loss: 98.0796\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.3853 - val_loss: 98.0796\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4279 - val_loss: 98.0796\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 88.3987 - val_loss: 98.0796\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3571 - val_loss: 98.0796\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.3429 - val_loss: 98.0796\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 88.4672 - val_loss: 98.0796\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.3840 - val_loss: 98.0796\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.4254 - val_loss: 98.0796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.3836 - val_loss: 98.0796\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3833 - val_loss: 98.0796\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 88.4671 - val_loss: 98.0796\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.3550 - val_loss: 98.0796\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 88.4246 - val_loss: 98.0796\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.3965 - val_loss: 98.0796\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 88.4243 - val_loss: 98.0796\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 88.3961 - val_loss: 98.0796\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.3819 - val_loss: 98.0796\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 88.3816 - val_loss: 98.0796\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4237 - val_loss: 98.0796\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.3812 - val_loss: 98.0796\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 88.4092 - val_loss: 98.0796\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.3949 - val_loss: 98.0796\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 88.4089 - val_loss: 98.0796\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.4087 - val_loss: 98.0796\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4512 - val_loss: 98.0796\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4653 - val_loss: 98.0796\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.3940 - val_loss: 98.0796\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 88.3517 - val_loss: 98.0796\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.4233 - val_loss: 98.0796\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4507 - val_loss: 98.0796\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.4219 - val_loss: 98.0796\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.3370 - val_loss: 98.0796\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.3785 - val_loss: 98.0796\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 88.4071 - val_loss: 98.0796\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3492 - val_loss: 98.0796\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4355 - val_loss: 98.0796\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 88.3211 - val_loss: 98.0796\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.3628 - val_loss: 98.0796\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4934 - val_loss: 98.0796\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.3769 - val_loss: 98.0796\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3766 - val_loss: 98.0796\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.3618 - val_loss: 98.0796\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4199 - val_loss: 98.0796\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3467 - val_loss: 98.0796\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.3332 - val_loss: 98.0796\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 88.3765 - val_loss: 98.0796\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 88.4191 - val_loss: 98.0796\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 88.3602 - val_loss: 98.0796\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.3599 - val_loss: 98.0796\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3460 - val_loss: 98.0796\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 88.3748 - val_loss: 98.0796\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4182 - val_loss: 98.0796\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 88.4328 - val_loss: 98.0796\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.3734 - val_loss: 98.0796\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4474 - val_loss: 98.0796\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4032 - val_loss: 98.0796\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.4026 - val_loss: 98.0796\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.4471 - val_loss: 98.0796\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 88.3277 - val_loss: 98.0796\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 88.4020 - val_loss: 98.0796\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.4483 - val_loss: 98.0796\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 88.3514 - val_loss: 98.0796\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 88.2170 - val_loss: 98.0796\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 87.8931 - val_loss: 98.0796\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 87.8439 - val_loss: 98.0796\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 87.9175 - val_loss: 98.0796\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 88.0203 - val_loss: 98.0796\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 88.0922 - val_loss: 98.0796\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 87.9245 - val_loss: 98.0796\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 87.9673 - val_loss: 98.0796\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 87.9964 - val_loss: 98.0796\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 87.7771 - val_loss: 97.9118\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 87.2303 - val_loss: 96.6397\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 86.4336 - val_loss: 95.7551\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 85.7193 - val_loss: 93.2934\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 81.7781 - val_loss: 89.7125\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 81.1913 - val_loss: 89.2178\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 80.8100 - val_loss: 89.1148\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 81.1040 - val_loss: 89.8225\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 79.0641 - val_loss: 88.5175\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 75.9807 - val_loss: 86.3070\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 72.7357 - val_loss: 83.4262\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 70.1686 - val_loss: 81.2374\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 69.4981 - val_loss: 81.5769\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 69.0482 - val_loss: 81.5374\n",
      "Epoch 198/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 62us/step - loss: 65.9799 - val_loss: 58.3921\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 53.6153 - val_loss: 59.6858\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 49.8971 - val_loss: 48.3856\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 48.5468 - val_loss: 50.9776\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 48.7526 - val_loss: 49.8537\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 46.8156 - val_loss: 50.8464\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 47.8844 - val_loss: 51.0895\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 50.0602 - val_loss: 47.7633\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.4156 - val_loss: 50.9120\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 48.5519 - val_loss: 47.3757\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 47.9835 - val_loss: 50.3564\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 48.6383 - val_loss: 49.5072\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 49.1314 - val_loss: 49.5260\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 46.3135 - val_loss: 49.9714\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 49.9004 - val_loss: 50.7520\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 48.9258 - val_loss: 48.7686\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.2658 - val_loss: 49.8090\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 47.2222 - val_loss: 49.5904\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 48.2232 - val_loss: 48.2983\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 48.1811 - val_loss: 49.6017\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 45.8585 - val_loss: 49.7879\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 49.0217 - val_loss: 49.9113\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 50.1167 - val_loss: 49.6303\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 50.5131 - val_loss: 48.5834\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.6945 - val_loss: 50.5762\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 48.4929 - val_loss: 50.6036\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 47.5598 - val_loss: 48.0754\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 49.1184 - val_loss: 50.7106\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.4349 - val_loss: 48.7596\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 50.1580 - val_loss: 47.8544\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 48.5409 - val_loss: 50.1342\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 47.3846 - val_loss: 49.5107\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 47.8179 - val_loss: 48.7957\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 46.3963 - val_loss: 49.3445\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 46.1804 - val_loss: 47.2706\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 45.8717 - val_loss: 49.5918\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 47.4885 - val_loss: 48.3609\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 47.9754 - val_loss: 49.2510\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 48.6453 - val_loss: 48.9382\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 48.5425 - val_loss: 48.7223\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 50.1381 - val_loss: 47.9693\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 50.8888 - val_loss: 50.6818\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 48.4942 - val_loss: 49.3011\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 47.7672 - val_loss: 49.5541\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 49.0797 - val_loss: 49.0461\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 46.2457 - val_loss: 48.7997\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 46.3185 - val_loss: 48.9383\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 47.6587 - val_loss: 48.6632\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 46.0429 - val_loss: 49.7927\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 46.7902 - val_loss: 49.2962\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 49.2888 - val_loss: 48.3300\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 46.3585 - val_loss: 49.8169\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 47.1719 - val_loss: 48.2311\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 50.1892 - val_loss: 50.9097\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 47.0012 - val_loss: 49.4646\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 47.7274 - val_loss: 51.0317\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 49.7257 - val_loss: 48.9016\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 46.1929 - val_loss: 48.2969\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 45.7585 - val_loss: 50.8688\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 47.0304 - val_loss: 49.0603\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 46.8134 - val_loss: 48.4577\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 47.6245 - val_loss: 48.9633\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 47.2739 - val_loss: 49.8187\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 48.1834 - val_loss: 47.6595\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 48.5766 - val_loss: 49.6450\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 47.2854 - val_loss: 47.8626\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 47.6898 - val_loss: 50.8822\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 47.6714 - val_loss: 48.2337\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 48.6145 - val_loss: 49.9031\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 48.0774 - val_loss: 47.2642\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 46.3715 - val_loss: 48.8635\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 48.6862 - val_loss: 49.8263\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 47.1333 - val_loss: 48.6366\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 48.4183 - val_loss: 50.0972\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 49.0699 - val_loss: 50.6304\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.2064 - val_loss: 46.7210\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.4120 - val_loss: 51.8340\n",
      "Epoch 275/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 45.4395 - val_loss: 48.0485\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 45.8102 - val_loss: 48.3664\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 47.2491 - val_loss: 50.8851\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 46.9720 - val_loss: 48.2361\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 47.7567 - val_loss: 49.1031\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 47.9683 - val_loss: 49.5574\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 47.4200 - val_loss: 50.3358\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 47.7835 - val_loss: 47.5364\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 46.0002 - val_loss: 51.8088\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 45.2234 - val_loss: 47.9936\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 47.0809 - val_loss: 50.9553\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 45.7145 - val_loss: 49.1503\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 48.2132 - val_loss: 50.2046\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.8351 - val_loss: 48.8262\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 46.0096 - val_loss: 49.8623\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 46.6562 - val_loss: 47.8485\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 47.2980 - val_loss: 50.4503\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.5077 - val_loss: 48.5055\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 47.4717 - val_loss: 49.1058\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 49.3174 - val_loss: 50.0716\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 47.4064 - val_loss: 47.5904\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 46.3384 - val_loss: 49.7933\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 46.7396 - val_loss: 48.7491\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 48.4650 - val_loss: 49.8240\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 46.5085 - val_loss: 47.2278\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 47.3672 - val_loss: 49.7953\n",
      "wm mw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 40.1119 - val_loss: 28.3693\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 24.8619 - val_loss: 17.5129\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.6446 - val_loss: 12.7760\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.9688 - val_loss: 11.1311\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 9.2236 - val_loss: 10.7649\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.0438 - val_loss: 10.6382\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.9251 - val_loss: 10.5717\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.8756 - val_loss: 10.5275\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.8212 - val_loss: 10.4958\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 8.8214 - val_loss: 10.4741\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.8282 - val_loss: 10.4526\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 8.8021 - val_loss: 10.4313\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.7956 - val_loss: 10.4108\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.7737 - val_loss: 10.3893\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.7504 - val_loss: 10.3711\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.7475 - val_loss: 10.3522\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.7328 - val_loss: 10.3351\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.7085 - val_loss: 10.3184\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 8.6908 - val_loss: 10.3034\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.6938 - val_loss: 10.2880\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.6622 - val_loss: 10.2751\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.6603 - val_loss: 10.2620\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.6457 - val_loss: 10.2490\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 8.6404 - val_loss: 10.2364\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.6226 - val_loss: 10.2234\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 8.6237 - val_loss: 10.2102\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.6155 - val_loss: 10.1963\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 8.6001 - val_loss: 10.1838\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 8.5810 - val_loss: 10.1717\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.5786 - val_loss: 10.1595\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 8.5616 - val_loss: 10.1479\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 8.5520 - val_loss: 10.1365\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.5383 - val_loss: 10.1254\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 8.5290 - val_loss: 10.1147\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.5199 - val_loss: 10.1044\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 8.5121 - val_loss: 10.0938\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 8.5054 - val_loss: 10.0838\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 8.4919 - val_loss: 10.0738\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.4869 - val_loss: 10.0638\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.4761 - val_loss: 10.0535\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 8.4634 - val_loss: 10.0434\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.4544 - val_loss: 10.0335\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.4436 - val_loss: 10.0236\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.4325 - val_loss: 10.0137\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.4262 - val_loss: 10.0041\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.4151 - val_loss: 9.9946\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.4047 - val_loss: 9.9849\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.3943 - val_loss: 9.9755\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.3847 - val_loss: 9.9661\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.3766 - val_loss: 9.9565\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.3671 - val_loss: 9.9472\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.3575 - val_loss: 9.9377\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 55us/step - loss: 8.3479 - val_loss: 9.9285\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.3387 - val_loss: 9.9191\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.3284 - val_loss: 9.9098\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.3208 - val_loss: 9.9005\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.3104 - val_loss: 9.8911\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.3021 - val_loss: 9.8817\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.2933 - val_loss: 9.8726\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.2818 - val_loss: 9.8637\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 8.2727 - val_loss: 9.8546\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.2653 - val_loss: 9.8456\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.2537 - val_loss: 9.8367\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 8.2438 - val_loss: 9.8277\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.2366 - val_loss: 9.8186\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 8.2262 - val_loss: 9.8097\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.2186 - val_loss: 9.8007\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 8.2072 - val_loss: 9.7916\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.1992 - val_loss: 9.7826\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.1885 - val_loss: 9.7736\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 8.1798 - val_loss: 9.7647\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.1708 - val_loss: 9.7557\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.1626 - val_loss: 9.7467\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.1527 - val_loss: 9.7377\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.1445 - val_loss: 9.7287\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.1348 - val_loss: 9.7197\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.1241 - val_loss: 9.7108\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 8.1167 - val_loss: 9.7017\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.1063 - val_loss: 9.6928\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 8.0974 - val_loss: 9.6837\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.0889 - val_loss: 9.6747\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 8.0792 - val_loss: 9.6658\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 8.0707 - val_loss: 9.6568\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.0610 - val_loss: 9.6478\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.0524 - val_loss: 9.6388\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.0427 - val_loss: 9.6299\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 8.0333 - val_loss: 9.6209\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.0237 - val_loss: 9.6119\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.0151 - val_loss: 9.6029\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.0068 - val_loss: 9.5940\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.9977 - val_loss: 9.5850\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.9886 - val_loss: 9.5761\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.9795 - val_loss: 9.5671\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.9704 - val_loss: 9.5581\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.9604 - val_loss: 9.5491\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.9516 - val_loss: 9.5402\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.9423 - val_loss: 9.5311\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.9326 - val_loss: 9.5222\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.9247 - val_loss: 9.5132\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.9152 - val_loss: 9.5042\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.9065 - val_loss: 9.4952\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.8969 - val_loss: 9.4862\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.8882 - val_loss: 9.4772\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.8787 - val_loss: 9.4682\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.8695 - val_loss: 9.4592\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.8608 - val_loss: 9.4502\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.8510 - val_loss: 9.4412\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.8426 - val_loss: 9.4322\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.8324 - val_loss: 9.4232\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.8237 - val_loss: 9.4141\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.8151 - val_loss: 9.4051\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.8054 - val_loss: 9.3961\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 7.7965 - val_loss: 9.3871\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.7877 - val_loss: 9.3780\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.7780 - val_loss: 9.3690\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.7690 - val_loss: 9.3601\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.7598 - val_loss: 9.3510\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.7511 - val_loss: 9.3419\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.7419 - val_loss: 9.3330\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.7329 - val_loss: 9.3240\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.7238 - val_loss: 9.3150\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.7143 - val_loss: 9.3059\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.7056 - val_loss: 9.2969\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.6964 - val_loss: 9.2879\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.6873 - val_loss: 9.2789\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.6779 - val_loss: 9.2699\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 7.6688 - val_loss: 9.2609\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.6596 - val_loss: 9.2519\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.6506 - val_loss: 9.2429\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.6413 - val_loss: 9.2338\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.6322 - val_loss: 9.2248\n",
      "Epoch 132/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 58us/step - loss: 7.6233 - val_loss: 9.2157\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.6144 - val_loss: 9.2067\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.6053 - val_loss: 9.1977\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 7.5962 - val_loss: 9.1887\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.5872 - val_loss: 9.1796\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.5777 - val_loss: 9.1707\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.5684 - val_loss: 9.1617\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.5598 - val_loss: 9.1527\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.5508 - val_loss: 9.1437\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.5414 - val_loss: 9.1347\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.5328 - val_loss: 9.1256\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.5235 - val_loss: 9.1167\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.5145 - val_loss: 9.1077\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.5055 - val_loss: 9.0987\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.4964 - val_loss: 9.0897\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.4870 - val_loss: 9.0807\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.4783 - val_loss: 9.0716\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.4692 - val_loss: 9.0626\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.4598 - val_loss: 9.0537\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.4512 - val_loss: 9.0446\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.4421 - val_loss: 9.0356\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.4329 - val_loss: 9.0266\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.4241 - val_loss: 9.0176\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.4147 - val_loss: 9.0086\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.4057 - val_loss: 8.9997\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.3969 - val_loss: 8.9907\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.3882 - val_loss: 8.9817\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.3792 - val_loss: 8.9728\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.3700 - val_loss: 8.9638\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.3612 - val_loss: 8.9549\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.3526 - val_loss: 8.9459\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.3434 - val_loss: 8.9371\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.3345 - val_loss: 8.9281\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.3258 - val_loss: 8.9192\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.3169 - val_loss: 8.9103\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.3081 - val_loss: 8.9014\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.2993 - val_loss: 8.8926\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.2907 - val_loss: 8.8837\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.2820 - val_loss: 8.8747\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.2731 - val_loss: 8.8659\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.2644 - val_loss: 8.8570\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.2557 - val_loss: 8.8481\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.2469 - val_loss: 8.8392\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.2382 - val_loss: 8.8304\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 7.2294 - val_loss: 8.8216\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.2209 - val_loss: 8.8127\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.2122 - val_loss: 8.8038\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.2035 - val_loss: 8.7950\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 7.1948 - val_loss: 8.7861\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.1861 - val_loss: 8.7773\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.1776 - val_loss: 8.7684\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.1689 - val_loss: 8.7596\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.1603 - val_loss: 8.7508\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 7.1517 - val_loss: 8.7420\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.1431 - val_loss: 8.7333\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.1346 - val_loss: 8.7245\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.1261 - val_loss: 8.7156\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.1175 - val_loss: 8.7068\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.1089 - val_loss: 8.6980\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.1005 - val_loss: 8.6892\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.0919 - val_loss: 8.6804\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.0834 - val_loss: 8.6718\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.0751 - val_loss: 8.6629\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.0665 - val_loss: 8.6542\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.0579 - val_loss: 8.6456\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.0498 - val_loss: 8.6367\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 7.0412 - val_loss: 8.6280\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.0327 - val_loss: 8.6193\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.0244 - val_loss: 8.6105\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.0160 - val_loss: 8.6018\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.0076 - val_loss: 8.5932\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.9994 - val_loss: 8.5844\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.9909 - val_loss: 8.5757\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.9827 - val_loss: 8.5670\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.9743 - val_loss: 8.5584\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.9661 - val_loss: 8.5497\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.9578 - val_loss: 8.5410\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.9495 - val_loss: 8.5323\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.9411 - val_loss: 8.5237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.9330 - val_loss: 8.5149\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.9246 - val_loss: 8.5063\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.9165 - val_loss: 8.4976\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.9082 - val_loss: 8.4888\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.8999 - val_loss: 8.4803\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.8918 - val_loss: 8.4717\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.8837 - val_loss: 8.4629\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.8754 - val_loss: 8.4544\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.8674 - val_loss: 8.4457\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.8591 - val_loss: 8.4372\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.8512 - val_loss: 8.4285\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.8429 - val_loss: 8.4199\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.8349 - val_loss: 8.4112\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.8267 - val_loss: 8.4026\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.8186 - val_loss: 8.3941\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.8106 - val_loss: 8.3855\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.8025 - val_loss: 8.3769\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.7944 - val_loss: 8.3684\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.7864 - val_loss: 8.3598\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.7784 - val_loss: 8.3511\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.7703 - val_loss: 8.3426\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.7623 - val_loss: 8.3340\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.7543 - val_loss: 8.3255\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.7463 - val_loss: 8.3169\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.7384 - val_loss: 8.3082\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.7304 - val_loss: 8.2997\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.7224 - val_loss: 8.2912\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.7146 - val_loss: 8.2827\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.7067 - val_loss: 8.2741\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.6988 - val_loss: 8.2656\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.6909 - val_loss: 8.2571\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.6832 - val_loss: 8.2485\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.6752 - val_loss: 8.2401\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.6675 - val_loss: 8.2316\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.6596 - val_loss: 8.2230\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.6518 - val_loss: 8.2146\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.6441 - val_loss: 8.2062\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.6364 - val_loss: 8.1977\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.6286 - val_loss: 8.1892\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.6208 - val_loss: 8.1809\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.6132 - val_loss: 8.1723\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.6055 - val_loss: 8.1639\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.5979 - val_loss: 8.1554\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.5900 - val_loss: 8.1471\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.5825 - val_loss: 8.1385\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.5748 - val_loss: 8.1300\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.5673 - val_loss: 8.1216\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.5594 - val_loss: 8.1132\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.5519 - val_loss: 8.1047\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.5442 - val_loss: 8.0963\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.5368 - val_loss: 8.0878\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.5291 - val_loss: 8.0795\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.5216 - val_loss: 8.0709\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.5139 - val_loss: 8.0625\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.5065 - val_loss: 8.0541\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.4987 - val_loss: 8.0458\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.4913 - val_loss: 8.0373\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.4837 - val_loss: 8.0290\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.4763 - val_loss: 8.0205\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.4687 - val_loss: 8.0120\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.4612 - val_loss: 8.0037\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.4538 - val_loss: 7.9952\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.4462 - val_loss: 7.9869\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.4392 - val_loss: 7.9783\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.4314 - val_loss: 7.9701\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.4242 - val_loss: 7.9617\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.4167 - val_loss: 7.9533\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.4092 - val_loss: 7.9451\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.4019 - val_loss: 7.9369\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 6.3946 - val_loss: 7.9288\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.3872 - val_loss: 7.9209\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.3802 - val_loss: 7.9128\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.3729 - val_loss: 7.9046\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.3654 - val_loss: 7.8967\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3581 - val_loss: 7.8888\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.3510 - val_loss: 7.8806\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 6.3438 - val_loss: 7.8726\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.3363 - val_loss: 7.8648\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.3292 - val_loss: 7.8569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3220 - val_loss: 7.8489\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.3153 - val_loss: 7.8408\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.3074 - val_loss: 7.8331\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.3005 - val_loss: 7.8253\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.2933 - val_loss: 7.8177\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2867 - val_loss: 7.8101\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.2792 - val_loss: 7.8026\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.2721 - val_loss: 7.7952\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.2656 - val_loss: 7.7878\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.2582 - val_loss: 7.7804\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.2517 - val_loss: 7.7731\n",
      "wm dw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 17.1341 - val_loss: 21.2757\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 17.1233 - val_loss: 21.2650\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 17.1126 - val_loss: 21.2542\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.1019 - val_loss: 21.2435\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.0912 - val_loss: 21.2327\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.0806 - val_loss: 21.2220\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 17.0700 - val_loss: 21.2112\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 17.0594 - val_loss: 21.2004\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 17.0488 - val_loss: 21.1897\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.0382 - val_loss: 21.1790\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.0276 - val_loss: 21.1684\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 17.0171 - val_loss: 21.1577\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 17.0066 - val_loss: 21.1470\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.9961 - val_loss: 21.1363\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.9856 - val_loss: 21.1257\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.9752 - val_loss: 21.1150\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 16.9647 - val_loss: 21.1043\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 16.9543 - val_loss: 21.0936\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 16.9438 - val_loss: 21.0829\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 16.9334 - val_loss: 21.0723\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.9229 - val_loss: 21.0616\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 16.9125 - val_loss: 21.0510\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.9021 - val_loss: 21.0403\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 16.8916 - val_loss: 21.0296\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.8812 - val_loss: 21.0189\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.8708 - val_loss: 21.0083\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 16.8605 - val_loss: 20.9976\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 16.8500 - val_loss: 20.9869\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.8396 - val_loss: 20.9763\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 16.8293 - val_loss: 20.9656\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.8189 - val_loss: 20.9550\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 16.8085 - val_loss: 20.9444\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 16.7981 - val_loss: 20.9337\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 16.7878 - val_loss: 20.9231\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.7774 - val_loss: 20.9124\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.7670 - val_loss: 20.9018\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 16.7568 - val_loss: 20.8911\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 16.7464 - val_loss: 20.8804\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.7360 - val_loss: 20.8698\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 16.7256 - val_loss: 20.8592\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.7153 - val_loss: 20.8485\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 16.7050 - val_loss: 20.8378\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 16.6946 - val_loss: 20.8272\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 16.6842 - val_loss: 20.8165\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.6738 - val_loss: 20.8059\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.6635 - val_loss: 20.7952\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 16.6533 - val_loss: 20.7845\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 16.6430 - val_loss: 20.7739\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 16.6326 - val_loss: 20.7633\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 16.6224 - val_loss: 20.7527\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 16.6122 - val_loss: 20.7421\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.6019 - val_loss: 20.7315\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.5917 - val_loss: 20.7208\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.5813 - val_loss: 20.7103\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.5712 - val_loss: 20.6995\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.5608 - val_loss: 20.6889\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.5506 - val_loss: 20.6783\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 16.5403 - val_loss: 20.6677\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 16.5301 - val_loss: 20.6570\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 16.5198 - val_loss: 20.6464\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.5096 - val_loss: 20.6358\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 16.4993 - val_loss: 20.6252\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.4891 - val_loss: 20.6146\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.4789 - val_loss: 20.6039\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 16.4687 - val_loss: 20.5933\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.4585 - val_loss: 20.5827\n",
      "Epoch 67/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 16.4483 - val_loss: 20.5721\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.4381 - val_loss: 20.5614\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.4279 - val_loss: 20.5509\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 16.4177 - val_loss: 20.5402\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 16.4075 - val_loss: 20.5297\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 84us/step - loss: 16.3974 - val_loss: 20.5191\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 16.3872 - val_loss: 20.5084\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 15.49 - 0s 71us/step - loss: 16.3771 - val_loss: 20.4978\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 16.3669 - val_loss: 20.4872\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 16.3567 - val_loss: 20.4766\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 16.3466 - val_loss: 20.4660\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 16.3365 - val_loss: 20.4555\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 16.3264 - val_loss: 20.4449\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 16.3163 - val_loss: 20.4343\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 16.3063 - val_loss: 20.4238\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 16.2962 - val_loss: 20.4133\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 16.2863 - val_loss: 20.4027\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 16.2764 - val_loss: 20.3922\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.2666 - val_loss: 20.3818\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 16.2568 - val_loss: 20.3715\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 16.2471 - val_loss: 20.3610\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 16.2373 - val_loss: 20.3506\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 16.2276 - val_loss: 20.3400\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 16.2177 - val_loss: 20.3297\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 16.2081 - val_loss: 20.3192\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 16.1982 - val_loss: 20.3088\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 16.1884 - val_loss: 20.2985\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 16.1788 - val_loss: 20.2879\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 16.1690 - val_loss: 20.2775\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 16.1592 - val_loss: 20.2670\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 16.1494 - val_loss: 20.2566\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 16.1397 - val_loss: 20.2462\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 16.1300 - val_loss: 20.2357\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 16.1201 - val_loss: 20.2252\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 16.1104 - val_loss: 20.2147\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 16.1006 - val_loss: 20.2042\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 16.0907 - val_loss: 20.1938\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 16.0811 - val_loss: 20.1833\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 16.0713 - val_loss: 20.1727\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 16.0616 - val_loss: 20.1623\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 16.0519 - val_loss: 20.1520\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 16.0423 - val_loss: 20.1416\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 99us/step - loss: 16.0327 - val_loss: 20.1311\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 16.0230 - val_loss: 20.1207\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 16.0134 - val_loss: 20.1104\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 16.0038 - val_loss: 20.1000\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 15.9943 - val_loss: 20.0896\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.9845 - val_loss: 20.0792\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 15.9750 - val_loss: 20.0688\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 15.9654 - val_loss: 20.0583\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 15.9558 - val_loss: 20.0479\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 15.9462 - val_loss: 20.0376\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 17.76 - 0s 64us/step - loss: 15.9367 - val_loss: 20.0272\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 15.9272 - val_loss: 20.0168\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 15.9176 - val_loss: 20.0065\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 15.9081 - val_loss: 19.9961\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 15.8987 - val_loss: 19.9858\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 15.8893 - val_loss: 19.9755\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 16.51 - 0s 71us/step - loss: 15.8800 - val_loss: 19.9651\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 15.8705 - val_loss: 19.9549\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.8612 - val_loss: 19.9446\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.8519 - val_loss: 19.9342\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 15.8424 - val_loss: 19.9238\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 15.8329 - val_loss: 19.9136\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 15.8235 - val_loss: 19.9034\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 15.8143 - val_loss: 19.8929\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 15.8048 - val_loss: 19.8826\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.7954 - val_loss: 19.8723\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 15.7860 - val_loss: 19.8619\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 15.7766 - val_loss: 19.8516\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 15.7672 - val_loss: 19.8413\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 15.7578 - val_loss: 19.8309\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 15.7484 - val_loss: 19.8205\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 15.7389 - val_loss: 19.8102\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 15.7296 - val_loss: 19.7998\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.7203 - val_loss: 19.7893\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 15.7107 - val_loss: 19.7791\n",
      "Epoch 144/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 62us/step - loss: 15.7014 - val_loss: 19.7688\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 15.6921 - val_loss: 19.7583\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 15.6825 - val_loss: 19.7481\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 15.6733 - val_loss: 19.7376\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 15.6637 - val_loss: 19.7273\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 15.6543 - val_loss: 19.7170\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 15.6449 - val_loss: 19.7066\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 15.6355 - val_loss: 19.6962\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 15.6261 - val_loss: 19.6858\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 15.6167 - val_loss: 19.6755\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 15.6073 - val_loss: 19.6650\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 15.5979 - val_loss: 19.6546\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 15.5884 - val_loss: 19.6443\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 15.5791 - val_loss: 19.6338\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 15.5696 - val_loss: 19.6234\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.5602 - val_loss: 19.6130\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 15.5508 - val_loss: 19.6026\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 15.5413 - val_loss: 19.5923\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 15.5319 - val_loss: 19.5818\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 15.5225 - val_loss: 19.5714\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 15.5132 - val_loss: 19.5609\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 15.5036 - val_loss: 19.5506\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 15.4943 - val_loss: 19.5401\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 15.4849 - val_loss: 19.5298\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 15.4755 - val_loss: 19.5194\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 15.4661 - val_loss: 19.5090\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 15.4567 - val_loss: 19.4985\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.4473 - val_loss: 19.4881\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 15.4379 - val_loss: 19.4776\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 15.4284 - val_loss: 19.4673\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.4191 - val_loss: 19.4568\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 15.4096 - val_loss: 19.4464\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 15.4002 - val_loss: 19.4361\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 15.3909 - val_loss: 19.4256\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.3815 - val_loss: 19.4151\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 15.3720 - val_loss: 19.4047\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 15.3626 - val_loss: 19.3943\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 15.3533 - val_loss: 19.3839\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 15.3439 - val_loss: 19.3734\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 15.3344 - val_loss: 19.3630\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 15.3250 - val_loss: 19.3526\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 15.3157 - val_loss: 19.3421\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 15.3062 - val_loss: 19.3317\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 15.2969 - val_loss: 19.3212\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.2875 - val_loss: 19.3108\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.2780 - val_loss: 19.3004\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.2688 - val_loss: 19.2899\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 15.2593 - val_loss: 19.2795\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.2500 - val_loss: 19.2690\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 15.2406 - val_loss: 19.2586\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 15.2312 - val_loss: 19.2481\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 15.2219 - val_loss: 19.2375\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 15.2124 - val_loss: 19.2272\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.2030 - val_loss: 19.2169\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 15.1938 - val_loss: 19.2064\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 12.01 - 0s 72us/step - loss: 15.1845 - val_loss: 19.1960\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 15.1750 - val_loss: 19.1856\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 15.1657 - val_loss: 19.1751\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.1564 - val_loss: 19.1646\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 15.1471 - val_loss: 19.1541\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 15.1376 - val_loss: 19.1437\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 15.1283 - val_loss: 19.1334\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 15.1191 - val_loss: 19.1228\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 15.1097 - val_loss: 19.1124\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 15.1003 - val_loss: 19.1021\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 15.0910 - val_loss: 19.0918\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 15.0819 - val_loss: 19.0813\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 15.0725 - val_loss: 19.0709\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 15.0633 - val_loss: 19.0605\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 15.0540 - val_loss: 19.0500\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 12.55 - 0s 65us/step - loss: 15.0447 - val_loss: 19.0398\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 15.0356 - val_loss: 19.0294\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 15.0263 - val_loss: 19.0190\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 15.0171 - val_loss: 19.0086\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 15.0080 - val_loss: 18.9981\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 15.38 - 0s 69us/step - loss: 14.9987 - val_loss: 18.9877\n",
      "Epoch 220/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 74us/step - loss: 14.9894 - val_loss: 18.9774\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.9802 - val_loss: 18.9670\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.9710 - val_loss: 18.9566\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 14.9618 - val_loss: 18.9462\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 14.9526 - val_loss: 18.9358\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 14.9435 - val_loss: 18.9253\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 14.9341 - val_loss: 18.9150\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 11.64 - 0s 71us/step - loss: 14.9250 - val_loss: 18.9047\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 14.9159 - val_loss: 18.8942\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.9066 - val_loss: 18.8838\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 14.8975 - val_loss: 18.8734\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.8884 - val_loss: 18.8629\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 14.8790 - val_loss: 18.8527\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.8700 - val_loss: 18.8424\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.8608 - val_loss: 18.8321\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 14.8518 - val_loss: 18.8216\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.8426 - val_loss: 18.8112\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.8334 - val_loss: 18.8010\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.8243 - val_loss: 18.7906\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.8153 - val_loss: 18.7803\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.8061 - val_loss: 18.7700\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 12.19 - 0s 72us/step - loss: 14.7971 - val_loss: 18.7596\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 14.7879 - val_loss: 18.7494\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.7789 - val_loss: 18.7390\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 14.7699 - val_loss: 18.7285\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.7608 - val_loss: 18.7182\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.7516 - val_loss: 18.7079\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 14.7426 - val_loss: 18.6976\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 14.7335 - val_loss: 18.6873\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 14.88 - 0s 73us/step - loss: 14.7245 - val_loss: 18.6769\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.7155 - val_loss: 18.6664\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.7064 - val_loss: 18.6561\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.6973 - val_loss: 18.6458\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 14.6882 - val_loss: 18.6354\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.6792 - val_loss: 18.6251\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.6701 - val_loss: 18.6148\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 14.6611 - val_loss: 18.6045\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.6521 - val_loss: 18.5942\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.6430 - val_loss: 18.5838\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 14.6340 - val_loss: 18.5736\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.6250 - val_loss: 18.5633\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 14.6162 - val_loss: 18.5528\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.6071 - val_loss: 18.5425\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.5982 - val_loss: 18.5323\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 14.5892 - val_loss: 18.5221\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.5804 - val_loss: 18.5118\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 14.5716 - val_loss: 18.5014\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.5625 - val_loss: 18.4913\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.5538 - val_loss: 18.4809\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.5448 - val_loss: 18.4708\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 14.5361 - val_loss: 18.4605\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.5273 - val_loss: 18.4502\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.5184 - val_loss: 18.4400\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.5097 - val_loss: 18.4297\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 14.5009 - val_loss: 18.4195\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 14.4920 - val_loss: 18.4095\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 14.4834 - val_loss: 18.3992\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.4746 - val_loss: 18.3889\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.4659 - val_loss: 18.3787\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 14.4572 - val_loss: 18.3684\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 14.4484 - val_loss: 18.3583\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.4397 - val_loss: 18.3482\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 14.4311 - val_loss: 18.3381\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 14.4224 - val_loss: 18.3279\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.4138 - val_loss: 18.3178\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.4052 - val_loss: 18.3075\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.3965 - val_loss: 18.2974\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.3878 - val_loss: 18.2873\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 14.3794 - val_loss: 18.2770\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.3708 - val_loss: 18.2667\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 14.3621 - val_loss: 18.2568\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 14.3538 - val_loss: 18.2467\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.3453 - val_loss: 18.2367\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 14.3369 - val_loss: 18.2267\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 14.3284 - val_loss: 18.2167\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 14.3199 - val_loss: 18.2068\n",
      "Epoch 296/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 72us/step - loss: 14.3116 - val_loss: 18.1968\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.3031 - val_loss: 18.1868\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.2947 - val_loss: 18.1769\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 14.2863 - val_loss: 18.1671\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 14.2781 - val_loss: 18.1571\n",
      "wm oven\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 13.8856 - val_loss: 14.6435\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.8817 - val_loss: 14.6393\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.8777 - val_loss: 14.6351\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.8734 - val_loss: 14.6310\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.8691 - val_loss: 14.6269\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.8650 - val_loss: 14.6227\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.8607 - val_loss: 14.6185\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.8564 - val_loss: 14.6145\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.8523 - val_loss: 14.6103\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.8482 - val_loss: 14.6061\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.8439 - val_loss: 14.6020\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.8400 - val_loss: 14.5976\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.8358 - val_loss: 14.5935\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.8316 - val_loss: 14.5895\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.8275 - val_loss: 14.5854\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.8235 - val_loss: 14.5814\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.8197 - val_loss: 14.5772\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.8156 - val_loss: 14.5732\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.8116 - val_loss: 14.5692\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.8076 - val_loss: 14.5652\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.8038 - val_loss: 14.5612\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.7998 - val_loss: 14.5574\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.7960 - val_loss: 14.5535\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 13.7920 - val_loss: 14.5497\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.7883 - val_loss: 14.5457\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.7844 - val_loss: 14.5419\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.7807 - val_loss: 14.5378\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.7769 - val_loss: 14.5338\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.7729 - val_loss: 14.5300\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.7691 - val_loss: 14.5262\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.7654 - val_loss: 14.5223\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.7615 - val_loss: 14.5186\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.7579 - val_loss: 14.5146\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.7541 - val_loss: 14.5108\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.7502 - val_loss: 14.5072\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.7468 - val_loss: 14.5033\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 13.7429 - val_loss: 14.4997\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.7393 - val_loss: 14.4960\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.7358 - val_loss: 14.4921\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 13.7320 - val_loss: 14.4885\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.7283 - val_loss: 14.4850\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 13.7249 - val_loss: 14.4814\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 13.7212 - val_loss: 14.4778\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 13.7177 - val_loss: 14.4743\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 13.7143 - val_loss: 14.4706\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.7106 - val_loss: 14.4673\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.7073 - val_loss: 14.4636\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 13.7036 - val_loss: 14.4603\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.7003 - val_loss: 14.4567\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 13.6968 - val_loss: 14.4532\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.6934 - val_loss: 14.4498\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 13.6900 - val_loss: 14.4464\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.6866 - val_loss: 14.4430\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 13.6831 - val_loss: 14.4397\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.6799 - val_loss: 14.4363\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.6766 - val_loss: 14.4330\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 13.6733 - val_loss: 14.4296\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.6697 - val_loss: 14.4266\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.6666 - val_loss: 14.4234\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.6634 - val_loss: 14.4201\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.6599 - val_loss: 14.4170\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.6569 - val_loss: 14.4137\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.6535 - val_loss: 14.4106\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.6504 - val_loss: 14.4074\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.6472 - val_loss: 14.4043\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.6440 - val_loss: 14.4013\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.6409 - val_loss: 14.3981\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.6377 - val_loss: 14.3950\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.6345 - val_loss: 14.3920\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.6313 - val_loss: 14.3889\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.6281 - val_loss: 14.3859\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.6251 - val_loss: 14.3826\n",
      "Epoch 73/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 70us/step - loss: 13.6219 - val_loss: 14.3794\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.6186 - val_loss: 14.3766\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.6156 - val_loss: 14.3736\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.6126 - val_loss: 14.3704\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.6094 - val_loss: 14.3673\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.6063 - val_loss: 14.3642\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.6033 - val_loss: 14.3611\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.6001 - val_loss: 14.3581\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.5970 - val_loss: 14.3551\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.5941 - val_loss: 14.3520\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.5909 - val_loss: 14.3491\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.5880 - val_loss: 14.3461\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.5851 - val_loss: 14.3431\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.5820 - val_loss: 14.3401\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.5791 - val_loss: 14.3371\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.5760 - val_loss: 14.3343\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.5732 - val_loss: 14.3313\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.5702 - val_loss: 14.3283\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.5672 - val_loss: 14.3255\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.5643 - val_loss: 14.3226\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.5613 - val_loss: 14.3197\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.5583 - val_loss: 14.3168\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.5554 - val_loss: 14.3140\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.5526 - val_loss: 14.3110\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.5497 - val_loss: 14.3080\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.5466 - val_loss: 14.3053\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 13.5440 - val_loss: 14.3023\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.5410 - val_loss: 14.2995\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.5381 - val_loss: 14.2967\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.5353 - val_loss: 14.2939\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.5325 - val_loss: 14.2910\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.5297 - val_loss: 14.2882\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.5268 - val_loss: 14.2854\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.5239 - val_loss: 14.2828\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.5212 - val_loss: 14.2800\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.5185 - val_loss: 14.2772\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.5156 - val_loss: 14.2745\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.5128 - val_loss: 14.2719\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 98us/step - loss: 13.5100 - val_loss: 14.2692\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.5074 - val_loss: 14.2665\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.5046 - val_loss: 14.2639\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 91us/step - loss: 13.5019 - val_loss: 14.2612\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 84us/step - loss: 13.4993 - val_loss: 14.2584\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 13.4965 - val_loss: 14.2558\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 88us/step - loss: 13.4938 - val_loss: 14.2532\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 112us/step - loss: 13.4910 - val_loss: 14.2508\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 112us/step - loss: 13.4885 - val_loss: 14.2481\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 13.4859 - val_loss: 14.2454\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4832 - val_loss: 14.2428\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 101us/step - loss: 13.4804 - val_loss: 14.2404\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 107us/step - loss: 13.4779 - val_loss: 14.2379\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 100us/step - loss: 13.4752 - val_loss: 14.2354\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 105us/step - loss: 13.4727 - val_loss: 14.2328\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 107us/step - loss: 13.4701 - val_loss: 14.2301\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 99us/step - loss: 13.4674 - val_loss: 14.2277\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 104us/step - loss: 13.4648 - val_loss: 14.2252\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 98us/step - loss: 13.4624 - val_loss: 14.2227\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 110us/step - loss: 13.4597 - val_loss: 14.2204\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 99us/step - loss: 13.4573 - val_loss: 14.2178\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 107us/step - loss: 13.4545 - val_loss: 14.2155\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 99us/step - loss: 13.4520 - val_loss: 14.2132\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 104us/step - loss: 13.4496 - val_loss: 14.2106\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 112us/step - loss: 13.4470 - val_loss: 14.2082\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 98us/step - loss: 13.4445 - val_loss: 14.2058\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 95us/step - loss: 13.4420 - val_loss: 14.2033\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 110us/step - loss: 13.4395 - val_loss: 14.2009\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 94us/step - loss: 13.4369 - val_loss: 14.1988\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4347 - val_loss: 14.1964\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 13.4320 - val_loss: 14.1942\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4298 - val_loss: 14.1917\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4273 - val_loss: 14.1893\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4248 - val_loss: 14.1870\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4224 - val_loss: 14.1847\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.4199 - val_loss: 14.1824\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.4175 - val_loss: 14.1801\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.4150 - val_loss: 14.1779\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.4127 - val_loss: 14.1756\n",
      "Epoch 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 68us/step - loss: 13.4104 - val_loss: 14.1733\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.4077 - val_loss: 14.1713\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 13.4055 - val_loss: 14.1690\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.4032 - val_loss: 14.1668\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.4007 - val_loss: 14.1647\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.3984 - val_loss: 14.1625\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.3961 - val_loss: 14.1603\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.3936 - val_loss: 14.1583\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.3913 - val_loss: 14.1562\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.3890 - val_loss: 14.1540\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.3867 - val_loss: 14.1519\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.3845 - val_loss: 14.1496\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.3820 - val_loss: 14.1475\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.3798 - val_loss: 14.1454\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.3774 - val_loss: 14.1435\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.3752 - val_loss: 14.1415\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.3729 - val_loss: 14.1395\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.3708 - val_loss: 14.1373\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 13.3683 - val_loss: 14.1355\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.3662 - val_loss: 14.1335\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.3640 - val_loss: 14.1315\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.3617 - val_loss: 14.1295\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.3595 - val_loss: 14.1275\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.3570 - val_loss: 14.1258\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.3551 - val_loss: 14.1239\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.3527 - val_loss: 14.1222\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.3507 - val_loss: 14.1204\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.3484 - val_loss: 14.1186\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.3462 - val_loss: 14.1169\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 13.3442 - val_loss: 14.1151\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 13.3420 - val_loss: 14.1133\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.3398 - val_loss: 14.1117\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.3377 - val_loss: 14.1100\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.3355 - val_loss: 14.1085\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.3334 - val_loss: 14.1069\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.3313 - val_loss: 14.1053\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.3292 - val_loss: 14.1038\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.3273 - val_loss: 14.1021\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.3250 - val_loss: 14.1007\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.3230 - val_loss: 14.0992\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.3211 - val_loss: 14.0977\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 9.363 - 0s 79us/step - loss: 13.3189 - val_loss: 14.0964\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.3169 - val_loss: 14.0951\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.3150 - val_loss: 14.0937\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.3130 - val_loss: 14.0923\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.3110 - val_loss: 14.0910\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.3090 - val_loss: 14.0898\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.3070 - val_loss: 14.0886\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.3052 - val_loss: 14.0873\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.3033 - val_loss: 14.0861\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.3015 - val_loss: 14.0850\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2996 - val_loss: 14.0838\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2976 - val_loss: 14.0828\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2960 - val_loss: 14.0817\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.2941 - val_loss: 14.0807\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2925 - val_loss: 14.0796\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.2906 - val_loss: 14.0787\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.2889 - val_loss: 14.0777\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.2871 - val_loss: 14.0768\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.2854 - val_loss: 14.0758\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 13.2838 - val_loss: 14.0749\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.2820 - val_loss: 14.0740\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2803 - val_loss: 14.0732\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.2788 - val_loss: 14.0723\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.2771 - val_loss: 14.0714\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.2755 - val_loss: 14.0706\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.2738 - val_loss: 14.0699\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.2722 - val_loss: 14.0691\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2706 - val_loss: 14.0683\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.2689 - val_loss: 14.0675\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.2674 - val_loss: 14.0668\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.2658 - val_loss: 14.0661\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.2642 - val_loss: 14.0655\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.2627 - val_loss: 14.0647\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.2612 - val_loss: 14.0640\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.2598 - val_loss: 14.0633\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.2582 - val_loss: 14.0626\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 75us/step - loss: 13.2565 - val_loss: 14.0620\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.2552 - val_loss: 14.0613\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.2538 - val_loss: 14.0607\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 13.2520 - val_loss: 14.0602\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.2507 - val_loss: 14.0597\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.2492 - val_loss: 14.0592\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2478 - val_loss: 14.0587\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.2465 - val_loss: 14.0582\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.2450 - val_loss: 14.0576\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.2437 - val_loss: 14.0572\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.2421 - val_loss: 14.0568\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.2409 - val_loss: 14.0563\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.2395 - val_loss: 14.0559\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.2382 - val_loss: 14.0555\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2368 - val_loss: 14.0551\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.2355 - val_loss: 14.0547\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.2342 - val_loss: 14.0543\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.2329 - val_loss: 14.0539\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2317 - val_loss: 14.0535\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 13.2302 - val_loss: 14.0532\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.2291 - val_loss: 14.0528\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 13.2278 - val_loss: 14.0524\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.2266 - val_loss: 14.0520\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 13.2253 - val_loss: 14.0517\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.2242 - val_loss: 14.0514\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.2228 - val_loss: 14.0510\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.2216 - val_loss: 14.0507\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.2206 - val_loss: 14.0503\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.2191 - val_loss: 14.0501\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.2179 - val_loss: 14.0498\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.2167 - val_loss: 14.0495\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.2155 - val_loss: 14.0492\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.2145 - val_loss: 14.0489\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2132 - val_loss: 14.0486\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.2121 - val_loss: 14.0484\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.2109 - val_loss: 14.0482\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.2097 - val_loss: 14.0480\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.2088 - val_loss: 14.0478\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.2075 - val_loss: 14.0476\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.2065 - val_loss: 14.0475\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 13.2054 - val_loss: 14.0473\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 13.2043 - val_loss: 14.0472\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 13.2036 - val_loss: 14.0471\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.2022 - val_loss: 14.0470\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 13.2013 - val_loss: 14.0468\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.2002 - val_loss: 14.0467\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.1992 - val_loss: 14.0467\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 13.1982 - val_loss: 14.0466\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 8.748 - 0s 79us/step - loss: 13.1973 - val_loss: 14.0466\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.1962 - val_loss: 14.0464\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 13.1952 - val_loss: 14.0464\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.1942 - val_loss: 14.0463\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 13.1933 - val_loss: 14.0463\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.1923 - val_loss: 14.0463\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 13.1914 - val_loss: 14.0463\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 25.94 - 0s 61us/step - loss: 13.1903 - val_loss: 14.0462\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 88us/step - loss: 13.1894 - val_loss: 14.0463\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 89us/step - loss: 13.1885 - val_loss: 14.0463\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 13.1875 - val_loss: 14.0463\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.1865 - val_loss: 14.0463\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 13.1856 - val_loss: 14.0464\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.1848 - val_loss: 14.0465\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.1838 - val_loss: 14.0465\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 13.1829 - val_loss: 14.0466\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 13.1820 - val_loss: 14.0467\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.1810 - val_loss: 14.0467\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.1803 - val_loss: 14.0468\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 13.1793 - val_loss: 14.0469\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 13.1785 - val_loss: 14.0470\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 13.1778 - val_loss: 14.0471\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 13.1769 - val_loss: 14.0473\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 13.1761 - val_loss: 14.0475\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 13.1753 - val_loss: 14.0476\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 13.1745 - val_loss: 14.0477\n",
      "oven hvac\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 859.3008 - val_loss: 872.1705\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 859.2932 - val_loss: 872.1654\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 69us/step - loss: 859.2857 - val_loss: 872.1603\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 859.2780 - val_loss: 872.1552\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 859.2704 - val_loss: 872.1501\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 859.2628 - val_loss: 872.1450\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 859.2552 - val_loss: 872.1399\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 859.2477 - val_loss: 872.1350\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 859.2400 - val_loss: 872.1300\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 859.2324 - val_loss: 872.1250\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 859.2248 - val_loss: 872.1200\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 859.2172 - val_loss: 872.1151\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 859.2096 - val_loss: 872.1102\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 859.2020 - val_loss: 872.1052\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 859.1944 - val_loss: 872.1004\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 859.1869 - val_loss: 872.0955\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 859.1793 - val_loss: 872.0907\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 859.1717 - val_loss: 872.0858\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 859.1642 - val_loss: 872.0810\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 859.1565 - val_loss: 872.0763\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 859.1490 - val_loss: 872.0714\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 859.1414 - val_loss: 872.0666\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 859.1339 - val_loss: 872.0619\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 859.1263 - val_loss: 872.0570\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 859.1186 - val_loss: 872.0522\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 859.1112 - val_loss: 872.0475\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 859.1037 - val_loss: 872.0425\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 859.0961 - val_loss: 872.0377\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 859.0884 - val_loss: 872.0330\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 859.0810 - val_loss: 872.0281\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 84us/step - loss: 859.0734 - val_loss: 872.0234\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 93us/step - loss: 859.0659 - val_loss: 872.0185\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 859.0584 - val_loss: 872.0137\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 859.0508 - val_loss: 872.0090\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 859.0432 - val_loss: 872.0043\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 859.0358 - val_loss: 871.9994\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 859.0282 - val_loss: 871.9946\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 859.0207 - val_loss: 871.9898\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 859.0132 - val_loss: 871.9851\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 859.0055 - val_loss: 871.9804\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 858.9981 - val_loss: 871.9756\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 858.9906 - val_loss: 871.9708\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.9832 - val_loss: 871.9660\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 858.9755 - val_loss: 871.9612\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 858.9682 - val_loss: 871.9564\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 858.9605 - val_loss: 871.9517\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 858.9530 - val_loss: 871.9468\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 858.9454 - val_loss: 871.9421\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.9381 - val_loss: 871.9373\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 858.9306 - val_loss: 871.9324\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 858.9229 - val_loss: 871.9277\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.9155 - val_loss: 871.9230\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 858.9080 - val_loss: 871.9181\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 858.9005 - val_loss: 871.9134\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 858.8930 - val_loss: 871.9085\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 858.8855 - val_loss: 871.9038\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 858.8779 - val_loss: 871.8990\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 858.8704 - val_loss: 871.8943\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 858.8630 - val_loss: 871.8895\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 858.8554 - val_loss: 871.8847\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 858.8478 - val_loss: 871.8799\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 858.8404 - val_loss: 871.8752\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 858.8328 - val_loss: 871.8703\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 858.8254 - val_loss: 871.8656\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 858.8178 - val_loss: 871.8607\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 858.8104 - val_loss: 871.8560\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 858.8027 - val_loss: 871.8512\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 858.7952 - val_loss: 871.8466\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 858.7878 - val_loss: 871.8417\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 858.7803 - val_loss: 871.8370\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 858.7729 - val_loss: 871.8322\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 858.7653 - val_loss: 871.8274\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 858.7578 - val_loss: 871.8227\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 858.7502 - val_loss: 871.8179\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 858.7428 - val_loss: 871.8132\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.7354 - val_loss: 871.8084\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 858.7279 - val_loss: 871.8037\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 858.7202 - val_loss: 871.7989\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 74us/step - loss: 858.7128 - val_loss: 871.7942\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 858.7054 - val_loss: 871.7895\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 858.6978 - val_loss: 871.7847\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 858.6903 - val_loss: 871.7801\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 858.6829 - val_loss: 871.7753\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 858.6754 - val_loss: 871.7705\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 858.6677 - val_loss: 871.7658\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 858.6603 - val_loss: 871.7610\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 858.6528 - val_loss: 871.7564\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 858.6453 - val_loss: 871.7516\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 858.6379 - val_loss: 871.7469\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 895.130 - 0s 88us/step - loss: 858.6302 - val_loss: 871.7420\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 858.6228 - val_loss: 871.7374\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 858.6154 - val_loss: 871.7326\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 858.6077 - val_loss: 871.7280\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 858.6003 - val_loss: 871.7232\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 858.5929 - val_loss: 871.7184\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.5853 - val_loss: 871.7137\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 858.5779 - val_loss: 871.7089\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 858.5704 - val_loss: 871.7042\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 858.5630 - val_loss: 871.6994\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 858.5554 - val_loss: 871.6948\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 858.5480 - val_loss: 871.6900\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 858.5405 - val_loss: 871.6853\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 858.5331 - val_loss: 871.6805\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 858.5256 - val_loss: 871.6758\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 858.5181 - val_loss: 871.6711\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 858.5108 - val_loss: 871.6662\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 858.5032 - val_loss: 871.6615\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 858.4958 - val_loss: 871.6568\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 858.4882 - val_loss: 871.6521\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 858.4809 - val_loss: 871.6474\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 858.4734 - val_loss: 871.6426\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 858.4659 - val_loss: 871.6379\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 858.4584 - val_loss: 871.6332\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 858.4511 - val_loss: 871.6285\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 858.4435 - val_loss: 871.6238\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.4361 - val_loss: 871.6191\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 858.4286 - val_loss: 871.6143\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 858.4213 - val_loss: 871.6096\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 858.4138 - val_loss: 871.6048\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 858.4064 - val_loss: 871.6000\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 858.3988 - val_loss: 871.5953\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.3914 - val_loss: 871.5906\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 858.3840 - val_loss: 871.5858\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 858.3765 - val_loss: 871.5810\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 858.3690 - val_loss: 871.5764\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 858.3616 - val_loss: 871.5716\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 858.3543 - val_loss: 871.5669\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 858.3467 - val_loss: 871.5622\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 858.3392 - val_loss: 871.5575\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 84us/step - loss: 858.3319 - val_loss: 871.5528\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 858.3245 - val_loss: 871.5479\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 858.3169 - val_loss: 871.5432\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 858.3096 - val_loss: 871.5386\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 858.3021 - val_loss: 871.5338\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 858.2946 - val_loss: 871.5291\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.2873 - val_loss: 871.5242\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 858.2798 - val_loss: 871.5196\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 858.2724 - val_loss: 871.5148\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 858.2649 - val_loss: 871.5101\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 858.2575 - val_loss: 871.5053\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 858.2501 - val_loss: 871.5006\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 858.2426 - val_loss: 871.4959\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 858.2351 - val_loss: 871.4912\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 858.2278 - val_loss: 871.4864\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 858.2203 - val_loss: 871.4817\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 858.2128 - val_loss: 871.4770\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 858.2055 - val_loss: 871.4722\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 858.1980 - val_loss: 871.4675\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 858.1906 - val_loss: 871.4627\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 858.1832 - val_loss: 871.4581\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 858.1757 - val_loss: 871.4533\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 858.1683 - val_loss: 871.4486\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 858.1608 - val_loss: 871.4439\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 858.1535 - val_loss: 871.4391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 858.1461 - val_loss: 871.4343\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 858.1385 - val_loss: 871.4297\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 858.1312 - val_loss: 871.4248\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 858.1237 - val_loss: 871.4202\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 858.1162 - val_loss: 871.4154\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.1089 - val_loss: 871.4107\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 858.1015 - val_loss: 871.4059\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 858.0940 - val_loss: 871.4012\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 858.0865 - val_loss: 871.3966\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 858.0792 - val_loss: 871.3918\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 858.0717 - val_loss: 871.3870\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 858.0643 - val_loss: 871.3823\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 858.0569 - val_loss: 871.3775\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 858.0495 - val_loss: 871.3728\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 858.0421 - val_loss: 871.3681\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 858.0346 - val_loss: 871.3633\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 858.0271 - val_loss: 871.3586\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 858.0198 - val_loss: 871.3539\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 858.0123 - val_loss: 871.3492\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 858.0049 - val_loss: 871.3445\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 857.9975 - val_loss: 871.3397\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 857.9901 - val_loss: 871.3349\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 857.9826 - val_loss: 871.3302\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 857.9752 - val_loss: 871.3255\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 857.9678 - val_loss: 871.3208\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 857.9604 - val_loss: 871.3160\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 857.9529 - val_loss: 871.3113\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 857.9455 - val_loss: 871.3065\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 857.9381 - val_loss: 871.3018\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 857.9306 - val_loss: 871.2972\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 857.9232 - val_loss: 871.2924\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 857.9157 - val_loss: 871.2877\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 857.9085 - val_loss: 871.2829\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 857.9009 - val_loss: 871.2782\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 857.8935 - val_loss: 871.2735\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 857.8860 - val_loss: 871.2688\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.8788 - val_loss: 871.2639\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 857.8712 - val_loss: 871.2593\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 857.8638 - val_loss: 871.2545\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 857.8564 - val_loss: 871.2498\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 857.8490 - val_loss: 871.2451\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 857.8415 - val_loss: 871.2404\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 857.8342 - val_loss: 871.2356\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 857.8267 - val_loss: 871.2308\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 857.8192 - val_loss: 871.2261\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 857.8117 - val_loss: 871.2214\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 857.8043 - val_loss: 871.2167\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 857.7971 - val_loss: 871.2120\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 857.7895 - val_loss: 871.2073\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.7821 - val_loss: 871.2025\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 857.7747 - val_loss: 871.1977\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 857.7673 - val_loss: 871.1930\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 857.7598 - val_loss: 871.1883\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 857.7525 - val_loss: 871.1836\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 857.7450 - val_loss: 871.1788\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 857.7376 - val_loss: 871.1741\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.7302 - val_loss: 871.1694\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.7227 - val_loss: 871.1647\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 857.7153 - val_loss: 871.1599\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 857.7079 - val_loss: 871.1551\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 857.7005 - val_loss: 871.1504\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 857.6929 - val_loss: 871.1457\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 857.6857 - val_loss: 871.1409\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 857.6781 - val_loss: 871.1362\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 857.6706 - val_loss: 871.1315\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 857.6634 - val_loss: 871.1267\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.6558 - val_loss: 871.1220\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 857.6486 - val_loss: 871.1172\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.6410 - val_loss: 871.1125\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 857.6336 - val_loss: 871.1078\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 857.6263 - val_loss: 871.1031\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 857.6187 - val_loss: 871.0983\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 857.6115 - val_loss: 871.0936\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.6040 - val_loss: 871.0889\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 857.5967 - val_loss: 871.0841\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 93us/step - loss: 857.5891 - val_loss: 871.0794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 857.5817 - val_loss: 871.0747\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 857.5743 - val_loss: 871.0700\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 857.5670 - val_loss: 871.0652\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 857.5596 - val_loss: 871.0605\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 857.5521 - val_loss: 871.0557\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 857.5447 - val_loss: 871.0510\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 857.5372 - val_loss: 871.0463\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 857.5298 - val_loss: 871.0415\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 857.5224 - val_loss: 871.0368\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.5151 - val_loss: 871.0321\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 857.5077 - val_loss: 871.0273\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 857.5001 - val_loss: 871.0226\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.4928 - val_loss: 871.0179\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 857.4853 - val_loss: 871.0132\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 857.4780 - val_loss: 871.0084\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 902.712 - 0s 54us/step - loss: 857.4705 - val_loss: 871.0036\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 857.4631 - val_loss: 870.9989\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 857.4557 - val_loss: 870.9941\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 857.4481 - val_loss: 870.9894\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 857.4409 - val_loss: 870.9847\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 857.4334 - val_loss: 870.9800\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.4261 - val_loss: 870.9753\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 857.4185 - val_loss: 870.9706\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.4112 - val_loss: 870.9658\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.4038 - val_loss: 870.9610\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.3963 - val_loss: 870.9563\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 857.3889 - val_loss: 870.9515\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.3815 - val_loss: 870.9468\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 857.3740 - val_loss: 870.9421\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.3667 - val_loss: 870.9373\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.3592 - val_loss: 870.9326\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.3519 - val_loss: 870.9279\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 857.3443 - val_loss: 870.9232\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 857.3369 - val_loss: 870.9184\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 857.3296 - val_loss: 870.9137\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 857.3221 - val_loss: 870.9089\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 857.3147 - val_loss: 870.9042\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.3072 - val_loss: 870.8994\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 857.2999 - val_loss: 870.8948\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 857.2925 - val_loss: 870.8900\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 857.2851 - val_loss: 870.8852\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 857.2776 - val_loss: 870.8805\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.2702 - val_loss: 870.8757\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 857.2628 - val_loss: 870.8710\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.2553 - val_loss: 870.8663\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 857.2479 - val_loss: 870.8615\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 93us/step - loss: 857.2405 - val_loss: 870.8568\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 857.2331 - val_loss: 870.8520\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 857.2257 - val_loss: 870.8473\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.2183 - val_loss: 870.8426\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 857.2107 - val_loss: 870.8379\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.2033 - val_loss: 870.8331\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 103us/step - loss: 857.1959 - val_loss: 870.8284\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.1886 - val_loss: 870.8236\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 857.1811 - val_loss: 870.8188\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 857.1736 - val_loss: 870.8142\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 101us/step - loss: 857.1662 - val_loss: 870.8095\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 107us/step - loss: 857.1589 - val_loss: 870.8046\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 100us/step - loss: 857.1513 - val_loss: 870.7999\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 857.1439 - val_loss: 870.7953\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 857.1367 - val_loss: 870.7905\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 88us/step - loss: 857.1290 - val_loss: 870.7858\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 92us/step - loss: 857.1218 - val_loss: 870.7811\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 857.1143 - val_loss: 870.7763\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 84us/step - loss: 857.1069 - val_loss: 870.7716\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 857.0995 - val_loss: 870.7669\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 857.0919 - val_loss: 870.7620\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 857.0845 - val_loss: 870.7573\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 857.0771 - val_loss: 870.7526\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 857.0697 - val_loss: 870.7478\n",
      "oven fridge\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 81.2731 - val_loss: 90.2026\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 81.2613 - val_loss: 90.1910\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 81.2495 - val_loss: 90.1793\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 81.2376 - val_loss: 90.1677\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 81.2258 - val_loss: 90.1560\n",
      "Epoch 6/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 51us/step - loss: 81.2140 - val_loss: 90.1444\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 81.2021 - val_loss: 90.1328\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 81.1903 - val_loss: 90.1211\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 81.1785 - val_loss: 90.1095\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 81.1667 - val_loss: 90.0979\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 81.1549 - val_loss: 90.0863\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 81.1430 - val_loss: 90.0746\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 81.1312 - val_loss: 90.0630\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 81.1194 - val_loss: 90.0514\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 81.1076 - val_loss: 90.0398\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 93us/step - loss: 81.0958 - val_loss: 90.0281\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 81.0840 - val_loss: 90.0165\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 81.0722 - val_loss: 90.0049\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 81.0604 - val_loss: 89.9933\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 81.0486 - val_loss: 89.9817\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 81.0368 - val_loss: 89.9701\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 81.0249 - val_loss: 89.9584\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 81.0131 - val_loss: 89.9468\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 142us/step - loss: 81.0014 - val_loss: 89.9352\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 80.9896 - val_loss: 89.9236\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 80.9778 - val_loss: 89.9120\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 80.9660 - val_loss: 89.9004\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 80.9542 - val_loss: 89.8888\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 80.9424 - val_loss: 89.8772\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 80.9306 - val_loss: 89.8656\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 80.9188 - val_loss: 89.8539\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 80.9070 - val_loss: 89.8423\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 80.8952 - val_loss: 89.8307\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 80.8834 - val_loss: 89.8191\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 80.8716 - val_loss: 89.8075\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 80.8598 - val_loss: 89.7959\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 80.8480 - val_loss: 89.7843\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.8362 - val_loss: 89.7727\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 80.8244 - val_loss: 89.7610\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 80.8126 - val_loss: 89.7494\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 80.8008 - val_loss: 89.7378\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 80.7890 - val_loss: 89.7262\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 80.7772 - val_loss: 89.7146\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 80.7654 - val_loss: 89.7030\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 80.7537 - val_loss: 89.6914\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 80.7419 - val_loss: 89.6797\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 80.7300 - val_loss: 89.6682\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 76.06 - 0s 58us/step - loss: 80.7183 - val_loss: 89.6566\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 80.7065 - val_loss: 89.6450\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 80.6947 - val_loss: 89.6334\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 80.6829 - val_loss: 89.6218\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 80.6711 - val_loss: 89.6102\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 80.6593 - val_loss: 89.5987\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.6475 - val_loss: 89.5871\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 80.6357 - val_loss: 89.5755\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 80.6239 - val_loss: 89.5639\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 80.6121 - val_loss: 89.5523\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.6003 - val_loss: 89.5407\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 80.5885 - val_loss: 89.5291\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 80.5767 - val_loss: 89.5175\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.5649 - val_loss: 89.5059\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.5531 - val_loss: 89.4943\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.5414 - val_loss: 89.4827\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 80.5295 - val_loss: 89.4712\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 80.5178 - val_loss: 89.4596\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 80.5060 - val_loss: 89.4480\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 80.4942 - val_loss: 89.4364\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.4824 - val_loss: 89.4248\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.4706 - val_loss: 89.4132\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.4588 - val_loss: 89.4016\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 80.4470 - val_loss: 89.3900\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.4352 - val_loss: 89.3784\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.4234 - val_loss: 89.3669\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.4116 - val_loss: 89.3553\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 80.3998 - val_loss: 89.3437\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.3881 - val_loss: 89.3321\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.3763 - val_loss: 89.3205\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 80.3645 - val_loss: 89.3089\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 80.3527 - val_loss: 89.2974\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 80.3409 - val_loss: 89.2858\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.3291 - val_loss: 89.2742\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 80.3173 - val_loss: 89.2626\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.3055 - val_loss: 89.2510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.2938 - val_loss: 89.2394\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.2820 - val_loss: 89.2279\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.2702 - val_loss: 89.2163\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 80.2584 - val_loss: 89.2047\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.2466 - val_loss: 89.1931\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.2348 - val_loss: 89.1815\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.2230 - val_loss: 89.1699\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.2112 - val_loss: 89.1583\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.1995 - val_loss: 89.1468\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 80.1877 - val_loss: 89.1352\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 80.1759 - val_loss: 89.1236\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 80.1641 - val_loss: 89.1120\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 80.1523 - val_loss: 89.1004\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.1405 - val_loss: 89.0888\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.1288 - val_loss: 89.0773\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.1170 - val_loss: 89.0657\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.1052 - val_loss: 89.0541\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.0934 - val_loss: 89.0425\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 80.0816 - val_loss: 89.0309\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.0699 - val_loss: 89.0193\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 80.0581 - val_loss: 89.0077\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 80.0463 - val_loss: 88.9961\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 80.0345 - val_loss: 88.9846\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 80.0227 - val_loss: 88.9730\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 80.0110 - val_loss: 88.9614\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 79.9992 - val_loss: 88.9498\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.9874 - val_loss: 88.9382\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.9756 - val_loss: 88.9267\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.9638 - val_loss: 88.9151\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.9521 - val_loss: 88.9035\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 79.9403 - val_loss: 88.8919\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.9285 - val_loss: 88.8803\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.9167 - val_loss: 88.8688\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.9050 - val_loss: 88.8572\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.8932 - val_loss: 88.8456\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.8814 - val_loss: 88.8340\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.8696 - val_loss: 88.8224\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.8578 - val_loss: 88.8108\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.8460 - val_loss: 88.7993\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.8343 - val_loss: 88.7877\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 79.8225 - val_loss: 88.7761\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.8107 - val_loss: 88.7645\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.7989 - val_loss: 88.7530\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.7872 - val_loss: 88.7414\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.7754 - val_loss: 88.7298\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 79.7636 - val_loss: 88.7183\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.7518 - val_loss: 88.7067\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.7400 - val_loss: 88.6952\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.7282 - val_loss: 88.6836\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.7165 - val_loss: 88.6721\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 79.7047 - val_loss: 88.6605\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 79.6929 - val_loss: 88.6489\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.6811 - val_loss: 88.6374\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.6693 - val_loss: 88.6258\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.6576 - val_loss: 88.6143\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.6458 - val_loss: 88.6027\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.6340 - val_loss: 88.5911\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.6222 - val_loss: 88.5796\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.6104 - val_loss: 88.5680\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.5987 - val_loss: 88.5565\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 79.5869 - val_loss: 88.5449\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.5752 - val_loss: 88.5333\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.5634 - val_loss: 88.5218\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.5516 - val_loss: 88.5102\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.5398 - val_loss: 88.4987\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.5280 - val_loss: 88.4871\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.5163 - val_loss: 88.4756\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.5045 - val_loss: 88.4640\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.4927 - val_loss: 88.4524\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.4809 - val_loss: 88.4409\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.4692 - val_loss: 88.4293\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.4574 - val_loss: 88.4178\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 79.4456 - val_loss: 88.4062\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.4338 - val_loss: 88.3946\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.4221 - val_loss: 88.3831\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.4103 - val_loss: 88.3715\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.3985 - val_loss: 88.3599\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 54us/step - loss: 79.3867 - val_loss: 88.3484\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.3749 - val_loss: 88.3368\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.3632 - val_loss: 88.3253\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.3514 - val_loss: 88.3137\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.3396 - val_loss: 88.3022\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.3279 - val_loss: 88.2906\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 79.3161 - val_loss: 88.2791\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.3043 - val_loss: 88.2675\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.2926 - val_loss: 88.2559\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.2808 - val_loss: 88.2444\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 50us/step - loss: 79.2690 - val_loss: 88.2328\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.2572 - val_loss: 88.2213\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.2455 - val_loss: 88.2097\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.2337 - val_loss: 88.1982\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.2219 - val_loss: 88.1866\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.2101 - val_loss: 88.1750\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.1984 - val_loss: 88.1635\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 79.1866 - val_loss: 88.1519\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 79.1748 - val_loss: 88.1403\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.1630 - val_loss: 88.1288\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.1513 - val_loss: 88.1172\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 79.1395 - val_loss: 88.1057\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 79.1277 - val_loss: 88.0941\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 82.03 - 0s 52us/step - loss: 79.1160 - val_loss: 88.0825\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 79.1042 - val_loss: 88.0710\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.0924 - val_loss: 88.0594\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 79.0806 - val_loss: 88.0479\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 79.0688 - val_loss: 88.0363\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.0571 - val_loss: 88.0247\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 79.0453 - val_loss: 88.0132\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.0335 - val_loss: 88.0016\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 79.0218 - val_loss: 87.9901\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 79.0100 - val_loss: 87.9785\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 78.9982 - val_loss: 87.9670\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 78.9864 - val_loss: 87.9554\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.9747 - val_loss: 87.9438\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 78.9629 - val_loss: 87.9323\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 78.9511 - val_loss: 87.9207\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 78.9393 - val_loss: 87.9091\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.9276 - val_loss: 87.8976\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 78.9158 - val_loss: 87.8860\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.9040 - val_loss: 87.8745\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 78.8923 - val_loss: 87.8629\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 108us/step - loss: 78.8805 - val_loss: 87.8514\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 78.8687 - val_loss: 87.8398\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.8569 - val_loss: 87.8282\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.8452 - val_loss: 87.8167\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.8334 - val_loss: 87.8051\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.8217 - val_loss: 87.7935\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 78.8099 - val_loss: 87.7820\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.7981 - val_loss: 87.7705\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.7864 - val_loss: 87.7589\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.7746 - val_loss: 87.7474\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.7628 - val_loss: 87.7358\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.7511 - val_loss: 87.7243\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.7393 - val_loss: 87.7128\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.7275 - val_loss: 87.7012\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.7158 - val_loss: 87.6897\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.7040 - val_loss: 87.6782\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.6922 - val_loss: 87.6666\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.6805 - val_loss: 87.6551\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 78.6687 - val_loss: 87.6435\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 78.6569 - val_loss: 87.6320\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.6452 - val_loss: 87.6205\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.6334 - val_loss: 87.6089\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 78.6216 - val_loss: 87.5974\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.6099 - val_loss: 87.5859\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.5981 - val_loss: 87.5743\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.5863 - val_loss: 87.5628\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.5746 - val_loss: 87.5513\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 78.5629 - val_loss: 87.5397\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.5511 - val_loss: 87.5282\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 78.5393 - val_loss: 87.5167\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 78.5276 - val_loss: 87.5051\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.5158 - val_loss: 87.4936\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.5040 - val_loss: 87.4821\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.4923 - val_loss: 87.4705\n",
      "Epoch 238/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 55us/step - loss: 78.4805 - val_loss: 87.4590\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.4687 - val_loss: 87.4475\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.4570 - val_loss: 87.4360\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.4453 - val_loss: 87.4244\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 78.4335 - val_loss: 87.4129\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.4217 - val_loss: 87.4014\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 78.4100 - val_loss: 87.3898\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.3982 - val_loss: 87.3783\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.3865 - val_loss: 87.3668\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 78.3747 - val_loss: 87.3553\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.3630 - val_loss: 87.3437\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.3512 - val_loss: 87.3322\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 78.3395 - val_loss: 87.3207\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.3277 - val_loss: 87.3091\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.3159 - val_loss: 87.2976\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.3042 - val_loss: 87.2861\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 78.2924 - val_loss: 87.2746\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 78.2807 - val_loss: 87.2630\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.2689 - val_loss: 87.2515\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 78.2572 - val_loss: 87.2400\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 76.26 - 0s 57us/step - loss: 78.2454 - val_loss: 87.2284\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.2337 - val_loss: 87.2169\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 78.2219 - val_loss: 87.2054\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.2102 - val_loss: 87.1938\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.1984 - val_loss: 87.1823\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.1866 - val_loss: 87.1708\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 78.1749 - val_loss: 87.1592\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.1631 - val_loss: 87.1477\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.1514 - val_loss: 87.1362\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.1396 - val_loss: 87.1246\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 78.1279 - val_loss: 87.1131\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.1161 - val_loss: 87.1016\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 78.1044 - val_loss: 87.0900\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 78.0926 - val_loss: 87.0785\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 78.0808 - val_loss: 87.0670\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 78.0691 - val_loss: 87.0555\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 88us/step - loss: 78.0573 - val_loss: 87.0439\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 123us/step - loss: 78.0456 - val_loss: 87.0324\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 78.0338 - val_loss: 87.0208\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 78.0220 - val_loss: 87.0093\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 110us/step - loss: 78.0103 - val_loss: 86.9978\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 77.9985 - val_loss: 86.9862\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 77.9867 - val_loss: 86.9747\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 77.9750 - val_loss: 86.9632\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 77.9633 - val_loss: 86.9516\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 77.9515 - val_loss: 86.9401\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 77.9398 - val_loss: 86.9286\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 77.9280 - val_loss: 86.9171\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 77.9163 - val_loss: 86.9055\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 90us/step - loss: 77.9045 - val_loss: 86.8940\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 77.8928 - val_loss: 86.8825\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 77.8810 - val_loss: 86.8710\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 77.8693 - val_loss: 86.8594\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 77.8575 - val_loss: 86.8479\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 77.8458 - val_loss: 86.8364\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 93us/step - loss: 77.8340 - val_loss: 86.8248\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 77.8223 - val_loss: 86.8133\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 77.8105 - val_loss: 86.8018\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 77.7988 - val_loss: 86.7902\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 77.7870 - val_loss: 86.7787\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 136us/step - loss: 77.7753 - val_loss: 86.7672\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 102us/step - loss: 77.7635 - val_loss: 86.7557\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 115us/step - loss: 77.7518 - val_loss: 86.7441\n",
      "oven mw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 11.2174 - val_loss: 12.2730\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 11.2071 - val_loss: 12.2637\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 11.1967 - val_loss: 12.2543\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 11.1864 - val_loss: 12.2449\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 11.1760 - val_loss: 12.2356\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 11.1656 - val_loss: 12.2263\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 11.1553 - val_loss: 12.2169\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 11.1450 - val_loss: 12.2076\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 11.1346 - val_loss: 12.1983\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 11.1242 - val_loss: 12.1890\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 11.1139 - val_loss: 12.1797\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 11.1036 - val_loss: 12.1703\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 11.0933 - val_loss: 12.1610\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 11.0829 - val_loss: 12.1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 11.0726 - val_loss: 12.1424\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 11.0623 - val_loss: 12.1331\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 11.0519 - val_loss: 12.1239\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 11.0416 - val_loss: 12.1145\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 11.0313 - val_loss: 12.1052\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 11.0210 - val_loss: 12.0959\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 11.0106 - val_loss: 12.0866\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 11.0004 - val_loss: 12.0773\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 10.9900 - val_loss: 12.0680\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 10.9797 - val_loss: 12.0586\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 10.9694 - val_loss: 12.0493\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 10.9591 - val_loss: 12.0400\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 10.9487 - val_loss: 12.0308\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 10.9385 - val_loss: 12.0214\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.9281 - val_loss: 12.0121\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 10.9178 - val_loss: 12.0028\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 10.9075 - val_loss: 11.9935\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 11.31 - 0s 52us/step - loss: 10.8972 - val_loss: 11.9842\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 10.8869 - val_loss: 11.9749\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 10.8766 - val_loss: 11.9656\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.8663 - val_loss: 11.9563\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 10.8560 - val_loss: 11.9470\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 10.8457 - val_loss: 11.9377\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.8353 - val_loss: 11.9284\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 10.8250 - val_loss: 11.9191\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 10.8147 - val_loss: 11.9098\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 10.8044 - val_loss: 11.9005\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 10.7941 - val_loss: 11.8912\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 10.7838 - val_loss: 11.8819\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 10.7735 - val_loss: 11.8726\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 10.7632 - val_loss: 11.8633\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.7529 - val_loss: 11.8540\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.7425 - val_loss: 11.8447\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 10.7323 - val_loss: 11.8354\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 10.7219 - val_loss: 11.8261\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 10.7116 - val_loss: 11.8168\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 10.7013 - val_loss: 11.8074\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.6910 - val_loss: 11.7981\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 10.6807 - val_loss: 11.7888\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 10.6704 - val_loss: 11.7795\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 10.6601 - val_loss: 11.7702\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 10.6497 - val_loss: 11.7609\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 10.6395 - val_loss: 11.7516\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 10.6292 - val_loss: 11.7422\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 10.6188 - val_loss: 11.7330\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 10.6085 - val_loss: 11.7237\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 12.61 - 0s 65us/step - loss: 10.5982 - val_loss: 11.7144\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 10.5879 - val_loss: 11.7051\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 10.5776 - val_loss: 11.6958\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 10.5673 - val_loss: 11.6864\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 10.5570 - val_loss: 11.6771\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 10.5466 - val_loss: 11.6679\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 10.5364 - val_loss: 11.6585\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 10.5260 - val_loss: 11.6492\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 10.5158 - val_loss: 11.6399\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 10.5054 - val_loss: 11.6306\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 10.4951 - val_loss: 11.6213\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 10.4849 - val_loss: 11.6120\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 10.4746 - val_loss: 11.6027\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 10.4642 - val_loss: 11.5934\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 10.4540 - val_loss: 11.5841\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 10.4437 - val_loss: 11.5748\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 10.4334 - val_loss: 11.5655\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 10.4231 - val_loss: 11.5562\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 10.4128 - val_loss: 11.5469\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 10.4025 - val_loss: 11.5376\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 10.3922 - val_loss: 11.5283\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 10.3819 - val_loss: 11.5190\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 10.3716 - val_loss: 11.5097\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 10.3613 - val_loss: 11.5004\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 10.3510 - val_loss: 11.4911\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 10.3407 - val_loss: 11.4818\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 10.3304 - val_loss: 11.4725\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 10.3201 - val_loss: 11.4632\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 10.3099 - val_loss: 11.4539\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 10.2996 - val_loss: 11.4446\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 10.2893 - val_loss: 11.4353\n",
      "Epoch 92/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 54us/step - loss: 10.2790 - val_loss: 11.4260\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 10.2687 - val_loss: 11.4168\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 10.2585 - val_loss: 11.4075\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 10.2482 - val_loss: 11.3982\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.2379 - val_loss: 11.3889\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 10.2276 - val_loss: 11.3796\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.2174 - val_loss: 11.3703\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 10.2071 - val_loss: 11.3610\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.1968 - val_loss: 11.3517\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 10.1865 - val_loss: 11.3424\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 10.1762 - val_loss: 11.3331\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 10.1660 - val_loss: 11.3238\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 10.1557 - val_loss: 11.3145\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 10.1454 - val_loss: 11.3052\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 10.1352 - val_loss: 11.2959\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 10.1249 - val_loss: 11.2866\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 10.1146 - val_loss: 11.2773\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 10.1043 - val_loss: 11.2681\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 10.0941 - val_loss: 11.2587\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 10.0838 - val_loss: 11.2494\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 10.0735 - val_loss: 11.2402\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 10.0633 - val_loss: 11.2309\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 10.0530 - val_loss: 11.2216\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 10.0427 - val_loss: 11.2123\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 9.438 - 0s 53us/step - loss: 10.0325 - val_loss: 11.2030\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 10.0222 - val_loss: 11.1937\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 10.0120 - val_loss: 11.1844\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 10.0017 - val_loss: 11.1751\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 9.9914 - val_loss: 11.1658\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.9812 - val_loss: 11.1565\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.9709 - val_loss: 11.1473\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.9607 - val_loss: 11.1379\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.9504 - val_loss: 11.1286\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.9401 - val_loss: 11.1194\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.9299 - val_loss: 11.1101\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.9196 - val_loss: 11.1008\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 9.9094 - val_loss: 11.0915\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.8991 - val_loss: 11.0822\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 9.8889 - val_loss: 11.0729\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 9.8786 - val_loss: 11.0636\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 9.8684 - val_loss: 11.0544\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.8582 - val_loss: 11.0451\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 9.8479 - val_loss: 11.0358\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.8377 - val_loss: 11.0266\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 9.8274 - val_loss: 11.0173\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.8172 - val_loss: 11.0080\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.8069 - val_loss: 10.9988\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.7967 - val_loss: 10.9895\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 9.7865 - val_loss: 10.9802\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.7762 - val_loss: 10.9710\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.7660 - val_loss: 10.9617\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.7557 - val_loss: 10.9525\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.7455 - val_loss: 10.9432\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 9.7353 - val_loss: 10.9339\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.7250 - val_loss: 10.9247\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.7148 - val_loss: 10.9155\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.7046 - val_loss: 10.9062\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.6943 - val_loss: 10.8969\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.6841 - val_loss: 10.8877\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.6739 - val_loss: 10.8784\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 9.6636 - val_loss: 10.8692\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.6534 - val_loss: 10.8599\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.6432 - val_loss: 10.8506\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.6330 - val_loss: 10.8414\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.6227 - val_loss: 10.8321\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.6125 - val_loss: 10.8229\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.6023 - val_loss: 10.8136\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 9.5920 - val_loss: 10.8043\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.5818 - val_loss: 10.7951\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.5715 - val_loss: 10.7859\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.5613 - val_loss: 10.7766\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.5511 - val_loss: 10.7673\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 9.5409 - val_loss: 10.7580\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.5306 - val_loss: 10.7488\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.5204 - val_loss: 10.7396\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.5102 - val_loss: 10.7304\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.5000 - val_loss: 10.7212\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 53us/step - loss: 9.4898 - val_loss: 10.7119\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.4795 - val_loss: 10.7027\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 9.4693 - val_loss: 10.6935\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.4591 - val_loss: 10.6842\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 9.4489 - val_loss: 10.6750\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 9.4387 - val_loss: 10.6658\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.4286 - val_loss: 10.6566\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.4184 - val_loss: 10.6475\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 9.4084 - val_loss: 10.6383\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.3984 - val_loss: 10.6292\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.3884 - val_loss: 10.6201\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 9.3784 - val_loss: 10.6111\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.3685 - val_loss: 10.6020\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.3585 - val_loss: 10.5929\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.3486 - val_loss: 10.5838\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 9.3387 - val_loss: 10.5747\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.3287 - val_loss: 10.5656\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.3187 - val_loss: 10.5565\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.3088 - val_loss: 10.5474\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.2988 - val_loss: 10.5382\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.2888 - val_loss: 10.5292\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.2789 - val_loss: 10.5200\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.2689 - val_loss: 10.5110\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 9.2590 - val_loss: 10.5019\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.2490 - val_loss: 10.4928\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 9.2391 - val_loss: 10.4837\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.2292 - val_loss: 10.4745\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 9.2192 - val_loss: 10.4654\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 8.447 - 0s 58us/step - loss: 9.2093 - val_loss: 10.4564\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.1994 - val_loss: 10.4473\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.1895 - val_loss: 10.4382\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 10.48 - 0s 52us/step - loss: 9.1796 - val_loss: 10.4291\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 9.1697 - val_loss: 10.4200\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 9.1597 - val_loss: 10.4109\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 9.1499 - val_loss: 10.4018\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.1400 - val_loss: 10.3927\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.1301 - val_loss: 10.3836\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.1202 - val_loss: 10.3746\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.1105 - val_loss: 10.3655\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.1007 - val_loss: 10.3565\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.0910 - val_loss: 10.3475\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.0812 - val_loss: 10.3384\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.0715 - val_loss: 10.3294\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 9.0617 - val_loss: 10.3204\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 9.0519 - val_loss: 10.3114\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 9.0422 - val_loss: 10.3024\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 9.0325 - val_loss: 10.2933\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 9.0227 - val_loss: 10.2843\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 9.0130 - val_loss: 10.2752\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 9.0033 - val_loss: 10.2662\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.9935 - val_loss: 10.2572\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.9838 - val_loss: 10.2481\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.9741 - val_loss: 10.2391\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.9644 - val_loss: 10.2301\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.9547 - val_loss: 10.2211\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.9450 - val_loss: 10.2121\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.9354 - val_loss: 10.2031\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.9258 - val_loss: 10.1941\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.9162 - val_loss: 10.1851\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.9066 - val_loss: 10.1762\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 8.8971 - val_loss: 10.1672\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 8.8875 - val_loss: 10.1583\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 8.8780 - val_loss: 10.1493\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 8.8684 - val_loss: 10.1404\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.8589 - val_loss: 10.1314\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.8494 - val_loss: 10.1224\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.8398 - val_loss: 10.1135\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.8302 - val_loss: 10.1046\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.8207 - val_loss: 10.0956\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.8111 - val_loss: 10.0866\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.8016 - val_loss: 10.0777\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.7921 - val_loss: 10.0687\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 8.7826 - val_loss: 10.0597\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 8.218 - 0s 64us/step - loss: 8.7731 - val_loss: 10.0507\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.7635 - val_loss: 10.0418\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.7539 - val_loss: 10.0328\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 8.7445 - val_loss: 10.0238\n",
      "Epoch 246/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step - loss: 8.7349 - val_loss: 10.0149\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.7254 - val_loss: 10.0059\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.7159 - val_loss: 9.9970\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.7065 - val_loss: 9.9880\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.6971 - val_loss: 9.9791\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.6877 - val_loss: 9.9702\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 8.6784 - val_loss: 9.9613\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.6692 - val_loss: 9.9524\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 8.6598 - val_loss: 9.9436\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.6505 - val_loss: 9.9348\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 9.814 - 0s 66us/step - loss: 8.6414 - val_loss: 9.9259\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 8.6321 - val_loss: 9.9170\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.6228 - val_loss: 9.9082\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.6135 - val_loss: 9.8994\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.6044 - val_loss: 9.8905\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.5951 - val_loss: 9.8816\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.5859 - val_loss: 9.8728\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 8.5766 - val_loss: 9.8639\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.5674 - val_loss: 9.8550\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 8.5582 - val_loss: 9.8461\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.5489 - val_loss: 9.8374\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.5399 - val_loss: 9.8286\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.5308 - val_loss: 9.8198\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.5217 - val_loss: 9.8109\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 8.5126 - val_loss: 9.8021\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 8.5035 - val_loss: 9.7932\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.4943 - val_loss: 9.7845\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.4853 - val_loss: 9.7756\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 8.4761 - val_loss: 9.7668\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.4670 - val_loss: 9.7580\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.4580 - val_loss: 9.7491\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.4487 - val_loss: 9.7404\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.4397 - val_loss: 9.7316\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.4306 - val_loss: 9.7227\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.4215 - val_loss: 9.7139\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.4124 - val_loss: 9.7050\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.4033 - val_loss: 9.6962\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.3942 - val_loss: 9.6874\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.3851 - val_loss: 9.6785\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 8.3760 - val_loss: 9.6697\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.3669 - val_loss: 9.6608\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.3578 - val_loss: 9.6520\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.3488 - val_loss: 9.6432\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.3397 - val_loss: 9.6344\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 8.3307 - val_loss: 9.6255\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.3216 - val_loss: 9.6166\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 8.3125 - val_loss: 9.6078\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 8.3035 - val_loss: 9.5989\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 8.2944 - val_loss: 9.5901\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 8.2854 - val_loss: 9.5813\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 8.2763 - val_loss: 9.5725\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 8.2673 - val_loss: 9.5636\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 8.2583 - val_loss: 9.5548\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 8.2492 - val_loss: 9.5460\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 8.2402 - val_loss: 9.5371\n",
      "oven dw\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 19.5721 - val_loss: 23.3777\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 19.5612 - val_loss: 23.3669\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 19.5501 - val_loss: 23.3561\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 19.5391 - val_loss: 23.3454\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 19.5280 - val_loss: 23.3346\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 91us/step - loss: 19.5171 - val_loss: 23.3237\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 19.5060 - val_loss: 23.3129\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 19.4950 - val_loss: 23.3021\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 19.4840 - val_loss: 23.2914\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 19.4730 - val_loss: 23.2806\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 19.4620 - val_loss: 23.2698\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 19.4510 - val_loss: 23.2590\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 19.4400 - val_loss: 23.2482\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 19.4290 - val_loss: 23.2375\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 19.4180 - val_loss: 23.2267\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 92us/step - loss: 19.4071 - val_loss: 23.2159\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 89us/step - loss: 19.3961 - val_loss: 23.2052\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 19.3852 - val_loss: 23.1945\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 19.3743 - val_loss: 23.1837\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 19.3633 - val_loss: 23.1729\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 98us/step - loss: 19.3523 - val_loss: 23.1621\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 19.3414 - val_loss: 23.1514\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 19.3304 - val_loss: 23.1406\n",
      "Epoch 24/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 58us/step - loss: 19.3195 - val_loss: 23.1299\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 19.3085 - val_loss: 23.1191\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 19.2976 - val_loss: 23.1084\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 19.2866 - val_loss: 23.0976\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 19.2757 - val_loss: 23.0868\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 19.2647 - val_loss: 23.0761\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 19.2538 - val_loss: 23.0653\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 19.2428 - val_loss: 23.0545\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 19.2319 - val_loss: 23.0438\n",
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 19.2209 - val_loss: 23.0330\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 19.2099 - val_loss: 23.0223\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 19.1990 - val_loss: 23.0115\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 19.1881 - val_loss: 23.0007\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 96us/step - loss: 19.1771 - val_loss: 22.9899\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 19.1662 - val_loss: 22.9792\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 104us/step - loss: 19.1552 - val_loss: 22.9684\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 128us/step - loss: 19.1443 - val_loss: 22.9577\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 19.1334 - val_loss: 22.9469\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 92us/step - loss: 19.1224 - val_loss: 22.9362\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 96us/step - loss: 19.1115 - val_loss: 22.9254\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 19.1007 - val_loss: 22.9147\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 19.0898 - val_loss: 22.9039\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 91us/step - loss: 19.0788 - val_loss: 22.8932\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 109us/step - loss: 19.0680 - val_loss: 22.8825\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 88us/step - loss: 19.0571 - val_loss: 22.8717\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 172us/step - loss: 19.0462 - val_loss: 22.8610\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 119us/step - loss: 19.0353 - val_loss: 22.8502\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 175us/step - loss: 19.0243 - val_loss: 22.8395\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 102us/step - loss: 19.0135 - val_loss: 22.8287\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 19.0026 - val_loss: 22.8180\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 18.9917 - val_loss: 22.8073\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 18.9809 - val_loss: 22.7965\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 18.9700 - val_loss: 22.7858\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 18.9591 - val_loss: 22.7751\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 18.9482 - val_loss: 22.7644\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 20.07 - 0s 60us/step - loss: 18.9374 - val_loss: 22.7536\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 18.9265 - val_loss: 22.7429\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 18.9156 - val_loss: 22.7321\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 18.9047 - val_loss: 22.7214\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 18.8939 - val_loss: 22.7107\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 18.8830 - val_loss: 22.7000\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 18.8722 - val_loss: 22.6893\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 18.8614 - val_loss: 22.6785\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 18.8505 - val_loss: 22.6678\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 18.8397 - val_loss: 22.6571\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 18.8288 - val_loss: 22.6464\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 18.8180 - val_loss: 22.6356\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 87us/step - loss: 18.8071 - val_loss: 22.6249\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 18.7962 - val_loss: 22.6142\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 18.7854 - val_loss: 22.6034\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 18.7745 - val_loss: 22.5927\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 18.7637 - val_loss: 22.5820\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 18.7528 - val_loss: 22.5712\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 18.7420 - val_loss: 22.5605\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 18.7312 - val_loss: 22.5498\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 18.7203 - val_loss: 22.5390\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 18.7094 - val_loss: 22.5283\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 18.6986 - val_loss: 22.5176\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 18.6878 - val_loss: 22.5069\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 18.6769 - val_loss: 22.4962\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 18.6661 - val_loss: 22.4854\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 18.6552 - val_loss: 22.4746\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 18.6443 - val_loss: 22.4639\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 18.6335 - val_loss: 22.4532\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 18.6227 - val_loss: 22.4424\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 18.6118 - val_loss: 22.4317\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 18.6009 - val_loss: 22.4210\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 106us/step - loss: 18.5901 - val_loss: 22.4102\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 18.5793 - val_loss: 22.3995\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 18.5684 - val_loss: 22.3888\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 18.5575 - val_loss: 22.3780\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 19.38 - 0s 72us/step - loss: 18.5467 - val_loss: 22.3673\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 84us/step - loss: 18.5359 - val_loss: 22.3565\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 18.5250 - val_loss: 22.3458\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 18.5141 - val_loss: 22.3351\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 18.5033 - val_loss: 22.3243\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 18.4924 - val_loss: 22.3136\n",
      "Epoch 101/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 66us/step - loss: 18.4816 - val_loss: 22.3029\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 102us/step - loss: 18.4707 - val_loss: 22.2921\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 18.4598 - val_loss: 22.2814\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 18.4490 - val_loss: 22.2706\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 18.4381 - val_loss: 22.2598\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 18.4273 - val_loss: 22.2491\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 18.4164 - val_loss: 22.2384\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 18.4056 - val_loss: 22.2277\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 18.3947 - val_loss: 22.2169\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 18.3838 - val_loss: 22.2062\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 92us/step - loss: 18.3730 - val_loss: 22.1954\n",
      "Epoch 112/300\n",
      "378/378 [==============================] - 0s 104us/step - loss: 18.3621 - val_loss: 22.1847\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 84us/step - loss: 18.3512 - val_loss: 22.1739\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 18.3404 - val_loss: 22.1632\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 18.3296 - val_loss: 22.1524\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 18.3186 - val_loss: 22.1417\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 106us/step - loss: 18.3078 - val_loss: 22.1310\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 18.2969 - val_loss: 22.1202\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 18.2861 - val_loss: 22.1095\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 18.2752 - val_loss: 22.0987\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 18.2643 - val_loss: 22.0880\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 18.2535 - val_loss: 22.0771\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 18.2426 - val_loss: 22.0664\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 18.2318 - val_loss: 22.0557\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 18.2209 - val_loss: 22.0449\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 18.2100 - val_loss: 22.0342\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 18.1992 - val_loss: 22.0234\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 18.1883 - val_loss: 22.0126\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 18.1774 - val_loss: 22.0019\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 18.1665 - val_loss: 21.9912\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 18.1557 - val_loss: 21.9804\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 91us/step - loss: 18.1448 - val_loss: 21.9697\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 18.1340 - val_loss: 21.9589\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 18.1231 - val_loss: 21.9481\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 18.1123 - val_loss: 21.9374\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 18.1014 - val_loss: 21.9266\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 18.0905 - val_loss: 21.9159\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 18.0797 - val_loss: 21.9052\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 18.0688 - val_loss: 21.8944\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 18.0580 - val_loss: 21.8837\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 18.0471 - val_loss: 21.8729\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 18.0362 - val_loss: 21.8622\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 18.0254 - val_loss: 21.8514\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 18.0145 - val_loss: 21.8407\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 18.0037 - val_loss: 21.8299\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 17.9928 - val_loss: 21.8192\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 17.9820 - val_loss: 21.8084\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 17.9711 - val_loss: 21.7976\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 17.9602 - val_loss: 21.7869\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 17.9494 - val_loss: 21.7762\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.9386 - val_loss: 21.7654\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 17.9277 - val_loss: 21.7546\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 17.9168 - val_loss: 21.7439\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 17.9060 - val_loss: 21.7332\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 17.8952 - val_loss: 21.7224\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 17.8843 - val_loss: 21.7117\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 17.8735 - val_loss: 21.7009\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 88us/step - loss: 17.8627 - val_loss: 21.6902\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 17.8518 - val_loss: 21.6794\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 76us/step - loss: 17.8410 - val_loss: 21.6687\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 17.8302 - val_loss: 21.6580\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 17.8194 - val_loss: 21.6473\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 17.8086 - val_loss: 21.6365\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 17.7977 - val_loss: 21.6257\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 17.7869 - val_loss: 21.6151\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 17.7761 - val_loss: 21.6043\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 17.7653 - val_loss: 21.5936\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 17.7544 - val_loss: 21.5830\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 17.7437 - val_loss: 21.5722\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 17.7329 - val_loss: 21.5615\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 17.7220 - val_loss: 21.5508\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 17.7113 - val_loss: 21.5400\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.7004 - val_loss: 21.5294\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 17.6896 - val_loss: 21.5187\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 17.6788 - val_loss: 21.5080\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 17.6680 - val_loss: 21.4973\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 17.6572 - val_loss: 21.4865\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 63us/step - loss: 17.6464 - val_loss: 21.4758\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 17.6355 - val_loss: 21.4651\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 17.6247 - val_loss: 21.4544\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 87us/step - loss: 17.6139 - val_loss: 21.4437\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 17.6031 - val_loss: 21.4330\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 17.5923 - val_loss: 21.4222\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 17.5815 - val_loss: 21.4115\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 17.5707 - val_loss: 21.4008\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.5599 - val_loss: 21.3901\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 17.5491 - val_loss: 21.3794\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.5383 - val_loss: 21.3687\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.5275 - val_loss: 21.3580\n",
      "Epoch 190/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 17.5167 - val_loss: 21.3473\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 17.5059 - val_loss: 21.3366\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 17.4951 - val_loss: 21.3259\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 17.4843 - val_loss: 21.3152\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 17.4735 - val_loss: 21.3045\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.4627 - val_loss: 21.2938\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.4519 - val_loss: 21.2831\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.4411 - val_loss: 21.2723\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.4303 - val_loss: 21.2616\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 17.4195 - val_loss: 21.2510\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 72us/step - loss: 17.4087 - val_loss: 21.2402\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 17.3979 - val_loss: 21.2295\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 141us/step - loss: 17.3871 - val_loss: 21.2188\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 17.3763 - val_loss: 21.2081\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.3656 - val_loss: 21.1974\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 17.3548 - val_loss: 21.1867\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 17.3440 - val_loss: 21.1760\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 17.3332 - val_loss: 21.1653\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 17.3224 - val_loss: 21.1546\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.3117 - val_loss: 21.1438\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 17.3009 - val_loss: 21.1332\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.2901 - val_loss: 21.1225\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 17.2793 - val_loss: 21.1118\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 17.2686 - val_loss: 21.1011\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 17.2578 - val_loss: 21.0904\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 17.2470 - val_loss: 21.0797\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 17.2363 - val_loss: 21.0690\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 17.2256 - val_loss: 21.0583\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.2150 - val_loss: 21.0477\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 17.2044 - val_loss: 21.0371\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 17.1938 - val_loss: 21.0265\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 17.1833 - val_loss: 21.0159\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 17.1727 - val_loss: 21.0053\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 17.1622 - val_loss: 20.9947\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 17.1517 - val_loss: 20.9841\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 17.1412 - val_loss: 20.9736\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 17.1307 - val_loss: 20.9629\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.1202 - val_loss: 20.9524\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 17.1097 - val_loss: 20.9419\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 17.0992 - val_loss: 20.9313\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 17.0887 - val_loss: 20.9207\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 17.0783 - val_loss: 20.9101\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.0677 - val_loss: 20.8995\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 17.0573 - val_loss: 20.8890\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 17.0468 - val_loss: 20.8784\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 17.0363 - val_loss: 20.8678\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 17.0258 - val_loss: 20.8573\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 17.0153 - val_loss: 20.8467\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 17.0049 - val_loss: 20.8361\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 16.9944 - val_loss: 20.8255\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 16.9839 - val_loss: 20.8150\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 16.9734 - val_loss: 20.8044\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 74us/step - loss: 16.9630 - val_loss: 20.7938\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 16.9525 - val_loss: 20.7833\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 16.9422 - val_loss: 20.7728\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.9319 - val_loss: 20.7623\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 16.9216 - val_loss: 20.7518\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 16.9114 - val_loss: 20.7413\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 16.9010 - val_loss: 20.7309\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 16.8908 - val_loss: 20.7204\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 16.8805 - val_loss: 20.7100\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 16.8703 - val_loss: 20.6994\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 16.8600 - val_loss: 20.6889\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 16.8497 - val_loss: 20.6785\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.8395 - val_loss: 20.6680\n",
      "Epoch 255/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 57us/step - loss: 16.8292 - val_loss: 20.6576\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 16.8190 - val_loss: 20.6471\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 16.8088 - val_loss: 20.6365\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 16.7985 - val_loss: 20.6260\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 16.7882 - val_loss: 20.6156\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.7780 - val_loss: 20.6051\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 16.7678 - val_loss: 20.5947\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 16.7577 - val_loss: 20.5842\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 16.7475 - val_loss: 20.5738\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 16.7374 - val_loss: 20.5634\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 16.7273 - val_loss: 20.5529\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 16.7172 - val_loss: 20.5425\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 16.7071 - val_loss: 20.5321\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 16.6970 - val_loss: 20.5216\n",
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 16.6869 - val_loss: 20.5112\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 16.6768 - val_loss: 20.5008\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 16.6668 - val_loss: 20.4903\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 16.6566 - val_loss: 20.4799\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 16.6465 - val_loss: 20.4696\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 70us/step - loss: 16.6365 - val_loss: 20.4591\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 16.6264 - val_loss: 20.4486\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 79us/step - loss: 16.6163 - val_loss: 20.4382\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 78us/step - loss: 16.6062 - val_loss: 20.4277\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 16.5962 - val_loss: 20.4173\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 16.5860 - val_loss: 20.4069\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 16.5760 - val_loss: 20.3964\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 16.5658 - val_loss: 20.3861\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 16.5558 - val_loss: 20.3756\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 16.5457 - val_loss: 20.3652\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 16.5356 - val_loss: 20.3547\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 16.5256 - val_loss: 20.3442\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 16.5155 - val_loss: 20.3338\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 16.5055 - val_loss: 20.3235\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 16.4956 - val_loss: 20.3131\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 16.4857 - val_loss: 20.3026\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 16.4758 - val_loss: 20.2923\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 16.4660 - val_loss: 20.2819\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 16.4562 - val_loss: 20.2715\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 16.4464 - val_loss: 20.2612\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 16.4366 - val_loss: 20.2510\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.4268 - val_loss: 20.2406\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 16.4171 - val_loss: 20.2303\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 16.4073 - val_loss: 20.2199\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 16.3974 - val_loss: 20.2096\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 16.3877 - val_loss: 20.1993\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 16.3779 - val_loss: 20.1890\n",
      "oven wm\n",
      "Train on 378 samples, validate on 42 samples\n",
      "Epoch 1/300\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 7.6177 - val_loss: 9.2698\n",
      "Epoch 2/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.6080 - val_loss: 9.2596\n",
      "Epoch 3/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.5983 - val_loss: 9.2493\n",
      "Epoch 4/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.5885 - val_loss: 9.2391\n",
      "Epoch 5/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.5788 - val_loss: 9.2288\n",
      "Epoch 6/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 7.5691 - val_loss: 9.2185\n",
      "Epoch 7/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.5594 - val_loss: 9.2083\n",
      "Epoch 8/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.5497 - val_loss: 9.1981\n",
      "Epoch 9/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.5399 - val_loss: 9.1879\n",
      "Epoch 10/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.5303 - val_loss: 9.1777\n",
      "Epoch 11/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.5207 - val_loss: 9.1673\n",
      "Epoch 12/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.5109 - val_loss: 9.1571\n",
      "Epoch 13/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.5013 - val_loss: 9.1468\n",
      "Epoch 14/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.4915 - val_loss: 9.1366\n",
      "Epoch 15/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.4819 - val_loss: 9.1264\n",
      "Epoch 16/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.4722 - val_loss: 9.1162\n",
      "Epoch 17/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.4625 - val_loss: 9.1060\n",
      "Epoch 18/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.4528 - val_loss: 9.0958\n",
      "Epoch 19/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.4431 - val_loss: 9.0856\n",
      "Epoch 20/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.4335 - val_loss: 9.0753\n",
      "Epoch 21/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.4238 - val_loss: 9.0650\n",
      "Epoch 22/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.4140 - val_loss: 9.0548\n",
      "Epoch 23/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.4044 - val_loss: 9.0446\n",
      "Epoch 24/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.3947 - val_loss: 9.0343\n",
      "Epoch 25/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.3850 - val_loss: 9.0241\n",
      "Epoch 26/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.3753 - val_loss: 9.0140\n",
      "Epoch 27/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.3658 - val_loss: 9.0036\n",
      "Epoch 28/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.3561 - val_loss: 8.9934\n",
      "Epoch 29/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.3463 - val_loss: 8.9833\n",
      "Epoch 30/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.3367 - val_loss: 8.9731\n",
      "Epoch 31/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 7.3271 - val_loss: 8.9629\n",
      "Epoch 32/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.3175 - val_loss: 8.9526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.3078 - val_loss: 8.9424\n",
      "Epoch 34/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.2981 - val_loss: 8.9323\n",
      "Epoch 35/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.2885 - val_loss: 8.9220\n",
      "Epoch 36/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.2789 - val_loss: 8.9118\n",
      "Epoch 37/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.2692 - val_loss: 8.9015\n",
      "Epoch 38/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.2595 - val_loss: 8.8914\n",
      "Epoch 39/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.2499 - val_loss: 8.8812\n",
      "Epoch 40/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.2403 - val_loss: 8.8709\n",
      "Epoch 41/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.2306 - val_loss: 8.8607\n",
      "Epoch 42/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 7.2209 - val_loss: 8.8505\n",
      "Epoch 43/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 7.2114 - val_loss: 8.8401\n",
      "Epoch 44/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 7.2018 - val_loss: 8.8299\n",
      "Epoch 45/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.1920 - val_loss: 8.8199\n",
      "Epoch 46/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.1825 - val_loss: 8.8097\n",
      "Epoch 47/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 7.1729 - val_loss: 8.7996\n",
      "Epoch 48/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 7.1634 - val_loss: 8.7893\n",
      "Epoch 49/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.1538 - val_loss: 8.7791\n",
      "Epoch 50/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.1441 - val_loss: 8.7691\n",
      "Epoch 51/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.1347 - val_loss: 8.7589\n",
      "Epoch 52/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 7.1250 - val_loss: 8.7487\n",
      "Epoch 53/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.1156 - val_loss: 8.7384\n",
      "Epoch 54/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.1059 - val_loss: 8.7282\n",
      "Epoch 55/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 7.0964 - val_loss: 8.7181\n",
      "Epoch 56/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.0868 - val_loss: 8.7079\n",
      "Epoch 57/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.0773 - val_loss: 8.6977\n",
      "Epoch 58/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 7.0677 - val_loss: 8.6876\n",
      "Epoch 59/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.0583 - val_loss: 8.6774\n",
      "Epoch 60/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 7.0487 - val_loss: 8.6673\n",
      "Epoch 61/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 7.0393 - val_loss: 8.6571\n",
      "Epoch 62/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 7.0297 - val_loss: 8.6469\n",
      "Epoch 63/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 7.0202 - val_loss: 8.6368\n",
      "Epoch 64/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.0107 - val_loss: 8.6266\n",
      "Epoch 65/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 7.0012 - val_loss: 8.6165\n",
      "Epoch 66/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.9918 - val_loss: 8.6063\n",
      "Epoch 67/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.9822 - val_loss: 8.5961\n",
      "Epoch 68/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.9727 - val_loss: 8.5860\n",
      "Epoch 69/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.9632 - val_loss: 8.5759\n",
      "Epoch 70/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.9538 - val_loss: 8.5657\n",
      "Epoch 71/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.9443 - val_loss: 8.5555\n",
      "Epoch 72/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.9347 - val_loss: 8.5454\n",
      "Epoch 73/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.9253 - val_loss: 8.5353\n",
      "Epoch 74/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.9159 - val_loss: 8.5251\n",
      "Epoch 75/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.9064 - val_loss: 8.5150\n",
      "Epoch 76/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.8969 - val_loss: 8.5048\n",
      "Epoch 77/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.8875 - val_loss: 8.4947\n",
      "Epoch 78/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 6.8781 - val_loss: 8.4845\n",
      "Epoch 79/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.8686 - val_loss: 8.4743\n",
      "Epoch 80/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 6.8591 - val_loss: 8.4641\n",
      "Epoch 81/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.8496 - val_loss: 8.4542\n",
      "Epoch 82/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.8402 - val_loss: 8.4441\n",
      "Epoch 83/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.8309 - val_loss: 8.4339\n",
      "Epoch 84/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.8213 - val_loss: 8.4238\n",
      "Epoch 85/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.8120 - val_loss: 8.4136\n",
      "Epoch 86/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.8025 - val_loss: 8.4035\n",
      "Epoch 87/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.7931 - val_loss: 8.3934\n",
      "Epoch 88/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 6.7836 - val_loss: 8.3832\n",
      "Epoch 89/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.7742 - val_loss: 8.3731\n",
      "Epoch 90/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.7649 - val_loss: 8.3629\n",
      "Epoch 91/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.7554 - val_loss: 8.3528\n",
      "Epoch 92/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.7460 - val_loss: 8.3426\n",
      "Epoch 93/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.7365 - val_loss: 8.3326\n",
      "Epoch 94/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.7271 - val_loss: 8.3225\n",
      "Epoch 95/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.7178 - val_loss: 8.3124\n",
      "Epoch 96/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.7085 - val_loss: 8.3021\n",
      "Epoch 97/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.6989 - val_loss: 8.2921\n",
      "Epoch 98/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.6895 - val_loss: 8.2820\n",
      "Epoch 99/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.6803 - val_loss: 8.2718\n",
      "Epoch 100/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 6.6708 - val_loss: 8.2617\n",
      "Epoch 101/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.6615 - val_loss: 8.2516\n",
      "Epoch 102/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.6520 - val_loss: 8.2416\n",
      "Epoch 103/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.6427 - val_loss: 8.2314\n",
      "Epoch 104/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.6334 - val_loss: 8.2213\n",
      "Epoch 105/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.6240 - val_loss: 8.2112\n",
      "Epoch 106/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.6147 - val_loss: 8.2012\n",
      "Epoch 107/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.6054 - val_loss: 8.1910\n",
      "Epoch 108/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.5961 - val_loss: 8.1809\n",
      "Epoch 109/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.5867 - val_loss: 8.1708\n",
      "Epoch 110/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.5774 - val_loss: 8.1607\n",
      "Epoch 111/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.5681 - val_loss: 8.1507\n",
      "Epoch 112/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 60us/step - loss: 6.5588 - val_loss: 8.1406\n",
      "Epoch 113/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.5496 - val_loss: 8.1305\n",
      "Epoch 114/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.5402 - val_loss: 8.1205\n",
      "Epoch 115/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.5310 - val_loss: 8.1104\n",
      "Epoch 116/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.5218 - val_loss: 8.1002\n",
      "Epoch 117/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.5123 - val_loss: 8.0902\n",
      "Epoch 118/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.5032 - val_loss: 8.0801\n",
      "Epoch 119/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.4939 - val_loss: 8.0700\n",
      "Epoch 120/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.4846 - val_loss: 8.0599\n",
      "Epoch 121/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 6.4753 - val_loss: 8.0499\n",
      "Epoch 122/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 6.4661 - val_loss: 8.0399\n",
      "Epoch 123/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 6.4569 - val_loss: 8.0298\n",
      "Epoch 124/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.4476 - val_loss: 8.0198\n",
      "Epoch 125/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.4384 - val_loss: 8.0096\n",
      "Epoch 126/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 6.4290 - val_loss: 7.9997\n",
      "Epoch 127/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.4199 - val_loss: 7.9897\n",
      "Epoch 128/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 6.4107 - val_loss: 7.9796\n",
      "Epoch 129/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 6.4015 - val_loss: 7.9695\n",
      "Epoch 130/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 6.3922 - val_loss: 7.9594\n",
      "Epoch 131/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 6.3830 - val_loss: 7.9494\n",
      "Epoch 132/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 6.3738 - val_loss: 7.9394\n",
      "Epoch 133/300\n",
      "378/378 [==============================] - 0s 89us/step - loss: 6.3646 - val_loss: 7.9295\n",
      "Epoch 134/300\n",
      "378/378 [==============================] - 0s 96us/step - loss: 6.3555 - val_loss: 7.9193\n",
      "Epoch 135/300\n",
      "378/378 [==============================] - 0s 90us/step - loss: 6.3463 - val_loss: 7.9093\n",
      "Epoch 136/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 6.3371 - val_loss: 7.8994\n",
      "Epoch 137/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 6.3280 - val_loss: 7.8894\n",
      "Epoch 138/300\n",
      "378/378 [==============================] - 0s 97us/step - loss: 6.3188 - val_loss: 7.8793\n",
      "Epoch 139/300\n",
      "378/378 [==============================] - 0s 92us/step - loss: 6.3096 - val_loss: 7.8694\n",
      "Epoch 140/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 6.3005 - val_loss: 7.8594\n",
      "Epoch 141/300\n",
      "378/378 [==============================] - 0s 85us/step - loss: 6.2914 - val_loss: 7.8494\n",
      "Epoch 142/300\n",
      "378/378 [==============================] - 0s 86us/step - loss: 6.2823 - val_loss: 7.8393\n",
      "Epoch 143/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 6.2731 - val_loss: 7.8293\n",
      "Epoch 144/300\n",
      "378/378 [==============================] - 0s 75us/step - loss: 6.2639 - val_loss: 7.8193\n",
      "Epoch 145/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2549 - val_loss: 7.8093\n",
      "Epoch 146/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 6.2458 - val_loss: 7.7992\n",
      "Epoch 147/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 6.2366 - val_loss: 7.7893\n",
      "Epoch 148/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 6.2276 - val_loss: 7.7793\n",
      "Epoch 149/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 6.2186 - val_loss: 7.7692\n",
      "Epoch 150/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 6.2093 - val_loss: 7.7593\n",
      "Epoch 151/300\n",
      "378/378 [==============================] - ETA: 0s - loss: 4.583 - 0s 65us/step - loss: 6.2003 - val_loss: 7.7494\n",
      "Epoch 152/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 6.1913 - val_loss: 7.7393\n",
      "Epoch 153/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 6.1822 - val_loss: 7.7294\n",
      "Epoch 154/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 6.1732 - val_loss: 7.7195\n",
      "Epoch 155/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 6.1643 - val_loss: 7.7094\n",
      "Epoch 156/300\n",
      "378/378 [==============================] - 0s 82us/step - loss: 6.1551 - val_loss: 7.6995\n",
      "Epoch 157/300\n",
      "378/378 [==============================] - 0s 83us/step - loss: 6.1462 - val_loss: 7.6896\n",
      "Epoch 158/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 6.1371 - val_loss: 7.6797\n",
      "Epoch 159/300\n",
      "378/378 [==============================] - 0s 106us/step - loss: 6.1282 - val_loss: 7.6698\n",
      "Epoch 160/300\n",
      "378/378 [==============================] - 0s 127us/step - loss: 6.1192 - val_loss: 7.6599\n",
      "Epoch 161/300\n",
      "378/378 [==============================] - 0s 109us/step - loss: 6.1103 - val_loss: 7.6500\n",
      "Epoch 162/300\n",
      "378/378 [==============================] - 0s 104us/step - loss: 6.1013 - val_loss: 7.6400\n",
      "Epoch 163/300\n",
      "378/378 [==============================] - 0s 99us/step - loss: 6.0923 - val_loss: 7.6302\n",
      "Epoch 164/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 6.0835 - val_loss: 7.6202\n",
      "Epoch 165/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 6.0745 - val_loss: 7.6104\n",
      "Epoch 166/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 6.0656 - val_loss: 7.6004\n",
      "Epoch 167/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 6.0567 - val_loss: 7.5905\n",
      "Epoch 168/300\n",
      "378/378 [==============================] - 0s 73us/step - loss: 6.0478 - val_loss: 7.5807\n",
      "Epoch 169/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 6.0389 - val_loss: 7.5708\n",
      "Epoch 170/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 6.0301 - val_loss: 7.5609\n",
      "Epoch 171/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 6.0211 - val_loss: 7.5512\n",
      "Epoch 172/300\n",
      "378/378 [==============================] - 0s 66us/step - loss: 6.0123 - val_loss: 7.5413\n",
      "Epoch 173/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 6.0034 - val_loss: 7.5314\n",
      "Epoch 174/300\n",
      "378/378 [==============================] - 0s 69us/step - loss: 5.9945 - val_loss: 7.5216\n",
      "Epoch 175/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.9857 - val_loss: 7.5117\n",
      "Epoch 176/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.9769 - val_loss: 7.5018\n",
      "Epoch 177/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.9681 - val_loss: 7.4920\n",
      "Epoch 178/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.9593 - val_loss: 7.4822\n",
      "Epoch 179/300\n",
      "378/378 [==============================] - 0s 71us/step - loss: 5.9505 - val_loss: 7.4724\n",
      "Epoch 180/300\n",
      "378/378 [==============================] - 0s 68us/step - loss: 5.9417 - val_loss: 7.4626\n",
      "Epoch 181/300\n",
      "378/378 [==============================] - 0s 80us/step - loss: 5.9329 - val_loss: 7.4528\n",
      "Epoch 182/300\n",
      "378/378 [==============================] - 0s 81us/step - loss: 5.9242 - val_loss: 7.4430\n",
      "Epoch 183/300\n",
      "378/378 [==============================] - 0s 77us/step - loss: 5.9155 - val_loss: 7.4331\n",
      "Epoch 184/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.9066 - val_loss: 7.4234\n",
      "Epoch 185/300\n",
      "378/378 [==============================] - 0s 67us/step - loss: 5.8980 - val_loss: 7.4134\n",
      "Epoch 186/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.8892 - val_loss: 7.4037\n",
      "Epoch 187/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.8806 - val_loss: 7.3938\n",
      "Epoch 188/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.8718 - val_loss: 7.3840\n",
      "Epoch 189/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.8630 - val_loss: 7.3743\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 58us/step - loss: 5.8543 - val_loss: 7.3645\n",
      "Epoch 191/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 5.8456 - val_loss: 7.3548\n",
      "Epoch 192/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.8369 - val_loss: 7.3450\n",
      "Epoch 193/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.8283 - val_loss: 7.3352\n",
      "Epoch 194/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.8196 - val_loss: 7.3254\n",
      "Epoch 195/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.8110 - val_loss: 7.3155\n",
      "Epoch 196/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.8022 - val_loss: 7.3058\n",
      "Epoch 197/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.7936 - val_loss: 7.2961\n",
      "Epoch 198/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.7850 - val_loss: 7.2863\n",
      "Epoch 199/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.7765 - val_loss: 7.2765\n",
      "Epoch 200/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.7679 - val_loss: 7.2667\n",
      "Epoch 201/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.7592 - val_loss: 7.2570\n",
      "Epoch 202/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.7506 - val_loss: 7.2474\n",
      "Epoch 203/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.7422 - val_loss: 7.2377\n",
      "Epoch 204/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.7338 - val_loss: 7.2278\n",
      "Epoch 205/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.7250 - val_loss: 7.2183\n",
      "Epoch 206/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.7166 - val_loss: 7.2085\n",
      "Epoch 207/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.7081 - val_loss: 7.1988\n",
      "Epoch 208/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.6995 - val_loss: 7.1892\n",
      "Epoch 209/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.6911 - val_loss: 7.1795\n",
      "Epoch 210/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.6828 - val_loss: 7.1698\n",
      "Epoch 211/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.6742 - val_loss: 7.1601\n",
      "Epoch 212/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.6657 - val_loss: 7.1505\n",
      "Epoch 213/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.6573 - val_loss: 7.1409\n",
      "Epoch 214/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.6489 - val_loss: 7.1313\n",
      "Epoch 215/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.6404 - val_loss: 7.1218\n",
      "Epoch 216/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.6320 - val_loss: 7.1122\n",
      "Epoch 217/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.6236 - val_loss: 7.1025\n",
      "Epoch 218/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.6153 - val_loss: 7.0929\n",
      "Epoch 219/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.6069 - val_loss: 7.0832\n",
      "Epoch 220/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.5984 - val_loss: 7.0738\n",
      "Epoch 221/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.5901 - val_loss: 7.0643\n",
      "Epoch 222/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.5819 - val_loss: 7.0545\n",
      "Epoch 223/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.5733 - val_loss: 7.0450\n",
      "Epoch 224/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.5650 - val_loss: 7.0354\n",
      "Epoch 225/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.5567 - val_loss: 7.0258\n",
      "Epoch 226/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.5484 - val_loss: 7.0162\n",
      "Epoch 227/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.5400 - val_loss: 7.0067\n",
      "Epoch 228/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 5.5317 - val_loss: 6.9973\n",
      "Epoch 229/300\n",
      "378/378 [==============================] - 0s 65us/step - loss: 5.5234 - val_loss: 6.9878\n",
      "Epoch 230/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.5152 - val_loss: 6.9782\n",
      "Epoch 231/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.5069 - val_loss: 6.9686\n",
      "Epoch 232/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.4985 - val_loss: 6.9591\n",
      "Epoch 233/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.4903 - val_loss: 6.9496\n",
      "Epoch 234/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.4821 - val_loss: 6.9401\n",
      "Epoch 235/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.4737 - val_loss: 6.9306\n",
      "Epoch 236/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.4657 - val_loss: 6.9209\n",
      "Epoch 237/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.4573 - val_loss: 6.9115\n",
      "Epoch 238/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.4491 - val_loss: 6.9021\n",
      "Epoch 239/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.4409 - val_loss: 6.8927\n",
      "Epoch 240/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.4329 - val_loss: 6.8832\n",
      "Epoch 241/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.4247 - val_loss: 6.8737\n",
      "Epoch 242/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.4166 - val_loss: 6.8643\n",
      "Epoch 243/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.4084 - val_loss: 6.8549\n",
      "Epoch 244/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.4004 - val_loss: 6.8455\n",
      "Epoch 245/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.3923 - val_loss: 6.8361\n",
      "Epoch 246/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.3842 - val_loss: 6.8268\n",
      "Epoch 247/300\n",
      "378/378 [==============================] - 0s 52us/step - loss: 5.3761 - val_loss: 6.8174\n",
      "Epoch 248/300\n",
      "378/378 [==============================] - 0s 64us/step - loss: 5.3680 - val_loss: 6.8080\n",
      "Epoch 249/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.3600 - val_loss: 6.7986\n",
      "Epoch 250/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.3520 - val_loss: 6.7892\n",
      "Epoch 251/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.3439 - val_loss: 6.7799\n",
      "Epoch 252/300\n",
      "378/378 [==============================] - 0s 61us/step - loss: 5.3359 - val_loss: 6.7704\n",
      "Epoch 253/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.3278 - val_loss: 6.7612\n",
      "Epoch 254/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 5.3199 - val_loss: 6.7519\n",
      "Epoch 255/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.3118 - val_loss: 6.7428\n",
      "Epoch 256/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.3039 - val_loss: 6.7336\n",
      "Epoch 257/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.2960 - val_loss: 6.7243\n",
      "Epoch 258/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.2879 - val_loss: 6.7151\n",
      "Epoch 259/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.2799 - val_loss: 6.7061\n",
      "Epoch 260/300\n",
      "378/378 [==============================] - 0s 53us/step - loss: 5.2722 - val_loss: 6.6967\n",
      "Epoch 261/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.2641 - val_loss: 6.6876\n",
      "Epoch 262/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.2562 - val_loss: 6.6785\n",
      "Epoch 263/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.2484 - val_loss: 6.6694\n",
      "Epoch 264/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.2406 - val_loss: 6.6602\n",
      "Epoch 265/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.2328 - val_loss: 6.6513\n",
      "Epoch 266/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.2253 - val_loss: 6.6429\n",
      "Epoch 267/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.2181 - val_loss: 6.6343\n",
      "Epoch 268/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.2108 - val_loss: 6.6258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.2034 - val_loss: 6.6174\n",
      "Epoch 270/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1964 - val_loss: 6.6091\n",
      "Epoch 271/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.1892 - val_loss: 6.6009\n",
      "Epoch 272/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1822 - val_loss: 6.5928\n",
      "Epoch 273/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1754 - val_loss: 6.5849\n",
      "Epoch 274/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1686 - val_loss: 6.5770\n",
      "Epoch 275/300\n",
      "378/378 [==============================] - 0s 63us/step - loss: 5.1618 - val_loss: 6.5692\n",
      "Epoch 276/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1550 - val_loss: 6.5614\n",
      "Epoch 277/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.1484 - val_loss: 6.5535\n",
      "Epoch 278/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1416 - val_loss: 6.5458\n",
      "Epoch 279/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.1349 - val_loss: 6.5380\n",
      "Epoch 280/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.1281 - val_loss: 6.5303\n",
      "Epoch 281/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.1214 - val_loss: 6.5225\n",
      "Epoch 282/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.1147 - val_loss: 6.5148\n",
      "Epoch 283/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.1080 - val_loss: 6.5070\n",
      "Epoch 284/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.1013 - val_loss: 6.4991\n",
      "Epoch 285/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.0946 - val_loss: 6.4914\n",
      "Epoch 286/300\n",
      "378/378 [==============================] - 0s 60us/step - loss: 5.0880 - val_loss: 6.4837\n",
      "Epoch 287/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.0813 - val_loss: 6.4761\n",
      "Epoch 288/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.0748 - val_loss: 6.4683\n",
      "Epoch 289/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.0681 - val_loss: 6.4607\n",
      "Epoch 290/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.0615 - val_loss: 6.4531\n",
      "Epoch 291/300\n",
      "378/378 [==============================] - 0s 62us/step - loss: 5.0551 - val_loss: 6.4462\n",
      "Epoch 292/300\n",
      "378/378 [==============================] - 0s 58us/step - loss: 5.0495 - val_loss: 6.4395\n",
      "Epoch 293/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.0438 - val_loss: 6.4330\n",
      "Epoch 294/300\n",
      "378/378 [==============================] - 0s 57us/step - loss: 5.0381 - val_loss: 6.4264\n",
      "Epoch 295/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.0326 - val_loss: 6.4197\n",
      "Epoch 296/300\n",
      "378/378 [==============================] - 0s 54us/step - loss: 5.0268 - val_loss: 6.4132\n",
      "Epoch 297/300\n",
      "378/378 [==============================] - 0s 59us/step - loss: 5.0213 - val_loss: 6.4066\n",
      "Epoch 298/300\n",
      "378/378 [==============================] - 0s 56us/step - loss: 5.0157 - val_loss: 6.3999\n",
      "Epoch 299/300\n",
      "378/378 [==============================] - 0s 51us/step - loss: 5.0101 - val_loss: 6.3933\n",
      "Epoch 300/300\n",
      "378/378 [==============================] - 0s 55us/step - loss: 5.0045 - val_loss: 6.3867\n"
     ]
    }
   ],
   "source": [
    "pred_appliance ={}\n",
    "for sup_appliance in APPLIANCES_ORDER[1:]:\n",
    "    for test_appliance_name in APPLIANCES_ORDER[1:]:\n",
    "        if sup_appliance!=test_appliance_name:\n",
    "            print(sup_appliance, test_appliance_name)\n",
    "            model.compile('adam','mean_absolute_error')\n",
    "            model.fit([train_agg, train_appliance[sup_appliance]], train_appliance[test_appliance_name], epochs=300, validation_split=0.1)\n",
    "            pred_appliance[(sup_appliance, test_appliance_name)] = model.predict([test_agg, test_appliance[sup_appliance]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hvac', 'fridge', 'mw', 'dw', 'wm', 'oven'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sup_appliance\n",
    "test_appliance.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = {}\n",
    "for sup_appliance in APPLIANCES_ORDER[1:]:\n",
    "    for test_appliance_name in APPLIANCES_ORDER[1:]:\n",
    "        if sup_appliance!=test_appliance_name:\n",
    "            try:\n",
    "                mae[(sup_appliance, test_appliance_name)] = mean_absolute_error(test_appliance[test_appliance_name], \n",
    "                                                                                pred_appliance[(sup_appliance, test_appliance_name)])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dw</th>\n",
       "      <th>fridge</th>\n",
       "      <th>hvac</th>\n",
       "      <th>mw</th>\n",
       "      <th>oven</th>\n",
       "      <th>wm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dw</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78.991811</td>\n",
       "      <td>134.915511</td>\n",
       "      <td>6.348789</td>\n",
       "      <td>19.774485</td>\n",
       "      <td>5.636715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fridge</th>\n",
       "      <td>14.499116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.127259</td>\n",
       "      <td>6.300214</td>\n",
       "      <td>19.757202</td>\n",
       "      <td>5.617521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hvac</th>\n",
       "      <td>14.499116</td>\n",
       "      <td>30.939091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.026585</td>\n",
       "      <td>19.757202</td>\n",
       "      <td>5.617521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mw</th>\n",
       "      <td>14.519482</td>\n",
       "      <td>79.540721</td>\n",
       "      <td>135.071004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.770135</td>\n",
       "      <td>5.632393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oven</th>\n",
       "      <td>18.352681</td>\n",
       "      <td>78.654155</td>\n",
       "      <td>932.127908</td>\n",
       "      <td>9.151620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.445281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wm</th>\n",
       "      <td>16.168525</td>\n",
       "      <td>44.192168</td>\n",
       "      <td>937.646321</td>\n",
       "      <td>7.462605</td>\n",
       "      <td>19.179591</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dw     fridge        hvac        mw       oven        wm\n",
       "dw            NaN  78.991811  134.915511  6.348789  19.774485  5.636715\n",
       "fridge  14.499116        NaN  135.127259  6.300214  19.757202  5.617521\n",
       "hvac    14.499116  30.939091         NaN  7.026585  19.757202  5.617521\n",
       "mw      14.519482  79.540721  135.071004       NaN  19.770135  5.632393\n",
       "oven    18.352681  78.654155  932.127908  9.151620        NaN  6.445281\n",
       "wm      16.168525  44.192168  937.646321  7.462605  19.179591       NaN"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mae).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 24)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_hvac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.4446940174\n",
      "996.766596489\n"
     ]
    }
   ],
   "source": [
    "pred_hvac = model.predict(test_agg)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(pred_hvac, test_fridge))\n",
    "print(mean_absolute_error(pred_hvac, test_agg))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.907349e-06\n",
       "1    -3.877686e+00\n",
       "2    -9.150000e+00\n",
       "3     0.000000e+00\n",
       "4     0.000000e+00\n",
       "5    -9.633333e+00\n",
       "6     0.000000e+00\n",
       "7     2.861023e-06\n",
       "8    -8.683333e+00\n",
       "9     9.536743e-07\n",
       "10    0.000000e+00\n",
       "11    9.536743e-07\n",
       "12   -9.583333e+00\n",
       "13   -9.516666e+00\n",
       "14   -4.711666e+01\n",
       "15    3.099442e-06\n",
       "16   -4.685000e+01\n",
       "17    9.536743e-07\n",
       "18   -7.310000e+01\n",
       "19   -7.350000e+01\n",
       "20   -4.180000e+01\n",
       "21    0.000000e+00\n",
       "22   -9.616667e+00\n",
       "23   -9.533334e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(pred_hvac) - pd.DataFrame(test_agg)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c39139b38>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c391557b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(test_mw[1, :]).plot(label='GT')\n",
    "#pd.Series(test_agg[1, :]).plot(label='GT')\n",
    "\n",
    "\n",
    "pd.Series(model.predict(test_agg[1:2])[0, :24]).plot(label='Pred')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
