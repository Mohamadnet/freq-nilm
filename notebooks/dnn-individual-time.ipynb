{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataloader import APPLIANCE_ORDER, get_train_test\n",
    "from tensor_custom_core import stf_4dim, stf_4dim_time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDNN, self).__init__()\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        \n",
    "\n",
    "        #self.linear1 = nn.Linear(25, 50 )\n",
    "        #self.linear2 = nn.Linear(50, 1 )\n",
    "        self.l1 = nn.Linear(25, 1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #y = self.bn(x)\n",
    "        #pred = self.linear1(y)\n",
    "        #pred = self.bn(pred)\n",
    "        #pred = self.act1(pred)\n",
    "        #pred = self.linear2(pred)\n",
    "        #pred = self.act1(pred)\n",
    "        pred = self.l1(x)\n",
    "        print(x.size(), pred.size())\n",
    "        #pred = self.act2(pred)\n",
    "        \n",
    "        #pred = pred[:, :, 23:24]\n",
    "        #pred = self.act(pred)\n",
    "        #pred = torch.clamp(pred, min=0.)\n",
    "        #pred = self.act(pred)\n",
    "        #pred = torch.min(pred, x)\n",
    "        return pred\n",
    "\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cuda_av = True\n",
    "else:\n",
    "    cuda_av=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDNN (\n",
       "  (l1): Linear (25 -> 1)\n",
       "  (act1): ReLU ()\n",
       "  (act2): ReLU ()\n",
       "  (bn): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True)\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = CustomDNN()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 0\n",
    "num_folds = 5\n",
    "lr = 1\n",
    "\n",
    "appliance = \"hvac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.DataFrame(oh.fit_transform(np.array(range(1, 25)).reshape(-1, 1)).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "appliance_num = APPLIANCE_ORDER.index(appliance)\n",
    "train, test = get_train_test(1, num_folds=num_folds, fold_num=fold_num)\n",
    "train_aggregate = train[:, 0, :, :].reshape(-1, 24, 1)\n",
    "test_aggregate = test[:, 0, :, :].reshape(-1, 24, 1)\n",
    "\n",
    "train_appliance = train[:, appliance_num, :, :].reshape(-1,1)\n",
    "test_appliance = test[:, appliance_num, :, :].reshape(-1, 1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...    14   15   16   17  \\\n",
       "0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "4   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "5   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  0.0  0.0  0.0   \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  0.0   \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  1.0  0.0  0.0   \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  1.0  0.0   \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  1.0   \n",
       "18  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "19  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "21  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "22  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "23  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "     18   19   20   21   22   23  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "19  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "20  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "21  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "22  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "23  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6048, 24, 1)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aggregate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aggregate_time = np.zeros((train_aggregate.shape[0], 24, 25))\n",
    "for home in range(train_aggregate.shape[0]):\n",
    "    temp = d.copy()\n",
    "    temp['power'] = train_aggregate[home, :, :]\n",
    "    train_aggregate_time[home, :, :] = temp.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145152, 25)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_agg = train_aggregate_time.reshape(-1, 25)\n",
    "tr_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.L1Loss()\n",
    "r = CustomDNN()\n",
    "\n",
    "if cuda_av:\n",
    "    r = r.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(r.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([145152, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        ,    1.        ,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "        404.26667023])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_agg[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 211.6499939],\n",
       "       [ 208.       ],\n",
       "       [ 205.4833374]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_appliance[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "0 864.3749389648438\n",
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "1 864.3749389648438\n",
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "2 864.3749389648438\n",
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "3 864.3749389648438\n",
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "4 864.3749389648438\n",
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "5 864.3749389648438\n",
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "6 864.3749389648438\n",
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "7 864.3749389648438\n",
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "8 864.3749389648438\n",
      "torch.Size([145152, 25]) torch.Size([145152, 1])\n",
      "9 864.3749389648438\n"
     ]
    }
   ],
   "source": [
    "num_iterations=10\n",
    "for t in range(num_iterations):\n",
    "\n",
    "    inp = Variable(torch.Tensor(tr_agg), requires_grad=True)\n",
    "    train_y = Variable(torch.Tensor(train_appliance))\n",
    "    if cuda_av:\n",
    "        inp = inp.cuda()\n",
    "        train_y = train_y.cuda()\n",
    "    pred = c(inp)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_func(pred, train_y)\n",
    "    if t % 1 == 0:\n",
    "        print(t, loss.data[0])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a32ad1668>]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRFQlGOhERFXi/wNpg58jD34PeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a32963588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(pred[:24, 0].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_inp = Variable(torch.Tensor(test_aggregate), requires_grad=False)\n",
    "    test_y = Variable(torch.Tensor(test_appliance), requires_grad=False)\n",
    "    if cuda_av:\n",
    "        test_inp = test_inp.cuda()\n",
    "    pred = r(test_inp)\n",
    "    #pred[pred<0.] = 0.\n",
    "    pred = torch.clamp(pred, min=0.)\n",
    "    if cuda_av:\n",
    "        prediction_fold = pred.cpu().data.numpy()\n",
    "    else:\n",
    "        prediction_fold = pred.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = []\n",
    "preds = []\n",
    "\n",
    "def disagg_fold(fold_num, appliance, cell_type, hidden_size,\n",
    "                num_layers, bidirectional, lr,\n",
    "                num_iterations):\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    appliance_num = APPLIANCE_ORDER.index(appliance)\n",
    "    train, test = get_train_test(num_folds=num_folds, fold_num=fold_num)\n",
    "    train_aggregate = train[:, 0, :, :].reshape(-1, 24, 1)\n",
    "    test_aggregate = test[:, 0, :, :].reshape(-1, 24, 1)\n",
    "\n",
    "    train_appliance = train[:, appliance_num, :, :].reshape(-1, 24, 1)\n",
    "    test_appliance = test[:, appliance_num, :, :].reshape(-1, 24, 1)\n",
    "    gts.append(test_appliance.reshape(-1, 24))\n",
    "    loss_func = nn.L1Loss()\n",
    "    r = CustomRNN(cell_type, hidden_size, num_layers, bidirectional)\n",
    "\n",
    "    if cuda_av:\n",
    "        r = r.cuda()\n",
    "        loss_func = loss_func.cuda()\n",
    "\n",
    "    # Setting the params all to be non-negative\n",
    "    #for param in r.parameters():\n",
    "    #    param.data = param.data.abs()\n",
    "\n",
    "    optimizer = torch.optim.Adam(r.parameters(), lr=lr)\n",
    "\n",
    "    for t in range(num_iterations):\n",
    "\n",
    "        inp = Variable(torch.Tensor(train_aggregate), requires_grad=True)\n",
    "        train_y = Variable(torch.Tensor(train_appliance))\n",
    "        if cuda_av:\n",
    "            inp = inp.cuda()\n",
    "            train_y = train_y.cuda()\n",
    "        pred = r(inp)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_func(pred, train_y)\n",
    "        if t % 5 == 0:\n",
    "            print(t, loss.data[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_inp = Variable(torch.Tensor(test_aggregate), requires_grad=False)\n",
    "    test_y = Variable(torch.Tensor(test_appliance), requires_grad=False)\n",
    "    if cuda_av:\n",
    "        test_inp = test_inp.cuda()\n",
    "    pred = r(test_inp)\n",
    "    #pred[pred<0.] = 0.\n",
    "    pred = torch.clamp(pred, min=0.)\n",
    "    if cuda_av:\n",
    "        prediction_fold = pred.cpu().data.numpy()\n",
    "    else:\n",
    "        prediction_fold = pred.data.numpy()\n",
    "    return prediction_fold, test_appliance\n",
    "\n",
    "def disagg(appliance, cell_type, hidden_size, num_layers, bidirectional, lr, num_iterations):\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for cur_fold in range(num_folds):\n",
    "        pred, gt = disagg_fold(cur_fold, appliance, cell_type, hidden_size, num_layers\n",
    "                               ,bidirectional, lr, num_iterations)\n",
    "\n",
    "        preds.append(pred)\n",
    "        gts.append(gt)\n",
    "    return mean_absolute_error(np.concatenate(gts).flatten(), np.concatenate(preds).flatten())\n",
    "\n",
    "appliance = \"hvac\"\n",
    "cell_type=\"GRU\" # One of GRU, LSTM, RNN\n",
    "hidden_size=100 # [20, 50, 100, 150]\n",
    "num_layers=1  # [1, 2, 3, 4]\n",
    "bidirectional=False # True or False\n",
    "lr =1 # 1e-3, 1e-2, 1e-1, 1, 2\n",
    "num_iterations = 20 #200, 400, 600, 800\n",
    "\n",
    "appliance, cell_type, hidden_size, num_layers, bidirectional, lr, num_iterations = sys.argv[1:]\n",
    "hidden_size = int(hidden_size)\n",
    "num_layers = int(num_layers)\n",
    "lr = float(lr)\n",
    "num_iterations = int(num_iterations)\n",
    "\n",
    "p = disagg(appliance, cell_type, hidden_size, num_layers,\n",
    "                bidirectional, lr, num_iterations)\n",
    "\n",
    "import pickle\n",
    "pickle.dump(p, open(\"./baseline/rnn-individual-baseline-result/rnn-individual-{}-{}-{}-{}-{}-{}-{}.pkl\".format(appliance,\n",
    "\t\t\t\t\t\tcell_type, hidden_size, num_layers, bidirectional, lr, num_iterations), \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
