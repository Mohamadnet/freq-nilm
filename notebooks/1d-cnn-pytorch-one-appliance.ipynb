{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from dataloader import APPLIANCE_ORDER, get_train_test\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "cuda_av = False\n",
    "if torch.cuda.is_available():\n",
    "    cuda_av = True\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "weight_appliance = {'mw':1, 'dw':1, 'dr':1,'fridge':1, 'hvac':1}\n",
    "\n",
    "# num_hidden, num_iterations, num_layers, p, num_directions = sys.argv[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "appliance=\"hvac\"\n",
    "cell_type = \"GRU\"\n",
    "num_hidden = 120\n",
    "num_iterations = 100\n",
    "num_layers = 1\n",
    "num_directions = 1\n",
    "\n",
    "input_dim = 1\n",
    "hidden_size = num_hidden\n",
    "num_layers = num_layers\n",
    "if num_directions == 1:\n",
    "    bidirectional = False\n",
    "else:\n",
    "    bidirectional = True\n",
    "lr = 0.1\n",
    "p = 0.5\n",
    "num_folds = 5\n",
    "fold_num = 0\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "train, test = get_train_test(2, num_folds=num_folds, fold_num=fold_num)\n",
    "train_aggregate = train[:, 0, None, :, :] - train[:, 1, None, :, :]\n",
    "test_aggregate = test[:, 0, None, :, :]- test[:, 1, None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54, 1, 112, 24])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Variable(torch.Tensor(train[:, 0, None, :, :]), requires_grad=True)\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0  ,.,.) = \n",
       "   1366.9166   1367.6000    899.0000  ...    5006.9668   4656.8667   1456.9333\n",
       "\n",
       "( 1  ,.,.) = \n",
       "    946.7667    891.6500    890.1833  ...    4071.2166   3348.8833    915.8834\n",
       "\n",
       "( 2  ,.,.) = \n",
       "   1059.1000    788.1000    610.6000  ...    2488.2334   1840.3000   1359.0167\n",
       " ... \n",
       "\n",
       "(6045,.,.) = \n",
       "    579.5333    661.4833    606.6166  ...     948.5667    897.8333    987.7833\n",
       "\n",
       "(6046,.,.) = \n",
       "   1062.3667    597.3666    719.2833  ...    1208.1000   1270.4333    810.2000\n",
       "\n",
       "(6047,.,.) = \n",
       "    511.6000    480.5333    478.1833  ...    2177.7334   1905.5834   1545.0834\n",
       "[torch.FloatTensor of size 6048x1x24]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.view(-1, 1, 24)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6048, 50, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = nn.Conv1d(1, 30, 10, 1)\n",
    "q2 = nn.Conv1d(30, 30, 8, 1)\n",
    "q3 = nn.Conv1d(30, 40, 6, 1)\n",
    "q4 = nn.Conv1d(40, 50, 3, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "q4(q3(q2(q1(t)))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_appliance = train[:, APPLIANCE_ORDER.index(appliance),None, :, :]\n",
    "test_appliance = test[:, APPLIANCE_ORDER.index(appliance),None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "      \n",
    "        self.q1 = nn.Conv1d(1, 30, 10, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(30)\n",
    "        self.q2 = nn.Conv1d(30, 30, 8, 1)\n",
    "        self.q3 = nn.Conv1d(30, 40, 6, 1)\n",
    "        self.q4 = nn.Conv1d(40, 50, 3, 1)\n",
    "        self.l = nn.Linear(50, 24)\n",
    "    \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.q1(x)\n",
    "        pred = self.bn1(pred)\n",
    "        pred = self.q2(pred)\n",
    "        pred = self.q3(pred)\n",
    "        pred = self.q4(pred).view(-1, 50)\n",
    "        pred = self.l(pred)\n",
    "        #pred = self.act2(pred)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 892.5319\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = CustomCNN()\n",
    "c(t)\n",
    "loss_func(c(t), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.L1Loss()\n",
    "c = CustomCNN()\n",
    "lr = 0.001\n",
    "if cuda_av:\n",
    "    c = c.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "optimizer = torch.optim.Adam(c.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 892.5318603515625\n",
      "1 892.5123901367188\n",
      "2 892.490966796875\n",
      "3 892.4667358398438\n",
      "4 892.4356079101562\n",
      "5 892.3945922851562\n",
      "6 892.3429565429688\n",
      "7 892.2777709960938\n",
      "8 892.1909790039062\n",
      "9 892.0820922851562\n",
      "10 891.9553833007812\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-8d1f4d292009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inp = t\n",
    "for it in range(num_iterations):\n",
    "    out = Variable(torch.Tensor(train_appliance)).view(-1, 1, 24)\n",
    "    if cuda_av:\n",
    "        inp = inp.cuda()\n",
    "        out = out.cuda()\n",
    "\n",
    "    \n",
    "    pred = c(inp)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "    \n",
    "    loss = loss_func(pred, out)\n",
    "    if it % 1 == 0:\n",
    "        print(it, loss.data[0])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 1, 112, 24)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_appliance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  678.9951\n",
       "  471.3506\n",
       "  538.7216\n",
       "  442.9084\n",
       "  335.3699\n",
       "   67.2930\n",
       "   81.9102\n",
       "  188.2203\n",
       "   54.0691\n",
       "   94.5408\n",
       "    5.0193\n",
       "   32.8533\n",
       "   61.8343\n",
       "   77.6725\n",
       "   54.0530\n",
       "  226.6035\n",
       "  487.7267\n",
       " 2113.0188\n",
       " 1765.6757\n",
       " 1428.4148\n",
       " 1700.9680\n",
       " 1623.1222\n",
       " 1311.8258\n",
       "  961.6443\n",
       "[torch.FloatTensor of size 24]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-3f05f4a61d4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_appliance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "pd.Series(pred[0].data.numpy()[0, :]).plot()\n",
    "pd.Series(test_appliance[0,  :]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inp = Variable(torch.Tensor(test_aggregate).view(-1,1,24), requires_grad=False)\n",
    "test_out = Variable(torch.Tensor(test_appliance).view(-1,1,24), requires_grad=False)\n",
    "\n",
    "\n",
    "if cuda_av:\n",
    "    test_inp = test_inp.cuda()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-0bad20989064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "pd.Series(c(test_inp)[0].data.numpy()[0, 0, :]).plot()\n",
    "pd.Series(test_out.data.numpy()[0, 0, 0, :]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = c(test_inp)\n",
    "p[p<0.] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 535.2096\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(p, test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a24233e10>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAD8CAYAAAA7fRx2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25718ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(pd.DataFrame(list(c.parameters())[0].data.numpy().reshape(50, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [test_inp, -2]\n",
    "for i in range(len(ORDER)):\n",
    "    params.append(None)\n",
    "pr = a(*params)\n",
    "pr = torch.clamp(pr, min=0.)\n",
    "test_pred = torch.split(pr, test_aggregate.shape[0])\n",
    "prediction_fold = [None for x in range(len(ORDER))]\n",
    "\n",
    "if cuda_av:\n",
    "    for appliance_num, appliance in enumerate(ORDER):\n",
    "        prediction_fold[appliance_num] = test_pred[appliance_num].cpu().data.numpy().reshape(-1, 24)\n",
    "else:\n",
    "    for appliance_num, appliance in enumerate(ORDER):\n",
    "        prediction_fold[appliance_num] = test_pred[appliance_num].data.numpy().reshape(-1, 24)\n",
    "gt_fold = [None for x in range(len(ORDER))]\n",
    "for appliance_num, appliance in enumerate(ORDER):\n",
    "    gt_fold[appliance_num] = test[:, APPLIANCE_ORDER.index(appliance), :, :].reshape(test_aggregate.shape[0], -1,\n",
    "                                                                                         1).reshape(-1, 24)\n",
    "\n",
    "\n",
    "print([x.mean() for x in pred_split])\n",
    "error = pd.Series({appliance:mean_absolute_error(gt_fold[appliance_num], prediction_fold[appliance_num]) for appliance_num, appliance in enumerate(ORDER)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
