{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "from dataloader import APPLIANCE_ORDER, get_train_test\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_av = False\n",
    "if torch.cuda.is_available():\n",
    "    cuda_av = True\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, num_layers, bidirectional):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        if bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "        if cell_type == \"RNN\":\n",
    "            self.rnn = nn.RNN(input_size=1, hidden_size=hidden_size,\n",
    "                              num_layers=num_layers, batch_first=True,\n",
    "                              bidirectional=bidirectional)\n",
    "        elif cell_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(input_size=1, hidden_size=hidden_size,\n",
    "                              num_layers=num_layers, batch_first=True,\n",
    "                              bidirectional=bidirectional)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(input_size=1, hidden_size=hidden_size,\n",
    "                               num_layers=num_layers, batch_first=True,\n",
    "                               bidirectional=bidirectional)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size * self.num_directions, 1)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred, hidden = self.rnn(x, None)\n",
    "        pred = self.linear(pred).view(pred.data.shape[0], -1, 1)\n",
    "        pred = torch.min(pred, x)\n",
    "        return pred\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=7, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(20)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(20, 16, kernel_size=2, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv4 = nn.ConvTranspose2d(64, 16, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv5 = nn.ConvTranspose2d(16, 6, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(6)\n",
    "\n",
    "        self.conv6 = nn.ConvTranspose2d(6, 1, kernel_size=5, stride=1, padding=2) \n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        \n",
    "        e1 = self.conv1(input)\n",
    "        bn1 = self.bn1(self.act(e1))\n",
    "        e2 = self.bn2(self.conv2(bn1))        \n",
    "        e5 = self.bn5(self.conv5(e2))\n",
    "        e6 = self.conv6(e5)\n",
    "        return e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(train, valid, test):\n",
    "    out_train = [None for temp in range(len(ORDER))]\n",
    "    for a_num, appliance in enumerate(ORDER):\n",
    "        out_train[a_num] = Variable(\n",
    "            torch.Tensor(train[:, APPLIANCE_ORDER.index(appliance), :, :].reshape((train.shape[0], 1, -1, 24))))\n",
    "        if cuda_av:\n",
    "            out_train[a_num] = out_train[a_num].cuda()\n",
    "\n",
    "    out_valid = [None for temp in range(len(ORDER))]\n",
    "    for a_num, appliance in enumerate(ORDER):\n",
    "        out_valid[a_num] = Variable(\n",
    "            torch.Tensor(valid[:, APPLIANCE_ORDER.index(appliance), :, :].reshape((valid.shape[0], 1, -1, 24))))\n",
    "        if cuda_av:\n",
    "            out_valid[a_num] = out_valid[a_num].cuda()\n",
    "            \n",
    "    out_test = [None for temp in range(len(ORDER))]\n",
    "    for a_num, appliance in enumerate(ORDER):\n",
    "        out_test[a_num] = Variable(\n",
    "            torch.Tensor(test[:, APPLIANCE_ORDER.index(appliance), :, :].reshape((test.shape[0], 1, -1, 24))))\n",
    "        if cuda_av:\n",
    "            out_test[a_num] = out_test[a_num].cuda()\n",
    "\n",
    "    return out_train, out_valid, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AppliancesRNNCNN(nn.Module):\n",
    "    def __init__(self, cell_type, hidden_size, num_layers, bidirectional, num_appliance):\n",
    "        super(AppliancesRNNCNN, self).__init__()\n",
    "        self.num_appliance = num_appliance\n",
    "        self.preds = {}\n",
    "        self.order = ORDER\n",
    "        for appliance in range(self.num_appliance):\n",
    "            if ORDER[appliance] in ['fridge']:\n",
    "                print(\"use RNN\")\n",
    "                if cuda_av:\n",
    "                    setattr(self, \"Appliance_\" + str(appliance), CustomRNN(cell_type, hidden_size,\n",
    "                                                                           num_layers, bidirectional).cuda())\n",
    "                else:\n",
    "                    setattr(self, \"Appliance_\" + str(appliance), CustomRNN(cell_type, hidden_size,\n",
    "                                                                           num_layers, bidirectional))\n",
    "            else:\n",
    "                print(\"use CNN\")\n",
    "                if cuda_av:\n",
    "                    setattr(self, \"Appliance_\" + str(appliance), CustomCNN().cuda())\n",
    "                else:\n",
    "                    setattr(self, \"Appliance_\" + str(appliance), CustomCNN())\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "        agg_current = args[0]\n",
    "        flag = False\n",
    "        if np.random.random() > args[1]:\n",
    "            flag = True\n",
    "        else:\n",
    "            pass\n",
    "        for appliance in range(self.num_appliance):\n",
    "            agg_current = agg_current.contiguous()\n",
    "            if ORDER[appliance] in ['fridge']:\n",
    "                agg_current = agg_current.view(agg_current.shape[0], -1, 1)\n",
    "            else:\n",
    "                agg_current = agg_current.view(agg_current.shape[0], 1, -1, 24)\n",
    "            \n",
    "            self.preds[appliance] = getattr(self, \"Appliance_\" + str(appliance))(agg_current)\n",
    "            \n",
    "            agg_current = agg_current.view(agg_current.shape[0], 1, -1, 24)\n",
    "            self.preds[appliance] = self.preds[appliance].view(self.preds[appliance].shape[0], 1, -1, 24)\n",
    "            \n",
    "            \n",
    "            if flag:\n",
    "                agg_current = agg_current - self.preds[appliance]\n",
    "            else:\n",
    "                agg_current = agg_current - args[2 + appliance]\n",
    "\n",
    "        return torch.cat([self.preds[a] for a in range(self.num_appliance)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 3\n",
    "fold_num = 3\n",
    "num_folds = 5\n",
    "origin_train, origin_test = get_train_test(dataset, num_folds=num_folds, fold_num=fold_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the residual column\n",
    "train_residual = origin_train[:, 1:6, :, :].sum(axis=1).reshape(-1, 1, 112, 24).copy()\n",
    "train = np.hstack((origin_train, train_residual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the residual column\n",
    "test_residual = origin_test[:, 1:6, :, :].sum(axis=1).reshape(-1, 1, 112, 24).copy()\n",
    "test = np.hstack((origin_test, test_residual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "APPLIANCE_ORDER=['aggregate', 'hvac', 'fridge', 'dr', 'dw', 'mw', 'residual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid = train[int(0.8*len(train)):].copy()\n",
    "train = train[:int(0.8 * len(train))].copy()\n",
    "train_aggregate = train[:, 0, :, :].reshape(train.shape[0], 1, -1, 24)\n",
    "valid_aggregate = valid[:, 0, :, :].reshape(valid.shape[0], 1, -1, 24)\n",
    "test_aggregate = test[:, 0, :, :].reshape(test.shape[0], 1, -1, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ORDER = ['dr', 'fridge', 'residual', 'hvac','dw', 'mw']\n",
    "# ORDER = ORDER[::-1]\n",
    "out_train, out_valid, out_test = preprocess(train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Variable(torch.Tensor(train_aggregate), requires_grad=False)\n",
    "valid_inp = Variable(torch.Tensor(valid_aggregate), requires_grad=False)\n",
    "test_inp = Variable(torch.Tensor(test_aggregate), requires_grad=False)\n",
    "if cuda_av:\n",
    "    inp = inp.cuda()\n",
    "    valid_inp = valid_inp.cuda()\n",
    "    test_inp = test_inp.cuda()\n",
    "valid_out = torch.cat([out_valid[appliance_num] for appliance_num, appliance in enumerate(ORDER)])\n",
    "test_out = torch.cat([out_test[appliance_num] for appliance_num, appliance in enumerate(ORDER)])\n",
    "train_out = torch.cat([out_train[appliance_num] for appliance_num, appliance in enumerate(ORDER)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CNN\n",
      "use RNN\n",
      "use CNN\n",
      "use CNN\n",
      "use CNN\n",
      "use CNN\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.L1Loss()\n",
    "model = AppliancesRNNCNN('GRU', 20, 1, True, len(ORDER))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "p=0\n",
    "params = [inp, p]\n",
    "\n",
    "if cuda_av:\n",
    "    model = model.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "    \n",
    "for a_num, appliance in enumerate(ORDER):\n",
    "    params.append(out_train[a_num])\n",
    "\n",
    "if cuda_av:\n",
    "    train_out = train_out.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 356.53350830078125 353.7862854003906\n",
      "1 356.2173156738281 353.4793701171875\n",
      "2 355.42779541015625 352.76739501953125\n",
      "3 353.56658935546875 350.8727722167969\n",
      "4 351.5331726074219 348.9730529785156\n",
      "5 348.5419921875 346.0857238769531\n",
      "6 344.98284912109375 342.6145935058594\n",
      "7 340.6120910644531 338.457275390625\n",
      "8 335.3240966796875 333.4629211425781\n",
      "9 329.1043395996094 327.7042236328125\n",
      "10 322.0245361328125 321.1148376464844\n",
      "11 314.0142517089844 313.6829528808594\n",
      "12 305.0313720703125 305.6879577636719\n",
      "13 294.9853820800781 296.5195007324219\n",
      "14 283.9573974609375 286.86285400390625\n",
      "15 271.9574890136719 276.2972106933594\n",
      "16 258.8981018066406 265.1287536621094\n",
      "17 245.2588653564453 253.56961059570312\n",
      "18 231.4821014404297 241.45162963867188\n",
      "19 217.8900146484375 232.70486450195312\n",
      "20 202.651611328125 219.9980926513672\n",
      "21 189.1016082763672 210.69100952148438\n",
      "22 178.68441772460938 205.0570831298828\n",
      "23 169.61044311523438 196.71958923339844\n",
      "24 158.74453735351562 192.4138946533203\n",
      "25 159.67337036132812 196.67942810058594\n",
      "26 158.25991821289062 192.72547912597656\n",
      "27 158.23240661621094 195.1161651611328\n",
      "28 157.30337524414062 195.46133422851562\n",
      "29 159.30633544921875 196.5474090576172\n",
      "30 161.61135864257812 200.46609497070312\n",
      "31 159.7186279296875 202.33358764648438\n",
      "32 160.62619018554688 201.08177185058594\n",
      "33 157.53536987304688 196.62588500976562\n",
      "34 156.23121643066406 193.88360595703125\n",
      "35 154.25779724121094 191.8399200439453\n",
      "36 151.28616333007812 190.05166625976562\n",
      "37 149.04356384277344 188.5301055908203\n",
      "38 148.2517852783203 187.3624267578125\n",
      "39 147.23165893554688 185.96087646484375\n",
      "40 146.39894104003906 184.81219482421875\n",
      "41 146.5077362060547 184.29466247558594\n",
      "42 146.50259399414062 183.55520629882812\n",
      "43 146.36099243164062 182.77964782714844\n",
      "44 146.33306884765625 182.49191284179688\n",
      "45 146.24229431152344 182.6036834716797\n",
      "46 146.01638793945312 182.72593688964844\n",
      "47 145.4604949951172 182.40737915039062\n",
      "48 144.93365478515625 181.8852996826172\n",
      "49 144.416259765625 181.70993041992188\n",
      "50 143.69223022460938 181.69039916992188\n",
      "51 143.30368041992188 181.51344299316406\n",
      "52 142.68869018554688 180.94219970703125\n",
      "53 142.28184509277344 180.72607421875\n",
      "54 141.98202514648438 180.8386688232422\n",
      "55 141.6707000732422 180.6107635498047\n",
      "56 141.49533081054688 180.4835968017578\n",
      "57 141.32275390625 180.66647338867188\n",
      "58 141.17555236816406 180.5304412841797\n",
      "59 140.9669189453125 179.78634643554688\n",
      "60 140.73428344726562 179.58282470703125\n",
      "61 140.57130432128906 179.93020629882812\n",
      "62 140.27757263183594 179.57521057128906\n",
      "63 140.0644073486328 179.32630920410156\n",
      "64 139.85671997070312 179.4372100830078\n",
      "65 139.54307556152344 178.78179931640625\n",
      "66 139.32766723632812 178.45553588867188\n",
      "67 139.1414794921875 178.52667236328125\n",
      "68 138.87156677246094 178.14337158203125\n",
      "69 138.70172119140625 178.06027221679688\n",
      "70 138.57901000976562 178.20046997070312\n",
      "71 138.36207580566406 177.60540771484375\n",
      "72 138.16079711914062 177.6104278564453\n",
      "73 137.94589233398438 177.0531005859375\n",
      "74 137.72776794433594 177.317626953125\n",
      "75 137.56365966796875 177.35025024414062\n",
      "76 137.51296997070312 177.70143127441406\n",
      "77 137.6652069091797 177.51400756835938\n",
      "78 137.97776794433594 178.05490112304688\n",
      "79 137.6181640625 177.09214782714844\n",
      "80 136.89378356933594 178.03253173828125\n",
      "81 136.53375244140625 177.12274169921875\n",
      "82 136.6292266845703 177.82325744628906\n",
      "83 136.491943359375 177.52334594726562\n",
      "84 135.8502960205078 176.6418914794922\n",
      "85 135.69680786132812 177.40997314453125\n",
      "86 135.90802001953125 176.79331970214844\n",
      "87 135.34339904785156 177.2467803955078\n",
      "88 134.77505493164062 176.6839141845703\n",
      "89 134.78890991210938 176.3387908935547\n",
      "90 135.01351928710938 177.6155548095703\n",
      "91 135.1253662109375 176.20901489257812\n",
      "92 134.68299865722656 177.30584716796875\n",
      "93 135.0202178955078 176.5430450439453\n",
      "94 135.2705535888672 177.79434204101562\n",
      "95 133.86598205566406 176.76341247558594\n",
      "96 133.28565979003906 176.33621215820312\n",
      "97 133.9467315673828 176.9567108154297\n",
      "98 133.66236877441406 176.248046875\n",
      "99 132.84774780273438 176.8926544189453\n",
      "100 132.7454071044922 175.84202575683594\n",
      "101 132.8376007080078 176.68605041503906\n",
      "102 132.4943084716797 175.8849334716797\n",
      "103 131.7797393798828 175.98081970214844\n",
      "104 131.6051788330078 176.131103515625\n",
      "105 131.93984985351562 175.5115203857422\n",
      "106 132.03518676757812 176.7493896484375\n",
      "107 131.9087371826172 175.10874938964844\n",
      "108 131.67724609375 177.14520263671875\n",
      "109 133.52577209472656 175.25889587402344\n",
      "110 134.8275909423828 179.25965881347656\n",
      "111 131.36004638671875 174.7264404296875\n",
      "112 131.16725158691406 174.7462158203125\n",
      "113 132.32643127441406 176.91563415527344\n",
      "114 130.08660888671875 174.5970916748047\n",
      "115 131.6141357421875 174.6816864013672\n",
      "116 129.9692840576172 174.82037353515625\n",
      "117 130.23292541503906 175.1884765625\n",
      "118 130.32603454589844 174.22669982910156\n",
      "119 128.95870971679688 173.98873901367188\n",
      "120 129.84768676757812 175.33920288085938\n",
      "121 129.09178161621094 173.76614379882812\n",
      "122 128.44094848632812 173.77188110351562\n",
      "123 129.14002990722656 174.85345458984375\n",
      "124 128.39822387695312 173.655029296875\n",
      "125 127.81462097167969 173.61053466796875\n",
      "126 128.29969787597656 174.1034393310547\n",
      "127 128.03977966308594 173.4871063232422\n",
      "128 127.3813705444336 173.02894592285156\n",
      "129 127.59265899658203 173.84559631347656\n",
      "130 128.45626831054688 172.90289306640625\n",
      "131 128.13702392578125 174.2315673828125\n",
      "132 127.79019927978516 172.91549682617188\n",
      "133 126.8913345336914 172.43505859375\n",
      "134 126.52090454101562 173.06361389160156\n",
      "135 126.94172668457031 172.4026641845703\n",
      "136 126.7001724243164 172.2303466796875\n",
      "137 125.91804504394531 172.7705535888672\n",
      "138 125.6879653930664 171.92623901367188\n",
      "139 126.1375961303711 172.14151000976562\n",
      "140 126.13285827636719 172.23739624023438\n",
      "141 125.3055191040039 172.27981567382812\n",
      "142 124.90180969238281 171.03993225097656\n",
      "143 124.9687271118164 172.03282165527344\n",
      "144 124.90177154541016 171.77659606933594\n",
      "145 124.563232421875 171.48809814453125\n",
      "146 124.14767456054688 171.66583251953125\n",
      "147 124.24470520019531 171.0061798095703\n",
      "148 124.96244049072266 172.8905029296875\n",
      "149 126.7215347290039 170.7919464111328\n",
      "150 126.97905731201172 175.0612030029297\n",
      "151 124.90725708007812 170.1743927001953\n",
      "152 123.79783630371094 169.54306030273438\n",
      "153 125.13752746582031 172.4349365234375\n",
      "154 123.69932556152344 170.33981323242188\n",
      "155 123.82660675048828 169.2623291015625\n",
      "156 124.07166290283203 171.0041961669922\n",
      "157 122.74188232421875 170.0617218017578\n",
      "158 123.3331298828125 169.32730102539062\n",
      "159 123.31781768798828 170.26089477539062\n",
      "160 121.91472625732422 169.2984161376953\n",
      "161 122.56395721435547 169.3936767578125\n",
      "162 122.6699447631836 170.09825134277344\n",
      "163 121.51187133789062 168.7722625732422\n",
      "164 121.75566101074219 169.3001251220703\n",
      "165 121.89071655273438 170.01336669921875\n",
      "166 121.26038360595703 167.81280517578125\n",
      "167 120.80697631835938 168.8603515625\n",
      "168 120.98181915283203 169.171875\n",
      "169 121.09113311767578 167.11129760742188\n",
      "170 120.38246154785156 168.58901977539062\n",
      "171 120.15574645996094 167.97512817382812\n",
      "172 120.29083251953125 167.08436584472656\n",
      "173 120.37145233154297 167.89791870117188\n",
      "174 120.18622589111328 167.6402587890625\n",
      "175 119.86055755615234 166.81568908691406\n",
      "176 119.84813690185547 167.4887237548828\n",
      "177 120.38843536376953 167.36668395996094\n",
      "178 119.80299377441406 168.14990234375\n",
      "179 119.09689331054688 165.7222442626953\n",
      "180 118.49747467041016 167.0159454345703\n",
      "181 118.58851623535156 167.3124542236328\n",
      "182 119.02750396728516 165.62393188476562\n",
      "183 119.14759063720703 167.55645751953125\n",
      "184 119.26215362548828 166.26348876953125\n",
      "185 118.33010864257812 166.25901794433594\n",
      "186 117.72286224365234 165.12730407714844\n",
      "187 117.49169921875 165.43910217285156\n",
      "188 117.81542205810547 166.90310668945312\n",
      "189 118.40766143798828 164.36514282226562\n",
      "190 118.2876205444336 167.5486297607422\n",
      "191 117.89286041259766 164.95851135253906\n",
      "192 117.3076400756836 165.46189880371094\n",
      "193 117.16368103027344 165.50413513183594\n",
      "194 116.92398071289062 164.60037231445312\n",
      "195 116.57128143310547 165.3348388671875\n",
      "196 116.6107406616211 164.3806915283203\n",
      "197 116.74515533447266 165.41087341308594\n",
      "198 116.51824951171875 164.01654052734375\n",
      "199 116.48501586914062 165.67514038085938\n",
      "200 116.664794921875 163.83615112304688\n",
      "201 117.88768005371094 165.94224548339844\n",
      "202 116.64733123779297 163.66152954101562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 115.60597229003906 164.70924377441406\n",
      "204 115.42169189453125 163.84463500976562\n",
      "205 115.7393798828125 163.34019470214844\n",
      "206 115.9096908569336 164.52859497070312\n",
      "207 115.24949645996094 163.5325927734375\n",
      "208 115.2028579711914 163.43043518066406\n",
      "209 115.15058135986328 163.7792510986328\n",
      "210 114.3879165649414 163.3711700439453\n",
      "211 114.74634552001953 163.30398559570312\n",
      "212 114.985107421875 164.57009887695312\n",
      "213 114.98713684082031 162.5987091064453\n",
      "214 116.33683776855469 165.52645874023438\n",
      "215 120.1762466430664 164.35398864746094\n",
      "216 116.69371032714844 165.865234375\n",
      "217 115.43893432617188 162.39918518066406\n",
      "218 116.84423828125 162.409912109375\n",
      "219 115.2407455444336 164.0355224609375\n",
      "220 115.86105346679688 164.0711669921875\n",
      "221 115.30908203125 161.02561950683594\n",
      "222 114.8773193359375 162.5868377685547\n",
      "223 115.3040771484375 164.44876098632812\n",
      "224 114.22193145751953 162.02731323242188\n",
      "225 114.61346435546875 162.76487731933594\n",
      "226 113.82917022705078 162.8697967529297\n",
      "227 113.8672866821289 162.60992431640625\n",
      "228 114.41226959228516 163.56491088867188\n",
      "229 113.7059097290039 162.1894989013672\n",
      "230 113.00672149658203 162.4383087158203\n",
      "231 113.49116516113281 161.90106201171875\n",
      "232 112.93891906738281 161.27874755859375\n",
      "233 112.74372863769531 162.29901123046875\n",
      "234 113.16986846923828 161.31304931640625\n",
      "235 112.55718994140625 161.74090576171875\n",
      "236 112.3985595703125 160.85691833496094\n",
      "237 112.58435821533203 162.15914916992188\n",
      "238 112.5263442993164 160.51278686523438\n",
      "239 112.67622375488281 162.29385375976562\n",
      "240 113.61666870117188 160.6682891845703\n",
      "241 113.65733337402344 163.2207794189453\n",
      "242 112.68228912353516 160.0152587890625\n",
      "243 111.75365447998047 160.98193359375\n",
      "244 111.98261260986328 161.35533142089844\n",
      "245 112.15509796142578 159.83058166503906\n",
      "246 112.32669067382812 161.7805938720703\n",
      "247 111.59504699707031 160.35935974121094\n",
      "248 111.26548767089844 160.67855834960938\n",
      "249 111.26775360107422 160.70114135742188\n",
      "250 111.45756530761719 160.1949462890625\n",
      "251 111.55403137207031 161.35577392578125\n",
      "252 111.0754623413086 160.22821044921875\n",
      "253 110.87833404541016 160.5002899169922\n",
      "254 110.7855224609375 159.43592834472656\n",
      "255 110.96623229980469 161.1871337890625\n",
      "256 111.43294525146484 158.9355010986328\n",
      "257 113.01008605957031 161.92666625976562\n",
      "258 115.06525421142578 160.64633178710938\n",
      "259 112.28880310058594 162.15396118164062\n",
      "260 112.20022583007812 159.3804473876953\n",
      "261 111.9845199584961 158.03672790527344\n",
      "262 112.11668395996094 161.11041259765625\n",
      "263 110.98265838623047 160.15875244140625\n",
      "264 111.8140869140625 158.2621307373047\n",
      "265 111.48976135253906 159.7006072998047\n",
      "266 110.82237243652344 159.45616149902344\n",
      "267 110.67239379882812 159.48675537109375\n",
      "268 110.97402954101562 160.5067138671875\n",
      "269 111.14173126220703 159.0200653076172\n",
      "270 109.89749908447266 159.2364501953125\n",
      "271 110.60357666015625 159.78097534179688\n",
      "272 110.45018005371094 159.3438262939453\n",
      "273 110.35611724853516 160.1507110595703\n",
      "274 109.90853881835938 157.79910278320312\n",
      "275 109.32992553710938 158.58450317382812\n",
      "276 109.76818084716797 160.18698120117188\n",
      "277 109.75210571289062 157.76263427734375\n",
      "278 110.0385971069336 159.29734802246094\n",
      "279 110.1300277709961 158.23959350585938\n",
      "280 109.35812377929688 159.5257110595703\n",
      "281 109.4703598022461 157.4450225830078\n",
      "282 108.67572784423828 158.3608856201172\n",
      "283 108.82979583740234 158.479736328125\n",
      "284 109.06044006347656 157.34857177734375\n",
      "285 108.70236206054688 158.59829711914062\n",
      "286 109.11640930175781 158.33013916015625\n",
      "287 108.73283386230469 158.5818328857422\n",
      "288 108.84807586669922 157.18748474121094\n",
      "289 110.0668716430664 160.57546997070312\n",
      "290 110.60201263427734 156.93568420410156\n",
      "291 110.23487854003906 158.81988525390625\n",
      "292 109.20589447021484 157.5092315673828\n",
      "293 108.32856750488281 157.41156005859375\n",
      "294 109.82420349121094 158.6927032470703\n",
      "295 109.16864013671875 156.7056121826172\n",
      "296 108.8897705078125 158.3108367919922\n",
      "297 108.1028060913086 157.23385620117188\n",
      "298 108.48294067382812 157.26083374023438\n",
      "299 108.7613525390625 159.40542602539062\n",
      "300 107.95362854003906 157.3114471435547\n",
      "301 107.93438720703125 156.96102905273438\n",
      "302 107.99315643310547 158.18310546875\n",
      "303 108.3615493774414 157.4145050048828\n",
      "304 107.6654052734375 156.79315185546875\n",
      "305 107.46128845214844 156.43841552734375\n",
      "306 107.25686645507812 157.44114685058594\n",
      "307 106.99903106689453 157.22683715820312\n",
      "308 107.22911834716797 156.126708984375\n",
      "309 107.47622680664062 158.11402893066406\n",
      "310 107.51986694335938 156.54019165039062\n",
      "311 106.94507598876953 156.564453125\n",
      "312 106.81654357910156 155.75440979003906\n",
      "313 107.22525787353516 157.82957458496094\n",
      "314 107.89720916748047 155.66390991210938\n",
      "315 107.43360137939453 156.476806640625\n",
      "316 107.27825164794922 157.22637939453125\n",
      "317 106.6092300415039 157.15924072265625\n",
      "318 106.58976745605469 155.20626831054688\n",
      "319 106.8438720703125 156.26051330566406\n",
      "320 107.27318572998047 157.42794799804688\n",
      "321 106.28632354736328 154.91400146484375\n",
      "322 106.47880554199219 155.43067932128906\n",
      "323 106.4205322265625 156.0540313720703\n",
      "324 106.24938201904297 157.0205535888672\n",
      "325 106.42664337158203 154.4117889404297\n",
      "326 106.9814453125 155.7193145751953\n",
      "327 106.81124114990234 154.6110382080078\n",
      "328 107.12033081054688 157.3008270263672\n",
      "329 106.6689224243164 154.1979522705078\n",
      "330 105.5283432006836 155.16815185546875\n",
      "331 105.60377502441406 155.5081787109375\n",
      "332 105.51331329345703 154.39166259765625\n",
      "333 105.60691833496094 155.2434844970703\n",
      "334 106.17046356201172 154.390625\n",
      "335 105.86963653564453 156.4111785888672\n",
      "336 105.80376434326172 154.1281280517578\n",
      "337 105.52167510986328 155.77285766601562\n",
      "338 104.87228393554688 154.27403259277344\n",
      "339 104.7154769897461 153.95469665527344\n",
      "340 105.08452606201172 155.4012451171875\n",
      "341 105.15021514892578 153.3316192626953\n",
      "342 105.07843017578125 154.6845703125\n",
      "343 105.3446273803711 153.48519897460938\n",
      "344 105.13326263427734 155.7080078125\n",
      "345 104.6468276977539 154.08900451660156\n",
      "346 104.19003295898438 154.36300659179688\n",
      "347 103.89373779296875 153.7701873779297\n",
      "348 103.86466979980469 153.9851531982422\n",
      "349 103.99713897705078 154.1817626953125\n",
      "350 104.78632354736328 152.60397338867188\n",
      "351 105.57181549072266 155.82791137695312\n",
      "352 105.14814758300781 153.29920959472656\n",
      "353 103.85155487060547 153.5181121826172\n",
      "354 103.96150970458984 153.72276306152344\n",
      "355 104.0014877319336 153.0567169189453\n",
      "356 103.82267761230469 153.2786407470703\n",
      "357 103.6684341430664 152.91012573242188\n",
      "358 103.22279357910156 152.38626098632812\n",
      "359 103.0548324584961 153.6531524658203\n",
      "360 103.32476806640625 152.93922424316406\n",
      "361 104.05685424804688 154.3807830810547\n",
      "362 105.81504821777344 153.06307983398438\n",
      "363 104.81599426269531 154.96925354003906\n",
      "364 103.33167266845703 151.4689483642578\n",
      "365 103.39716339111328 151.88278198242188\n",
      "366 104.27216339111328 154.26382446289062\n",
      "367 103.92203521728516 152.48895263671875\n",
      "368 102.54527282714844 151.39747619628906\n",
      "369 103.23615264892578 152.62855529785156\n",
      "370 104.2414321899414 152.9336395263672\n",
      "371 103.53722381591797 153.96847534179688\n",
      "372 102.61614990234375 151.37120056152344\n",
      "373 102.5824966430664 151.7755126953125\n",
      "374 102.8515853881836 153.48497009277344\n",
      "375 102.28021240234375 151.6697998046875\n",
      "376 102.37334442138672 151.42642211914062\n",
      "377 102.3117446899414 152.1641082763672\n",
      "378 102.06202697753906 151.510009765625\n",
      "379 102.05926513671875 151.46810913085938\n",
      "380 102.41356658935547 152.1092071533203\n",
      "381 101.77407836914062 151.47999572753906\n",
      "382 101.5125961303711 151.37322998046875\n",
      "383 101.50155639648438 152.29917907714844\n",
      "384 101.49945068359375 150.23550415039062\n",
      "385 101.206787109375 151.2406463623047\n",
      "386 101.15355682373047 151.46148681640625\n",
      "387 101.52891540527344 151.33355712890625\n",
      "388 102.15044403076172 150.73382568359375\n",
      "389 102.99455261230469 152.5784149169922\n",
      "390 103.51737213134766 151.08265686035156\n",
      "391 101.50525665283203 151.48489379882812\n",
      "392 101.47492980957031 150.41476440429688\n",
      "393 102.08419799804688 151.7800750732422\n",
      "394 101.24148559570312 152.15451049804688\n",
      "395 101.39124298095703 149.25408935546875\n",
      "396 100.88118743896484 149.56991577148438\n",
      "397 100.97219848632812 153.05181884765625\n",
      "398 100.4948501586914 150.65618896484375\n",
      "399 100.28223419189453 149.97735595703125\n",
      "400 100.04094696044922 149.9857177734375\n",
      "401 100.08680725097656 150.84661865234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 99.70196533203125 149.62692260742188\n",
      "403 99.84529113769531 149.68084716796875\n",
      "404 99.65336608886719 149.87203979492188\n",
      "405 99.86654663085938 150.3488311767578\n",
      "406 99.94713592529297 149.07882690429688\n",
      "407 101.20326232910156 151.19773864746094\n",
      "408 102.9233169555664 150.15530395507812\n",
      "409 102.68289184570312 153.7037811279297\n",
      "410 100.19425201416016 149.29299926757812\n",
      "411 100.9339599609375 148.52830505371094\n",
      "412 101.40205383300781 150.79052734375\n",
      "413 100.24263763427734 151.31581115722656\n",
      "414 99.5019302368164 149.0958709716797\n",
      "415 101.22799682617188 149.94544982910156\n",
      "416 100.7734603881836 149.63890075683594\n",
      "417 99.52188110351562 151.50094604492188\n",
      "418 99.18094635009766 148.97923278808594\n",
      "419 100.14832305908203 148.51251220703125\n",
      "420 99.7710952758789 151.5628662109375\n",
      "421 98.95411682128906 150.38671875\n",
      "422 99.25357055664062 147.968505859375\n",
      "423 99.84656524658203 149.27813720703125\n",
      "424 99.20154571533203 150.22215270996094\n",
      "425 99.04293823242188 149.89930725097656\n",
      "426 98.74388885498047 148.91448974609375\n",
      "427 99.12374114990234 148.75189208984375\n",
      "428 98.97480010986328 151.11520385742188\n",
      "429 98.77617645263672 151.22396850585938\n",
      "430 98.9125747680664 148.63279724121094\n",
      "431 98.37714385986328 148.88790893554688\n",
      "432 98.63191986083984 149.78955078125\n",
      "433 98.52284240722656 150.5191192626953\n",
      "434 98.65846252441406 148.1136016845703\n",
      "435 98.47911834716797 149.03770446777344\n",
      "436 98.58683776855469 151.05563354492188\n",
      "437 98.18537139892578 150.1981964111328\n",
      "438 98.68868255615234 147.5582275390625\n",
      "439 99.15177154541016 150.24510192871094\n",
      "440 100.2749252319336 150.3613739013672\n",
      "441 98.96990203857422 150.47711181640625\n",
      "442 98.45989227294922 147.9529266357422\n",
      "443 98.29234313964844 148.3662872314453\n",
      "444 99.24422454833984 151.28993225097656\n",
      "445 99.55366516113281 149.43283081054688\n",
      "446 98.47984313964844 148.74339294433594\n",
      "447 98.13116455078125 148.52687072753906\n",
      "448 98.07625579833984 150.07449340820312\n",
      "449 98.32649993896484 150.46548461914062\n",
      "450 98.15742492675781 149.13796997070312\n",
      "451 98.38961029052734 149.9072723388672\n",
      "452 98.63284301757812 148.2635498046875\n",
      "453 98.15620422363281 149.6632537841797\n",
      "454 98.11393737792969 149.1464080810547\n",
      "455 98.14815521240234 149.32342529296875\n",
      "456 98.06853485107422 149.0153350830078\n",
      "457 98.61345672607422 149.21502685546875\n",
      "458 98.12721252441406 149.36216735839844\n",
      "459 98.3109130859375 149.25584411621094\n",
      "460 98.18598175048828 148.76779174804688\n",
      "461 98.56346130371094 152.62075805664062\n",
      "462 98.56661224365234 149.19664001464844\n",
      "463 98.54047393798828 149.13743591308594\n",
      "464 98.50370788574219 148.8394012451172\n",
      "465 98.33206176757812 150.86058044433594\n",
      "466 98.1070785522461 149.3282928466797\n",
      "467 97.61184692382812 148.38539123535156\n",
      "468 98.25404357910156 149.65744018554688\n",
      "469 98.8805160522461 149.63661193847656\n",
      "470 98.8351821899414 150.94802856445312\n",
      "471 98.65992736816406 148.32749938964844\n",
      "472 98.94898986816406 150.263671875\n",
      "473 97.75245666503906 148.76583862304688\n",
      "474 97.9368667602539 148.78836059570312\n",
      "475 97.94234466552734 150.06185913085938\n",
      "476 98.03746032714844 149.17648315429688\n",
      "477 97.76144409179688 149.49107360839844\n",
      "478 98.32142639160156 149.19850158691406\n",
      "479 98.12682342529297 151.68618774414062\n",
      "480 97.5134048461914 149.91575622558594\n",
      "481 97.8194580078125 148.82395935058594\n",
      "482 97.33086395263672 149.0509033203125\n",
      "483 97.50181579589844 151.26466369628906\n",
      "484 97.4090805053711 148.49073791503906\n",
      "485 97.82349395751953 148.16461181640625\n",
      "486 98.6241683959961 151.52403259277344\n",
      "487 98.59945678710938 149.53321838378906\n",
      "488 98.61638641357422 149.30348205566406\n",
      "489 98.3673324584961 149.5391387939453\n",
      "490 98.06724548339844 150.51412963867188\n",
      "491 97.9128646850586 148.14208984375\n",
      "492 98.11443328857422 148.5877227783203\n",
      "493 97.57083892822266 149.9697265625\n",
      "494 97.60625457763672 150.16973876953125\n",
      "495 98.09822845458984 150.08187866210938\n",
      "496 98.69137573242188 148.04075622558594\n",
      "497 98.21146392822266 150.4073028564453\n",
      "498 97.94368743896484 150.33746337890625\n",
      "499 97.45256042480469 148.89035034179688\n"
     ]
    }
   ],
   "source": [
    "for k in range(500):\n",
    "    pred = model(*params)\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_func(pred, train_out)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cuda_av:\n",
    "        test_inp = test_inp.cuda()\n",
    "    test_params = [test_inp, -2]\n",
    "    for i in range(len(ORDER)):\n",
    "        test_params.append(None)\n",
    "    test_pr = model(*test_params)\n",
    "    test_loss = loss_func(test_pr, test_out)\n",
    "    \n",
    "    print(k, loss.data[0], test_loss.data[0])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "from dataloader import get_train_test\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = torch.split(test_pr, test_aggregate.shape[0])\n",
    "test_fold = [None for x in range(len(ORDER))]\n",
    "if cuda_av:\n",
    "    for appliance_num, appliance in enumerate(ORDER):\n",
    "        test_fold[appliance_num] = test_pred[appliance_num].cpu().data.numpy().reshape(-1, 24)\n",
    "else:\n",
    "    for appliance_num, appliance in enumerate(ORDER):\n",
    "        test_fold[appliance_num] = test_pred[appliance_num].data.numpy().reshape(-1, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dr\n",
      "1 fridge\n",
      "2 residual\n",
      "3 hvac\n",
      "4 dw\n",
      "5 mw\n"
     ]
    }
   ],
   "source": [
    "test_gt_fold = [None for x in range(len(ORDER))]\n",
    "for appliance_num, appliance in enumerate(ORDER):\n",
    "    print(appliance_num, appliance)\n",
    "    test_gt_fold[appliance_num] = test[:, APPLIANCE_ORDER.index(appliance), :, :].reshape(\n",
    "        test_aggregate.shape[0],\n",
    "        -1, 1).reshape(-1, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_error = {}\n",
    "\n",
    "for appliance_num, appliance in enumerate(ORDER):\n",
    "    test_error[appliance] = mean_absolute_error(test_fold[appliance_num], test_gt_fold[appliance_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dr': 83.073210074429525,\n",
       " 'dw': 20.602055528907556,\n",
       " 'fridge': 31.841900517104573,\n",
       " 'hvac': 376.0803000773746,\n",
       " 'mw': 5.6529535734487624,\n",
       " 'residual': 376.09168160878897}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dr': 83.052269430245204,\n",
       " 'dw': 20.612454579551606,\n",
       " 'fridge': 31.649631276178969,\n",
       " 'hvac': 385.0988294568254,\n",
       " 'mw': 5.8155400524336569,\n",
       " 'residual': 383.32513222150027}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.load(\"../code/cnn_rnn_residual.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 24)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_aggregate[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ORDER.index('hvac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  633.29998779,   613.29998779,   716.18334961, ...,\n",
       "         1667.91662598,  1549.68334961,  3645.56665039],\n",
       "       [ 4170.31689453,  2615.81665039,   844.7333374 , ...,\n",
       "         1723.06665039,  1663.06665039,  1387.51672363],\n",
       "       [ 1038.93334961,   846.20001221,   870.31665039, ...,\n",
       "         1453.61669922,   904.09997559,   670.5166626 ],\n",
       "       ..., \n",
       "       [  500.45001221,  6888.36669922,  1832.34997559, ...,\n",
       "         1055.94995117,   838.88336182,   813.61663818],\n",
       "       [  372.33334351,   398.2833252 ,   230.08332825, ...,\n",
       "          451.91665649,   827.36663818,   815.88336182],\n",
       "       [  555.56665039,  6924.66650391,  3580.88330078, ...,\n",
       "          572.93334961,   903.61663818,   750.13336182]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gt_fold[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07750428,  0.08671144,  0.10246564, ...,  0.13023974,\n",
       "         0.08273464,  0.10448182],\n",
       "       [ 0.05899549,  0.05223992,  0.11015422, ...,  0.07455975,\n",
       "         0.01972076,  0.13222013],\n",
       "       [ 0.08781143,  0.0728396 ,  0.10689173, ...,  0.15625095,\n",
       "         0.06789164,  0.12791415],\n",
       "       ..., \n",
       "       [ 0.1494118 ,  0.04695046,  0.25481755, ...,  0.09123659,\n",
       "         0.04654347,  0.16041394],\n",
       "       [ 0.06217813,  0.03337047,  0.08406292, ...,  0.12789235,\n",
       "         0.06969883,  0.13166392],\n",
       "       [ 0.09288365,  0.06897522,  0.13209109, ...,  0.09046839,\n",
       "         0.03694388,  0.12192314]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fold[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6b852f89aa22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhome_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhome_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gt_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhome_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_aggregate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhome_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'reshape'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABaAAAANSCAYAAACTKmngAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAgCEU0AAAAAAADKGABgAAAABgiP8P8g2cyIiaSgUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd009446e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(ncols=3, nrows = 4, figsize=(25, 15))\n",
    "ax = axes.flatten()\n",
    "homes = [0, 4, 8, 12]\n",
    "appliance = 'dr'\n",
    "idx = ORDER.index(appliance)\n",
    "fold_num = 0\n",
    "\n",
    "for i, home_id in enumerate(homes):\n",
    "    sns.heatmap(pred[idx].reshape(-1, 112, 24)[home_id], ax=ax[i*3], cmap='Greens')\n",
    "    sns.heatmap(test_gt_fold[idx].reshape(-1 ,112, 24)[home_id], ax=ax[i*3+1], cmap='Greens')\n",
    "    sns.heatmap(test_aggregate[home_id][0], ax=ax[i*3+2], cmap='Greens')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
